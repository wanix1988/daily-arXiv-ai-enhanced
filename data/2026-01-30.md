<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 79]
- [cs.CL](#cs.CL) [Total: 54]
- [cs.AR](#cs.AR) [Total: 1]
- [cs.AI](#cs.AI) [Total: 64]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Non-Markov Multi-Round Conversational Image Generation with History-Conditioned MLLMs](https://arxiv.org/abs/2601.20911)
*Haochen Zhang,Animesh Sinha,Felix Juefei-Xu,Haoyu Ma,Kunpeng Li,Zhipeng Fan,Meng Dong,Xiaoliang Dai,Tingbo Hou,Peizhao Zhang,Zecheng He*

Main category: cs.CV

TL;DR: 本文通过提出非马尔可夫多轮数据构建策略、历史条件下的训练与推理框架以及增强高保真图像重建和可编辑个性化的技术，解决了对话图像生成中的长期历史依赖问题，提升了多轮一致性和指令遵从性。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大型语言模型在多轮生成中倾向于依赖最近的历史，而忽视了长期的历史依赖。本文旨在解决这一问题，使模型能更好地处理用户回溯、撤销操作以及跨多轮引用实体。

Method: 本文采用了回滚式的编辑策略和基于名称的多轮个性化方法来强制模型检索早期的视觉状态和保持名称与形象的一致性。同时，提出了一个基于token级别的缓存的历史条件下的训练与推理框架，以防止多轮次中的身份漂移。

Result: 通过上述方法，本文在多轮次中实现了更强的一致性、更高的指令遵从性、更高质量的图像重建以及更好的可编辑个性化。

Conclusion: 本研究通过增强模型对多轮次历史信息的依赖能力，显著改善了对话图像生成的质量和交互体验。

Abstract: Conversational image generation requires a model to follow user instructions across multiple rounds of interaction, grounded in interleaved text and images that accumulate as chat history. While recent multimodal large language models (MLLMs) can generate and edit images, most existing multi-turn benchmarks and training recipes are effectively Markov: the next output depends primarily on the most recent image, enabling shortcut solutions that ignore long-range history. In this work we formalize and target the more challenging non-Markov setting, where a user may refer back to earlier states, undo changes, or reference entities introduced several rounds ago. We present (i) non-Markov multi-round data construction strategies, including rollback-style editing that forces retrieval of earlier visual states and name-based multi-round personalization that binds names to appearances across rounds; (ii) a history-conditioned training and inference framework with token-level caching to prevent multi-round identity drift; and (iii) enabling improvements for high-fidelity image reconstruction and editable personalization, including a reconstruction-based DiT detokenizer and a multi-stage fine-tuning curriculum. We demonstrate that explicitly training for non-Markov interactions yields substantial improvements in multi-round consistency and instruction compliance, while maintaining strong single-round editing and personalization.

</details>


### [2] [Text controllable PET denoising](https://arxiv.org/abs/2601.20990)
*Xuehua Ye,Hongxu Yang,Adam J. Schwarz*

Main category: cs.CV

TL;DR: 提出了一个基于文本引导的降噪方法，能够在单一模型中提升不同计数水平的PET图像质量。


<details>
  <summary>Details</summary>
Motivation: PET图像由于各种因素的影响，常常存在噪声问题，影响诊断信息的准确性。

Method: 利用预训练CLIP模型的特征与U-Net降噪模型相结合的方法。

Result: 实验结果显示，该模型在定性和定量评估中均取得了显著改进。

Conclusion: 该模型具有高度灵活性，适用于复杂的降噪需求或者缩短采集时间。

Abstract: Positron Emission Tomography (PET) imaging is a vital tool in medical diagnostics, offering detailed insights into molecular processes within the human body. However, PET images often suffer from complicated noise, which can obscure critical diagnostic information. The quality of the PET image is impacted by various factors including scanner hardware, image reconstruction, tracer properties, dose/count level, and acquisition time. In this study, we propose a novel text-guided denoising method capable of enhancing PET images across a wide range of count levels within a single model. The model utilized the features from a pretrained CLIP model with a U-Net based denoising model. Experimental results demonstrate that the proposed model leads significant improvements in both qualitative and quantitative assessments. The flexibility of the model shows the potential for helping more complicated denoising demands or reducing the acquisition time.

</details>


### [3] [Low performing pixel correction in computed tomography with unrolled network and synthetic data training](https://arxiv.org/abs/2601.20995)
*Hongxu Yang,Levente Lippenszky,Edina Timko,Lehel Ferenczi,Gopal Avinash*

Main category: cs.CV

TL;DR: 本文提出了一种基于合成数据的双域退卷积方法，用于修正CT探测器中的低性能像素（LPP）伪影，实验中该方法在模拟1-2%的探测器故障情况下表现优于现有方法，且无需依赖昂贵的现实世界临床数据。


<details>
  <summary>Details</summary>
Motivation: 现有的LPP矫正方法需要专用的数据集进行训练，成本高昂，同时这些方法仅关注单一领域（图像域或原始数据域）矫正，没有充分利用CT几何的内在联系。本文通过使用合成数据，利用图像域和原始数据域之间的内在联系来解决此问题。

Method: 该方法使用合成数据从自然图像生成，通过退卷积技术（Unrolled Dual-Domain Method），在图像域和原始数据域之间进行交互操作，矫正LPP伪影。

Result: 实验证明，在1-2%探测器故障的模拟情况下，本文方法优于现有多数方法。表明所提出的解决方案无需收集现实世界训练数据，且适用于不同CT扫描设置的软件应用。

Conclusion: 综上所述，本文通过提出一个基于合成数据的双域退卷积方法，解决了现有LPP矫正方法的不足，为CT图像质量的提升提供了新的思路。

Abstract: Low performance pixels (LPP) in Computed Tomography (CT) detectors would lead to ring and streak artifacts in the reconstructed images, making them clinically unusable. In recent years, several solutions have been proposed to correct LPP artifacts, either in the image domain or in the sinogram domain using supervised deep learning methods. However, these methods require dedicated datasets for training, which are expensive to collect. Moreover, existing approaches focus solely either on image-space or sinogram-space correction, ignoring the intrinsic correlations from the forward operation of the CT geometry. In this work, we propose an unrolled dual-domain method based on synthetic data to correct LPP artifacts. Specifically, the intrinsic correlations of LPP between the sinogram and image domains are leveraged through synthetic data generated from natural images, enabling the trained model to correct artifacts without requiring any real-world clinical data. In experiments simulating 1-2% detectors defect near the isocenter, the proposed method outperformed the state-of-the-art approaches by a large margin. The results indicate that our solution can correct LPP artifacts without the cost of data collection for model training, and it is adaptable to different scanner settings for software-based applications.

</details>


### [4] [AI-based Prediction of Biochemical Recurrence from Biopsy and Prostatectomy Samples](https://arxiv.org/abs/2601.21022)
*Andrea Camilloni,Chiara Micoli,Nita Mulliqi,Erik Everett Palm,Thorgerdur Palsdottir,Kelvin Szolnoky,Xiaoyi Ji,Sol Erika Boman,Andrea Discacciati,Henrik Grönberg,Lars Egevad,Tobias Nordström,Kimmo Kartasalo,Martin Eklund*

Main category: cs.CV

TL;DR: 这篇论文训练了一个基于图像的AI模型来预测前列腺癌根治术后复发风险，模型在多个外部队列中都显示了较好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 目前的预后工具对于预测术后生物化学复发（BCR）的精确度不够高，因此开发一个更准确的预测模型是必要的。

Method: 使用基础模型和注意力机制的多种实例学习方法训练了一个基于活检切片的AI模型，外部验证了该模型。

Result: 模型在5年的时依AUC值分别为0.64、0.70和0.70，临床变量的整合提高了其预测价值。

Conclusion: 虽然AI模型在术后预后评估方面相较于指南有更好的表现，但它与其他预测模型相比的优势需要进一步验证。

Abstract: Biochemical recurrence (BCR) after radical prostatectomy (RP) is a surrogate marker for aggressive prostate cancer with adverse outcomes, yet current prognostic tools remain imprecise. We trained an AI-based model on diagnostic prostate biopsy slides from the STHLM3 cohort (n = 676) to predict patient-specific risk of BCR, using foundation models and attention-based multiple instance learning. Generalizability was assessed across three external RP cohorts: LEOPARD (n = 508), CHIMERA (n = 95), and TCGA-PRAD (n = 379). The image-based approach achieved 5-year time-dependent AUCs of 0.64, 0.70, and 0.70, respectively. Integrating clinical variables added complementary prognostic value and enabled statistically significant risk stratification. Compared with guideline-based CAPRA-S, AI incrementally improved postoperative prognostication. These findings suggest biopsy-trained histopathology AI can generalize across specimen types to support preoperative and postoperative decision making, but the added value of AI-based multimodal approaches over simpler predictive models should be critically scrutinized in further studies.

</details>


### [5] [BadDet+: Robust Backdoor Attacks for Object Detection](https://arxiv.org/abs/2601.21066)
*Kealan Dunnett,Reza Arablouei,Dimity Miller,Volkan Dedeoglu,Raja Jurdak*

Main category: cs.CV

TL;DR: 该研究引入了BadDet+框架，针对目标检测领域的后门攻击，通过引入基于惩罚的机制，实现了位置和尺度不变性，并增强了物理鲁棒性。实验证明，BadDet+在保持无触发状态下正常性能的前提下，比现有的基于区域误分类攻击和目标消失攻击的方法在实际环境中的转移性能更优。


<details>
  <summary>Details</summary>
Motivation: 目前对于目标检测中的后门攻击研究不足，且现有方法存在理想化的假设和缺乏物理验证的弱点。为了填补这一空白，研究引入BadDet+框架，旨在提升后门攻击在物体检测中的物理鲁棒性。

Method: BadDet+框架通过引入一种基于log-barrier惩罚的机制，抑制触发输入下的真类预测，以此实现位置和尺度不变性及增强物理鲁棒性。

Result: 在真实基准测试中，BadDet+相比现有的基于区域误分类攻击和目标消失攻击的方法在物理转移性能方面表现更佳，同时保留了在无触发状态下的正常性能。

Conclusion: 研究结果揭示了物体检测中的显著漏洞，并强调了专门防御措施的必要性。

Abstract: Backdoor attacks pose a severe threat to deep learning, yet their impact on object detection remains poorly understood compared to image classification. While attacks have been proposed, we identify critical weaknesses in existing detection-based methods, specifically their reliance on unrealistic assumptions and a lack of physical validation. To bridge this gap, we introduce BadDet+, a penalty-based framework that unifies Region Misclassification Attacks (RMA) and Object Disappearance Attacks (ODA). The core mechanism utilizes a log-barrier penalty to suppress true-class predictions for triggered inputs, resulting in (i) position and scale invariance, and (ii) enhanced physical robustness. On real-world benchmarks, BadDet+ achieves superior synthetic-to-physical transfer compared to existing RMA and ODA baselines while preserving clean performance. Theoretical analysis confirms the proposed penalty acts within a trigger-specific feature subspace, reliably inducing attacks without degrading standard inference. These results highlight significant vulnerabilities in object detection and the necessity for specialized defenses.

</details>


### [6] [Towards Mitigating Modality Bias in Vision-Language Models for Temporal Action Localization](https://arxiv.org/abs/2601.21078)
*Jiaqi Li,Guangming Wang,Shuntian Zheng,Minzhe Ni,Xiaoman Lu,Guanghui Ye,Yu Guan*

Main category: cs.CV

TL;DR: 本文提出了一种新的视觉-语言聚合框架ActionVLM，该框架通过使用去偏差重新加权模块和残差聚合策略来系统地减轻动作定位中的模态偏见。


<details>
  <summary>Details</summary>
Motivation: 现有动作定位方法倾向于过度强调语言先验，而忽视视觉性能，导致语言模态相对于视觉模态的偏见。

Method: ActionVLM框架包括两个创新点：去偏差重新加权模块和残差聚合策略。去偏差重新加权模块用于估计语言相对于仅使用视觉预测的加权优势，并根据此动态调整语言模态的权重。残差聚合策略将语言视为补充细化而非主要驱动。

Result: 在THUMOS14数据集上的实验表明，该模型的表现优于当前最先进的方法，提高了高达3.2%的mAP。

Conclusion: 该工作通过系统减轻模态偏见，减轻了语言先验的过度自信，并增强了时间推理，从而提高了动作定位的性能。

Abstract: Temporal Action Localization (TAL) requires identifying both the boundaries and categories of actions in untrimmed videos. While vision-language models (VLMs) offer rich semantics to complement visual evidence, existing approaches tend to overemphasize linguistic priors at the expense of visual performance, leading to a pronounced modality bias. We propose ActionVLM, a vision-language aggregation framework that systematically mitigates modality bias in TAL. Our key insight is to preserve vision as the dominant signal while adaptively exploiting language only when beneficial. To this end, we introduce (i) a debiasing reweighting module that estimates the language advantage-the incremental benefit of language over vision-only predictions-and dynamically reweights language modality accordingly, and (ii) a residual aggregation strategy that treats language as a complementary refinement rather than the primary driver. This combination alleviates modality bias, reduces overconfidence from linguistic priors, and strengthens temporal reasoning. Experiments on THUMOS14 show that our model outperforms state-of-the-art by up to 3.2% mAP.

</details>


### [7] [Shape of Thought: Progressive Object Assembly via Visual Chain-of-Thought](https://arxiv.org/abs/2601.21081)
*Yu Huo,Siyu Zhang,Kun Zeng,Haoyue Liu,Owen Lee,Junlin Chen,Yuquan Lu,Yifu Guo,Yaodong Liang,Xiaoying Tang*

Main category: cs.CV

TL;DR: Shape-of-Thought (SoT) 提出了一个视觉CoT框架，通过一致的2D投影逐步构建形状，无需外部引擎即可在推理时进行装配。SoT 基于大型数据集 SoT-26K 和 T2S-CompBench 进行训练和评估，显示出在组件数理和结构拓扑方面的显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 当前的多模态模型虽然在文本到图像生成方面取得了视觉保真的成功，但在组合结构约束下的生成能力仍然较弱，特别是在生成数量敏感性、属性结合及部分关系方面。

Method: SoT 训练了一个统一的多模态自回归模型，生成交错的文字规划和渲染中间状态，以便捕捉形状装配逻辑，而不是生成显式的几何表示。同时引入了 SoT-26K 数据集和 T2S-CompBench 基准作为训练和评估工具。

Result: SoT 在组件数理和结构拓扑方面分别达到了 88.4% 和 84.8% 的性能，超过了纯文本基线约 20%。

Conclusion: SoT 为透明、过程监督的组合生成设定了新标准。

Abstract: Multimodal models for text-to-image generation have achieved strong visual fidelity, yet they remain brittle under compositional structural constraints-notably generative numeracy, attribute binding, and part-level relations. To address these challenges, we propose Shape-of-Thought (SoT), a visual CoT framework that enables progressive shape assembly via coherent 2D projections without external engines at inference time. SoT trains a unified multimodal autoregressive model to generate interleaved textual plans and rendered intermediate states, helping the model capture shape-assembly logic without producing explicit geometric representations. To support this paradigm, we introduce SoT-26K, a large-scale dataset of grounded assembly traces derived from part-based CAD hierarchies, and T2S-CompBench, a benchmark for evaluating structural integrity and trace faithfulness. Fine-tuning on SoT-26K achieves 88.4% on component numeracy and 84.8% on structural topology, outperforming text-only baselines by around 20%. SoT establishes a new paradigm for transparent, process-supervised compositional generation. The code is available at https://anonymous.4open.science/r/16FE/. The SoT-26K dataset will be released upon acceptance.

</details>


### [8] [An AI Framework for Microanastomosis Motion Assessment](https://arxiv.org/abs/2601.21120)
*Yan Meng,Eduardo J. Torres-Rodríguez,Marcelle Altshuler,Nishanth Gowda,Arhum Naeem,Recai Yilmaz,Omar Arnaout,Daniel A. Donoho*

Main category: cs.CV

TL;DR: 本文提出了一种基于AI的新型框架，用于自动评估显微吻合手术工具操作技能。该系统包括四个核心模块，分别是基于YOLO的工具检测模块、基于DeepSORT的工具跟踪模块、使用形状描述符进行工具尖端定位的模块以及监督分类模块。实验结果显示，该框架具有97%的工具检测精度和96%的mAP值。


<details>
  <summary>Details</summary>
Motivation: 现有的显微外科技术评估方法存在主观性、不一致性及时间成本高等问题，因此迫切需要一种客观、可靠且自动化的评估系统来促进显微手术技能的学习与改进。

Method: 该论文提出了一种集成有四个核心模块的AI评估框架，包括基于YOLO的工具检测模块、基于DeepSORT的跟踪模块、使用形状描述符进行尖端定位的模块以及监督分类模块来评价操作熟练度。

Result: 该框架在实验中表现出色，工具检测精度达到97%，平均平均精度（mAP）为96%，交并比（IoU）范围从50%到95%。

Conclusion: 研究成果表明，这种自动评估系统可以有效地评估显微手术中的工具操作技能，并显示出极高的准确性和可靠性。

Abstract: Proficiency in microanastomosis is a fundamental competency across multiple microsurgical disciplines. These procedures demand exceptional precision and refined technical skills, making effective, standardized assessment methods essential. Traditionally, the evaluation of microsurgical techniques has relied heavily on the subjective judgment of expert raters. They are inherently constrained by limitations such as inter-rater variability, lack of standardized evaluation criteria, susceptibility to cognitive bias, and the time-intensive nature of manual review. These shortcomings underscore the urgent need for an objective, reliable, and automated system capable of assessing microsurgical performance with consistency and scalability. To bridge this gap, we propose a novel AI framework for the automated assessment of microanastomosis instrument handling skills. The system integrates four core components: (1) an instrument detection module based on the You Only Look Once (YOLO) architecture; (2) an instrument tracking module developed from Deep Simple Online and Realtime Tracking (DeepSORT); (3) an instrument tip localization module employing shape descriptors; and (4) a supervised classification module trained on expert-labeled data to evaluate instrument handling proficiency. Experimental results demonstrate the effectiveness of the framework, achieving an instrument detection precision of 97%, with a mean Average Precision (mAP) of 96%, measured by Intersection over Union (IoU) thresholds ranging from 50% to 95% (mAP50-95).

</details>


### [9] [Bidirectional Cross-Perception for Open-Vocabulary Semantic Segmentation in Remote Sensing Imagery](https://arxiv.org/abs/2601.21159)
*Jianzheng Wang,Huan Ni*

Main category: cs.CV

TL;DR: 本文提出了一种名为SDCI的训练无监督语义分割框架，引入了跨模型自注意力融合模块和双向跨图扩散精炼模块，提高了分割性能，并通过超像素协作预测机制进一步优化边界。


<details>
  <summary>Details</summary>
Motivation: 现有的训练无监督语义分割方法在高分辨率遥感图像上表现不佳，主要由于它们使用了一种单一模型融合方法，这难以满足高分辨率遥感图像对几何定位和语义预测的高要求。

Method: 1. 引入跨模型自注意力融合模块，在特征编码过程中，通过相互注入自注意力图进行协作推理。2. 提出双向跨图扩散精炼模块，通过迭代随机游走扩散增强双分支分割评分的可靠性。3. 融合低级别超像素结构，开发基于凸优化的超像素协作预测机制，进一步细化对象边界。

Result: 实验结果表明，本文方法在多个遥感语义分割基准上优于现有方法。并且通过消融研究进一步证实了利用超像素结构的传统基于对象的遥感图像分析方法在深度学习框架中仍然有效。

Conclusion: 本研究提出了一种新型的训练无监督语义分割框架，提高了遥感图像的不同层次语义信息的解析能力，并且展示了其在各种基准测试中的优越性。

Abstract: High-resolution remote sensing imagery is characterized by densely distributed land-cover objects and complex boundaries, which places higher demands on both geometric localization and semantic prediction. Existing training-free open-vocabulary semantic segmentation (OVSS) methods typically fuse CLIP and vision foundation models (VFMs) using "one-way injection" and "shallow post-processing" strategies, making it difficult to satisfy these requirements. To address this issue, we propose a spatial-regularization-aware dual-branch collaborative inference framework for training-free OVSS, termed SDCI. First, during feature encoding, SDCI introduces a cross-model attention fusion (CAF) module, which guides collaborative inference by injecting self-attention maps into each other. Second, we propose a bidirectional cross-graph diffusion refinement (BCDR) module that enhances the reliability of dual-branch segmentation scores through iterative random-walk diffusion. Finally, we incorporate low-level superpixel structures and develop a convex-optimization-based superpixel collaborative prediction (CSCP) mechanism to further refine object boundaries. Experiments on multiple remote sensing semantic segmentation benchmarks demonstrate that our method achieves better performance than existing approaches. Moreover, ablation studies further confirm that traditional object-based remote sensing image analysis methods leveraging superpixel structures remain effective within deep learning frameworks. Code: https://github.com/yu-ni1989/SDCI.

</details>


### [10] [Enhancing Underwater Light Field Images via Global Geometry-aware Diffusion Process](https://arxiv.org/abs/2601.21179)
*Yuji Lin,Qian Zhao,Zongsheng Yue,Junhui Hou,Deyu Meng*

Main category: cs.CV

TL;DR: GeoDiff-LF 提出了一种新颖的基于扩散的框架，通过借鉴 4-D 光场的空间-角度结构，改善了水下图像的质量。


<details>
  <summary>Details</summary>
Motivation: 当前缺少能够有效应对水下环境复杂光照条件引起的颜色失真的 4-D 光场成像方法。

Method: GeoDiff-LF 使用修改后的 U-Net 架构去建模几何线索，几何引导的损失函数结合张量分解和逐级加权进行全局结构的正则化，同时通过优化采样策略减少噪声进而来提高效率。

Result: 实验表明，GeoDiff-LF 在视觉保真度和定量性能方面都优于现有方法，显著提升了水下成像的效果。

Conclusion: 这篇文章通过提出的 GeoDiff-LF 框架改善了水下 4-D 光场成像质量，该框架将扩散先验和光场几何结构结合，有效解决了水下场景中的颜色失真问题。

Abstract: This work studies the challenging problem of acquiring high-quality underwater images via 4-D light field (LF) imaging. To this end, we propose GeoDiff-LF, a novel diffusion-based framework built upon SD-Turbo to enhance underwater 4-D LF imaging by leveraging its spatial-angular structure. GeoDiff-LF consists of three key adaptations: (1) a modified U-Net architecture with convolutional and attention adapters to model geometric cues, (2) a geometry-guided loss function using tensor decomposition and progressive weighting to regularize global structure, and (3) an optimized sampling strategy with noise prediction to improve efficiency. By integrating diffusion priors and LF geometry, GeoDiff-LF effectively mitigates color distortion in underwater scenes. Extensive experiments demonstrate that our framework outperforms existing methods across both visual fidelity and quantitative performance, advancing the state-of-the-art in enhancing underwater imaging. The code will be publicly available at https://github.com/linlos1234/GeoDiff-LF.

</details>


### [11] [Generative Recall, Dense Reranking: Learning Multi-View Semantic IDs for Efficient Text-to-Video Retrieval](https://arxiv.org/abs/2601.21193)
*Zecheng Zhao,Zhi Chen,Zi Huang,Shazia Sadiq,Tong Chen*

Main category: cs.CV

TL;DR: 该研究提出了一种名为GRDR的方法，旨在提升双阶段视频检索中的召回阶段性能。通过多视角分词器为每个视频分配多个语义ID，并共享编码本体联合训练分词器和生成检索器，从而提高检索质量。同时，实验表明GRDR在准确性上可媲美密集检索器，大幅降低索引存储空间并加快查询速度。


<details>
  <summary>Details</summary>
Motivation: 现有的双阶段视频检索方法依赖于密集检索，计算和存储成本随着语料库规模的增长而急剧增加。因此，需要一种新的方法来减小检索过程中的索引大小并加快检索速度，同时保持较高的准确性。

Method: GRDR方法通过以下步骤提升双阶段视频检索的召回阶段：首先，使用查询导向的多视角分词器为每个视频分配多个语义ID，以便捕捉视频的多义性。其次，联合训练分词器和生成检索器，以共享编码本体的方式将语义ID作为文本和视频之间的语义桥梁。最后，在推理阶段，通过Trie约束解码生成紧凑的候选集，这些候选集再由密集模型重新排序后进行精细匹配。

Result: 实验结果表明，GRDR方法可以匹配强大的密集检索器的准确性，在全语料检索速度上可加速高达300倍，并且相对于现有方法在索引存储空间上减少了至少一个数量级。

Conclusion: 该研究通过设计GRDR方法解决了生成检索和密集检索结合中存在的语义模糊性和跨模态对齐问题，显著提高了双阶段视频检索系统的性能。

Abstract: Text-to-Video Retrieval (TVR) is essential in video platforms. Dense retrieval with dual-modality encoders leads in accuracy, but its computation and storage scale poorly with corpus size. Thus, real-time large-scale applications adopt two-stage retrieval, where a fast recall model gathers a small candidate pool, which is reranked by an advanced dense retriever. Due to hugely reduced candidates, the reranking model can use any off-the-shelf dense retriever without hurting efficiency, meaning the recall model bounds two-stage TVR performance. Recently, generative retrieval (GR) replaces dense video embeddings with discrete semantic IDs and retrieves by decoding text queries into ID tokens. GR offers near-constant inference and storage complexity, and its semantic IDs capture high-level video features via quantization, making it ideal for quickly eliminating irrelevant candidates during recall. However, as a recall model in two-stage TVR, GR suffers from (i) semantic ambiguity, where each video satisfies diverse queries but is forced into one semantic ID; and (ii) cross-modal misalignment, as semantic IDs are solely derived from visual features without text supervision. We propose Generative Recall and Dense Reranking (GRDR), designing a novel GR method to uplift recalled candidate quality. GRDR assigns multiple semantic IDs to each video using a query-guided multi-view tokenizer exposing diverse semantic access paths, and jointly trains the tokenizer and generative retriever via a shared codebook to cast semantic IDs as the semantic bridge between texts and videos. At inference, trie-constrained decoding generates a compact candidate set reranked by a dense model for fine-grained matching. Experiments on TVR benchmarks show GRDR matches strong dense retrievers in accuracy while reducing index storage by an order of magnitude and accelerating up to 300$\times$ in full-corpus retrieval.

</details>


### [12] [Thinker: A vision-language foundation model for embodied intelligence](https://arxiv.org/abs/2601.21199)
*Baiyu Pan,Daqin Luo,Junpeng Yang,Jiyuan Wang,Yixuan Zhang,Hailin Shi,Jichao Jiao*

Main category: cs.CV

TL;DR: 提出了一种名为Thinker的大型视觉-语言基础模型，旨在解决机器人场景中的视角混淆及视频末尾信息忽略问题，通过构建专用数据集和引入新颖的输入方式提升了视频理解能力，达到了任务规划领域两个基准数据集的最优性能。


<details>
  <summary>Details</summary>
Motivation: 面对机器人领域中人类容易解决但模型容易出错的问题，如视角混淆和视频末尾信息忽略，本文旨在提升模型在机器人环境下的感知和推理能力。

Method: 通过创建定制化的数据集和改进模型输入方式，引入了Thinker模型，增强其对关键帧和全视频的理解能力。

Result: Thinker模型在两个常用任务规划基准数据集上取得了最佳性能。

Conclusion: 本文通过针对性的数据集构建和创新的模型输入方法，显著提升了视觉-语言模型在机器人环境下的表现。

Abstract: When large vision-language models are applied to the field of robotics, they encounter problems that are simple for humans yet error-prone for models. Such issues include confusion between third-person and first-person perspectives and a tendency to overlook information in video endings during temporal reasoning. To address these challenges, we propose Thinker, a large vision-language foundation model designed for embodied intelligence. We tackle the aforementioned issues from two perspectives. Firstly, we construct a large-scale dataset tailored for robotic perception and reasoning, encompassing ego-view videos, visual grounding, spatial understanding, and chain-of-thought data. Secondly, we introduce a simple yet effective approach that substantially enhances the model's capacity for video comprehension by jointly incorporating key frames and full video sequences as inputs. Our model achieves state-of-the-art results on two of the most commonly used benchmark datasets in the field of task planning.

</details>


### [13] [LAMP: Learning Universal Adversarial Perturbations for Multi-Image Tasks via Pre-trained Models](https://arxiv.org/abs/2601.21220)
*Alvi Md Ishmam,Najibul Haque Sarker,Zaber Ibn Abdul Hakim,Chris Thomas*

Main category: cs.CV

TL;DR: 该研究提出了一种名为LAMP的方法，旨在针对多图的大规模多模态语言模型（MLLMs）产生通用对抗性扰动，LAMP通过注意力机制约束和交叉图像传染约束，提高了攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 现有的对抗性攻击主要针对单张图像设置，并且通常假设白盒威胁模型，而在实际应用中，更可能出现黑盒环境。因此，研究针对多图的大规模多模态语言模型提出了一种新的对抗性攻击方法，以增强模型的安全性。

Method: LAMP采用注意力机制约束防止模型跨图信息聚合，并引入跨图传染约束使扰动影响未被修改的干净标记，同时使用索引-注意力抑制损失，实现位置不变的攻击。

Result: 实验表明，LAMP方法在多个视觉-语言任务和模型上，攻击成功率优于当前最先进的基线方法。

Conclusion: 该研究提出的LAMP方法填补了针对多图MLLMs的对抗性攻击方法的空白，提高了这些模型的防御能力。

Abstract: Multimodal Large Language Models (MLLMs) have achieved remarkable performance across vision-language tasks. Recent advancements allow these models to process multiple images as inputs. However, the vulnerabilities of multi-image MLLMs remain unexplored. Existing adversarial attacks focus on single-image settings and often assume a white-box threat model, which is impractical in many real-world scenarios. This paper introduces LAMP, a black-box method for learning Universal Adversarial Perturbations (UAPs) targeting multi-image MLLMs. LAMP applies an attention-based constraint that prevents the model from effectively aggregating information across images. LAMP also introduces a novel cross-image contagious constraint that forces perturbed tokens to influence clean tokens, spreading adversarial effects without requiring all inputs to be modified. Additionally, an index-attention suppression loss enables a robust position-invariant attack. Experimental results show that LAMP outperforms SOTA baselines and achieves the highest attack success rates across multiple vision-language tasks and models.

</details>


### [14] [PTQ4ARVG: Post-Training Quantization for AutoRegressive Visual Generation Models](https://arxiv.org/abs/2601.21238)
*Xuewen Liu,Zhikai Li,Jing Zhang,Mengjuan Chen,Qingyi Gu*

Main category: cs.CV

TL;DR: PTQ4ARVG 提出了一种针对 ARVG 模型的新型量化方案，通过三个关键组件解决了量化过程中的三个挑战，实现模型的紧凑化而不损失性能。


<details>
  <summary>Details</summary>
Motivation: ARVG 模型在视觉生成任务中展示了与扩散模型相当的性能，但目前对于该模型的量化研究较少且效果不佳。论文发现了三个主要问题并提出了解决方案。

Method: 提出了一种训练后无损量化 (PTQ) 框架，包含 Gain-Projected Scaling (GPS)、Static Token-Wise Quantization (STWQ) 和 Distribution-Guided Calibration (DGC) 三个技术组件。

Result: 实验表明该方法可以将 ARVG 模型量化至 8 位和 6 位，并保持较高性能。

Conclusion: 该研究有效推动了 ARVG 模型在实际工程应用中的轻量化进程。

Abstract: AutoRegressive Visual Generation (ARVG) models retain an architecture compatible with language models, while achieving performance comparable to diffusion-based models. Quantization is commonly employed in neural networks to reduce model size and computational latency. However, applying quantization to ARVG remains largely underexplored, and existing quantization methods fail to generalize effectively to ARVG models. In this paper, we explore this issue and identify three key challenges: (1) severe outliers at channel-wise level, (2) highly dynamic activations at token-wise level, and (3) mismatched distribution information at sample-wise level. To these ends, we propose PTQ4ARVG, a training-free post-training quantization (PTQ) framework consisting of: (1) Gain-Projected Scaling (GPS) mitigates the channel-wise outliers, which expands the quantization loss via a Taylor series to quantify the gain of scaling for activation-weight quantization, and derives the optimal scaling factor through differentiation.(2) Static Token-Wise Quantization (STWQ) leverages the inherent properties of ARVG, fixed token length and position-invariant distribution across samples, to address token-wise variance without incurring dynamic calibration overhead.(3) Distribution-Guided Calibration (DGC) selects samples that contribute most to distributional entropy, eliminating the sample-wise distribution mismatch. Extensive experiments show that PTQ4ARVG can effectively quantize the ARVG family models to 8-bit and 6-bit while maintaining competitive performance. Code is available at http://github.com/BienLuky/PTQ4ARVG .

</details>


### [15] [NFCDS: A Plug-and-Play Noise Frequency-Controlled Diffusion Sampling Strategy for Image Restoration](https://arxiv.org/abs/2601.21248)
*Zhen Wang,Hongyi Liu,Jianing Li,Zhihui Wei*

Main category: cs.CV

TL;DR: NFCDS通过频域滤波机制控制反向扩散过程中的噪声频率，提高了图像的保真度和视觉质量。


<details>
  <summary>Details</summary>
Motivation: 为了解决PnP（Plug-and-Play）方法在保持高感知质量的同时降低数据保真度的问题。

Method: 设计了一种基于Fourier域的频域滤波器，能够在反向扩散过程中逐步抑制低频噪声并保留高频细节。

Result: NFCDS方法能够提供高保真度和视觉感知的图像，无需额外训练，并且能够与现有的基于扩散的修复框架无缝集成。

Conclusion: NFCDS提高了扩散采样方法在零样本任务中的保真度和视觉质量之间的平衡。

Abstract: Diffusion sampling-based Plug-and-Play (PnP) methods produce images with high perceptual quality but often suffer from reduced data fidelity, primarily due to the noise introduced during reverse diffusion. To address this trade-off, we propose Noise Frequency-Controlled Diffusion Sampling (NFCDS), a spectral modulation mechanism for reverse diffusion noise. We show that the fidelity-perception conflict can be fundamentally understood through noise frequency: low-frequency components induce blur and degrade fidelity, while high-frequency components drive detail generation. Based on this insight, we design a Fourier-domain filter that progressively suppresses low-frequency noise and preserves high-frequency content. This controlled refinement injects a data-consistency prior directly into sampling, enabling fast convergence to results that are both high-fidelity and perceptually convincing--without additional training. As a PnP module, NFCDS seamlessly integrates into existing diffusion-based restoration frameworks and improves the fidelity-perception balance across diverse zero-shot tasks.

</details>


### [16] [Hypersolid: Emergent Vision Representations via Short-Range Repulsion](https://arxiv.org/abs/2601.21255)
*Esteban Rodríguez-Betancourt,Edgar Casasola-Murillo*

Main category: cs.CV

TL;DR: 该论文提出了一种名为Hypersolid的方法，通过使用短程硬球排斥力来防止局部碰撞，将表示学习重新解释为一个离散的打包问题，从而在细粒度和低分辨率分类任务上表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的自监督学习方法通常依赖于全局正则化策略来防止表示坍塌，但这些方法往往无法有效地保护特征之间的独立性。本文重新定义了表示学习为一个离散的打包问题，并提出Hypersolid方法以增强特征的独立性和多样性。

Method: Hypersolid方法利用短程硬球排斥力来防止局部碰撞，从而保持特征的高分离几何区域，这种方法简化了表示的保持性问题。

Result: Hypersolid方法在细粒度分类任务和低分辨率分类任务上表现优异，展示了其在保持特征独立性和多样性方面的优势。

Conclusion: 该研究通过提出Hypersolid方法，提供了一种新的视角来解决自监督学习中的表示坍塌问题，具有重要的理论和实际意义。

Abstract: A recurring challenge in self-supervised learning is preventing representation collapse. Existing solutions typically rely on global regularization, such as maximizing distances, decorrelating dimensions or enforcing certain distributions. We instead reinterpret representation learning as a discrete packing problem, where preserving information simplifies to maintaining injectivity. We operationalize this in Hypersolid, a method using short-range hard-ball repulsion to prevent local collisions. This constraint results in a high-separation geometric regime that preserves augmentation diversity, excelling on fine-grained and low-resolution classification tasks.

</details>


### [17] [Lightweight High-Fidelity Low-Bitrate Talking Face Compression for 3D Video Conference](https://arxiv.org/abs/2601.21269)
*Jianglong Li,Jun Xu,Bingcong Lu,Zhengxue Cheng,Hongwei Hu,Ronghua Wu,Li Song*

Main category: cs.CV

TL;DR: 该研究提出了一种轻量级的用于实时3D视频会议的3D人物面部压缩框架，通过结合FLAME参数建模和3DGS神经渲染，实现了在极低比特率下高质量的面部渲染。


<details>
  <summary>Details</summary>
Motivation: 为了克服传统2D视频压缩技术无法保持精细的几何和视觉细节及隐式神经渲染方法计算成本高的问题，该研究旨在开发一种能在低比特率下实现高保真3D人物面部表示的框架，从而适用于实时3D视频通讯。

Method: 该研究提出了一种综合使用FLAME参数化建模和3DGS神经渲染的方法。通过实时传输关键面部元数据，并利用基于高斯的头部模型进行高效重建。此外，引入了一种紧凑的表示和压缩方案，包括高斯属性压缩和MLP优化，以提高传输效率。

Result: 实验结果表明，该方法在比特率-失真性能方面表现出优越性，能够在极高比特率下实现高质量的面部渲染，特别适用于实时3D视频通讯应用。

Conclusion: 该研究提出的方法在保持高质量3D人物面部表示的同时，显著降低了所需比特率，展示了其在实际应用中的潜力。

Abstract: The demand for immersive and interactive communication has driven advancements in 3D video conferencing, yet achieving high-fidelity 3D talking face representation at low bitrates remains a challenge. Traditional 2D video compression techniques fail to preserve fine-grained geometric and appearance details, while implicit neural rendering methods like NeRF suffer from prohibitive computational costs. To address these challenges, we propose a lightweight, high-fidelity, low-bitrate 3D talking face compression framework that integrates FLAME-based parametric modeling with 3DGS neural rendering. Our approach transmits only essential facial metadata in real time, enabling efficient reconstruction with a Gaussian-based head model. Additionally, we introduce a compact representation and compression scheme, including Gaussian attribute compression and MLP optimization, to enhance transmission efficiency. Experimental results demonstrate that our method achieves superior rate-distortion performance, delivering high-quality facial rendering at extremely low bitrates, making it well-suited for real-time 3D video conferencing applications.

</details>


### [18] [GeoRC: A Benchmark for Geolocation Reasoning Chains](https://arxiv.org/abs/2601.21278)
*Mohit Talreja,Joshua Diao,Jim Thannikary James,Radu Casapu,Tejas Santanam,Ethan Mendes,Alan Ritter,Wei Xu,James Hays*

Main category: cs.CV

TL;DR: 该研究提出了一个地理由论链基准，并展示了在预测地理位置方面，尽管VLMs可以与人类专家相媲美，但在生成可验证的理由链方面，它们的表现却远逊于人类专家。该基准揭示了VLMs在从高分辨率图像中提取细微视觉特征方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前许多VLMs在预测照片的地理位置方面表现出色，但它们在解释推理过程中依赖的图像证据方面表现不佳。为了促进这一领域的研究，作者设立了一个基准来评估VLMs生成可验证推理链的能力。

Method: 研究者选择了流行游戏GeoGuessr中的任务，涵盖了全球超过100个国家的Google Street View。他们与包括世界冠军在内的专家玩家合作，制作了500个查询场景的800个专家推理链。基于这些专家推理链，研究者评估了LLM-as-a-judge和VLM-as-a-judge策略对VLM生成的推理链进行评估。

Result: Qwen 3 的LLM-as-a-judge策略与人类评分相关性最高。尽管大型不公开VLMs如Gemini和GPT 5在位置预测方面与人类专家相当，但在生成透明的推理链方面，它们的表现仍不及人类专家。开放模型的VLMs，如Llama和Qwen，在基准测试中的表现极为糟糕，甚至比一个使用正确照片位置但没有视觉信息的LLM生成造化的推理链的基线略好。

Conclusion: 研究揭示了VLMs在解析高分辨率图像中的细微视觉特征方面的局限性，并强调了在生成可验证地理由论链方面的改进需求。

Abstract: Vision Language Models (VLMs) are good at recognizing the global location of a photograph -- their geolocation prediction accuracy rivals the best human experts. But many VLMs are startlingly bad at explaining which image evidence led to their prediction, even when their location prediction is correct. The reasoning chains produced by VLMs frequently hallucinate scene attributes to support their location prediction (e.g. phantom writing, imagined infrastructure, misidentified flora). In this paper, we introduce the first benchmark for geolocation reasoning chains. We focus on the global location prediction task in the popular GeoGuessr game which draws from Google Street View spanning more than 100 countries. We collaborate with expert GeoGuessr players, including the reigning world champion, to produce 800 ground truth reasoning chains for 500 query scenes. These expert reasoning chains address hundreds of different discriminative visual attributes such as license plate shape, architecture, and soil properties to name just a few. We evaluate LLM-as-a-judge and VLM-as-a-judge strategies for scoring VLM-generated reasoning chains against our expert reasoning chains and find that Qwen 3 LLM-as-a-judge correlates best with human scoring. Our benchmark reveals that while large, closed-source VLMs such as Gemini and GPT 5 rival human experts at prediction locations, they still lag behind human experts when it comes to producing auditable reasoning chains. Open weights VLMs such as Llama and Qwen catastrophically fail on our benchmark -- they perform only slightly better than a baseline in which an LLM hallucinates a reasoning chain with oracle knowledge of the photo location but no visual information at all. We believe the gap between human experts and VLMs on this task points to VLM limitations at extracting fine-grained visual attributes from high resolution images.

</details>


### [19] [Token Entropy Regularization for Multi-modal Antenna Affiliation Identification](https://arxiv.org/abs/2601.21280)
*Dong Chen,Ruoyu Li,Xinyan Zhang,Jialei Xu,Ruoseng Zhao,Zhikang Zhang,Lingyun Li,Zizhuang Wei*

Main category: cs.CV

TL;DR: 本文提出了一种新的多模态分类和配对方法，用于基于视频、天线几何特性和PUCCH信号识别天线归属，通过自定义训练框架和Token Entropy Regularization模块提高了性能。


<details>
  <summary>Details</summary>
Motivation: 现有的天线归属识别方法依赖人工巡检，效率低且容易出错。本文为了解决这个问题，提出了一个创新方法来解决多模态对齐问题。

Method: 通过整合基站视频、天线几何特性和PUCCH信号，将天线归属识别任务转变为多模态分类和匹配问题。引入了一个专用的训练框架来对齐天线图像与相应的PUCCH信号，并在预训练阶段提出了一个创新的Token Entropy Regularization模块。

Result: 实验证明TER模块可以加速收敛并显著提高性能。进一步分析表明，第一令牌的熵具有模态依赖性。

Conclusion: 本文提出的方法在天线归属识别任务上取得了显著的性能提升，解决了跨模态对齐的挑战。

Abstract: Accurate antenna affiliation identification is crucial for optimizing and maintaining communication networks. Current practice, however, relies on the cumbersome and error-prone process of manual tower inspections. We propose a novel paradigm shift that fuses video footage of base stations, antenna geometric features, and Physical Cell Identity (PCI) signals, transforming antenna affiliation identification into multi-modal classification and matching tasks. Publicly available pretrained transformers struggle with this unique task due to a lack of analogous data in the communications domain, which hampers cross-modal alignment. To address this, we introduce a dedicated training framework that aligns antenna images with corresponding PCI signals. To tackle the representation alignment challenge, we propose a novel Token Entropy Regularization module in the pretraining stage. Our experiments demonstrate that TER accelerates convergence and yields significant performance gains. Further analysis reveals that the entropy of the first token is modality-dependent. Code will be made available upon publication.

</details>


### [20] [WorldBench: Disambiguating Physics for Diagnostic Evaluation of World Models](https://arxiv.org/abs/2601.21282)
*Rishi Upadhyay,Howard Zhang,Jim Solomon,Ayush Agrawal,Pranay Boreddy,Shruti Satya Narayana,Yunhao Ba,Alex Wong,Celso M de Melo,Achuta Kadambi*

Main category: cs.CV

TL;DR: WorldBench 提出了一种新型的视频基准，专门用于概念特异性、解缠的评估。该基准通过设计针对直观物理理解以及低级物理常数和材料属性的评估标准，识别现有模型在特定物理概念上的失败模式。


<details>
  <summary>Details</summary>
Motivation: 由于现有基于物理的视频基准在评估模型物理理解时存在纠缠问题，无法有效地对单一物理概念进行诊断性评估，因此需要一个更具体的基准来提高对物理推理能力的评估精度。

Method: WorldBench 通过设计两个不同层次的评估标准来实现概念特异性、解缠的评估：一个针对直观物理理解的概念，例如客体持续性或比例/视角，另一个针对低级物理常数和材料属性，如摩擦系数或流体粘度。

Result: 在 WorldBench 上评估现有的视频生成和世界模型时，发现特定物理概念上的失败模式，表明现有模型缺乏产生可靠现实交互所需的物理一致性。

Conclusion: WorldBench 提供了一个更细致和可扩展的框架，用于严格评估视频生成和世界模型中的物理推理能力，为更加稳健和泛化的世界模型驱动学习铺平了道路。

Abstract: Recent advances in generative foundational models, often termed "world models," have propelled interest in applying them to critical tasks like robotic planning and autonomous system training. For reliable deployment, these models must exhibit high physical fidelity, accurately simulating real-world dynamics. Existing physics-based video benchmarks, however, suffer from entanglement, where a single test simultaneously evaluates multiple physical laws and concepts, fundamentally limiting their diagnostic capability. We introduce WorldBench, a novel video-based benchmark specifically designed for concept-specific, disentangled evaluation, allowing us to rigorously isolate and assess understanding of a single physical concept or law at a time. To make WorldBench comprehensive, we design benchmarks at two different levels: 1) an evaluation of intuitive physical understanding with concepts such as object permanence or scale/perspective, and 2) an evaluation of low-level physical constants and material properties such as friction coefficients or fluid viscosity. When SOTA video-based world models are evaluated on WorldBench, we find specific patterns of failure in particular physics concepts, with all tested models lacking the physical consistency required to generate reliable real-world interactions. Through its concept-specific evaluation, WorldBench offers a more nuanced and scalable framework for rigorously evaluating the physical reasoning capabilities of video generation and world models, paving the way for more robust and generalizable world-model-driven learning.

</details>


### [21] [Gaussian Belief Propagation Network for Depth Completion](https://arxiv.org/abs/2601.21291)
*Jie Tang,Pingping Xie,Jian Li,Ping Tan*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的GBPN框架，将深度学习与概率图模型相结合，以解决深度图数据稀疏性和不规则性带来的挑战，从而实现端到端的深度补全。


<details>
  <summary>Details</summary>
Motivation: 深度图数据的稀疏性和不规则性历来是深度学习算法中的难点，尤其是在高稀疏度输入下，影响了模型的性能。

Method: GBPN框架包括两个主要部分：首先，通过Graphical Model Construction Network (GMCN)构建场景特定的Markov随机场，并通过Gaussian Belief Propagation (GBP)进行推断；其次，GBP增强算法引入了串联与并行的消息传递方案，有助于从稀疏测量中有效传播信息。

Result: 实验结果表明，GBPN在NYUv2和KITTI基准测试中达到了目前最优的表现。并对不同的稀疏度、稀疏模式和数据集的各种情况进行了评估，显示了其优越性、鲁棒性和可推广性。

Conclusion: 本文提出的GBPN为深度图数据的稀疏性和不规则性的深度补全问题提供了一个有效的解决方案，有效提高了模型在更复杂情况下的性能。

Abstract: Depth completion aims to predict a dense depth map from a color image with sparse depth measurements. Although deep learning methods have achieved state-of-the-art (SOTA), effectively handling the sparse and irregular nature of input depth data in deep networks remains a significant challenge, often limiting performance, especially under high sparsity. To overcome this limitation, we introduce the Gaussian Belief Propagation Network (GBPN), a novel hybrid framework synergistically integrating deep learning with probabilistic graphical models for end-to-end depth completion. Specifically, a scene-specific Markov Random Field (MRF) is dynamically constructed by the Graphical Model Construction Network (GMCN), and then inferred via Gaussian Belief Propagation (GBP) to yield the dense depth distribution. Crucially, the GMCN learns to construct not only the data-dependent potentials of MRF but also its structure by predicting adaptive non-local edges, enabling the capture of complex, long-range spatial dependencies. Furthermore, we enhance GBP with a serial \& parallel message passing scheme, designed for effective information propagation, particularly from sparse measurements. Extensive experiments demonstrate that GBPN achieves SOTA performance on the NYUv2 and KITTI benchmarks. Evaluations across varying sparsity levels, sparsity patterns, and datasets highlight GBPN's superior performance, notable robustness, and generalizable capability.

</details>


### [22] [Mam-App: A Novel Parameter-Efficient Mamba Model for Apple Leaf Disease Classification](https://arxiv.org/abs/2601.21307)
*Md Nadim Mahamood,Md Imran Hasan,Md Rasheduzzaman,Ausrukona Ray,Md Shafi Ud Doula,Kamrul Hasan*

Main category: cs.CV

TL;DR: 该研究提出了Mam-App模型，用于苹果叶片疾病的特征提取和分类。该模型在参数效率方面表现出色，参数量仅为0.051M，实现了99.58%的准确率和其他高F1分数，在多个数据集上均表现出色。


<details>
  <summary>Details</summary>
Motivation: 面对全球人口增长和技术进步对食物生产需求的增加，尤其苹果作为重要食品之一，但其叶片常受到病害的影响导致生产损失。为了提高诊断精度并适应资源受限的设备，研究提出了一种参数高效模型Mam-App。

Method: 该方法基于Mamba模型，聚焦于减少模型参数量，从而减轻训练和推断时间，采用自动编码器进行特征提取和分类。

Result: 该模型在苹果叶片疾病数据集上达到了99.58%的准确率以及其他高F1分数；进一步在玉米和马铃薯叶片疾病数据集上测试，分别取得了显著成绩，显示出了模型的鲁棒性和泛化能力。

Conclusion: 研究证明，Mam-App模型能够在保持高性能的同时，有效降低模型参数量，这使其非常适合部署在无人机、移动设备等低资源平台上。

Abstract: The rapid growth of the global population, alongside exponential technological advancement, has intensified the demand for food production. Meeting this demand depends not only on increasing agricultural yield but also on minimizing food loss caused by crop diseases. Diseases account for a substantial portion of apple production losses, despite apples being among the most widely produced and nutritionally valuable fruits worldwide. Previous studies have employed machine learning techniques for feature extraction and early diagnosis of apple leaf diseases, and more recently, deep learning-based models have shown remarkable performance in disease recognition. However, most state-of-the-art deep learning models are highly parameter-intensive, resulting in increased training and inference time. Although lightweight models are more suitable for user-friendly and resource-constrained applications, they often suffer from performance degradation. To address the trade-off between efficiency and performance, we propose Mam-App, a parameter-efficient Mamba-based model for feature extraction and leaf disease classification. The proposed approach achieves competitive state-of-the-art performance on the PlantVillage Apple Leaf Disease dataset, attaining 99.58% accuracy, 99.30% precision, 99.14% recall, and a 99.22% F1-score, while using only 0.051M parameters. This extremely low parameter count makes the model suitable for deployment on drones, mobile devices, and other low-resource platforms. To demonstrate the robustness and generalizability of the proposed model, we further evaluate it on the PlantVillage Corn Leaf Disease and Potato Leaf Disease datasets. The model achieves 99.48%, 99.20%, 99.34%, and 99.27% accuracy, precision, recall, and F1-score on the corn dataset and 98.46%, 98.91%, 95.39%, and 97.01% on the potato dataset, respectively.

</details>


### [23] [HiFi-Mesh: High-Fidelity Efficient 3D Mesh Generation via Compact Autoregressive Dependence](https://arxiv.org/abs/2601.21314)
*Yanfeng Li,Tao Tan,Qingquan Gao,Zhiwen Cao,Xiaohong liu,Yue Sun*

Main category: cs.CV

TL;DR: LANE通过引入紧凑的自回归依赖性和提出自适应计算图重构策略，显著提高了3D网格生成的速度和结构细节，实验表明该方法相比现有方法表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理高保真3D网格序列时存在资源利用率低下和生成速度慢的问题，限制了结构细节的表达能力。

Method: 提出了一种名为Latent Autoregressive Network (LANE) 的方法，通过引入自回归依赖性和自适应计算图重构策略来加速生成过程。

Result: 实验验证了LANE在生成速度、结构细节和几何一致性方面的优越性，相比现有方法实现更强的性能。

Conclusion: LANE为高质量3D网格生成提供了一个有效解决方案，解决了传统方法中的瓶颈问题。

Abstract: High-fidelity 3D meshes can be tokenized into one-dimension (1D) sequences and directly modeled using autoregressive approaches for faces and vertices. However, existing methods suffer from insufficient resource utilization, resulting in slow inference and the ability to handle only small-scale sequences, which severely constrains the expressible structural details. We introduce the Latent Autoregressive Network (LANE), which incorporates compact autoregressive dependencies in the generation process, achieving a $6\times$ improvement in maximum generatable sequence length compared to existing methods. To further accelerate inference, we propose the Adaptive Computation Graph Reconfiguration (AdaGraph) strategy, which effectively overcomes the efficiency bottleneck of traditional serial inference through spatiotemporal decoupling in the generation process. Experimental validation demonstrates that LANE achieves superior performance across generation speed, structural detail, and geometric consistency, providing an effective solution for high-quality 3D mesh generation.

</details>


### [24] [Do Pathology Foundation Models Encode Disease Progression? A Pseudotime Analysis of Visual Representations](https://arxiv.org/abs/2601.21334)
*Pritika Vig,Ren-Chin Wu,William Lotter*

Main category: cs.CV

TL;DR: 研究发现，即使不使用连续采样的数据，视觉基础模型也能隐式地学习到疾病进展的连续过程，轨迹一致性提供了衡量表示质量的新指标。


<details>
  <summary>Details</summary>
Motivation: 现有视觉基础模型在离散采样图像上表现出色，但它们是否学习了训练数据中潜在的连续过程仍是未知数。特别是在病理学领域，需要寻找能捕捉疾病连续进展的模型，以更好地反映生物学本质，提高泛化能力和量化疾病转变的特征。

Method: 通过使用开发的单细胞转录组数据分析方法（扩散伪时间），研究模型在疾病状态的表示空间中是否沿连贯的进展方向组织。跨四个癌症进展过程和六个模型进行测试。

Result: 研究发现：1) 所有病理特异性模型显著超越了随机基线，尤其视觉基础模型精度最高，如 CRC-Serrated; 2) 根据轨迹一致性排名，模型在模型排名预测未见疾病中的几shot分类性能上表现良好（ρ= 0.92）; 3) 投影分析表明细胞类型组成在推断的轨迹上平滑变化，且符合已知的基质重塑模式。

Conclusion: 视觉基础模型即使使用静态图像也能隐式地学习连续过程，且轨迹准确性提供了一种额外的表示质量评价指标。此框架在其他领域也适用，这些领域通过静态快照观察到连续过程。

Abstract: Vision foundation models trained on discretely sampled images achieve strong performance on classification benchmarks, yet whether their representations encode the continuous processes underlying their training data remains unclear. This question is especially pertinent in computational pathology, where we posit that models whose latent representations implicitly capture continuous disease progression may better reflect underlying biology, support more robust generalization, and enable quantitative analyses of features associated with disease transitions. Using diffusion pseudotime, a method developed to infer developmental trajectories from single-cell transcriptomics, we probe whether foundation models organize disease states along coherent progression directions in representation space. Across four cancer progressions and six models, we find that all pathology-specific models recover trajectory orderings significantly exceeding null baselines, with vision-only models achieving the highest fidelities $(τ> 0.78$ on CRC-Serrated). Model rankings by trajectory fidelity on reference diseases strongly predict few-shot classification performance on held-out diseases ($ρ= 0.92$), and exploratory analysis shows cell-type composition varies smoothly along inferred trajectories in patterns consistent with known stromal remodeling. Together, these results demonstrate that vision foundation models can implicitly learn to represent continuous processes from independent static observations, and that trajectory fidelity provides a complementary measure of representation quality beyond downstream performance. While demonstrated in pathology, this framework could be applied to other domains where continuous processes are observed through static snapshots.

</details>


### [25] [Dynamical Adapter Fusion: Constructing A Global Adapter for Pre-Trained Model-based Class-Incremental Learning](https://arxiv.org/abs/2601.21341)
*Ruiqi Liu,Boyu Diao,Zijia An,Zhulin An,Fei Wang,Yongjun Xu*

Main category: cs.CV

TL;DR: 提出了一种名为Dynamical Adapter Fusion（DAF）的方法，构建单一稳健的全局适配器，通过PAC-Bayes定理和泰勒展开，动态平衡稳定性和灵活性。


<details>
  <summary>Details</summary>
Motivation: 现有的类增量学习方法存在知识迁移受限、高检索成本以及参数融合可能导致灾难性遗忘的问题。

Method: 基于PAC-Bayes定理，提出了一种动态适配器融合机制，该机制结合了优化的特定任务适配器参数、先前的全球适配器参数和初始化参数，利用损失函数的泰勒展开推导出最优融合系数。同时，提出了一种鲁棒初始化策略以有效捕捉全局知识模式。

Result: 在多个类增量学习基准测试中，DAF方法取得了最先进的性能。

Conclusion: DAF有效地解决了当前类增量学习的限制，并在多个基准测试中展现了卓越的效果。

Abstract: Class-Incremental Learning (CIL) requires models to continuously acquire new classes without forgetting previously learned ones. A dominant paradigm involves freezing a pre-trained model and training lightweight, task-specific adapters. However, maintaining task-specific parameters hinders knowledge transfer and incurs high retrieval costs, while naive parameter fusion often leads to destructive interference and catastrophic forgetting. To address these challenges, we propose Dynamical Adapter Fusion (DAF) to construct a single robust global adapter. Grounded in the PAC-Bayes theorem, we derive a fusion mechanism that explicitly integrates three components: the optimized task-specific adapter parameters, the previous global adapter parameters, and the initialization parameters. We utilize the Taylor expansion of the loss function to derive the optimal fusion coefficients, dynamically achieving the best balance between stability and plasticity. Furthermore, we propose a Robust Initialization strategy to effectively capture global knowledge patterns. Experiments on multiple CIL benchmarks demonstrate that DAF achieves state-of-the-art (SOTA) performance.

</details>


### [26] [Semantic-Guided Dynamic Sparsification for Pre-Trained Model-based Class-Incremental Learning](https://arxiv.org/abs/2601.21345)
*Ruiqi Liu,Boyu Diao,Zijia An,Runjie Shao,Zhulin An,Fei Wang,Yongjun Xu*

Main category: cs.CV

TL;DR: 该研究提出了一种新的方法——语义引导动态稀疏化（SGDS），通过在激活空间中引导子空间的方向和秩，促进相似类别共享紧凑的激活子空间，同时防止不同类别之间的干扰，从而有效缓解过干扰问题。实验表明，SGDS在多个基准数据集上达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过限制参数空间来防止任务间干扰，但这种方法牺牲了模型的灵活性。

Method: SGDS通过目标稀疏化在激活空间中引导子空间的方向和秩，促进相似类别共享紧凑的激活子空间，同时防止不同类别之间的干扰。

Result: 在多种基准数据集上，SGDS达到了最先进的性能。

Conclusion: SGDS方法通过在激活空间中有效地塑造特定于类别的稀疏子空间，缓解了过干扰问题，展示了其在类增量学习中的潜力。

Abstract: Class-Incremental Learning (CIL) requires a model to continually learn new classes without forgetting old ones. A common and efficient solution freezes a pre-trained model and employs lightweight adapters, whose parameters are often forced to be orthogonal to prevent inter-task interference. However, we argue that this parameter-constraining method is detrimental to plasticity. To this end, we propose Semantic-Guided Dynamic Sparsification (SGDS), a novel method that proactively guides the activation space by governing the orientation and rank of its subspaces through targeted sparsification. Specifically, SGDS promotes knowledge transfer by encouraging similar classes to share a compact activation subspace, while simultaneously preventing interference by assigning non-overlapping activation subspaces to dissimilar classes. By sculpting class-specific sparse subspaces in the activation space, SGDS effectively mitigates interference without imposing rigid constraints on the parameter space. Extensive experiments on various benchmark datasets demonstrate the state-of-the-art performance of SGDS.

</details>


### [27] [Rectifying Geometry-Induced Similarity Distortions for Real-World Aerial-Ground Person Re-Identification](https://arxiv.org/abs/2601.21405)
*Kailash A. Hambarde,Hugo Proença*

Main category: cs.CV

TL;DR: 本文提出了一种名为GIQT的模块，通过考虑摄像机几何条件来调整相似性计算，以解决航拍和地面视角之间的几何畸变问题。同时，引入了一个基于摄像机几何生成的全局提示生成机制，以适应不同视图的表示先验。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理航拍和地面视角间极端视角和尺度差异时假设几何不变的点积相似性在注意力机制中仍然可靠，但这种假设在大视角和尺度变化下并不可靠。因此，需要一种新的方法来调整相似性计算，以补偿主要由几何引起的各向异性畸变。

Method: GIQT是一种轻量级的低秩模块，可以通过条件查询-键交互来显式地校正相似性空间。它不修改特征表示或注意力机制本身，而是适应相似性计算以补偿主要由几何引起的各向异性畸变。此外，还引入了一个基于摄像机几何生成的全局提示生成机制，以提供来自摄像机几何的全局、视图自适应的表示先验。

Result: 在四个航拍-地面行人再识别基准测试上，所提出的框架在极端和以前未见过的几何条件下表现出了一致的鲁棒性改进，同时计算开销相比最先进的方法较小。

Conclusion: 本文提出了一种新的方法来解决航拍-地面行人再识别中的几何畸变问题，该方法在多个基准测试上的表现优于现有方法。

Abstract: Aerial-ground person re-identification (AG-ReID) is fundamentally challenged by extreme viewpoint and distance discrepancies between aerial and ground cameras, which induce severe geometric distortions and invalidate the assumption of a shared similarity space across views. Existing methods primarily rely on geometry-aware feature learning or appearance-conditioned prompting, while implicitly assuming that the geometry-invariant dot-product similarity used in attention mechanisms remains reliable under large viewpoint and scale variations. We argue that this assumption does not hold. Extreme camera geometry systematically distorts the query-key similarity space and degrades attention-based matching, even when feature representations are partially aligned.
  To address this issue, we introduce Geometry-Induced Query-Key Transformation (GIQT), a lightweight low-rank module that explicitly rectifies the similarity space by conditioning query-key interactions on camera geometry. Rather than modifying feature representations or the attention formulation itself, GIQT adapts the similarity computation to compensate for dominant geometry-induced anisotropic distortions. Building on this local similarity rectification, we further incorporate a geometry-conditioned prompt generation mechanism that provides global, view-adaptive representation priors derived directly from camera geometry.
  Experiments on four aerial-ground person re-identification benchmarks demonstrate that the proposed framework consistently improves robustness under extreme and previously unseen geometric conditions, while introducing minimal computational overhead compared to state-of-the-art methods.

</details>


### [28] [Generation Enhances Understanding in Unified Multimodal Models via Multi-Representation Generation](https://arxiv.org/abs/2601.21406)
*Zihan Su,Hongyang Wei,Kangrui Cen,Yong Wang,Guanhua Chen,Chun Yuan,Xiangxiang Chu*

Main category: cs.CV

TL;DR: UniMRG 提出了一种简单而有效的后训练方法，通过增加辅助生成任务来增强 UMM 的理解能力，实验表明其显著提高了精细感知、减少了幻觉并提升了空间理解能力，同时也增强了生成能力。


<details>
  <summary>Details</summary>
Motivation: 当前 UMM 方法主要集中在利用理解来增强生成，但对利用生成来改进理解的研究较少。UniMRG 旨在通过引入辅助生成任务来弥补这一不足，从而提高 UMM 的整体性能。

Method: UniMRG 通过引入多种辅助生成任务来增强 UMM 的理解能力，具体包括像素重建、深度几何和分割结构。通过综合这些多样的表示形式，UMMs 捕获了关于外观、空间关系及结构布局的互补信息。这种方法在多种 UMM 架构上进行了广泛的实验证明其有效性。

Result: 在多种 UMM 架构上的广泛实验表明，UniMRG 可以显著提升 UMM 的精细感知能力，减少幻觉现象，并增强其空间理解，同时也能改善生成能力。

Conclusion: UniMRG 提供了一种新的视角来改进 UMM 的理解与生成，通过引入辅助生成任务，其有效提升了 UMM 的多种关键性能指标。

Abstract: Unified Multimodal Models (UMMs) integrate both visual understanding and generation within a single framework. Their ultimate aspiration is to create a cycle where understanding and generation mutually reinforce each other. While recent post-training methods have successfully leveraged understanding to enhance generation, the reverse direction of utilizing generation to improve understanding remains largely unexplored. In this work, we propose UniMRG (Unified Multi-Representation Generation), a simple yet effective architecture-agnostic post-training method. UniMRG enhances the understanding capabilities of UMMs by incorporating auxiliary generation tasks. Specifically, we train UMMs to generate multiple intrinsic representations of input images, namely pixel (reconstruction), depth (geometry), and segmentation (structure), alongside standard visual understanding objectives. By synthesizing these diverse representations, UMMs capture complementary information regarding appearance, spatial relations, and structural layout. Consequently, UMMs develop a deeper and more comprehensive understanding of visual inputs. Extensive experiments across diverse UMM architectures demonstrate that our method notably enhances fine-grained perception, reduces hallucinations, and improves spatial understanding, while simultaneously boosting generation capabilities.

</details>


### [29] [MPF-Net: Exposing High-Fidelity AI-Generated Video Forgeries via Hierarchical Manifold Deviation and Micro-Temporal Fluctuations](https://arxiv.org/abs/2601.21408)
*Xinan He,Kaiqing Lin,Yue Zhou,Jiaming Zhong,Wei Ye,Wenhui Yi,Bing Fan,Feng Ding,Haodong Li,Bo Cao,Bin Li*

Main category: cs.CV

TL;DR: 本文提出了一种分层级的双路径框架，通过静态流形偏差分支和微时空波动分支，检测AI生成的视频中的伪造内容，确保即使伪造内容未能在宏观场景和局部细节上明显偏离真实流形，也能被检测出来。


<details>
  <summary>Details</summary>
Motivation: 研究者注意到，尽管现代视频生成模型能生成高质量的合成内容，但在像素层面的相邻帧中仍然可能找到模式，这些模式揭示了这些视频是人工生成的，而非自然记录的。

Method: 该方法提出了一种分层级的双路径框架，通过Large-Scale Vision Foundation Models（VFM）捕捉空间上的异常，引入Micro-Temporal Fluctuation Branch进一步精细筛选，确保能够识别出不论是宏观场景还是细微时间上的伪造痕迹。

Result: 测试表明，该方法能够检测出即使完美契合自然真实场景流形的高保真伪造视频的细微异常，从而有效提升了伪造检测的准确性。

Conclusion: 这项研究为改进伪造视频检测技术提供了一个创新框架，有助于提高媒体的真实性验证能力。

Abstract: With the rapid advancement of video generation models such as Veo and Wan, the visual quality of synthetic content has reached a level where macro-level semantic errors and temporal inconsistencies are no longer prominent. However, this does not imply that the distinction between real and cutting-edge high-fidelity fake is untraceable. We argue that AI-generated videos are essentially products of a manifold-fitting process rather than a physical recording. Consequently, the pixel composition logic of consecutive adjacent frames residual in AI videos exhibits a structured and homogenous characteristic. We term this phenomenon `Manifold Projection Fluctuations' (MPF). Driven by this insight, we propose a hierarchical dual-path framework that operates as a sequential filtering process. The first, the Static Manifold Deviation Branch, leverages the refined perceptual boundaries of Large-Scale Vision Foundation Models (VFMs) to capture residual spatial anomalies or physical violations that deviate from the natural real-world manifold (off-manifold). For the remaining high-fidelity videos that successfully reside on-manifold and evade spatial detection, we introduce the Micro-Temporal Fluctuation Branch as a secondary, fine-grained filter. By analyzing the structured MPF that persists even in visually perfect sequences, our framework ensures that forgeries are exposed regardless of whether they manifest as global real-world manifold deviations or subtle computational fingerprints.

</details>


### [30] [From Implicit Ambiguity to Explicit Solidity: Diagnosing Interior Geometric Degradation in Neural Radiance Fields for Dense 3D Scene Understanding](https://arxiv.org/abs/2601.21421)
*Jiangsan Zhao,Jakob Geipel,Kryzysztof Kusnierek*

Main category: cs.CV

TL;DR: 研究探讨了NeRF在密集自遮挡场景中的可靠性问题，并提出了一种基于稀疏体素矢量化的显式几何处理方法，以提高实例恢复率。


<details>
  <summary>Details</summary>
Motivation: NeRFs在自遮挡密集场景中的定量3D分析可靠性不足，作者旨在解决这一问题。

Method: 作者通过合成数据集在不同遮挡程度下进行实验，显示出最先进的掩码监督NeRF在密集场景中的恢复率饱和在89%左右。引入基于SfM特征几何的稀疏体素矢量化方法，通过将2D实例掩码投影到显式的体素网格，并通过递归分裂确保几何分离，实现了95.8%的恢复率。

Result: 实验结果显示，使用退化分割掩码时，基于SfM的显式几何方法比隐式的恢复了43%更多的实例，证实了显式几何先验在高度自遮挡3D场景中的可靠性。

Conclusion: 研究展示了显式几何方法在密集自遮挡场景中的有效性，指出这对于可靠地进行定量3D分析是必要的。

Abstract: Neural Radiance Fields (NeRFs) have emerged as a powerful paradigm for multi-view reconstruction, complementing classical photogrammetric pipelines based on Structure-from-Motion (SfM) and Multi-View Stereo (MVS). However, their reliability for quantitative 3D analysis in dense, self-occluding scenes remains poorly understood. In this study, we identify a fundamental failure mode of implicit density fields under heavy occlusion, which we term Interior Geometric Degradation (IGD). We show that transmittance-based volumetric optimization satisfies photometric supervision by reconstructing hollow or fragmented structures rather than solid interiors, leading to systematic instance undercounting. Through controlled experiments on synthetic datasets with increasing occlusion, we demonstrate that state-of-the-art mask-supervised NeRFs saturate at approximately 89% instance recovery in dense scenes, despite improved surface coherence and mask quality. To overcome this limitation, we introduce an explicit geometric pipeline based on Sparse Voxel Rasterization (SVRaster), initialized from SfM feature geometry. By projecting 2D instance masks onto an explicit voxel grid and enforcing geometric separation via recursive splitting, our approach preserves physical solidity and achieves a 95.8% recovery rate in dense clusters. A sensitivity analysis using degraded segmentation masks further shows that explicit SfM-based geometry is substantially more robust to supervision failure, recovering 43% more instances than implicit baselines. These results demonstrate that explicit geometric priors are a prerequisite for reliable quantitative analysis in highly self-occluding 3D scenes.

</details>


### [31] [MultiModal Fine-tuning with Synthetic Captions](https://arxiv.org/abs/2601.21426)
*Shohei Enomoto,Shin'ya Yamaguchi*

Main category: cs.CV

TL;DR: 本文提出了一种将单模态数据集转换为多模态数据集的方法，通过使用多模态大语言模型生成合成图像字幕，以增强细调模型的多模态目标。该方法通过使用精心设计的提示以及监督对比损失函数和类平均文本嵌入，在多种图像分类基准测试中取得了优于基线方法的结果，特别是在少样本学习场景中。


<details>
  <summary>Details</summary>
Motivation: 本文旨在弥合预训练和细调之间的差距，尤其是随着预训练转向增强视觉理解的多模态学习，而细调仍停留在单模态。因此，通过引入多模态大语言模型生成合成图像字幕，利用单模态数据集并增强其多模态能力，以获得更多的预训练表示的利益。

Method: 方法包括使用精心设计的提示（结合类别标签和领域上下文）生成高质量的图像字幕，以及引入监督对比损失函数来鼓励在分类任务中相同类别表示的聚类。此外还提出了一种新的推理技术，利用来自每个图像多个合成字幕的类平均文本嵌入。

Result: 实验表明，该方法在13个图像分类基准测试中优于基线方法，特别是在少样本学习场景中表现出显著的性能提升。

Conclusion: 本文提出的方法建立了一个新的数据集增强范式，有效地弥合了多模态预训练和细调之间的差距，为后续多模态学习研究提供了新的思路和技术支持。

Abstract: In this paper, we address a fundamental gap between pre-training and fine-tuning of deep neural networks: while pre-training has shifted from unimodal to multimodal learning with enhanced visual understanding, fine-tuning predominantly remains unimodal, limiting the benefits of rich pre-trained representations. To bridge this gap, we propose a novel approach that transforms unimodal datasets into multimodal ones using Multimodal Large Language Models (MLLMs) to generate synthetic image captions for fine-tuning models with a multimodal objective. Our method employs carefully designed prompts incorporating class labels and domain context to produce high-quality captions tailored for classification tasks. Furthermore, we introduce a supervised contrastive loss function that explicitly encourages clustering of same-class representations during fine-tuning, along with a new inference technique that leverages class-averaged text embeddings from multiple synthetic captions per image. Extensive experiments across 13 image classification benchmarks demonstrate that our approach outperforms baseline methods, with particularly significant improvements in few-shot learning scenarios. Our work establishes a new paradigm for dataset enhancement that effectively bridges the gap between multimodal pre-training and fine-tuning. Our code is available at https://github.com/s-enmt/MMFT.

</details>


### [32] [Spava: Accelerating Long-Video Understanding via Sequence-Parallelism-aware Approximate Attention](https://arxiv.org/abs/2601.21444)
*Yuxiang Huang,Mingye Li,Xu Han,Chaojun Xiao,Weilin Zhao,Ao Sun,Ziqi Yuan,Hao Zhou,Fandong Meng,Zhiyuan Liu*

Main category: cs.CV

TL;DR: Spava提出了一个加速大型多模态模型处理长视频推理的序列并行框架，通过分布化近似注意机制减少计算量并提高并行度，同时进行系统级优化以实现显著加速。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过压缩视觉嵌入或在单张GPU上应用稀疏注意力来缓解长视频推理效率低的问题，但这种做法限制了模型处理更复杂视频的能力。为了改善这一现状，Spava框架被提出，旨在能够更高效地处理更长、更复杂的视频。

Method: Spava采用了一个序列并行框架，优化了注意力机制。它通过在多个GPU之间分配近似注意力来减少计算量并增强并行度。此外，还进行了系统级的优化，包括负载均衡和融合前向通过等。

Result: 使用Spava框架，长视频推理的速度得到了显著提升，相比FlashAttn、ZigZagRing和APB，分别实现了12.72倍、1.70倍和1.18倍的速度提升，且未对任务性能产生负面影响。

Conclusion: Spava为大规模多模态模型处理长视频推理提供了一个有效的解决方案，通过优化注意力机制和系统级优化，提升了处理效率和任务性能。

Abstract: The efficiency of long-video inference remains a critical bottleneck, mainly due to the dense computation in the prefill stage of Large Multimodal Models (LMMs). Existing methods either compress visual embeddings or apply sparse attention on a single GPU, yielding limited acceleration or degraded performance and restricting LMMs from handling longer, more complex videos. To overcome these issues, we propose Spava, a sequence-parallel framework with optimized attention that accelerates long-video inference across multiple GPUs. By distributing approximate attention, Spava reduces computation and increases parallelism, enabling efficient processing of more visual embeddings without compression and thereby improving task performance. System-level optimizations, such as load balancing and fused forward passes, further unleash the potential of Spava, delivering speedups of 12.72x, 1.70x, and 1.18x over FlashAttn, ZigZagRing, and APB, without notable performance loss. Code available at https://github.com/thunlp/APB

</details>


### [33] [Variance & Greediness: A comparative study of metric-learning losses](https://arxiv.org/abs/2601.21450)
*Donghuo Zeng,Hao Niu,Zhi Li,Masato Taya*

Main category: cs.CV

TL;DR: 研究通过引入诊断框架评估了七种代表性损失函数在五个图像检索数据集上的效果，揭示了不同损失函数在内/外类方差和贪婪度方面的差异，从而影响嵌入几何和优化动态。


<details>
  <summary>Details</summary>
Motivation: 为了更好地理解度量学习对嵌入几何和优化动力学的影响，研究引入了诊断框架来比较七种代表性损失函数。

Method: 使用VARIANCE（内/外类方差）和GREEDINESS（活动比率和梯度范数）进行评估，并在五个图像检索数据集上比较了这些损失函数的表现。

Result: 研究发现，内类方差和清晰的类间边界在细分类别设置中增强了前1个检索，而对比度和InfoNCE通过许多小更新快速紧凑地实现了嵌入，加速了收敛但可能简化了类结构。

Conclusion: 研究表明，当需要保持多样性和区分困难样本时，更倾向于Triplet/SCL，而需要更快的嵌入紧凑时，则倾向于使用Contrastive/InfoNCE。

Abstract: Metric learning is central to retrieval, yet its effects on embedding geometry and optimization dynamics are not well understood. We introduce a diagnostic framework, VARIANCE (intra-/inter-class variance) and GREEDINESS (active ratio and gradient norms), to compare seven representative losses, i.e., Contrastive, Triplet, N-pair, InfoNCE, ArcFace, SCL, and CCL, across five image-retrieval datasets. Our analysis reveals that Triplet and SCL preserve higher within-class variance and clearer inter-class margins, leading to stronger top-1 retrieval in fine-grained settings. In contrast, Contrastive and InfoNCE compact embeddings are achieved quickly through many small updates, accelerating convergence but potentially oversimplifying class structures. N-pair achieves a large mean separation but with uneven spacing. These insights reveal a form of efficiency-granularity trade-off and provide practical guidance: prefer Triplet/SCL when diversity preservation and hard-sample discrimination are critical, and Contrastive/InfoNCE when faster embedding compaction is desired.

</details>


### [34] [Mining Forgery Traces from Reconstruction Error: A Weakly Supervised Framework for Multimodal Deepfake Temporal Localization](https://arxiv.org/abs/2601.21458)
*Midou Guo,Qilin Yin,Wei Lu,Xiangyang Luo,Rui Yang*

Main category: cs.CV

TL;DR: RT-DeepLoc 通过利用 Masked Autoencoder 和 Asymmetric Intra-video Contrastive Loss 实现了细粒度的时间伪造定位，显著提高了未见伪造样本的泛化能力，达到了弱监督时间伪造定位的最新水平。


<details>
  <summary>Details</summary>
Motivation: 现代深度合成技术已发展成为局部和间歇性的操作，需要精细的时间定位。由于逐帧注释的成本极高，弱监督方法成为一种实用的选择，依赖于视频级别的标签。RT-DeepLoc 提出了一种新的框架，用于通过重建误差进行伪造识别。

Method: RT-DeepLoc 使用仅基于真实数据训练的 Masked Autoencoder 来学习其固有的时空模式，从而产生伪造段落的显著重建差异。它引入了一个新的 Asymmetric Intra-video Contrastive Loss，专注于由重建线索指导的真实特征的紧凑性，以建立稳定的决策边界，增强局部区分能力同时保持对未见伪造样本的泛化。

Result: 在大型数据集 LAV-DF 上的实验证明，RT-DeepLoc 达到了弱监督时间伪造定位的最新水平。

Conclusion: RT-DeepLoc 在弱监督时间伪造定位方面表现出色，为深度伪造检测提供了新的解决方案。

Abstract: Modern deepfakes have evolved into localized and intermittent manipulations that require fine-grained temporal localization. The prohibitive cost of frame-level annotation makes weakly supervised methods a practical necessity, which rely only on video-level labels. To this end, we propose Reconstruction-based Temporal Deepfake Localization (RT-DeepLoc), a weakly supervised temporal forgery localization framework that identifies forgeries via reconstruction errors. Our framework uses a Masked Autoencoder (MAE) trained exclusively on authentic data to learn its intrinsic spatiotemporal patterns; this allows the model to produce significant reconstruction discrepancies for forged segments, effectively providing the missing fine-grained cues for localization. To robustly leverage these indicators, we introduce a novel Asymmetric Intra-video Contrastive Loss (AICL). By focusing on the compactness of authentic features guided by these reconstruction cues, AICL establishes a stable decision boundary that enhances local discrimination while preserving generalization to unseen forgeries. Extensive experiments on large-scale datasets, including LAV-DF, demonstrate that RT-DeepLoc achieves state-of-the-art performance in weakly-supervised temporal forgery localization.

</details>


### [35] [SimGraph: A Unified Framework for Scene Graph-Based Image Generation and Editing](https://arxiv.org/abs/2601.21498)
*Thanh-Nhan Vo,Trong-Thuan Nguyen,Tam V. Nguyen,Minh-Triet Tran*

Main category: cs.CV

TL;DR: SimGraph是一种统一框架，它结合了基于场景图的图像生成和编辑，提供了对对象交互、布局和空间一致性的精确控制，实验结果表明其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前的GenAI方法在图像生成和编辑上处理方式分离，导致效率低下和空间一致性及语义连贯性问题，SimGraph旨在通过集成场景图驱动的图像生成和编辑来解决这些问题，以实现一致且高质量的结果。

Method: SimGraph通过结合基于场景图的生成令牌和基于扩散的编辑技术，创建一个单一的框架，确保对象交互、布局和空间一致性得到精确控制。

Result: SimGraph相比现有最先进的方法，在多个实验中表现出更好的性能。

Conclusion: 提出的SimGraph方法能够更有效地处理图像生成和编辑，通过集成场景图提高了控制力，实验验证了其有效性和优越性。

Abstract: Recent advancements in Generative Artificial Intelligence (GenAI) have significantly enhanced the capabilities of both image generation and editing. However, current approaches often treat these tasks separately, leading to inefficiencies and challenges in maintaining spatial consistency and semantic coherence between generated content and edits. Moreover, a major obstacle is the lack of structured control over object relationships and spatial arrangements. Scene graph-based methods, which represent objects and their interrelationships in a structured format, offer a solution by providing greater control over composition and interactions in both image generation and editing. To address this, we introduce SimGraph, a unified framework that integrates scene graph-based image generation and editing, enabling precise control over object interactions, layouts, and spatial coherence. In particular, our framework integrates token-based generation and diffusion-based editing within a single scene graph-driven model, ensuring high-quality and consistent results. Through extensive experiments, we empirically demonstrate that our approach outperforms existing state-of-the-art methods.

</details>


### [36] [HERS: Hidden-Pattern Expert Learning for Risk-Specific Vehicle Damage Adaptation in Diffusion Models](https://arxiv.org/abs/2601.21517)
*Teerapong Panboonyuen*

Main category: cs.CV

TL;DR: HERS框架旨在通过特定领域专家适应来提高文本转图像扩散模型生成的真实损伤图像的质量、可控性和领域一致性，从而改善保险行业的自动化流程，同时讨论了其在欺诈检测、可审性和安全部署方面的潜在影响。


<details>
  <summary>Details</summary>
Motivation: 随着文本转图像（T2I）扩散模型在汽车损伤合成方面的进步，生成逼真损伤图像的能力提出了信任问题。HERS框架的提出旨在解决这些问题，提高图像的现实性、可控性和领域一致性。

Method: HERS框架首先使用自监督的图像-文本对微调基础扩散模型，这些对由大型语言模型和T2I管道自动生成。接着，它将每个损伤类别视为一个单独的专家，并将这些专家统一到一个多损伤模型中。

Result: 在四种不同的扩散模型下进行评估，HERS在文本真实性提高了5.5%，人类偏好评级提高了2.3%，并且展示了在欺诈检测、可审性和安全部署方面的潜在影响。

Conclusion: 研究结果强调了领域特定扩散模型在安全关键应用（如汽车保险）中可靠生成的重要性，同时引起了对严格生成模型的广泛应用的关注。

Abstract: Recent advances in text-to-image (T2I) diffusion models have enabled increasingly realistic synthesis of vehicle damage, raising concerns about their reliability in automated insurance workflows. The ability to generate crash-like imagery challenges the boundary between authentic and synthetic data, introducing new risks of misuse in fraud or claim manipulation. To address these issues, we propose HERS (Hidden-Pattern Expert Learning for Risk-Specific Damage Adaptation), a framework designed to improve fidelity, controllability, and domain alignment of diffusion-generated damage images. HERS fine-tunes a base diffusion model via domain-specific expert adaptation without requiring manual annotation. Using self-supervised image-text pairs automatically generated by a large language model and T2I pipeline, HERS models each damage category, such as dents, scratches, broken lights, or cracked paint, as a separate expert. These experts are later integrated into a unified multi-damage model that balances specialization with generalization. We evaluate HERS across four diffusion backbones and observe consistent improvements: plus 5.5 percent in text faithfulness and plus 2.3 percent in human preference ratings compared to baselines. Beyond image fidelity, we discuss implications for fraud detection, auditability, and safe deployment of generative models in high-stakes domains. Our findings highlight both the opportunities and risks of domain-specific diffusion, underscoring the importance of trustworthy generation in safety-critical applications such as auto insurance.

</details>


### [37] [Unifying Heterogeneous Degradations: Uncertainty-Aware Diffusion Bridge Model for All-in-One Image Restoration](https://arxiv.org/abs/2601.21592)
*Luwei Tu,Jiawei Wu,Xing Luo,Zhi Jin*

Main category: cs.CV

TL;DR: 该研究提出了Uncertainty-Aware Diffusion Bridge Model (UDBM)，创新地将All-in-One图像恢复(AiOIR)问题重新表述为由像素不确定性引导的随机传输问题，通过引入一种松弛的扩散桥梁形式，将各种退化统一到一个高熵的潜空间中，实现了在单一推理步骤中的多种图像恢复任务的最佳性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理异构退化的冲突优化目标时存在局限性，通常受限于粗粒度的控制机制或固定的时间表映射，导致适应性不足。因此，为了提高图像恢复性能，该研究提出了UDBM。

Method: UDBM提出了一个放松的扩散桥梁形式，将其作为一种随机传输问题来解决AiOIR，通过路径计划和噪声计划共同调节运输轨迹，以高熵的潜空间为核心，解决了传统扩散桥梁中的漂移奇异问题。

Result: UDBM在单一推理步骤中实现了多种图像恢复任务的最新性能。

Conclusion: UDBM为理解复杂的图像退化问题，提供了更有效的解决策略，并展示了其在图形处理中的潜在应用价值。

Abstract: All-in-One Image Restoration (AiOIR) faces the fundamental challenge in reconciling conflicting optimization objectives across heterogeneous degradations. Existing methods are often constrained by coarse-grained control mechanisms or fixed mapping schedules, yielding suboptimal adaptation. To address this, we propose an Uncertainty-Aware Diffusion Bridge Model (UDBM), which innovatively reformulates AiOIR as a stochastic transport problem steered by pixel-wise uncertainty. By introducing a relaxed diffusion bridge formulation which replaces the strict terminal constraint with a relaxed constraint, we model the uncertainty of degradations while theoretically resolving the drift singularity inherent in standard diffusion bridges. Furthermore, we devise a dual modulation strategy: the noise schedule aligns diverse degradations into a shared high-entropy latent space, while the path schedule adaptively regulates the transport trajectory motivated by the viscous dynamics of entropy regularization. By effectively rectifying the transport geometry and dynamics, UDBM achieves state-of-the-art performance across diverse restoration tasks within a single inference step.

</details>


### [38] [HydroSense: A Dual-Microcontroller IoT Framework for Real-Time Multi-Parameter Water Quality Monitoring with Edge Processing and Cloud Analytics](https://arxiv.org/abs/2601.21595)
*Abdul Hasib,A. S. M. Ahsanul Sarkar Akib,Anish Giri*

Main category: cs.CV

TL;DR: HydroSense 是一种物联网框架，集成了六个关键的水质参数，使用了双微控制器架构以实现精确测量和无线连接。实验结果显示，其性能指标优于传统方法。通过降低实施成本，HydroSense 为资源匮乏地区提供了高效、经济的水质监测解决方案。


<details>
  <summary>Details</summary>
Motivation: 受全球水资源危机的推动，HydroSense 的开发旨在提供一种可负担、精确且实时的水质监控解决方案，以应对资源匮乏地区获取先进水质监控系统的困难。

Method: HydroSense 使用了双微控制器架构，利用 Arduino Uno 进行精确模拟测量和五点校准算法，以及 ESP32 实现无线连接。系统采用先进的信号处理技术如中值滤波、温度补偿算法，并具有 robust 错误处理。借助计算机视觉和 Firebase 实时数据库实施数传可靠性高的结果。

Result: HydroSense 在 pH 准确度、溶解氧（DO）稳定性、总溶解固体（TDS）准确度和云数据传输可靠性方面的性能指标均优于传统方法。pH 准确度为 0 至 14 范围内的±0.08 个单位，DO 稳定性在±0.2 mg/L，TDS 准确度为 0 至 1000 ppm 范围内的±1.9％，云数据传输可靠率达到 99.8％。

Conclusion: HydroSense 模型通过降低实施成本（约为 300 美元）实现 85％的成本节省，同时提供先进的连接性和专业级水质评估。这标志着新的可及环境监测范式，证明了通过智能系统架构和经济高效组件的选择可以实现高级水质评估。

Abstract: The global water crisis necessitates affordable, accurate, and real-time water quality monitoring solutions. Traditional approaches relying on manual sampling or expensive commercial systems fail to address accessibility challenges in resource-constrained environments. This paper presents HydroSense, an innovative Internet of Things framework that integrates six critical water quality parameters including pH, dissolved oxygen (DO), temperature, total dissolved solids (TDS), estimated nitrogen, and water level into a unified monitoring system. HydroSense employs a novel dual-microcontroller architecture, utilizing Arduino Uno for precision analog measurements with five-point calibration algorithms and ESP32 for wireless connectivity, edge processing, and cloud integration. The system implements advanced signal processing techniques including median filtering for TDS measurement, temperature compensation algorithms, and robust error handling. Experimental validation over 90 days demonstrates exceptional performance metrics: pH accuracy of plus or minus 0.08 units across the 0 to 14 range, DO measurement stability within plus or minus 0.2 mg/L, TDS accuracy of plus or minus 1.9 percent across 0 to 1000 ppm, and 99.8 percent cloud data transmission reliability. With a total implementation cost of 32,983 BDT (approximately 300 USD), HydroSense achieves an 85 percent cost reduction compared to commercial systems while providing enhanced connectivity through the Firebase real-time database. This research establishes a new paradigm for accessible environmental monitoring, demonstrating that professional-grade water quality assessment can be achieved through intelligent system architecture and cost-effective component selection.

</details>


### [39] [WMVLM: Evaluating Diffusion Model Image Watermarking via Vision-Language Models](https://arxiv.org/abs/2601.21610)
*Zijin Yang,Yu Sun,Kejiang Chen,Jiawei Zhao,Jun Jiang,Weiming Zhang,Nenghai Yu*

Main category: cs.CV

TL;DR: WMVLM 提出了一个统一且可解释的框架，用于评估生成模型中的图像水印，通过视觉-语言模型重新定义了质量和安全性指标。


<details>
  <summary>Details</summary>
Motivation: 现有方法在残差和语义水印的统一框架、可解释性、全面的安全性考虑及适合的度量标准方面存在不足，WMVLM旨在通过视觉-语言模型弥补这些不足。

Method: WMVLM 引入了一个三阶段训练策略，使模型能够逐步实现分类、评分和解释性的文本生成，同时重新定义了不同类型的水印质量及安全性的评估指标。

Result: 实验结果显示，WMVLM 在数据集、生成模型和水印方法上的普适性表现优，超越了最先进的视觉-语言模型。

Conclusion: WMVLM 是首个结合视觉-语言模型的统一且可解释的生成模型图像水印评估框架，具有重要的学术与实践意义。

Abstract: Digital watermarking is essential for securing generated images from diffusion models. Accurate watermark evaluation is critical for algorithm development, yet existing methods have significant limitations: they lack a unified framework for both residual and semantic watermarks, provide results without interpretability, neglect comprehensive security considerations, and often use inappropriate metrics for semantic watermarks. To address these gaps, we propose WMVLM, the first unified and interpretable evaluation framework for diffusion model image watermarking via vision-language models (VLMs). We redefine quality and security metrics for each watermark type: residual watermarks are evaluated by artifact strength and erasure resistance, while semantic watermarks are assessed through latent distribution shifts. Moreover, we introduce a three-stage training strategy to progressively enable the model to achieve classification, scoring, and interpretable text generation. Experiments show WMVLM outperforms state-of-the-art VLMs with strong generalization across datasets, diffusion models, and watermarking methods.

</details>


### [40] [PathReasoner-R1: Instilling Structured Reasoning into Pathology Vision-Language Model via Knowledge-Guided Policy Optimization](https://arxiv.org/abs/2601.21617)
*Songhan Jiang,Fengchun Liu,Ziyue Wang,Linghan Cai,Yongbing Zhang*

Main category: cs.CV

TL;DR: 该研究提出了PathReasoner，一个大型WSI推理数据集，并开发了PathReasoner-R1模型，结合轨迹掩蔽监督微调和推理导向的强化学习，增强模型的结构化推理能力，同时通过知识感知的多粒度奖励机制确保医学严谨性。


<details>
  <summary>Details</summary>
Motivation: 当前的VLMs在医学病理诊断中面临直接输出结论而不提供验证性证据推理的挑战，这对临床信任和专家错误纠正造成影响。为了克服这些障碍，研究构建了一个用于全切片图像推理的大规模数据集PathReasoner，旨在为病理模型提供透明且基于临床的推理能力。

Method: 研究通过利用医学知识图谱，建立了一个严谨的知识导向生成管道，生成了20000多条高质量的指导样本。基于此，提出了一种结合轨迹掩蔽监督微调和推理导向的强化学习的模型PathReasoner-R1，并使用一个知识意识的多粒度奖励函数，确保模型在提供医疗严谨性方面的逻辑一致性。

Result: 实验表明，PathReasoner-R1显著提升了病理模型的推理能力，在PathReasoner和公共基准测试中均达到了最先进的性能，在不同图像规模上表现出色。

Conclusion: 该研究通过构建PathReasoner数据集和PathReasoner-R1模型，提高了病理模型的推理能力和透明度，增强了对临床病理诊断的支持。

Abstract: Vision-Language Models (VLMs) are advancing computational pathology with superior visual understanding capabilities. However, current systems often reduce diagnosis to directly output conclusions without verifiable evidence-linked reasoning, which severely limits clinical trust and hinders expert error rectification. To address these barriers, we construct PathReasoner, the first large-scale dataset of whole-slide image (WSI) reasoning. Unlike previous work reliant on unverified distillation, we develop a rigorous knowledge-guided generation pipeline. By leveraging medical knowledge graphs, we explicitly align structured pathological findings and clinical reasoning with diagnoses, generating over 20K high-quality instructional samples. Based on the database, we propose PathReasoner-R1, which synergizes trajectory-masked supervised fine-tuning with reasoning-oriented reinforcement learning to instill structured chain-of-thought capabilities. To ensure medical rigor, we engineer a knowledge-aware multi-granular reward function incorporating an Entity Reward mechanism strictly aligned with knowledge graphs. This effectively guides the model to optimize for logical consistency rather than mere outcome matching, thereby enhancing robustness. Extensive experiments demonstrate that PathReasoner-R1 achieves state-of-the-art performance on both PathReasoner and public benchmarks across various image scales, equipping pathology models with transparent, clinically grounded reasoning capabilities. Dataset and code are available at https://github.com/cyclexfy/PathReasoner-R1.

</details>


### [41] [Similarity of Processing Steps in Vision Model Representations](https://arxiv.org/abs/2601.21621)
*Matéo Mahaut,Marco Baroni*

Main category: cs.CV

TL;DR: 本研究探讨了视觉模型在处理过程中是否存在相似的中间步骤和操作，通过量化不同模型在各个阶段的表示距离，发现尽管不同模型相似层的表示较为相似，但差异依然显著，特别是分类器模型在最终层会丢弃低级图像统计信息。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明，大型模型倾向于收敛到相似的“普遍”表示，无论训练目标、数据集或模态如何。本研究旨在更深入地了解模型在处理过程中如何达到这些通用表示，特别关注模型之间的中间步骤和操作的相似性。

Method: 该研究通过量化不同模型在各个处理阶段的距离来研究模型表示的相似性，跟踪模型距离随处理过程的变化，确定模型间最不同的处理步骤。

Result: 研究发现，尽管不同模型相似层的表示较为相似，但差异依然显著。分类器模型在最终层会丢弃低级图像统计信息；CNN-和基于Transformer的模型表现出不同行为，其中Transformer模型在相邻层间的表示变化更为平滑。

Conclusion: 研究表明，尽管模型在高层可能达到了相似的表示，但底层处理步骤和中间操作上存在明显的差异，进一步澄清了不同模型间的通用表示水平和性质。

Abstract: Recent literature suggests that the bigger the model, the more likely it is to converge to similar, ``universal'' representations, despite different training objectives, datasets, or modalities. While this literature shows that there is an area where model representations are similar, we study here how vision models might get to those representations--in particular, do they also converge to the same intermediate steps and operations? We therefore study the processes that lead to convergent representations in different models. First, we quantify distance between different model representations at different stages. We follow the evolution of distances between models throughout processing, identifying the processing steps which are most different between models. We find that while layers at similar positions in different models have the most similar representations, strong differences remain. Classifier models, unlike the others, will discard information about low-level image statistics in their final layers. CNN- and transformer-based models also behave differently, with transformer models applying smoother changes to representations from one layer to the next. These distinctions clarify the level and nature of convergence between model representations, and enables a more qualitative account of the underlying processes in image models.

</details>


### [42] [A Tilted Seesaw: Revisiting Autoencoder Trade-off for Controllable Diffusion](https://arxiv.org/abs/2601.21633)
*Pu Cao,Yiyang Ma,Feng Zhou,Xuedan Yin,Qing Song,Lu Yang*

Main category: cs.CV

TL;DR: 本文分析了在大规模ImageNet数据集上的自动编码器（AE）评估中，生成指标过度偏重的问题。AE优化倾向于生成友好但损重建准确性，从而影响条件对齐。研究表明，重建保真度尤其是实例级别的指标比全局特征距离（gFID）更能预测控制生成任务的性能，因此建议在评估AE时考虑重建指标。


<details>
  <summary>Details</summary>
Motivation: 本文的动机是纠正大规模自动编码器评估中，生成友好和重建准确性之间的不平衡问题，特别是在ImageNet等大规模数据集上。

Method: 通过理论分析，发现AE中的条件偏移限制了准确性。然后通过多维度的条件偏移评估协议验证了重建保真度对控制生成效果的影响，进一步通过ControlNet实验验证了该结论。

Result: 实验发现，全局特征距离（gFID）在条件保留方面只具有弱预测性，而重建保真度指标与条件保留更高度相关。这为更可靠的一致性评估提供了指导。

Conclusion: 文章最终结论是，AE评估需要更加注重重建保真度，更少依赖生成友好的指标，以满足可扩展可控扩散的必要条件。

Abstract: In latent diffusion models, the autoencoder (AE) is typically expected to balance two capabilities: faithful reconstruction and a generation-friendly latent space (e.g., low gFID). In recent ImageNet-scale AE studies, we observe a systematic bias toward generative metrics in handling this trade-off: reconstruction metrics are increasingly under-reported, and ablation-based AE selection often favors the best-gFID configuration even when reconstruction fidelity degrades. We theoretically analyze why this gFID-dominant preference can appear unproblematic for ImageNet generation, yet becomes risky when scaling to controllable diffusion: AEs can induce condition drift, which limits achievable condition alignment. Meanwhile, we find that reconstruction fidelity, especially instance-level measures, better indicates controllability. We empirically validate the impact of tilted autoencoder evaluation on controllability by studying several recent ImageNet AEs. Using a multi-dimensional condition-drift evaluation protocol reflecting controllable generation tasks, we find that gFID is only weakly predictive of condition preservation, whereas reconstruction-oriented metrics are substantially more aligned. ControlNet experiments further confirm that controllability tracks condition preservation rather than gFID. Overall, our results expose a gap between ImageNet-centric AE evaluation and the requirements of scalable controllable diffusion, offering practical guidance for more reliable benchmarking and model selection.

</details>


### [43] [RSGround-R1: Rethinking Remote Sensing Visual Grounding through Spatial Reasoning](https://arxiv.org/abs/2601.21634)
*Shiqi Huang,Shuting He,Bihan Wen*

Main category: cs.CV

TL;DR: 本文提出了一种新的后训练框架RSGround-R1，通过链式推理监督微调和强化学习微调来增强空间理解，该框架在遥感视觉定位基准上的实验证明了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 由于遥感场景中目标对象的位置信息和语义模糊性，在大规模空域图像中基于自然语言描述的目标物体定位是一项具有挑战性的任务。本文旨在通过构建位置感知并应用强化学习提升多模态模型在空间推理上的性能。

Method: 该方法包含链式推理监督微调(CoT-SFT)和增强学习微调(RFT)两部分。CoT-SFT使用合成的遥感视觉 grounding 数据集进行监督微调，以建立明确的位置感知。RFT则通过设计的位置奖励，在微调过程中提供连续的距离感知指导。此外，引入了基于空间一致性的优化策略，通过动态调整策略更新来确保稳定的收敛。

Result: 通过实验，该方法在遥感视觉定位基准上表现出更优异的效果，并且具有更强的泛化能力。

Conclusion: 该研究提出了一种创新的方法来处理遥感视觉定位任务中的空间推理问题，并展示了该方法的有效性。

Abstract: Remote Sensing Visual Grounding (RSVG) aims to localize target objects in large-scale aerial imagery based on natural language descriptions. Owing to the vast spatial scale and high semantic ambiguity of remote sensing scenes, these descriptions often rely heavily on positional cues, posing unique challenges for Multimodal Large Language Models (MLLMs) in spatial reasoning. To leverage this unique feature, we propose a reasoning-guided, position-aware post-training framework, dubbed \textbf{RSGround-R1}, to progressively enhance spatial understanding. Specifically, we first introduce Chain-of-Thought Supervised Fine-Tuning (CoT-SFT) using synthetically generated RSVG reasoning data to establish explicit position awareness. Reinforcement Fine-Tuning (RFT) is then applied, augmented by our newly designed positional reward that provides continuous and distance-aware guidance toward accurate localization. Moreover, to mitigate incoherent localization behaviors across rollouts, we introduce a spatial consistency guided optimization scheme that dynamically adjusts policy updates based on their spatial coherence, ensuring stable and robust convergence. Extensive experiments on RSVG benchmarks demonstrate superior performance and generalization of our model.

</details>


### [44] [OCRVerse: Towards Holistic OCR in End-to-End Vision-Language Models](https://arxiv.org/abs/2601.21639)
*Yufeng Zhong,Lei Chen,Xuanle Zhao,Wenkang Han,Liming Zheng,Jing Huang,Deyang Jiang,Yilin Cao,Lin Ma,Zhixiong Zeng*

Main category: cs.CV

TL;DR: 该技术报告提出了一种名为OCRVerse的端到端统一的大规模OCR方法，能够同时处理文本中心和视觉中心的目标，通过构建全面的数据工程和提出两阶段SFT-RL多领域训练方法来实现这一目标。


<details>
  <summary>Details</summary>
Motivation: 现有的OCR技术主要集中在识别图像或扫描文档中的文本，忽略了从图表、网页和科学图中识别视觉信息密集图像的需求。由于这些视觉信息密集的图像在互联网上广泛存在，并具有实际应用价值，如数据可视化和网页分析，因此有必要提出一种能够统一处理这两种类型的OCR技术，以满足大量多模态数据的管理与应用需求。

Method: OCRVerse采用端到端的方式整合了文本中心和视觉中心的OCR技术，通过构建全面的数据工程涵盖了文本中心和视觉中心的多种数据类型。训练方法则引入了两阶段SFT-RL方法，SFT用于建立跨域知识，而RL则设计个性化的奖励策略以适应每个领域的特性。

Result: 实验结果表明，OCRVerse在文本中心和视觉中心的数据类型上均达到了具有竞争力的效果，甚至与大型开源和自定义模型相当。

Conclusion: 这项技术报告提出的方法有效提高了OCR技术在处理视觉密集图像方面的表现，并展示了其在实际应用中的潜力。

Abstract: The development of large vision language models drives the demand for managing, and applying massive amounts of multimodal data, making OCR technology, which extracts information from visual images, increasingly popular. However, existing OCR methods primarily focus on recognizing text elements from images or scanned documents (\textbf{Text-centric OCR}), neglecting the identification of visual elements from visually information-dense image sources (\textbf{Vision-centric OCR}), such as charts, web pages and science plots. In reality, these visually information-dense images are widespread on the internet and have significant real-world application value, such as data visualization and web page analysis. In this technical report, we propose \textbf{OCRVerse}, the first holistic OCR method in end-to-end manner that enables unified text-centric OCR and vision-centric OCR. To this end, we constructe comprehensive data engineering to cover a wide range of text-centric documents, such as newspapers, magazines and books, as well as vision-centric rendered composites, including charts, web pages and scientific plots. Moreover, we propose a two-stage SFT-RL multi-domain training method for OCRVerse. SFT directly mixes cross-domain data to train and establish initial domain knowledge, while RL focuses on designing personalized reward strategies for the characteristics of each domain. Specifically, since different domains require various output formats and expected outputs, we provide sufficient flexibility in the RL stage to customize flexible reward signals for each domain, thereby improving cross-domain fusion and avoiding data conflicts. Experimental results demonstrate the effectiveness of OCRVerse, achieving competitive results across text-centric and vision-centric data types, even comparable to large-scale open-source and closed-source models.

</details>


### [45] [CAF-Mamba: Mamba-Based Cross-Modal Adaptive Attention Fusion for Multimodal Depression Detection](https://arxiv.org/abs/2601.21648)
*Bowen Zhou,Marc-André Fiedler,Ayoub Al-Hamadi*

Main category: cs.CV

TL;DR: 本文提出了一种新的跨模态自适应注意融合框架CAF-Mamba，能够明确和隐式捕捉跨模态交互，并通过模态-wise注意机制动态调整模态贡献，从而实现更有效的多模态融合。


<details>
  <summary>Details</summary>
Motivation: 当前的深度学习方法在抑郁检测方面已有成果，但大多依赖于有限的特征类型，忽视了显式的跨模态交互，仅采用简单的拼接或静态加权融合。因此，提出CAF-Mamba框架，旨在克服这些限制。

Method: CAF-Mamba框架采用了跨模态自适应注意机制，同时捕捉显式和隐式跨模态交互，并通过模态-wise注意机制动态调整模态贡献。

Result: CAF-Mamba在两个野外基准数据集LMVD和D-Vlog上进行实验，结果显示其表现优于现有方法，并达到最先进的水平。

Conclusion: 这种新的跨模态适应性注意融合框架为抑郁检测提供了新的解决方案。

Abstract: Depression is a prevalent mental health disorder that severely impairs daily functioning and quality of life. While recent deep learning approaches for depression detection have shown promise, most rely on limited feature types, overlook explicit cross-modal interactions, and employ simple concatenation or static weighting for fusion. To overcome these limitations, we propose CAF-Mamba, a novel Mamba-based cross-modal adaptive attention fusion framework. CAF-Mamba not only captures cross-modal interactions explicitly and implicitly, but also dynamically adjusts modality contributions through a modality-wise attention mechanism, enabling more effective multimodal fusion. Experiments on two in-the-wild benchmark datasets, LMVD and D-Vlog, demonstrate that CAF-Mamba consistently outperforms existing methods and achieves state-of-the-art performance.

</details>


### [46] [Few-Shot Domain Adaptation with Temporal References and Static Priors for Glacier Calving Front Delineation](https://arxiv.org/abs/2601.21663)
*Marcel Dreier,Nora Gourmelon,Dakota Pyles,Thorsten Seehaus,Matthias H. Braun,Andreas Maier,Vincent Christlein*

Main category: cs.CV

TL;DR: 通过采用少样本域适应策略并结合空间静态先验知识和夏季参考图像，将模型在新型研究站点的冰川断裂前沿分割误差从1131.6米降低到68.7米。


<details>
  <summary>Details</summary>
Motivation: 目前最先进的冰川断裂前沿分割模型在基准测试中表现出色，但应用于新研究站点时表现不佳，这推动了对改进方法的需求。

Method: 少样本域适应策略，结合空间静态先验知识以及夏季参考图像。

Result: 方法将误差降至68.7米，无需修改架构。

Conclusion: 建立了一种适用于新型研究站点的深度学习基冰川断裂前沿分割框架，可实现全球范围的监测。

Abstract: During benchmarking, the state-of-the-art model for glacier calving front delineation achieves near-human performance. However, when applied in a real-world setting at a novel study site, its delineation accuracy is insufficient for calving front products intended for further scientific analyses. This site represents an out-of-distribution domain for a model trained solely on the benchmark dataset. By employing a few-shot domain adaptation strategy, incorporating spatial static prior knowledge, and including summer reference images in the input time series, the delineation error is reduced from 1131.6 m to 68.7 m without any architectural modifications. These methodological advancements establish a framework for applying deep learning-based calving front segmentation to novel study sites, enabling calving front monitoring on a global scale.

</details>


### [47] [When Gradient Optimization Is Not Enough: $\dagger$ Dispersive and Anchoring Geometric Regularizer for Multimodal Learning](https://arxiv.org/abs/2601.21670)
*Zixuan Xia,Hao Wang,Pengcheng Weng,Yanyu Qian,Yangxin Xu,William Dan,Fei Wang*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级的几何感知正则化框架 egName，用于多模态学习，通过两个约束来优化中间嵌入：鼓励多样性内模态散布正则化和边界跨模态偏移的模态锚定正则化。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态学习方法依赖于优化，但不能确保良好的内部表示结构，即使在精细平衡的训练方案下，多模态模型仍可能表现出几何病态，如内部模态表示崩溃和样本级跨模态不一致。

Method: 本文提出了一个几何感知正则化框架 egName，它对中间嵌入施加两个约束：内模态散布正则化鼓励表示多样性，模态锚定正则化将样本级跨模态偏移限制在一定范围内但并不是严格对齐。

Result: 在多个多模态基准上进行的广泛实验显示，这种正则化方法在多模态和单模态性能方面都提高了效果，表明明确规范表示几何可以有效缓解模态之间的权衡。

Conclusion: 通过几何感知正则化，本文成功地改善了多模态学习中的表示质量和模型性能。

Abstract: Multimodal learning aims to integrate complementary information from heterogeneous modalities, yet strong optimization alone does not guaranty well-structured representations. Even under carefully balanced training schemes, multimodal models often exhibit geometric pathologies, including intra-modal representation collapse and sample-level cross-modal inconsistency, which degrade both unimodal robustness and multimodal fusion.
  We identify representation geometry as a missing control axis in multimodal learning and propose \regName, a lightweight geometry-aware regularization framework. \regName enforces two complementary constraints on intermediate embeddings: an intra-modal dispersive regularization that promotes representation diversity, and an inter-modal anchoring regularization that bounds sample-level cross-modal drift without rigid alignment. The proposed regularizer is plug-and-play, requires no architectural modifications, and is compatible with various training paradigms.
  Extensive experiments across multiple multimodal benchmarks demonstrate consistent improvements in both multimodal and unimodal performance, showing that explicitly regulating representation geometry effectively mitigates modality trade-offs.

</details>


### [48] [Multimodal Visual Surrogate Compression for Alzheimer's Disease Classification](https://arxiv.org/abs/2601.21673)
*Dexuan Ding,Ciyuan Peng,Endrowednes Kuantama,Jingcai Guo,Jia Wu,Jian Yang,Amin Beheshti,Ming-Hsuan Yang,Yuankai Qi*

Main category: cs.CV

TL;DR: 提出了一种名为Multimodal Visual Surrogate Compression (MVSC)的方法，用于将高维度的结构MRI图像压缩为紧凑的2D特征，并通过文本增强捕捉跨切片的全局上下文，从而在AD分类任务中取得比现有方法更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的sMRI表示学习方法面临高计算成本、跨切片关系丢失和难以提取特征的挑战。

Method: MVSC方法包括Volume Context Encoder和Adaptive Slice Fusion模块，分别用于捕捉文本指导下的全局跨层上下文和通过文本增强以块为单位聚合切片级信息。

Result: 在三个大规模的AD基准测试上，MVSC在二分类和多分类任务中都优于现有的方法。

Conclusion: MVSC方法能够有效地压缩和适应3D sMRI体积到紧凑的2D特征，利用文本增强的全球跨层上下文，提取强大的表示进行最终的AD分类。

Abstract: High-dimensional structural MRI (sMRI) images are widely used for Alzheimer's Disease (AD) diagnosis. Most existing methods for sMRI representation learning rely on 3D architectures (e.g., 3D CNNs), slice-wise feature extraction with late aggregation, or apply training-free feature extractions using 2D foundation models (e.g., DINO). However, these three paradigms suffer from high computational cost, loss of cross-slice relations, and limited ability to extract discriminative features, respectively. To address these challenges, we propose Multimodal Visual Surrogate Compression (MVSC). It learns to compress and adapt large 3D sMRI volumes into compact 2D features, termed as visual surrogates, which are better aligned with frozen 2D foundation models to extract powerful representations for final AD classification. MVSC has two key components: a Volume Context Encoder that captures global cross-slice context under textual guidance, and an Adaptive Slice Fusion module that aggregates slice-level information in a text-enhanced, patch-wise manner. Extensive experiments on three large-scale Alzheimer's disease benchmarks demonstrate our MVSC performs favourably on both binary and multi-class classification tasks compared against state-of-the-art methods.

</details>


### [49] [ChartE$^{3}$: A Comprehensive Benchmark for End-to-End Chart Editing](https://arxiv.org/abs/2601.21694)
*Shuo Li,Jiajun Sun,Zhekai Wang,Xiaoran Fan,Hui Li,Dingwen Yang,Zhiheng Xi,Yijun Wang,Zifei Shan,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.CV

TL;DR: ChartE$^{3}$ 是一个直接评价模型的端到端图表编辑基准，不依赖于自然语言程序或代码级监督。该基准专注于局部编辑和全局编辑两种互补的编辑维度，并提供了超过1200个高质量样本进行客观和主观的评估。


<details>
  <summary>Details</summary>
Motivation: 当前大多数方法在图表编辑中依赖于管道设计，需要使用自然语言或代码作为中间表示，限制了其对复杂编辑的准确性执行。而 ChartE$^{3}$ 直接基于图表编辑，能够更好地评估模型的实际应用效果。

Method: ChartE$^{3}$ 通过一个精心设计的数据流程和专业的人类审校，形成了超过1200个包含图表图像、代码和多模态编辑指令的数据样本，用于评估不同模型在局部和全局编辑任务上的性能。

Result: 基准测试揭示了现有的最先进的多模态大型语言模型在图表编辑中的显著性能差距，特别是在全局编辑任务上展示出的关键局限。

Conclusion: ChartE$^{3}$ 的主要结论在于指出现有的多模态模型在全局编辑任务上的不足，并强调了直接评估模型在图表编辑能力改进上的重要性。

Abstract: Charts are a fundamental visualization format for structured data analysis. Enabling end-to-end chart editing according to user intent is of great practical value, yet remains challenging due to the need for both fine-grained control and global structural consistency. Most existing approaches adopt pipeline-based designs, where natural language or code serves as an intermediate representation, limiting their ability to faithfully execute complex edits. We introduce ChartE$^{3}$, an End-to-End Chart Editing benchmark that directly evaluates models without relying on intermediate natural language programs or code-level supervision. ChartE$^{3}$ focuses on two complementary editing dimensions: local editing, which involves fine-grained appearance changes such as font or color adjustments, and global editing, which requires holistic, data-centric transformations including data filtering and trend line addition. ChartE$^{3}$ contains over 1,200 high-quality samples constructed via a well-designed data pipeline with human curation. Each sample is provided as a triplet of a chart image, its underlying code, and a multimodal editing instruction, enabling evaluation from both objective and subjective perspectives. Extensive benchmarking of state-of-the-art multimodal large language models reveals substantial performance gaps, particularly on global editing tasks, highlighting critical limitations in current end-to-end chart editing capabilities.

</details>


### [50] [DreamActor-M2: Universal Character Image Animation via Spatiotemporal In-Context Learning](https://arxiv.org/abs/2601.21716)
*Mingshuang Luo,Shuang Liang,Zhengkun Rong,Yuxuan Luo,Tianshu Hu,Ruibing Hou,Hong Chang,Yong Li,Yuan Zhang,Mingyuan Gao*

Main category: cs.CV

TL;DR: DreamActor-M2 提出了一种基于两阶段建模的动画框架，解决了身份和运动一致性之间的权衡问题，并引入了自我引导的数据合成流程来增强泛化能力。通过引入 AW Bench 基准，展示了其在多种角色和运动场景下的优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在身份保持和运动一致性之间存在权衡，过度依赖于显式姿态先验，难以捕捉复杂的动态并泛化到非拟人角色。

Method: DreamActor-M2 通过两阶段建模方法，首先将参考图像和运动线索结合到统一的潜在空间，利用生成先验推理时空身份和时间动态。其次，引入自我引导的数据合成流程生成跨身份的伪样例训练对，实现从姿态依赖控制到直接端到端 RGB 动画的无缝过渡。

Result: 该方法在多种角色和运动场景下展示了优越的性能，尤其是视觉保真度和跨域泛化能力强。

Conclusion: DreamActor-M2 是一种先进的动画框架，解决了传统方法中的两个根本问题，并通过大量的实验证明了其优越性。

Abstract: Character image animation aims to synthesize high-fidelity videos by transferring motion from a driving sequence to a static reference image. Despite recent advancements, existing methods suffer from two fundamental challenges: (1) suboptimal motion injection strategies that lead to a trade-off between identity preservation and motion consistency, manifesting as a "see-saw", and (2) an over-reliance on explicit pose priors (e.g., skeletons), which inadequately capture intricate dynamics and hinder generalization to arbitrary, non-humanoid characters. To address these challenges, we present DreamActor-M2, a universal animation framework that reimagines motion conditioning as an in-context learning problem. Our approach follows a two-stage paradigm. First, we bridge the input modality gap by fusing reference appearance and motion cues into a unified latent space, enabling the model to jointly reason about spatial identity and temporal dynamics by leveraging the generative prior of foundational models. Second, we introduce a self-bootstrapped data synthesis pipeline that curates pseudo cross-identity training pairs, facilitating a seamless transition from pose-dependent control to direct, end-to-end RGB-driven animation. This strategy significantly enhances generalization across diverse characters and motion scenarios. To facilitate comprehensive evaluation, we further introduce AW Bench, a versatile benchmark encompassing a wide spectrum of characters types and motion scenarios. Extensive experiments demonstrate that DreamActor-M2 achieves state-of-the-art performance, delivering superior visual fidelity and robust cross-domain generalization. Project Page: https://grisoon.github.io/DreamActor-M2/

</details>


### [51] [From Global to Granular: Revealing IQA Model Performance via Correlation Surface](https://arxiv.org/abs/2601.21738)
*Baoliang Chen,Danni Huang,Hanwei Zhu,Lingyu Zhu,Wei Zhou,Shiqi Wang,Yuming Fang,Weisi Lin*

Main category: cs.CV

TL;DR: 该研究提出了一种新的评估图像质量评估（IQA）模型的方法——Granularity-Modulated Correlation (GMC)，通过引入粒度调节器和分布调节器，提供了更精细和结构化的IQA性能分析。


<details>
  <summary>Details</summary>
Motivation: 传统上，IQA模型的评估主要依赖于全局相关性指标（如PLCC和SRCC），这些指标简化了性能为单一数值，无法捕捉局部质量谱上的一致性变化。GMC旨在解决这一问题，通过细粒度分析提供更可靠的IQA模型比较。

Method: GMC方法包括两个部分：粒度调节器（应用具有高斯权重的相关性，基于绝对MOS值和质量差异）和分布调节器（规范相关性以减轻非均匀质量分布带来的偏差）。其结果是一个包含相关性值的表面，作为MOS和$|Δ$MOS$|$的联合函数，提供了IQA性能的3D表示。

Result: 在标准基准测试上的实验表明，GMC揭示了单一标量指标所无法识别的性能特征，为IQA模型的分析、比较和部署提供了更丰富可靠的方式。

Conclusion: GMC提供了一种新的评价IQA模型的方式，有助于更深入理解和可靠地进行IQA模型的评估。

Abstract: Evaluation of Image Quality Assessment (IQA) models has long been dominated by global correlation metrics, such as Pearson Linear Correlation Coefficient (PLCC) and Spearman Rank-Order Correlation Coefficient (SRCC). While widely adopted, these metrics reduce performance to a single scalar, failing to capture how ranking consistency varies across the local quality spectrum. For example, two IQA models may achieve identical SRCC values, yet one ranks high-quality images (related to high Mean Opinion Score, MOS) more reliably, while the other better discriminates image pairs with small quality/MOS differences (related to $|Δ$MOS$|$). Such complementary behaviors are invisible under global metrics. Moreover, SRCC and PLCC are sensitive to test-sample quality distributions, yielding unstable comparisons across test sets. To address these limitations, we propose \textbf{Granularity-Modulated Correlation (GMC)}, which provides a structured, fine-grained analysis of IQA performance. GMC includes: (1) a \textbf{Granularity Modulator} that applies Gaussian-weighted correlations conditioned on absolute MOS values and pairwise MOS differences ($|Δ$MOS$|$) to examine local performance variations, and (2) a \textbf{Distribution Regulator} that regularizes correlations to mitigate biases from non-uniform quality distributions. The resulting \textbf{correlation surface} maps correlation values as a joint function of MOS and $|Δ$MOS$|$, providing a 3D representation of IQA performance. Experiments on standard benchmarks show that GMC reveals performance characteristics invisible to scalar metrics, offering a more informative and reliable paradigm for analyzing, comparing, and deploying IQA models. Codes are available at https://github.com/Dniaaa/GMC.

</details>


### [52] [Dynamic Topology Awareness: Breaking the Granularity Rigidity in Vision-Language Navigation](https://arxiv.org/abs/2601.21751)
*Jiankun Peng,Jianyuan Guo,Ying Xu,Yue Liu,Jiashuang Yan,Xuanwei Ye,Houhua Li,Xiaoming Wang*

Main category: cs.CV

TL;DR: DGNav 提出了一种适应环境复杂性的动态拓扑导航框架。通过场景感知的动态图构造策略和动态图变换器，使得导航模型能够根据环境的不确定性动态调整图的密度和连通性，从而提高了导航效率和安全性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于拓扑规划的视觉-语言导航方法在环境复杂度变化时存在固定的几何阈值导致的刚性问题，这会导致在简单区域过度采样，在高不确定性区域下采样，无法适应不同环境的需求。

Method: DGNav 引入了场景感知的动态图构造策略和动态图变换器。策略通过预测的地标分散度动态调整图的构建阈值；动态图变换器融合视觉、语言和几何线索，生成动态边权重，以过滤拓扑噪声，提高指令遵循度。

Result: 在 R2R-CE 和 RxR-CE 数据集上的实验表明，DGNav 在导航性能和通用能力方面表现优越，并且通过消融研究证实了框架在导航效率与安全探索之间的最佳权衡。

Conclusion: DGNav 为视觉-语言导航任务提供了一种有效的方法，能够根据环境动态调整拓扑图的结构，从而增强了导航功能的适应性和鲁棒性。

Abstract: Vision-Language Navigation in Continuous Environments (VLN-CE) presents a core challenge: grounding high-level linguistic instructions into precise, safe, and long-horizon spatial actions. Explicit topological maps have proven to be a vital solution for providing robust spatial memory in such tasks. However, existing topological planning methods suffer from a "Granularity Rigidity" problem. Specifically, these methods typically rely on fixed geometric thresholds to sample nodes, which fails to adapt to varying environmental complexities. This rigidity leads to a critical mismatch: the model tends to over-sample in simple areas, causing computational redundancy, while under-sampling in high-uncertainty regions, increasing collision risks and compromising precision. To address this, we propose DGNav, a framework for Dynamic Topological Navigation, introducing a context-aware mechanism to modulate map density and connectivity on-the-fly. Our approach comprises two core innovations: (1) A Scene-Aware Adaptive Strategy that dynamically modulates graph construction thresholds based on the dispersion of predicted waypoints, enabling "densification on demand" in challenging environments; (2) A Dynamic Graph Transformer that reconstructs graph connectivity by fusing visual, linguistic, and geometric cues into dynamic edge weights, enabling the agent to filter out topological noise and enhancing instruction adherence. Extensive experiments on the R2R-CE and RxR-CE benchmarks demonstrate DGNav exhibits superior navigation performance and strong generalization capabilities. Furthermore, ablation studies confirm that our framework achieves an optimal trade-off between navigation efficiency and safe exploration. The code is available at https://github.com/shannanshouyin/DGNav.

</details>


### [53] [MMFineReason: Closing the Multimodal Reasoning Gap via Open Data-Centric Methods](https://arxiv.org/abs/2601.21821)
*Honglin Lin,Zheng Liu,Yun Zhu,Chonghan Qin,Juekai Lin,Xiaoran Shang,Conghui He,Wentao Zhang,Lijun Wu*

Main category: cs.CV

TL;DR: 提出了一个名为MMFineReason的大型多模态推理数据集，包含1.8M样本和5.1B解决方案标记，涵盖STEM问题、视觉谜题、游戏和复杂图表，每个样本都有基于视觉的推理轨迹。该数据集通过系统的三阶段流程建立，采用难易度感知过滤策略，展示了通过多模态推理问题增强通用能力的现象。


<details>
  <summary>Details</summary>
Motivation: 当前开源Vision Language Models（VLMs）在视觉推理方面仍有不足，主要是由于缺乏高质量的推理数据。现有数据集覆盖不足，特别是在STEM图表和视觉谜题等领域，且缺乏连贯且长期的推理链（CoT）注解，这些都影响了推理能力的增强。因此，本研究旨在建立一个大型多模态推理数据集，以弥补这一差距。

Method: MMFineReason数据集构建采用了系统性的三阶段流程：1. 大规模数据采集和标准化；2. 生成推理链理由；3. 根据推理质量和难度进行全面选择。此过程使用了Qwen3-VL-235B-A22B-Thinking的推理提取技术。

Result: MMFineReason 数据集包含 1.8M 样本和 5.1B 解决方案标记，覆盖 STEM 问题、视觉谜题、游戏和复杂图表。通过微调 Qwen3-VL-Instruct，建立并展示了 2B/4B/8B 版本的模型，这些模型在各自规模类别中达到了新的 SOTA 结果。具体而言，该4B版本超过了 Qwen3-VL-8B-Thinking，而8B版本甚至超越了30B版本，显示出惊人的参数效率，并且通过难易度感知过滤策略，仅选取 7% （123K 样本）达到了与完整数据集相当的表现。

Conclusion: MMFineReason 提供了比现有数据集更广覆盖领域的高质量多模态推理数据，其构建的模型在各种规模中取得了优异的性能，证明了通过专门的推理数据增强多模态推理任务的有效性，这进一步验证了“少即是多”的现象在过往策略中的共同增益效果。

Abstract: Recent advances in Vision Language Models (VLMs) have driven significant progress in visual reasoning. However, open-source VLMs still lag behind proprietary systems, largely due to the lack of high-quality reasoning data. Existing datasets offer limited coverage of challenging domains such as STEM diagrams and visual puzzles, and lack consistent, long-form Chain-of-Thought (CoT) annotations essential for eliciting strong reasoning capabilities. To bridge this gap, we introduce MMFineReason, a large-scale multimodal reasoning dataset comprising 1.8M samples and 5.1B solution tokens, featuring high-quality reasoning annotations distilled from Qwen3-VL-235B-A22B-Thinking. The dataset is established via a systematic three-stage pipeline: (1) large-scale data collection and standardization, (2) CoT rationale generation, and (3) comprehensive selection based on reasoning quality and difficulty awareness. The resulting dataset spans STEM problems, visual puzzles, games, and complex diagrams, with each sample annotated with visually grounded reasoning traces. We fine-tune Qwen3-VL-Instruct on MMFineReason to develop MMFineReason-2B/4B/8B versions. Our models establish new state-of-the-art results for their size class. Notably, MMFineReason-4B succesfully surpasses Qwen3-VL-8B-Thinking, and MMFineReason-8B even outperforms Qwen3-VL-30B-A3B-Thinking while approaching Qwen3-VL-32B-Thinking, demonstrating remarkable parameter efficiency. Crucially, we uncover a "less is more" phenomenon via our difficulty-aware filtering strategy: a subset of just 7\% (123K samples) achieves performance comparable to the full dataset. Notably, we reveal a synergistic effect where reasoning-oriented data composition simultaneously boosts general capabilities.

</details>


### [54] [Trajectory-Guided Diffusion for Foreground-Preserving Background Generation in Multi-Layer Documents](https://arxiv.org/abs/2601.21857)
*Taewon Kang*

Main category: cs.CV

TL;DR: 本文提出了一种基于扩散的框架，用于单文档背景生成，通过潜在空间设计而非显式约束实现前景保留和多页风格一致性。该方法通过改变初始化噪声及其几何对齐来避免前景区域，无需额外机制即可保持内容可读。此外，通过对风格控制进行解耦并引入缓存的风格方向作为潜在空间中的持久向量，解决跨页面的风格漂移问题。这种方法在多页生成中无需重复的提示式风格指定，提供了一种无需训练、与现有扩散主干兼容且生成结果视觉上连贯且前景保留的方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统背景生成方法在多页文档中风格不一致的问题，本文提出了一个新的框架，通过潜在空间设计来实现背景的自动生成，同时保持前景区域的完整性。

Method: 本文的方法基于扩散模型。首先，通过重新解释扩散作为一种潜在空间中随机轨迹的演变，来生成背景。接着，通过初始噪声的几何对齐来避免前景区域。为了确保跨页面的样式一致性，引入了缓存风格方向的概念，并将其作为潜在空间中的持久向量，从而将扩散轨迹限制在共享的样式子空间中。

Result: 实验结果表明，该方法可以生成视觉上连贯且前景保留的多页文档背景，无需额外的提示式风格选择，并且能够与现有的扩散模型兼容。

Conclusion: 本文提出的方法为多页文档背景的自动生成提供了一种新的途径，通过对扩散模型的潜在空间进行操作，实现了风格的一致性和结构化生成，为生成模型提供了更加稳定的基础。

Abstract: We present a diffusion-based framework for document-centric background generation that achieves foreground preservation and multi-page stylistic consistency through latent-space design rather than explicit constraints. Instead of suppressing diffusion updates or applying masking heuristics, our approach reinterprets diffusion as the evolution of stochastic trajectories through a structured latent space. By shaping the initial noise and its geometric alignment, background generation naturally avoids designated foreground regions, allowing readable content to remain intact without auxiliary mechanisms. To address the long-standing issue of stylistic drift across pages, we decouple style control from text conditioning and introduce cached style directions as persistent vectors in latent space. Once selected, these directions constrain diffusion trajectories to a shared stylistic subspace, ensuring consistent appearance across pages and editing iterations. This formulation eliminates the need for repeated prompt-based style specification and provides a more stable foundation for multi-page generation. Our framework admits a geometric and physical interpretation, where diffusion paths evolve on a latent manifold shaped by preferred directions, and foreground regions are rarely traversed as a consequence of trajectory initialization rather than explicit exclusion. The proposed method is training-free, compatible with existing diffusion backbones, and produces visually coherent, foreground-preserving results across complex documents. By reframing diffusion as trajectory design in latent space, we offer a principled approach to consistent and structured generative modeling.

</details>


### [55] [Improving Classifier-Free Guidance of Flow Matching via Manifold Projection](https://arxiv.org/abs/2601.21892)
*Jian-Feng Cai,Haixia Liu,Zhengyi Su,Chao Wang*

Main category: cs.CV

TL;DR: 本文提出了通过对优化原理进行解释，改进无分类器引导（CFG）方法。通过流匹配中的速度场与平滑距离函数梯度之间的联系，解释了CFG的工作机制，并提出了一种新的同调优化方法来改进CFG的采样过程。


<details>
  <summary>Details</summary>
Motivation: 传统CFG方法依赖于线性外推，而这种外推对指导比例特别敏感。为了克服这个问题，本文从优化原理的角度重新解释了CFG，并提出了一种新的方法来提高其稳健性和性能。

Method: 本文通过分析流匹配中的速度场对应于平滑距离函数的梯度，提出了一种新的CFG方法，该方法被表述为具有流形约束的同调优化问题。利用此观察结果，提出了增量梯度下降方案，并引入了Anderson加速来增强迭代过程，而无需额外的模型评估。另外，所提出的框架是训练免费的。

Result: 在一系列基准测试中，包括DiT-XL-2-256，Flux和Stable Diffusion 3.5等大型模型，本文提出的方法有效提高了生成保真度、提示对齐和对指导比例的鲁棒性。

Conclusion: 本文提出的方法通过提供CFG的新解释和改进的采样方法，展示了在各种生成模型上增强技术指导生成能力的有效性。

Abstract: Classifier-free guidance (CFG) is a widely used technique for controllable generation in diffusion and flow-based models. Despite its empirical success, CFG relies on a heuristic linear extrapolation that is often sensitive to the guidance scale. In this work, we provide a principled interpretation of CFG through the lens of optimization. We demonstrate that the velocity field in flow matching corresponds to the gradient of a sequence of smoothed distance functions, which guides latent variables toward the scaled target image set. This perspective reveals that the standard CFG formulation is an approximation of this gradient, where the prediction gap, the discrepancy between conditional and unconditional outputs, governs guidance sensitivity. Leveraging this insight, we reformulate the CFG sampling as a homotopy optimization with a manifold constraint. This formulation necessitates a manifold projection step, which we implement via an incremental gradient descent scheme during sampling. To improve computational efficiency and stability, we further enhance this iterative process with Anderson Acceleration without requiring additional model evaluations. Our proposed methods are training-free and consistently refine generation fidelity, prompt alignment, and robustness to the guidance scale. We validate their effectiveness across diverse benchmarks, demonstrating significant improvements on large-scale models such as DiT-XL-2-256, Flux, and Stable Diffusion 3.5.

</details>


### [56] [Past- and Future-Informed KV Cache Policy with Salience Estimation in Autoregressive Video Diffusion](https://arxiv.org/abs/2601.21896)
*Hanmo Chen,Chenghao Xu,Xu Yang,Xuan Chen,Cheng Deng*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的时间和未来信息驱动的 KV 缓存策略（PaFu-KV），它利用双向教师提炼出的轻量级显著性估计头，来估计时间上异质的 token 贡献。这种方法在保持高效的同时提高了视频生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有的自回归视频生成方法主要依赖于启发式的 KV 缓存策略，这些策略未能考虑到长期视频生成中 token 重要性的差异，导致关键的时空信息丢失和缓存中积累的冗余无效数据。

Method: PaFu-KV 引入了一种轻量级的显著性估计头，从双向教师中提炼出，用于估计 token 的显著性评分。这种方法可以使 KV 缓存保留更有信息量的 token，同时丢弃不相关的 token。

Result: 实验结果表明，PaFu-KV 在保持高保真度视频生成质量的同时，能够加速推理过程，从而使得长期视频生成更加高效。

Conclusion: 本文提出的方法可以显著提高自回归视频生成中的质量和效率，并将在论文接受后开源。

Abstract: Video generation is pivotal to digital media creation, and recent advances in autoregressive video generation have markedly enhanced the efficiency of real-time video synthesis. However, existing approaches generally rely on heuristic KV Cache policies, which ignore differences in token importance in long-term video generation. This leads to the loss of critical spatiotemporal information and the accumulation of redundant, invalid cache, thereby degrading video generation quality and efficiency. To address this limitation, we first observe that token contributions to video generation are highly time-heterogeneous and accordingly propose a novel Past- and Future-Informed KV Cache Policy (PaFu-KV). Specifically, PaFu-KV introduces a lightweight Salience Estimation Head distilled from a bidirectional teacher to estimate salience scores, allowing the KV cache to retain informative tokens while discarding less relevant ones. This policy yields a better quality-efficiency trade-off by shrinking KV cache capacity and reducing memory footprint at inference time. Extensive experiments on benchmarks demonstrate that our method preserves high-fidelity video generation quality while enables accelerated inference, thereby enabling more efficient long-horizon video generation. Our code will be released upon paper acceptance.

</details>


### [57] [TraceRouter: Robust Safety for Large Foundation Models via Path-Level Intervention](https://arxiv.org/abs/2601.21900)
*Chuancheng Shi,Shangze Li,Wenjun Lu,Wenhua Wu,Cong Wang,Zifeng Cheng,Fei Shen,Tat-Seng Chua*

Main category: cs.CV

TL;DR: 本文提出了一种名为TraceRouter的方法，用于防止大型基础模型受到恶意语义的篡改，通过路径级别框架追踪和切断潜在有害语义的因果传播电路。


<details>
  <summary>Details</summary>
Motivation: 当前的防御方法主要依赖局部假设，抑制孤立的神经元或特征，但对于分布式、跨层的恶意语义效果不佳，因此需要一种新的方法来有效防御这些恶意形式。

Method: TraceRouter方法分为三个阶段：首先通过注意力变化定位敏感层；其次利用稀疏自编码器和差异激活分析分离恶意特征；最后通过特征影响分数映射这些特征到下游因果路径。

Result: 实验结果表明，与现有最先进的基准方法相比，TraceRouter在对抗鲁棒性和通用效用之间实现了更好的权衡。

Conclusion: 本文展示了TraceRouter方法的有效性，并进行了公开代码的发布。

Abstract: Despite their capabilities, large foundation models (LFMs) remain susceptible to adversarial manipulation. Current defenses predominantly rely on the "locality hypothesis", suppressing isolated neurons or features. However, harmful semantics act as distributed, cross-layer circuits, rendering such localized interventions brittle and detrimental to utility. To bridge this gap, we propose \textbf{TraceRouter}, a path-level framework that traces and disconnects the causal propagation circuits of illicit semantics. TraceRouter operates in three stages: (1) it pinpoints a sensitive onset layer by analyzing attention divergence; (2) it leverages sparse autoencoders (SAEs) and differential activation analysis to disentangle and isolate malicious features; and (3) it maps these features to downstream causal pathways via feature influence scores (FIS) derived from zero-out interventions. By selectively suppressing these causal chains, TraceRouter physically severs the flow of harmful information while leaving orthogonal computation routes intact. Extensive experiments demonstrate that TraceRouter significantly outperforms state-of-the-art baselines, achieving a superior trade-off between adversarial robustness and general utility. Our code will be publicly released. WARNING: This paper contains unsafe model responses.

</details>


### [58] [Beyond Global Alignment: Fine-Grained Motion-Language Retrieval via Pyramidal Shapley-Taylor Learning](https://arxiv.org/abs/2601.21904)
*Hanmo Chen,Guangtao Lyu,Chenghao Xu,Jiexi Yan,Xu Yang,Cheng Deng*

Main category: cs.CV

TL;DR: 本文提出了一种新的金字塔式Shapley-Taylor（PST）学习框架，用于细粒度的运动-语言检索。该框架通过分层关节和段落级别的对齐来解构人体运动，并学习跨模态对应关系，从而捕捉局部语义细节和层次结构关系。


<details>
  <summary>Details</summary>
Motivation: 现有的方法主要集中在全局文本表示与整个运动序列的对齐，忽略了局部运动片段、身体关节和文本词汇之间的细微交互，导致检索性能不佳。本文提出的PST框架旨在解决这一问题。

Method: PST框架将人体运动分解为时间上的段和空间上的身体关节，通过层级的、关节级和段落级的对齐来学习跨模态对应关系。该方法从关节动力学到片段连贯性，再到整体理解，模仿人类对运动的感知过程，有效捕捉局部语义细节和层次结构关系。

Result: 在多个公开的标准数据集上的实验证明，PST方法显著优于最先进的方法，实现了运动片段及其相应文本词汇之间的精确对齐。

Conclusion: 通过PST框架，本文提出了一个有效的细粒度运动-语言检索模型，该模型能够捕捉局部语义细节和层次结构关系，从而提高了检索性能。

Abstract: As a foundational task in human-centric cross-modal intelligence, motion-language retrieval aims to bridge the semantic gap between natural language and human motion, enabling intuitive motion analysis, yet existing approaches predominantly focus on aligning entire motion sequences with global textual representations. This global-centric paradigm overlooks fine-grained interactions between local motion segments and individual body joints and text tokens, inevitably leading to suboptimal retrieval performance. To address this limitation, we draw inspiration from the pyramidal process of human motion perception (from joint dynamics to segment coherence, and finally to holistic comprehension) and propose a novel Pyramidal Shapley-Taylor (PST) learning framework for fine-grained motion-language retrieval. Specifically, the framework decomposes human motion into temporal segments and spatial body joints, and learns cross-modal correspondences through progressive joint-wise and segment-wise alignment in a pyramidal fashion, effectively capturing both local semantic details and hierarchical structural relationships. Extensive experiments on multiple public benchmark datasets demonstrate that our approach significantly outperforms state-of-the-art methods, achieving precise alignment between motion segments and body joints and their corresponding text tokens. The code of this work will be released upon acceptance.

</details>


### [59] [VideoAesBench: Benchmarking the Video Aesthetics Perception Capabilities of Large Multimodal Models](https://arxiv.org/abs/2601.21915)
*Yunhao Li,Sijing Wu,Zhilin Gao,Zicheng Zhang,Qi Jia,Huiyu Duan,Xiongkuo Min,Guangtao Zhai*

Main category: cs.CV

TL;DR: 引入了VideoAesBench，这是一个评估大跨模态模型在视频审美质量方面理解能力的基准，包含多种多样的视频内容和提问方式，展示了当前LMMs在这方面的局限性，旨在推动视频审美评估的发展。


<details>
  <summary>Details</summary>
Motivation: 由于大跨模态模型在多项视觉感知任务中表现出色，其在视频审美质量评价方面的能力显得尤为重要但尚未被充分研究。因此，为了解决这一问题，提出了VideoAesBench这一全面基准。

Method: 构建了一个包含不同来源的1,804个视频的基准，采用丰富的问题形式和三维视频审美维度进行评估。

Result: 当前的大跨模态模型在视频审美感知能力方面存在局限，功能不完整且不够精确。

Conclusion: VideoAesBench旨在成为视频审美评估的测试平台，并提供可解释的驱动，促进该领域的发展。

Abstract: Large multimodal models (LMMs) have demonstrated outstanding capabilities in various visual perception tasks, which has in turn made the evaluation of LMMs significant. However, the capability of video aesthetic quality assessment, which is a fundamental ability for human, remains underexplored for LMMs. To address this, we introduce VideoAesBench, a comprehensive benchmark for evaluating LMMs' understanding of video aesthetic quality. VideoAesBench has several significant characteristics: (1) Diverse content including 1,804 videos from multiple video sources including user-generated (UGC), AI-generated (AIGC), compressed, robotic-generated (RGC), and game videos. (2) Multiple question formats containing traditional single-choice questions, multi-choice questions, True or False questions, and a novel open-ended questions for video aesthetics description. (3) Holistic video aesthetics dimensions including visual form related questions from 5 aspects, visual style related questions from 4 aspects, and visual affectiveness questions from 3 aspects. Based on VideoAesBench, we benchmark 23 open-source and commercial large multimodal models. Our findings show that current LMMs only contain basic video aesthetics perception ability, their performance remains incomplete and imprecise. We hope our VideoAesBench can be served as a strong testbed and offer insights for explainable video aesthetics assessment.

</details>


### [60] [Zero-Shot Video Restoration and Enhancement with Assistance of Video Diffusion Models](https://arxiv.org/abs/2601.21922)
*Cong Cao,Huanjing Yue,Shangbin Xie,Xin Liu,Jingyu Yang*

Main category: cs.CV

TL;DR: 提出了一种结合视频扩散模型的框架，用于辅助零样本视频恢复和增强，以保持更强的时间一致性。


<details>
  <summary>Details</summary>
Motivation: 当前的扩散模型在视频恢复或增强中普遍存在严重的帧间闪烁问题，本文通过引入视频扩散模型辅助图像方法来解决此问题。

Method: 提出了同质潜变量融合、异质潜变量融合及基于COT的融合比例策略，结合文本到视频的同质和异质扩散模型以及图像到视频的扩散模型，提高时间一致性。此外，提出了一种暂态加权后处理策略。

Result: 实验结果表明该方法在零样本视频恢复和增强中具有显著优势。

Conclusion: 该方法无需训练即可应用于任何基于扩散模型的图像恢复和增强方法。

Abstract: Although diffusion-based zero-shot image restoration and enhancement methods have achieved great success, applying them to video restoration or enhancement will lead to severe temporal flickering. In this paper, we propose the first framework that utilizes the rapidly-developed video diffusion model to assist the image-based method in maintaining more temporal consistency for zero-shot video restoration and enhancement. We propose homologous latents fusion, heterogenous latents fusion, and a COT-based fusion ratio strategy to utilize both homologous and heterogenous text-to-video diffusion models to complement the image method. Moreover, we propose temporal-strengthening post-processing to utilize the image-to-video diffusion model to further improve temporal consistency. Our method is training-free and can be applied to any diffusion-based image restoration and enhancement methods. Experimental results demonstrate the superiority of the proposed method.

</details>


### [61] [Just Noticeable Difference Modeling for Deep Visual Features](https://arxiv.org/abs/2601.21933)
*Rui Zhao,Wenrui Li,Lin Zhu,Yajing Zheng,Weisi Lin*

Main category: cs.CV

TL;DR: 本文提出了一种任务对齐的JND（JND）形式化方法FeatJND，用于预测保持下游任务性能时的最大可容忍特征位移图。该方法在图像分类、目标检测和实例分割任务上进行了验证，表明基于FeatJND的扰动可以更好地保持任务性能，同时还可以指导基于特征的动态量化。


<details>
  <summary>Details</summary>
Motivation: 由于深度视觉特征在视觉系统中扮演重要角色，因此需要描述特征特性并控制特征质量以满足机器感知的需求。

Method: 我们采用了一种新的方法FeatJND来预测可持续保持下游任务性能的最大可容忍特征扰动图。该方法在图像分类、目标检测和实例分割任务上的性能进行了验证。

Result: 实验结果表明，使用FeatJND进行扰动时，可以比随机步长置换和全局统一步长获得更好的任务性能。此外，Attribution可视化也表明FeatJND可以抑制非关键特征区域。

Conclusion: 实验验证了FeatJND的有效性，估计器在各类任务中均可有效应用，并且在量化过程中对步长分配具有指导意义。

Abstract: Deep visual features are increasingly used as the interface in vision systems, motivating the need to describe feature characteristics and control feature quality for machine perception. Just noticeable difference (JND) characterizes the maximum imperceptible distortion for images under human or machine vision. Extending it to deep visual features naturally meets the above demand by providing a task-aligned tolerance boundary in feature space, offering a practical reference for controlling feature quality under constrained resources. We propose FeatJND, a task-aligned JND formulation that predicts the maximum tolerable per-feature perturbation map while preserving downstream task performance. We propose a FeatJND estimator at standardized split points and validate it across image classification, detection, and instance segmentation. Under matched distortion strength, FeatJND-based distortions consistently preserve higher task performance than unstructured Gaussian perturbations, and attribution visualizations suggest FeatJND can suppress non-critical feature regions. As an application, we further apply FeatJND to token-wise dynamic quantization and show that FeatJND-guided step-size allocation yields clear gains over random step-size permutation and global uniform step size under the same noise budget. Our code will be released after publication.

</details>


### [62] [BookNet: Book Image Rectification via Cross-Page Attention Network](https://arxiv.org/abs/2601.21938)
*Shaokai Liu,Hao Feng,Bozhi Luan,Min Hou,Jiajun Deng,Wengang Zhou*

Main category: cs.CV

TL;DR: BookNet 提供了一种端到端的深度学习框架，专门用于双页书本图像校正，通过跨页注意力机制捕捉相邻页面间的几何耦合关系，并提供了 Book3D 和 Book100 数据集以支持训练和评估。


<details>
  <summary>Details</summary>
Motivation: 现有的单页文档图像校正方法无法捕捉书籍中相邻页面之间的耦合几何关系，本研究旨在解决这一问题。

Method: BookNet 采用双分支结构并带有跨页注意力机制来估计单个页面和整本书籍的扭曲流，明确建模左页和右页之间的相互影响。

Result: 实验表明，BookNet 在图书图像校正方面的表现优于现有最先进的方法。

Conclusion: BookNet 和相关的数据集将对相关领域的研究起到推动作用。

Abstract: Book image rectification presents unique challenges in document image processing due to complex geometric distortions from binding constraints, where left and right pages exhibit distinctly asymmetric curvature patterns. However, existing single-page document image rectification methods fail to capture the coupled geometric relationships between adjacent pages in books. In this work, we introduce BookNet, the first end-to-end deep learning framework specifically designed for dual-page book image rectification. BookNet adopts a dual-branch architecture with cross-page attention mechanisms, enabling it to estimate warping flows for both individual pages and the complete book spread, explicitly modeling how left and right pages influence each other. Moreover, to address the absence of specialized datasets, we present Book3D, a large-scale synthetic dataset for training, and Book100, a comprehensive real-world benchmark for evaluation. Extensive experiments demonstrate that BookNet outperforms existing state-of-the-art methods on book image rectification. Code and dataset will be made publicly available.

</details>


### [63] [Deep Models, Shallow Alignment: Uncovering the Granularity Mismatch in Neural Decoding](https://arxiv.org/abs/2601.21948)
*Yang Du,Siyuan Dai,Yonghao Song,Paul M. Thompson,Haoteng Tang,Liang Zhan*

Main category: cs.CV

TL;DR: 本文提出了一种新的对比学习策略，称为浅层对齐，它在不对齐最终输出的情况下，将神经信号与视觉编码器的中间表示进行对齐，从而在低层次纹理细节和高层次语义特征之间取得更好的平衡。实验结果显示，与传统的最终层对齐相比，浅层对齐在多种基准上的性能提高了22%到58%，并展示了解码性能与预训练视觉模型容量之间的可预测性增长规律。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视了人类和机器视觉之间基本的粒度不匹配问题，本文提出消除这种不匹配，以提高神经视觉解码的性能。

Method: 浅层对齐是一种新的对比学习策略，它对齐神经信号与视觉编码器的中间表示而非最终输出。

Result: 实验结果表明，浅层对齐在多个基准上显著优于传统的最终层对齐，性能提高了22%到58%。此外，它还揭示了深度学习模型的容量与解码性能之间的可预测性增长规律。

Conclusion: 通过引入浅层对齐，本文提出的方法不仅在现有模型上取得了更好的性能，还推动了该领域的发展，为未来研究提供了新的思路。

Abstract: Neural visual decoding is a central problem in brain computer interface research, aiming to reconstruct human visual perception and to elucidate the structure of neural representations. However, existing approaches overlook a fundamental granularity mismatch between human and machine vision, where deep vision models emphasize semantic invariance by suppressing local texture information, whereas neural signals preserve an intricate mixture of low-level visual attributes and high-level semantic content. To address this mismatch, we propose Shallow Alignment, a novel contrastive learning strategy that aligns neural signals with intermediate representations of visual encoders rather than their final outputs, thereby striking a better balance between low-level texture details and high-level semantic features. Extensive experiments across multiple benchmarks demonstrate that Shallow Alignment significantly outperforms standard final-layer alignment, with performance gains ranging from 22% to 58% across diverse vision backbones. Notably, our approach effectively unlocks the scaling law in neural visual decoding, enabling decoding performance to scale predictably with the capacity of pre-trained vision backbones. We further conduct systematic empirical analyses to shed light on the mechanisms underlying the observed performance gains.

</details>


### [64] [PaddleOCR-VL-1.5: Towards a Multi-Task 0.9B VLM for Robust In-the-Wild Document Parsing](https://arxiv.org/abs/2601.21957)
*Cheng Cui,Ting Sun,Suyin Liang,Tingquan Gao,Zelun Zhang,Jiaxuan Liu,Xueqing Wang,Changda Zhou,Hongen Liu,Manhui Lin,Yue Zhang,Yubo Zhang,Yi Liu,Dianhai Yu,Yanjun Ma*

Main category: cs.CV

TL;DR: PaddleOCR-VL-1.5是一款升级版模型，在OmniDocBench v1.5上取得了94.5%的新SOTA准确性。该模型在实世界物理扭曲的严格评估中表现出色，同时支持印章识别和文本定位任务，体积仅为0.9B。


<details>
  <summary>Details</summary>
Motivation: 为了评估OCR模型在实际应用场景中的鲁棒性，设计了一个包含扫描、倾斜、扭曲、屏幕摄影和照明等多种物理因素的Real5-OmniDocBench基准测试。

Method: 该方法通过引入一个新的基准测试，即Real5-OmniDocBench，来评估模型在面对现实世界物理扭曲时的性能。

Result: 通过引入新的基准测试，PaddleOCR-VL-1.5在新的基准上达到了SOTA性能，并且在包括印章识别和文本定位在内的多种任务上表现优秀。

Conclusion: 该模型不仅在复杂场景下表现出色，同时保持了高效率和小型化的优点，证明了其在实际场景下应用的可能性。

Abstract: We introduce PaddleOCR-VL-1.5, an upgraded model achieving a new state-of-the-art (SOTA) accuracy of 94.5% on OmniDocBench v1.5. To rigorously evaluate robustness against real-world physical distortions, including scanning, skew, warping, screen-photography, and illumination, we propose the Real5-OmniDocBench benchmark. Experimental results demonstrate that this enhanced model attains SOTA performance on the newly curated benchmark. Furthermore, we extend the model's capabilities by incorporating seal recognition and text spotting tasks, while remaining a 0.9B ultra-compact VLM with high efficiency. Code: https://github.com/PaddlePaddle/PaddleOCR

</details>


### [65] [Causal World Modeling for Robot Control](https://arxiv.org/abs/2601.21998)
*Lin Li,Qihang Zhang,Yiming Luo,Shuai Yang,Ruilin Wang,Fei Han,Mingrui Yu,Zelin Gao,Nan Xue,Xing Zhu,Yujun Shen,Yinghao Xu*

Main category: cs.CV

TL;DR: 该研究提出了一种名为LingBot-VA的自回归扩散框架，将帧预测与策略执行同时学习。模型通过一个共享的潜空间将视觉和动作标记相结合，采用混合变换器架构，并设计了闭环回放机制和异步推理管道来优化控制效率。该模型在模拟基准和真实世界场景中的评估显示了其在长时间操作、后训练中的高效数据利用和对新型配置的强大适应性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索一种新的模型框架，该框架能够在机器人学习中建立视觉语言预训练和视频世界建模之间新的独立基础，增强对因果关系的理解并改善未来时间步的操作预测。

Method: 该模型采用了一个自回归扩散框架，结合了共享潜空间设计、闭环回放机制和异步推理管道三个特点，运用混合变换器架构进行视觉和动作信息的处理。

Result: 研究结果表明，LingBot-VA模型能够显著提高长时操作的表现，在后训练中展现出高效的数据利用能力，并具有良好的泛化能力，特别是在面对新配置时。

Conclusion: 该研究的成功证明了结合视频世界建模与视觉语言预训练对提高机器人学习性能的重要性，并为未来的机器人研究提供了新的探索方向。

Abstract: This work highlights that video world modeling, alongside vision-language pre-training, establishes a fresh and independent foundation for robot learning. Intuitively, video world models provide the ability to imagine the near future by understanding the causality between actions and visual dynamics. Inspired by this, we introduce LingBot-VA, an autoregressive diffusion framework that learns frame prediction and policy execution simultaneously. Our model features three carefully crafted designs: (1) a shared latent space, integrating vision and action tokens, driven by a Mixture-of-Transformers (MoT) architecture, (2) a closed-loop rollout mechanism, allowing for ongoing acquisition of environmental feedback with ground-truth observations, (3) an asynchronous inference pipeline, parallelizing action prediction and motor execution to support efficient control. We evaluate our model on both simulation benchmarks and real-world scenarios, where it shows significant promise in long-horizon manipulation, data efficiency in post-training, and strong generalizability to novel configurations. The code and model are made publicly available to facilitate the community.

</details>


### [66] [Drive-JEPA: Video JEPA Meets Multimodal Trajectory Distillation for End-to-End Driving](https://arxiv.org/abs/2601.22032)
*Linhan Wang,Zichong Yang,Chen Bai,Guoxiang Zhang,Xiaotong Liu,Xiaoyin Zheng,Xiao-Xiao Long,Chang-Tien Lu,Cheng Lu*

Main category: cs.CV

TL;DR: 提出了一种称为Drive-JEPA的框架，结合了视频联合嵌入预测架构（V-JEPA）和多模态轨迹蒸馏，用于端到端的自动驾驶，显著提升了驾驶表现。


<details>
  <summary>Details</summary>
Motivation: 传统的视频预训练方法在场景理解方面带来有限的改进，且驾驶中的场景通常只能提供单一的人类轨迹，使得学习多模态行为变得困难。因此，为了克服这些挑战，本文提出了Drive-JEPA框架。

Method: Drive-JEPA框架首先将V-JEPA适应于端到端驾驶，使用大规模驾驶视频预训练ViT编码器，产生与轨迹规划对齐的预测表示。其次，引入了以提案为中心的规划者，通过与人类轨迹一起蒸馏多样的模拟器生成轨迹，并采用一种前瞻性选择机制来促进稳定和安全的行为。

Result: 在无感知设置中，V-JEPA表示结合简单的基于变换器的解码器超过了之前的最佳方法3 PDMS。完整的Drive-JEPA框架在v1上达到了93.3 PDMS，在v2上达到了87.8 EPDMS，创下了新的最佳状态。

Conclusion: Drive-JEPA框架通过结合视频联合嵌入预测架构和多模态轨迹蒸馏，显著改善了端到端驾驶的表现，为未来的自动驾驶技术提供了新的解决方案。

Abstract: End-to-end autonomous driving increasingly leverages self-supervised video pretraining to learn transferable planning representations. However, pretraining video world models for scene understanding has so far brought only limited improvements. This limitation is compounded by the inherent ambiguity of driving: each scene typically provides only a single human trajectory, making it difficult to learn multimodal behaviors. In this work, we propose Drive-JEPA, a framework that integrates Video Joint-Embedding Predictive Architecture (V-JEPA) with multimodal trajectory distillation for end-to-end driving. First, we adapt V-JEPA for end-to-end driving, pretraining a ViT encoder on large-scale driving videos to produce predictive representations aligned with trajectory planning. Second, we introduce a proposal-centric planner that distills diverse simulator-generated trajectories alongside human trajectories, with a momentum-aware selection mechanism to promote stable and safe behavior. When evaluated on NAVSIM, the V-JEPA representation combined with a simple transformer-based decoder outperforms prior methods by 3 PDMS in the perception-free setting. The complete Drive-JEPA framework achieves 93.3 PDMS on v1 and 87.8 EPDMS on v2, setting a new state-of-the-art.

</details>


### [67] [Urban Neural Surface Reconstruction from Constrained Sparse Aerial Imagery with 3D SAR Fusion](https://arxiv.org/abs/2601.22045)
*Da Li,Chen Yao,Tong Mao,Jiacheng Bao,Houjun Sun*

Main category: cs.CV

TL;DR: 该研究提出了一种新的城市表面重建框架，结合3D合成孔径雷达(SAR)点云和航空图像，以增强在受限、稀疏视点条件下的高保真度重建。


<details>
  <summary>Details</summary>
Motivation: 传统的城市表面重建方法在稀疏视点条件下存在几何模糊和不稳定的问题，特别是在大规模城市遥感中，航空图像采集受限于飞行路径、地形和成本。

Method: 该框架将3D SAR提供的空间约束信息整合到基于SDF的城市表面重建模型中，通过引导结构感知的射线选择和自适应采样来实现稳定和高效的优化。

Result: 实验结果表明，结合3D SAR显著提高了在高度稀疏和斜视条件下的重建精度、完整性和鲁棒性，与单一模态基线相比具有明显优势。

Conclusion: 该研究提出的方法为大规模高保真城市重建提供了实用途径，并强调了利用先进机载和星载光学-SAR 成像的潜在优势。

Abstract: Neural surface reconstruction (NSR) has recently shown strong potential for urban 3D reconstruction from multi-view aerial imagery. However, existing NSR methods often suffer from geometric ambiguity and instability, particularly under sparse-view conditions. This issue is critical in large-scale urban remote sensing, where aerial image acquisition is limited by flight paths, terrain, and cost. To address this challenge, we present the first urban NSR framework that fuses 3D synthetic aperture radar (SAR) point clouds with aerial imagery for high-fidelity reconstruction under constrained, sparse-view settings. 3D SAR can efficiently capture large-scale geometry even from a single side-looking flight path, providing robust priors that complement photometric cues from images. Our framework integrates radar-derived spatial constraints into an SDF-based NSR backbone, guiding structure-aware ray selection and adaptive sampling for stable and efficient optimization. We also construct the first benchmark dataset with co-registered 3D SAR point clouds and aerial imagery, facilitating systematic evaluation of cross-modal 3D reconstruction. Extensive experiments show that incorporating 3D SAR markedly enhances reconstruction accuracy, completeness, and robustness compared with single-modality baselines under highly sparse and oblique-view conditions, highlighting a viable route toward scalable high-fidelity urban reconstruction with advanced airborne and spaceborne optical-SAR sensing.

</details>


### [68] [MetricAnything: Scaling Metric Depth Pretraining with Noisy Heterogeneous Sources](https://arxiv.org/abs/2601.22054)
*Baorui Ma,Jiahui Yang,Donglin Di,Xuancheng Zhang,Jianxun Cui,Hao Li,Yan Xie,Wei Chen*

Main category: cs.CV

TL;DR: Metric Anything 提出了一种新的预训练框架，能够从异质噪声传感器数据中学习元深度，无需手动标记提示、特定于相机的建模或特定任务的架构。该框架通过随机掩蔽深度图来创建Sparse Metric Prompt，以此来解耦空间推理和传感器/相机偏见。通过大规模数据集的预训练，该模型在多种任务上展现了卓越的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的深度估计方法在处理异质噪声传感器数据、相机依赖性偏差以及存在噪声的多源3D数据时存在挑战。Metric Anything 的目标是通过采用通用接口来学习元深度，从而解决这些问题，实现可扩展的预训练，并且在多元任务中表现良好。

Method: Metric Anything 使用随机掩蔽深度图的 Sparse Metric Prompt 方法，它作为一种通用接口，解耦了空间推理和传感器/相机偏见。采用约2000万张图像-深度图对来培训模型，覆盖了从重建到捕捉的数据，横跨10000种不同的相机模型。通过这种方法，模型能够在多个任务上表现出色。

Result: 预训练模型在深度完成任务、超分辨率以及雷达-相机融合任务上表现出色。其经过蒸馏的学生模型在单目深度估计、相机内参恢复、单视角或多视角元3D重建以及VLA规划任务上达到最先进的结果。使用预训练的 Metric Anything ViT 作为视觉编码器能显著提升多模态大语言模型在空间智能领域的表现。

Conclusion: Metric Anything 的研究结果表明，元深度估计可以从驱动现代基础模型扩展的同一扩展法则中获益，为可扩展和高效的真实世界元感知建立了新的途径。该模型可以支持社区研究，促进相关领域的探索和发展。

Abstract: Scaling has powered recent advances in vision foundation models, yet extending this paradigm to metric depth estimation remains challenging due to heterogeneous sensor noise, camera-dependent biases, and metric ambiguity in noisy cross-source 3D data. We introduce Metric Anything, a simple and scalable pretraining framework that learns metric depth from noisy, diverse 3D sources without manually engineered prompts, camera-specific modeling, or task-specific architectures. Central to our approach is the Sparse Metric Prompt, created by randomly masking depth maps, which serves as a universal interface that decouples spatial reasoning from sensor and camera biases. Using about 20M image-depth pairs spanning reconstructed, captured, and rendered 3D data across 10000 camera models, we demonstrate-for the first time-a clear scaling trend in the metric depth track. The pretrained model excels at prompt-driven tasks such as depth completion, super-resolution and Radar-camera fusion, while its distilled prompt-free student achieves state-of-the-art results on monocular depth estimation, camera intrinsics recovery, single/multi-view metric 3D reconstruction, and VLA planning. We also show that using pretrained ViT of Metric Anything as a visual encoder significantly boosts Multimodal Large Language Model capabilities in spatial intelligence. These results show that metric depth estimation can benefit from the same scaling laws that drive modern foundation models, establishing a new path toward scalable and efficient real-world metric perception. We open-source MetricAnything at http://metric-anything.github.io/metric-anything-io/ to support community research.

</details>


### [69] [Unsupervised Decomposition and Recombination with Discriminator-Driven Diffusion Models](https://arxiv.org/abs/2601.22057)
*Archer Wang,Emile Anand,Yilun Du,Marin Soljačić*

Main category: cs.CV

TL;DR: 该研究通过引入对抗训练信号来提高复杂数据的分解和组合生成的质量，实现了在多个数据集上的优越性能，并应用于生成多样化的机器人视频轨迹以提高探索性能。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于利用分解复杂数据的因子表示，揭示可重用组件，以助力合成新的样本。对抗训练信号的引入旨在提升潜在因子发现的准确性和生成样本的组合质量。

Method: 该方法采用对抗训练策略优化生成器，通过训练一个判别器来区分单源样本与因子重组生成的样本，促使生成器生成与物理和语义一致的重组结果。

Result: 该研究在CelebA-HQ、Virtual KITTI、CLEVR、Falcor3D等多个数据集上优于先前baseline模型，实现了更低的FID得分和更好的语义解缠能力。并在机器人视频轨迹的应用中，生成了多样化的序列，显著增加了探索空间的覆盖度。

Conclusion: 该研究为复杂数据的因子表示和组合生成提供了一种有效的解决方案，表明对抗训练在复杂任务中的有效性。

Abstract: Decomposing complex data into factorized representations can reveal reusable components and enable synthesizing new samples via component recombination. We investigate this in the context of diffusion-based models that learn factorized latent spaces without factor-level supervision. In images, factors can capture background, illumination, and object attributes; in robotic videos, they can capture reusable motion components. To improve both latent factor discovery and quality of compositional generation, we introduce an adversarial training signal via a discriminator trained to distinguish between single-source samples and those generated by recombining factors across sources. By optimizing the generator to fool this discriminator, we encourage physical and semantic consistency in the resulting recombinations. Our method outperforms implementations of prior baselines on CelebA-HQ, Virtual KITTI, CLEVR, and Falcor3D, achieving lower FID scores and better disentanglement as measured by MIG and MCC. Furthermore, we demonstrate a novel application to robotic video trajectories: by recombining learned action components, we generate diverse sequences that significantly increase state-space coverage for exploration on the LIBERO benchmark.

</details>


### [70] [Vision-DeepResearch: Incentivizing DeepResearch Capability in Multimodal Large Language Models](https://arxiv.org/abs/2601.22060)
*Wenxuan Huang,Yu Zeng,Qiuchen Wang,Zhen Fang,Shaosheng Cao,Zheng Chu,Qingyu Yin,Shuang Chen,Zhenfei Yin,Lin Chen,Zehui Chen,Yao Hu,Philip Torr,Feng Zhao,Wanli Ouyang*

Main category: cs.CV

TL;DR: 本文提出了一种新的多模态深研究范式Vision-DeepResearch，通过多轮次、多实体和多尺度的视觉和文本搜索，即使在大量视觉噪声下也能实现稳健的搜索结果，显著优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常在复杂的视觉和文本搜索任务中表现不佳，原因包括假定单次图像和少量文本查询足以获取答案所需的证据，以及在推理深度和搜索广度上的局限性。

Method: Vision-DeepResearch通过多轮次、多实体和多尺度的视觉和文本搜索来构建新的多模态深研究范式，同时通过冷启动监督和RL训练，将深研究能力内置于MLLM中。

Result: 实验结果显示Vision-DeepResearch在多个多模态搜索任务中表现出色，远超现有模型和基于强大闭源基础模型的工作。

Conclusion: Vision-DeepResearch提供了一种新的方法，能够在复杂、高噪声的真实世界环境中实现多模态深研究任务，具有广泛应用潜力。

Abstract: Multimodal large language models (MLLMs) have achieved remarkable success across a broad range of vision tasks. However, constrained by the capacity of their internal world knowledge, prior work has proposed augmenting MLLMs by ``reasoning-then-tool-call'' for visual and textual search engines to obtain substantial gains on tasks requiring extensive factual information. However, these approaches typically define multimodal search in a naive setting, assuming that a single full-level or entity-level image query and few text query suffices to retrieve the key evidence needed to answer the question, which is unrealistic in real-world scenarios with substantial visual noise. Moreover, they are often limited in the reasoning depth and search breadth, making it difficult to solve complex questions that require aggregating evidence from diverse visual and textual sources. Building on this, we propose Vision-DeepResearch, which proposes one new multimodal deep-research paradigm, i.e., performs multi-turn, multi-entity and multi-scale visual and textual search to robustly hit real-world search engines under heavy noise. Our Vision-DeepResearch supports dozens of reasoning steps and hundreds of engine interactions, while internalizing deep-research capabilities into the MLLM via cold-start supervision and RL training, resulting in a strong end-to-end multimodal deep-research MLLM. It substantially outperforming existing multimodal deep-research MLLMs, and workflows built on strong closed-source foundation model such as GPT-5, Gemini-2.5-pro and Claude-4-Sonnet. The code will be released in https://github.com/Osilly/Vision-DeepResearch.

</details>


### [71] [BLO-Inst: Bi-Level Optimization Based Alignment of YOLO and SAM for Robust Instance Segmentation](https://arxiv.org/abs/2601.22061)
*Li Zhang,Pengtao Xie*

Main category: cs.CV

TL;DR: BLO-Inst 简介：BLO-Inst 通过二阶优化统一了检测和分割目标，解决了对象检测器与 Segment Anything Model (SAM) 之间因目标不匹配和联合训练中的过度关注特定提示调整而导致的问题。该方法通过在两个分层优化过程中迭代细调 SAM 和更新检测器生成提示，优化了检测器以生成高质量分割掩模。实验表明，BLO-Inst 在各种任务中显著优于标准基线，特别是在生物医学领域。


<details>
  <summary>Details</summary>
Motivation: 引言：前言部分指出 Segment Anything Model 的零样本能力虽然强大，但对手动提示的依赖阻碍了自动化部署。已有的通过集成对象检测器作为提示生成器的方法在两方面存在问题：目标不匹配和标准联合训练中的过度适应。因此，需要一个解决方案来弥合这种差距。

Method: 方法：BLO-Inst 引入了统一框架，通过二阶优化对检测和分割目标进行对齐。该方法将对齐问题形式化为在分离数据集上嵌套的优化问题。在较低层级，SAM 在当前检测建议集上进行细调，以最大化分割保真度。在较高层级，检测器被更新以生成减小了细调后的 SAM 验证损失的边界框。这使得检测器成为分割感知的提示生成器，优化了边界框以不仅提高定位准确性，还提高下游掩模的质量。

Result: 结果：实验结果表明，BLO-Inst 在多种任务中实现了优越的表现，并在生物医学领域等任务中优于标准基线。

Conclusion: 结论：BLO-Inst 为解决现有方法中存在的目标不匹配和联合训练中的过度适应问题提供了一个有效方案，通过二阶优化显著提高了分割掩模的质量和自动化部署的可能性。

Abstract: The Segment Anything Model has revolutionized image segmentation with its zero-shot capabilities, yet its reliance on manual prompts hinders fully automated deployment. While integrating object detectors as prompt generators offers a pathway to automation, existing pipelines suffer from two fundamental limitations: objective mismatch, where detectors optimized for geometric localization do not correspond to the optimal prompting context required by SAM, and alignment overfitting in standard joint training, where the detector simply memorizes specific prompt adjustments for training samples rather than learning a generalizable policy. To bridge this gap, we introduce BLO-Inst, a unified framework that aligns detection and segmentation objectives by bi-level optimization. We formulate the alignment as a nested optimization problem over disjoint data splits. In the lower level, the SAM is fine-tuned to maximize segmentation fidelity given the current detection proposals on a subset ($D_1$). In the upper level, the detector is updated to generate bounding boxes that explicitly minimize the validation loss of the fine-tuned SAM on a separate subset ($D_2$). This effectively transforms the detector into a segmentation-aware prompt generator, optimizing the bounding boxes not just for localization accuracy, but for downstream mask quality. Extensive experiments demonstrate that BLO-Inst achieves superior performance, outperforming standard baselines on tasks in general and biomedical domains.

</details>


### [72] [RefAny3D: 3D Asset-Referenced Diffusion Models for Image Generation](https://arxiv.org/abs/2601.22094)
*Hanzhuo Huang,Qingyang Bao,Zekai Gu,Zhongshuo Du,Cheng Lin,Yuan Liu,Sibei Yang*

Main category: cs.CV

TL;DR: 该研究提出了一种基于3D资产的图像生成模型，通过多视角RGB图像和3D资产的点云图来生成与3D参考一致的图像，扩展了图像生成的应用范围。


<details>
  <summary>Details</summary>
Motivation: 现有的参考图像生成方法存在只能利用单张参考图像的问题，无法充分利用3D资产，在实际应用中受限。因此，该研究旨在解决这一问题，提出了一种能够利用多视角图像和3D资产生成一致图像的方法，以增强图像生成模型的多样性和实用性。

Method: 该方法基于跨域的扩散模型，并采用双分支感知架构。通过结合多视角RGB图像和3D资产的点云图，同时建模颜色和空间坐标，实现精确的空间对齐与内容分离，生成与3D参考一致的图像。

Result: 通过实验验证，该方法能有效地利用3D资产生成与给定资产一致的图像，展示了在3D内容生成中的新可能性。

Conclusion: 该研究提出了一种创新的3D资产参考的扩散模型，显著扩展了图像生成的技术边界，对未来基于3D的数据生成技术具有重要意义。

Abstract: In this paper, we propose a 3D asset-referenced diffusion model for image generation, exploring how to integrate 3D assets into image diffusion models. Existing reference-based image generation methods leverage large-scale pretrained diffusion models and demonstrate strong capability in generating diverse images conditioned on a single reference image. However, these methods are limited to single-image references and cannot leverage 3D assets, constraining their practical versatility. To address this gap, we present a cross-domain diffusion model with dual-branch perception that leverages multi-view RGB images and point maps of 3D assets to jointly model their colors and canonical-space coordinates, achieving precise consistency between generated images and the 3D references. Our spatially aligned dual-branch generation architecture and domain-decoupled generation mechanism ensure the simultaneous generation of two spatially aligned but content-disentangled outputs, RGB images and point maps, linking 2D image attributes with 3D asset attributes. Experiments show that our approach effectively uses 3D assets as references to produce images consistent with the given assets, opening new possibilities for combining diffusion models with 3D content creation.

</details>


### [73] [SINA: A Circuit Schematic Image-to-Netlist Generator Using Artificial Intelligence](https://arxiv.org/abs/2601.22114)
*Saoud Aldowaish,Yashwanth Karumanchi,Kai-Chen Chiang,Soroosh Noorzad,Morteza Fayazi*

Main category: cs.CV

TL;DR: SINA 提供了一种新的自动化电路图转网表工具，通过深度学习、连接区域标注、光学字符识别和视觉语言模型实现高精度的电路图解析。


<details>
  <summary>Details</summary>
Motivation: 当前电路图转网表工具在组件识别和连接性推断方面存在困难，为了提高准确性和自动化程度。

Method: SINA 使用深度学习进行组件检测、连通区域标注进行精确连接提取、光学字符识别获取组件参考设计号，并利用视觉语言模型进行可靠的参考设计号分配。

Result: SINA 在实验中实现了 96.47% 的整体网表生成准确性，比现有的最先进的方法高出 2.72 倍。

Conclusion: SINA 是一个开源的、完全自动化的电路图到网表生成器，能够显著提高电路图转网表的准确性。

Abstract: Current methods for converting circuit schematic images into machine-readable netlists struggle with component recognition and connectivity inference. In this paper, we present SINA, an open-source, fully automated circuit schematic image-to-netlist generator. SINA integrates deep learning for accurate component detection, Connected-Component Labeling (CCL) for precise connectivity extraction, and Optical Character Recognition (OCR) for component reference designator retrieval, while employing a Vision-Language Model (VLM) for reliable reference designator assignments. In our experiments, SINA achieves 96.47% overall netlist-generation accuracy, which is 2.72x higher than state-of-the-art approaches.

</details>


### [74] [Creative Image Generation with Diffusion Model](https://arxiv.org/abs/2601.22125)
*Kunpeng Song,Ahmed Elgammal*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的基于扩散模型的创造性生成框架，通过将创造力与CLIP嵌入空间中图像存在的逆概率关联，旨在生成稀有、有创意且视觉上引人入胜的图像。论文通过大量实验展示了该框架的有效性和效率。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在通过创造性生成框架推动视觉内容合成的创新。现有方法主要依赖手动混合概念或排除某些子类别，本文通过概率分布驱动生成图像向低概率区域迁移，以生成独特且引人深思的图像。

Method: 本文提出的方法基于扩散模型，将创造力与CLIP嵌入空间的图像存在逆概率联系起来。通过计算生成图像的概率分布，并驱动其向低概率区域转移，以生成稀有、有创意且视觉上吸引人的输出。论文还引入了“拉回机制”来实现高创造力和视觉保真度。

Result: 实验结果表明，该方法在文本到图像的扩散模型上表现有效且高效，能生成独特且富有创意的图像。这对于实现有创意的生成内容具有重要意义。

Conclusion: 本文提供了一种新的视角来理解生成模型中的创造力，通过一个具有原则性的方法促进了视觉内容合成的创新。

Abstract: Creative image generation has emerged as a compelling area of research, driven by the need to produce novel and high-quality images that expand the boundaries of imagination. In this work, we propose a novel framework for creative generation using diffusion models, where creativity is associated with the inverse probability of an image's existence in the CLIP embedding space. Unlike prior approaches that rely on a manual blending of concepts or exclusion of subcategories, our method calculates the probability distribution of generated images and drives it towards low-probability regions to produce rare, imaginative, and visually captivating outputs. We also introduce pullback mechanisms, achieving high creativity without sacrificing visual fidelity. Extensive experiments on text-to-image diffusion models demonstrate the effectiveness and efficiency of our creative generation framework, showcasing its ability to produce unique, novel, and thought-provoking images. This work provides a new perspective on creativity in generative models, offering a principled method to foster innovation in visual content synthesis.

</details>


### [75] [EditYourself: Audio-Driven Generation and Manipulation of Talking Head Videos with Diffusion Transformers](https://arxiv.org/abs/2601.22127)
*John Flynn,Wolfgang Paier,Dimitar Dinev,Sam Nhut Nguyen,Hayk Poghosyan,Manuel Toribio,Sandipan Banerjee,Guy Gafni*

Main category: cs.CV

TL;DR: EditYourself 是一个基于 DiT 的框架，能够通过音频驱动的方式对已录制的视频进行编辑，实现对对话头部视频中视觉说话内容的增删改操作，同时保持时空连贯性和视觉一致性。


<details>
  <summary>Details</summary>
Motivation: 当前视频生成模型虽然能够在文本和图像提示下生成新的内容，但在编辑现有视频时存在缺口，特别是需要保留说话者的动作、时序一致性和唇部同步。

Method: EditYourself 采用了通用视频扩散模型，通过音频条件和区域感知编辑训练扩展，实现了时空插值，以生成现实的视觉运动。

Result: 该方法能够在不破坏运动连贯性和视觉保真度的情况下，对对话头部视频进行精确的唇部同步和时序连贯重构。

Conclusion: EditYourself 为生成视频模型作为专业视频后期制作的实际工具奠定了基础。

Abstract: Current generative video models excel at producing novel content from text and image prompts, but leave a critical gap in editing existing pre-recorded videos, where minor alterations to the spoken script require preserving motion, temporal coherence, speaker identity, and accurate lip synchronization. We introduce EditYourself, a DiT-based framework for audio-driven video-to-video (V2V) editing that enables transcript-based modification of talking head videos, including the seamless addition, removal, and retiming of visually spoken content. Building on a general-purpose video diffusion model, EditYourself augments its V2V capabilities with audio conditioning and region-aware, edit-focused training extensions. This enables precise lip synchronization and temporally coherent restructuring of existing performances via spatiotemporal inpainting, including the synthesis of realistic human motion in newly added segments, while maintaining visual fidelity and identity consistency over long durations. This work represents a foundational step toward generative video models as practical tools for professional video post-production.

</details>


### [76] [Early and Prediagnostic Detection of Pancreatic Cancer from Computed Tomography](https://arxiv.org/abs/2601.22134)
*Wenxuan Li,Pedro R. A. S. Bassi,Lizhou Wu,Xinze Zhou,Yuxuan Zhao,Qi Chen,Szymon Plotka,Tianyu Lin,Zheren Zhu,Marisa Martin,Justin Caskey,Shanshan Jiang,Xiaoxi Chen,Jaroslaw B. Ćwikla,Artur Sankowski,Yaping Wu,Sergio Decherchi,Andrea Cavalli,Chandana Lall,Cristian Tomasetti,Yaxing Guo,Xuan Yu,Yuqing Cai,Hualin Qiao,Jie Bao,Chenhan Hu,Ximing Wang,Arkadiusz Sitek,Kai Ding,Heng Li,Meiyun Wang,Dexin Yu,Guang Zhang,Yang Yang,Kang Wang,Alan L. Yuille,Zongwei Zhou*

Main category: cs.CV

TL;DR: 该系统在检测早期胰腺癌方面表现出色，在多个验证中均达到了较高的敏感性和特异性。


<details>
  <summary>Details</summary>
Motivation: 由于胰腺导管腺癌（PDAC）在晚期才被诊断，且预后较差，开发一种可以在早期发现该疾病的辅助工具显得尤为重要。

Method: 研究团队开发了一种名为ePAI的自动化系统，通过培训来自单个医学中心的1,598名患者的图像数据。该系统在内部测试中使用了1,009名患者的数据，在外部测试中则使用了遍布6个中心的7,158名患者的数据。同时，还进行了多读者研究，以评估系统性能。

Result: 在内部测试中，ePAI达到了0.939-0.999的AUC，95.3%的敏感性和98.7%的特异性。在外部测试中，AUC为0.918-0.945，敏感性为91.5%，特异性为88.0%。此外，该系统在临床诊断之前3到36个月识别了早期PDAC，并成功检测和定位了159名患者中的75名早期PDAC，中位延迟时间为347天。多读者研究还表明，ePAI在保持与30名认证放射科医师相似的特异性（95.4%）的情况下，显著提高了敏感性（50.3%，P < 0.05）。

Conclusion: 研究结果表明，ePAI有望成为一种辅助工具，有助于提高胰腺癌的早期发现率。

Abstract: Pancreatic ductal adenocarcinoma (PDAC), one of the deadliest solid malignancies, is often detected at a late and inoperable stage. Retrospective reviews of prediagnostic CT scans, when conducted by expert radiologists aware that the patient later developed PDAC, frequently reveal lesions that were previously overlooked. To help detecting these lesions earlier, we developed an automated system named ePAI (early Pancreatic cancer detection with Artificial Intelligence). It was trained on data from 1,598 patients from a single medical center. In the internal test involving 1,009 patients, ePAI achieved an area under the receiver operating characteristic curve (AUC) of 0.939-0.999, a sensitivity of 95.3%, and a specificity of 98.7% for detecting small PDAC less than 2 cm in diameter, precisely localizing PDAC as small as 2 mm. In an external test involving 7,158 patients across 6 centers, ePAI achieved an AUC of 0.918-0.945, a sensitivity of 91.5%, and a specificity of 88.0%, precisely localizing PDAC as small as 5 mm. Importantly, ePAI detected PDACs on prediagnostic CT scans obtained 3 to 36 months before clinical diagnosis that had originally been overlooked by radiologists. It successfully detected and localized PDACs in 75 of 159 patients, with a median lead time of 347 days before clinical diagnosis. Our multi-reader study showed that ePAI significantly outperformed 30 board-certified radiologists by 50.3% (P < 0.05) in sensitivity while maintaining a comparable specificity of 95.4% in detecting PDACs early and prediagnostic. These findings suggest its potential of ePAI as an assistive tool to improve early detection of pancreatic cancer.

</details>


### [77] [PI-Light: Physics-Inspired Diffusion for Full-Image Relighting](https://arxiv.org/abs/2601.22135)
*Zhexin Liang,Zhaoxi Chen,Yongwei Chen,Tianyi Wei,Tengfei Wang,Xingang Pan*

Main category: cs.CV

TL;DR: 本文提出了一种名为$π$-Light的两阶段框架，利用物理启发式的扩散模型，通过批量感知注意力、物理引导的神经渲染模块、物理启发式的损失以及精心构建的在受控光照条件下捕捉的多样物体和场景的数据集，解决了全图重新光照中的精细高光和漫反射合成难题，实现在实际场景中的优越泛化性能。


<details>
  <summary>Details</summary>
Motivation: 由于难以获得大规模的具有物理一致性标签的数据集，现有的方法在实际应用中仍然存在局限性。本文提出了$π$-Light框架，旨在改进和解决目前存在的问题。

Method: 该方法包括四个关键组件：1. 批量感知注意力，有助于提高图像集合中内在预测的一致性；2. 物理引导的神经渲染模块，确保光传输具有物理合理性；3. 物理启发式的损失函数，规整训练动态，改善泛化能力；4. 一个精心构建的具有多样化物体和场景的数据集，这些场景在受控光照条件下拍摄。

Result: 实验结果表明，$π$-Light在多种材料上合成的高光和漫反射具有出色的多样性和新颖性，相比之前的方案，它在现实场景中的泛化能力得到了显著提升。

Conclusion: 总之，$π$-Light框架提供了一个有效的解决方案，能够实现高光和漫反射在不同材料上的合成，进而更好地应用于实际场景，同时也为后续研究提供了坚实的基础和基准。

Abstract: Full-image relighting remains a challenging problem due to the difficulty of collecting large-scale structured paired data, the difficulty of maintaining physical plausibility, and the limited generalizability imposed by data-driven priors. Existing attempts to bridge the synthetic-to-real gap for full-scene relighting remain suboptimal. To tackle these challenges, we introduce Physics-Inspired diffusion for full-image reLight ($π$-Light, or PI-Light), a two-stage framework that leverages physics-inspired diffusion models. Our design incorporates (i) batch-aware attention, which improves the consistency of intrinsic predictions across a collection of images, (ii) a physics-guided neural rendering module that enforces physically plausible light transport, (iii) physics-inspired losses that regularize training dynamics toward a physically meaningful landscape, thereby enhancing generalizability to real-world image editing, and (iv) a carefully curated dataset of diverse objects and scenes captured under controlled lighting conditions. Together, these components enable efficient finetuning of pretrained diffusion models while also providing a solid benchmark for downstream evaluation. Experiments demonstrate that $π$-Light synthesizes specular highlights and diffuse reflections across a wide variety of materials, achieving superior generalization to real-world scenes compared with prior approaches.

</details>


### [78] [Do VLMs Perceive or Recall? Probing Visual Perception vs. Memory with Classic Visual Illusions](https://arxiv.org/abs/2601.22150)
*Xiaoxiao Sun,Mingyang Li,Kun yuan,Min Woo Sun,Mark Endo,Shengguang Wu,Changlin Li,Yuhui Zhang,Zeyu Wang,Serena Yeung-Levy*

Main category: cs.CV

TL;DR: VI-Probe 引入了一个可控的视觉错觉框架，通过分等级的干扰和匹配的视觉控制来区分视觉感知和语言驱动的记忆。实验结果显示，响应的一致性来源于多种原因而非单一机制。


<details>
  <summary>Details</summary>
Motivation: 研究 VLMs 对视觉错觉的处理方式，挑战了单一机制的观点，提出基于探针的评估方法来衡量知识和对控制视觉变化的敏感性。

Method: 开发了一个可控的视觉错觉框架，使用分等级干扰和匹配的视觉控制，并引入新的测量指标：极性反转一致性、模板固定指数和幻觉乘数。通过不同模型的对比试验来揭示不同模型处理视觉错觉的一致性来源。

Result: 实验显示，不同模型对视觉错觉一致性的原因各不相同，包括记忆覆写、感知记忆竞争以及视觉处理限制等。

Conclusion: 研究结果表明，VLMs 的一致响应并非由单一机制造成，强调了使用探针评估方法的重要性，以同时衡量知识和对控制视觉变化的敏感性。

Abstract: Large Vision-Language Models (VLMs) often answer classic visual illusions "correctly" on original images, yet persist with the same responses when illusion factors are inverted, even though the visual change is obvious to humans. This raises a fundamental question: do VLMs perceive visual changes or merely recall memorized patterns? While several studies have noted this phenomenon, the underlying causes remain unclear. To move from observations to systematic understanding, this paper introduces VI-Probe, a controllable visual-illusion framework with graded perturbations and matched visual controls (without illusion inducer) that disentangles visually grounded perception from language-driven recall. Unlike prior work that focuses on averaged accuracy, we measure stability and sensitivity using Polarity-Flip Consistency, Template Fixation Index, and an illusion multiplier normalized against matched controls. Experiments across different families reveal that response persistence arises from heterogeneous causes rather than a single mechanism. For instance, GPT-5 exhibits memory override, Claude-Opus-4.1 shows perception-memory competition, while Qwen variants suggest visual-processing limits. Our findings challenge single-cause views and motivate probing-based evaluation that measures both knowledge and sensitivity to controlled visual change. Data and code are available at https://sites.google.com/view/vi-probe/.

</details>


### [79] [UEval: A Benchmark for Unified Multimodal Generation](https://arxiv.org/abs/2601.22155)
*Bo Li,Yida Yin,Wenhao Chai,Xingyu Fu,Zhuang Liu*

Main category: cs.CV

TL;DR: UEval 是一个基准，评估可以生成图像和文本的统一模型。它包含1000个专家策划的问题，并设计了一种基于rubric的评分系统，而不是依赖MLLM来评分。对于当前的统一模型来说，UEval 很具挑战性。


<details>
  <summary>Details</summary>
Motivation: UEval 的设计动机是为了应对评估开放型多模态生成的难题，提出了新的评分机制。

Method: UEval 通过专家策划和多步骤评分流程，设计了一种新的评分系统，与其之前的评价方法相比更加精细和公平。

Result: UEval 挑战了当前的统一模型，GPT-5-Thinking 的成绩为66.4%，而最好的开源模型仅为49.1%。

Conclusion: UEval 表现出了统一模型在处理复杂多模态理解与生成任务方面的重要不足，并暗示了推理对于此类任务的重要性。

Abstract: We introduce UEval, a benchmark to evaluate unified models, i.e., models capable of generating both images and text. UEval comprises 1,000 expert-curated questions that require both images and text in the model output, sourced from 8 real-world tasks. Our curated questions cover a wide range of reasoning types, from step-by-step guides to textbook explanations. Evaluating open-ended multimodal generation is non-trivial, as simple LLM-as-a-judge methods can miss the subtleties. Different from previous works that rely on multimodal Large Language Models (MLLMs) to rate image quality or text accuracy, we design a rubric-based scoring system in UEval. For each question, reference images and text answers are provided to a MLLM to generate an initial rubric, consisting of multiple evaluation criteria, and human experts then refine and validate these rubrics. In total, UEval contains 10,417 validated rubric criteria, enabling scalable and fine-grained automatic scoring. UEval is challenging for current unified models: GPT-5-Thinking scores only 66.4 out of 100, while the best open-source model reaches merely 49.1. We observe that reasoning models often outperform non-reasoning ones, and transferring reasoning traces from a reasoning model to a non-reasoning model significantly narrows the gap. This suggests that reasoning may be important for tasks requiring complex multimodal understanding and generation.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [80] [asr_eval: Algorithms and tools for multi-reference and streaming speech recognition evaluation](https://arxiv.org/abs/2601.20992)
*Oleg Sedukhin,Andrey Kostin*

Main category: cs.CL

TL;DR: 该研究改进了语音识别评估方法，提出了一种支持多参考标签、任意长度插入和更好词对齐的字符串对齐算法，适用于非拉丁语等语言。此外，收集了一个多样化的俄罗斯语长句测试集，并研究了模型对特定数据集标签的适应性，开发了评估流式语音识别和多转录对齐的工具，并提供了多种语音识别模型的统一接口。


<details>
  <summary>Details</summary>
Motivation: 为解决现有语音识别评估方法在非拉丁语等复杂语言中对齐难度大、标签不准确的问题，提出改进方法并测试其有效性。

Method: 研究开发了一种新的字符串对齐算法，可以更好地处理非标准或长语音段的多参考标注，同时收集了俄罗斯语的多样语音数据，进行多参考重新标注，并研究模型对特定训练集的适应性。

Result: 该方法在多参考标签和长语音处理上表现更好，能更准确地评估模型性能，还开发了评估流式语音识别和多转录对比的工具，为用户提供便利。

Conclusion: 研究结果表明，改进的对齐算法能够有效提升语音识别评估的准确性，促进了相关工具的开发和开源，有助于提升语音识别技术的整体水平。

Abstract: We propose several improvements to the speech recognition evaluation. First, we propose a string alignment algorithm that supports both multi-reference labeling, arbitrary-length insertions and better word alignment. This is especially useful for non-Latin languages, those with rich word formation, to label cluttered or longform speech. Secondly, we collect a novel test set DiverseSpeech-Ru of longform in-the-wild Russian speech with careful multi-reference labeling. We also perform multi-reference relabeling of popular Russian tests set and study fine-tuning dynamics on its corresponding train set. We demonstrate that the model often adopts to dataset-specific labeling, causing an illusion of metric improvement. Based on the improved word alignment, we develop tools to evaluate streaming speech recognition and to align multiple transcriptions to compare them visually. Additionally, we provide uniform wrappers for many offline and streaming speech recognition models. Our code will be made publicly available.

</details>


### [81] [Position-invariant Fine-tuning of Speech Enhancement Models with Self-supervised Speech Representations](https://arxiv.org/abs/2601.21084)
*Amit Meghanani,Thomas Hain*

Main category: cs.CL

TL;DR: 该研究探讨了将前端语音增强模型与基于自监督学习的语音模型结合的方法，发现传统的MSE损失会导致目标通过位置相关性而非内容信息来最小化，提出了两种改进方法：零填充和速度扰动结合软DTW损失，其中软DTW方法表现出更快的收敛性和更好的下游性能。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在改进基于自监督学习的语音模型中存在的定位偏差问题，解决传统损失函数易导致目标通过位置相关性而非内容信息来最小化的问题。

Method: 研究提出了两种方法来解决定位偏差问题：一种是零填充，另一种是速度扰动结合软DTW损失。

Result: 实验结果显示，基于软DTW损失的方法在收敛速度和下游性能方面均优于零填充的方法。

Conclusion: 研究指出，定位不变的微调对于基于自监督学习的语音建模至关重要。

Abstract: Integrating front-end speech enhancement (SE) models with self-supervised learning (SSL)-based speech models is effective for downstream tasks in noisy conditions. SE models are commonly fine-tuned using SSL representations with mean squared error (MSE) loss between enhanced and clean speech. However, MSE is prone to exploiting positional embeddings in SSL models, allowing the objective to be minimised through positional correlations instead of content-related information. This work frames the problem as a general limitation of self-supervised representation fine-tuning and investigates it through representation-guided SE. Two strategies are considered: (1) zero-padding, previously explored in SSL pre-training but here examined in the fine-tuning setting, and (2) speed perturbations with a soft-DTW loss. Experiments show that the soft-DTW-based approach achieves faster convergence and improved downstream performance, underscoring the importance of position-invariant fine-tuning in SSL-based speech modelling.

</details>


### [82] [ChunkWise LoRA: Adaptive Sequence Partitioning for Memory-Efficient Low-Rank Adaptation and Accelerated LLM Inference](https://arxiv.org/abs/2601.21109)
*Ketan Thakkar,Maitreyi Chatterjee,Ramasubramanian Balasubramanian,Achyuthan Jootoo,Rajendra Ugrani*

Main category: cs.CL

TL;DR: ChunkWise LoRA提出了一种动态且适应性强的方法，通过基于词元复杂度划分变长片段并为每个片段定制低秩配置，以适应token的复杂度和计算需求，从而降低延迟和内存使用，同时保持或改善任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有的低秩适应（LoRA）方法使用统一的静态秩配置应用于所有输入tokens，忽视了tokens复杂度和计算需求的差异。ChunkWise LoRA旨在通过动态划分tokens和分配适合的参数配置来改善这些问题。

Method: ChunkWise LoRA通过引入一个运行时调度器来估算token难度，执行自适应分块，并使用秩阶梯机制选择每个块的LoRA秩和缩放。同时，该方法还介绍了边界安全的组合模块和基于策略的KV缓存策略来保持输出一致性。

Result: 在Wikitext-103和SQuAD等基准数据集上的实验表明，与基础LoRA相比，ChunkWise LoRA可以降低高达34%的延迟和38%的内存使用，同时保持或提升任务性能指标（如BLEU、EM和困惑度）。

Conclusion: 该框架与现有的变压器架构和推理框架完全兼容，为实际部署参数高效的大型语言模型提供了实用的解决方案。

Abstract: Recent advances in low-rank adaptation (LoRA) have enabled efficient fine-tuning of large language models (LLMs) with minimal additional parameters. However, existing LoRA methods apply static rank configurations uniformly across all input tokens, ignoring variation in token complexity and computational requirements. In this work, we propose ChunkWise LoRA, a dynamic and adaptive approach that partitions sequences into variable-length chunks based on token complexity and assigns each chunk a tailored low-rank configuration. Our system introduces a runtime scheduler that estimates token difficulty, performs adaptive chunking, and selects per-chunk LoRA rank and scaling using a rank-ladder mechanism. To preserve output consistency, we further introduce a boundary-safe composition module and integrate policy-driven KV-cache strategies. Experiments on benchmark datasets such as Wikitext-103 and SQuAD demonstrate that ChunkWise LoRA achieves up to 34\% lower latency and 38% memory reduction compared to baseline LoRA, while maintaining or improving task performance metrics like BLEU, EM, and perplexity. The proposed framework remains fully compatible with existing transformer architectures and inference frameworks, providing a practical solution for real-world deployment of parameter-efficient LLMs.

</details>


### [83] [Large Language Models Naively Recover Ethnicity from Individual Records](https://arxiv.org/abs/2601.21132)
*Noah Dasanaike*

Main category: cs.CL

TL;DR: 大型语言模型可以从名字中推断出种族信息，准确率超过贝叶斯改进姓氏地理编码方法(BISG)，并在多种语境和国家中有效。这些模型在包括政党注册和宗教宗派等元数据的帮助下，可以进一步提高准确性。


<details>
  <summary>Details</summary>
Motivation: 为了研究大型语言模型在种族推断方面的性能，特别是在美国之外的背景下，以及与传统方法如BISG相比的优势。

Method: 使用来自佛罗里达和北卡罗来纳的选民文件样本，对包括Gemini 3 Flash、GPT-4o在内的六种模型进行测试，同时验证在不同国家和语境下的准确性。

Result: 大型语言模型可以在多种语境下达到84.7%的准确性，超越了BISG在平衡样本中的表现（68.2%），并且通过加入元数据如政党注册可以达到86.7%的准确性。此外，这种方法减少了BISG中存在的收入偏见问题。

Conclusion: 小型变压器模型的精细化训练可以超过BISG的准确性，同时允许在本地部署，无需成本。

Abstract: I demonstrate that large language models can infer ethnicity from names with accuracy exceeding that of Bayesian Improved Surname Geocoding (BISG) without additional training data, enabling inference outside the United States and to contextually appropriate classification categories. Using stratified samples from Florida and North Carolina voter files with self-reported race, LLM-based classification achieves up to 84.7% accuracy, outperforming BISG (68.2%) on balanced samples. I test six models including Gemini 3 Flash, GPT-4o, and open-source alternatives such as DeepSeek v3.2 and GLM-4.7. Enabling extended reasoning can improve accuracy by 1-3 percentage points, though effects vary across contexts; including metadata such as party registration reaches 86.7%. LLM classification also reduces the income bias inherent in BISG, where minorities in wealthier neighborhoods are systematically misclassified as White. I further validate using Lebanese voter registration with religious sect (64.3% accuracy), Indian MPs from reserved constituencies (99.2%), and Indian land records with caste classification (74.0%). Aggregate validation across India, Uganda, Nepal, Armenia, Chile, and Costa Rica using original full-count voter rolls demonstrates that the method recovers known population distributions where naming conventions are distinctive. For large-scale applications, small transformer models fine-tuned on LLM labels exceed BISG accuracy while enabling local deployment at no cost.

</details>


### [84] [EnsembleLink: Accurate Record Linkage Without Training Data](https://arxiv.org/abs/2601.21138)
*Noah Dasanaike*

Main category: cs.CL

TL;DR: EnsembleLink 是一种无需训练标签即可实现高准确性的实体链接方法，利用预训练的语言模型识别语义关系，适用于多个领域，并且运行速度快，无需外部 API 调用。


<details>
  <summary>Details</summary>
Motivation: 现有实体链接方法要么准确率低，要么需要大量的标记训练数据，而 EnsembleLink 方法通过利用预训练语言模型学习到的语义关系，能够在不依赖大量标注数据的情况下，实现高准确性的实体链接。

Method: EnsembleLink 方法采用集成学习的方式来提高实体链接的准确性，利用预训练的语言模型自动识别实体间的语义关系，而无需手动标注数据进行训练。

Result: EnsembleLink 在不同类型的基准测试中均实现了高准确度，涵盖了城市名称、人名、组织、多语言政党和文献记录等场景，并且运行速度快，能够快速完成常见的实体链接任务。

Conclusion: EnsembleLink 提供了一种有效的实体链接解决方案，能够在无需大量标注数据的条件下实现高准确度，适用于多种应用场景，相较于传统方法具有明显的优势。

Abstract: Record linkage, the process of matching records that refer to the same entity across datasets, is essential to empirical social science but remains methodologically underdeveloped. Researchers treat it as a preprocessing step, applying ad hoc rules without quantifying the uncertainty that linkage errors introduce into downstream analyses. Existing methods either achieve low accuracy or require substantial labeled training data. I present EnsembleLink, a method that achieves high accuracy without any training labels. EnsembleLink leverages pre-trained language models that have learned semantic relationships (e.g., that "South Ozone Park" is a neighborhood in "New York City" or that "Lutte ouvriere" refers to the Trotskyist "Workers' Struggle" party) from large text corpora. On benchmarks spanning city names, person names, organizations, multilingual political parties, and bibliographic records, EnsembleLink matches or exceeds methods requiring extensive labeling. The method runs locally on open-source models, requiring no external API calls, and completes typical linkage tasks in minutes.

</details>


### [85] [Output-Space Search: Targeting LLM Generations in a Frozen Encoder-Defined Output Space](https://arxiv.org/abs/2601.21169)
*Tobias Materzok*

Main category: cs.CL

TL;DR: 本文介绍了Output-Space Search (OS-Search)，将LLM生成转化为终点搜索。通过外循环在冻结编码器定义的3D输出空间Z中选择目标点 z*，并使用序列级RL训练检索导向策略生成接近 z* 的输出坐标，从而在Z中实现并行搜索和无路径依赖的优化。


<details>
  <summary>Details</summary>
Motivation: 在LLM生成中采用终点搜索方法，以提高模型生成的多样性和有效性。

Method: OS-Search方法通过冻结编码器定义一个固定的3维输出空间Z，在这个空间中选择目标点，使用序列级别强化学习训练检索导向策略生成符合条件的输出。

Result: OS-Search在故事生成上实现了多样性提高3.1倍的效果；在代码生成上，通过Bayesian优化在保持代码有效性的同时提高了目标客观指标。

Conclusion: OS-Search通过将生成任务转化为终点搜索任务，在不依赖于路径依赖的令牌或程序搜索的情况下实现了有效的并行搜索和优化。

Abstract: We introduce Output-Space Search (OS-Search), which turns LLM generation into endpoint search. An outer loop selects a target z* in a frozen encoder-defined 3D output space Z, and a retrieval-grounded policy trained with sequence-level RL generates outputs whose coordinates land near z* under standard autoregressive decoding. This enables parallel sweeps and black-box optimization in Z without path-dependent token/program search. On stories, sweeping Z (text) yields 3.1x higher LLM-scored diversity than prompt-chaining. On code, Bayesian optimization over Z (code) improves an objective withheld from the controller under matched inference budgets while preserving validity.

</details>


### [86] [Scaling Embeddings Outperforms Scaling Experts in Language Models](https://arxiv.org/abs/2601.21204)
*Hong Liu,Jiaqi Zhang,Chao Wang,Xing Hu,Linkun Lyu,Jiaqi Sun,Xurui Yang,Bo Wang,Fengcun Li,Yulei Qian,Lingtong Si,Yerui Sun,Rumei Li,Peng Pei,Yuchen Xie,Xunliang Cai*

Main category: cs.CL

TL;DR: 该研究探索了嵌入缩放作为大型语言模型中稀疏性扩展的有效维度，并通过系统分析和实验，展示了在某些情况下，嵌入缩放比专家缩放效果更好。研究通过优化系统并将稀疏性转化为实际的推理速度提升，提出了具有超过30亿参数的LongCat-Flash-Lite模型，在参量上超越了MoE基线，并且在多个领域中表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前MoE架构在大型语言模型中的应用虽然广泛但存在效率下降和系统瓶颈问题，该研究旨在通过探索嵌入缩放提供一种新方向，解决现有模型的局限性。

Method: 研究团队进行全面分析和实验，涉及参数预算、模型宽度与深度的交互作用，并提出了嵌入缩放的几种关键架构因素。此外，通过结合定制系统优化和推测解码，将嵌入缩放的效果转化为实际的推理速度提升。

Result: 实验结果显示，在特定条件下嵌入缩放表现优于专家缩放，并且团队开发的LongCat-Flash-Lite模型不仅超越了参数量相当的MoE模型，还在多个应用领域中表现出强大的竞争力。

Conclusion: 该研究证明了在某些情景下嵌入缩放的有效性，并提出了一个新的大型语言模型架构设计思路，对未来的研究和模型优化具有指导意义。

Abstract: While Mixture-of-Experts (MoE) architectures have become the standard for sparsity scaling in large language models, they increasingly face diminishing returns and system-level bottlenecks. In this work, we explore embedding scaling as a potent, orthogonal dimension for scaling sparsity. Through a comprehensive analysis and experiments, we identify specific regimes where embedding scaling achieves a superior Pareto frontier compared to expert scaling. We systematically characterize the critical architectural factors governing this efficacy -- ranging from parameter budgeting to the interplay with model width and depth. Moreover, by integrating tailored system optimizations and speculative decoding, we effectively convert this sparsity into tangible inference speedups. Guided by these insights, we introduce LongCat-Flash-Lite, a 68.5B parameter model with ~3B activated trained from scratch. Despite allocating over 30B parameters to embeddings, LongCat-Flash-Lite not only surpasses parameter-equivalent MoE baselines but also exhibits exceptional competitiveness against existing models of comparable scale, particularly in agentic and coding domains.

</details>


### [87] [Multilingual Dysarthric Speech Assessment Using Universal Phone Recognition and Language-Specific Phonemic Contrast Modeling](https://arxiv.org/abs/2601.21205)
*Eunjung Yeo,Julie M. Liss,Visar Berisha,David R. Mortensen*

Main category: cs.CL

TL;DR: 本文提出了一种多语言音素生产评估框架，结合了通用音素识别和语言特定的音素解释，通过对比音素特征距离进行音素到音素的映射和序列对齐。


<details>
  <summary>Details</summary>
Motivation: 针对神经性疾病导致的发音障碍日益增加的趋势，研究旨在开发一种能够跨越语言的自动清晰度评估方法，以解决现有方法受限于单一语言或无法捕捉语言特定因素的问题。

Method: 该研究通过将通用音素识别与语言特定的音素解释相结合，利用对比音学特征距离进行音素到音素的映射和序列对齐，以构建多语言音素生产评估框架。

Result: 在英语、西班牙语、意大利语和泰米尔语上的分析表明，音素错误率（PER）得益于映射和对齐的结合，音学特征错误率（PFER）得益于对齐，而未对齐的音素覆盖率（PhonCov）得益于映射。

Conclusion: 该框架能够捕捉到与特定神经性疾病相关的语言清晰度退化的临床显著模式，与现有观察结果一致。

Abstract: The growing prevalence of neurological disorders associated with dysarthria motivates the need for automated intelligibility assessment methods that are applicalbe across languages. However, most existing approaches are either limited to a single language or fail to capture language-specific factors shaping intelligibility. We present a multilingual phoneme-production assessment framework that integrates universal phone recognition with language-specific phoneme interpretation using contrastive phonological feature distances for phone-to-phoneme mapping and sequence alignment. The framework yields three metrics: phoneme error rate (PER), phonological feature error rate (PFER), and a newly proposed alignment-free measure, phoneme coverage (PhonCov). Analysis on English, Spanish, Italian, and Tamil show that PER benefits from the combination of mapping and alignment, PFER from alignment alone, and PhonCov from mapping. Further analyses demonstrate that the proposed framework captures clinically meaningful patterns of intelligibility degradation consistent with established observations of dysarthric speech.

</details>


### [88] [Scaling Reasoning Hop Exposes Weaknesses: Demystifying and Improving Hop Generalization in Large Language Models](https://arxiv.org/abs/2601.21214)
*Zhaoyi Li,Jiatong Li,Gangwei Jiang,Linqi Song,Defu Lian,Ying Wei*

Main category: cs.CL

TL;DR: 该研究通过系统研究复杂任务中的内部竞争机制，提出了一种新的测试时纠正方法来修复推理错误，从而提高大语言模型的多步骤推理泛化能力。


<details>
  <summary>Details</summary>
Motivation: 尽管链式思维推理已成为大语言模型解决复杂问题的标准方法，但研究发现在推理跳跃泛化场景下，模型性能会出现显著下降。因此，研究动机在于探索导致这一问题内部机制的原因，并提出解决方案以改善性能。

Method: 该研究在多个领域的任务上进行系统研究，发现错误集中发生在少数关键错误类型上的特定标记位置。研究进一步分析这些标记级错误预测背后的内部竞争机制，最终提出测试时纠正推理的方法，在推理过程中动态识别并停用误导性的处理头。

Result: 实验表明，该测试时纠正推理方法在不同任务和模型上均有效，能够显著提高多步骤推理泛化能力。

Conclusion: 研究结论指出，通过针对关键错误类型的标记级纠正，可以在推理过程中恢复正确的推理轨迹，增强模型的泛化能力。此方法具有广泛应用潜力。

Abstract: Chain-of-thought (CoT) reasoning has become the standard paradigm for enabling Large Language Models (LLMs) to solve complex problems. However, recent studies reveal a sharp performance drop in reasoning hop generalization scenarios, where the required number of reasoning steps exceeds training distributions while the underlying algorithm remains unchanged. The internal mechanisms driving this failure remain poorly understood. In this work, we conduct a systematic study on tasks from multiple domains, and find that errors concentrate at token positions of a few critical error types, rather than being uniformly distributed. Closer inspection reveals that these token-level erroneous predictions stem from internal competition mechanisms: certain attention heads, termed erroneous processing heads (ep heads), tip the balance by amplifying incorrect reasoning trajectories while suppressing correct ones. Notably, removing individual ep heads during inference can often restore the correct predictions. Motivated by these insights, we propose test-time correction of reasoning, a lightweight intervention method that dynamically identifies and deactivates ep heads in the reasoning process. Extensive experiments across different tasks and LLMs show that it consistently improves reasoning hop generalization, highlighting both its effectiveness and potential.

</details>


### [89] [Parametric Knowledge is Not All You Need: Toward Honest Large Language Models via Retrieval of Pretraining Data](https://arxiv.org/abs/2601.21218)
*Christopher Adrian Kusuma,Muhammad Reza Qorib,Hwee Tou Ng*

Main category: cs.CL

TL;DR: 本文提出了一种使用公开预训练数据的更 robust 的 LLM 诚实性评估基准集，并提出了一种利用预训练数据构建更诚实 LLM 的新方法。


<details>
  <summary>Details</summary>
Motivation: 由于大语言模型容易产生事实错误的回答（hallucination），本文旨在提高 LLM 的诚实性，使其在缺乏知识时明确承认未知。

Method: 通过利用 Pythia 这一开源且预训练数据公开的语言模型，构建了一套评估 LLM 诚实性的 benchmark 数据集。同时，提出了结合预训练数据改进模型诚实性的方法。

Result: 本文提出了一个新的评估基准，并且展示了通过利用预训练数据来改进 LLM 能够达到提高其诚实性的效果。

Conclusion: 通过这种方法，可以更准确地评估 LLM 的诚实性，并改进模型以生成更可靠的答案。

Abstract: Large language models (LLMs) are highly capable of answering questions, but they are often unaware of their own knowledge boundary, i.e., knowing what they know and what they don't know. As a result, they can generate factually incorrect responses on topics they do not have enough knowledge of, commonly known as hallucination. Rather than hallucinating, a language model should be more honest and respond with "I don't know" when it does not have enough knowledge about a topic. Many methods have been proposed to improve LLM honesty, but their evaluations lack robustness, as they do not take into account the knowledge that the LLM has ingested during its pretraining. In this paper, we propose a more robust evaluation benchmark dataset for LLM honesty by utilizing Pythia, a truly open LLM with publicly available pretraining data. In addition, we also propose a novel method for harnessing the pretraining data to build a more honest LLM.

</details>


### [90] [SHARP: Social Harm Analysis via Risk Profiles for Measuring Inequities in Large Language Models](https://arxiv.org/abs/2601.21235)
*Alok Abhishek,Tushar Bandopadhyay,Lisa Erickson*

Main category: cs.CL

TL;DR: SHARP框架通过引入多维、分布认知评估方法，强调了偏见、公平性、伦理和知识可靠性在大型语言模型社会风险评估中的重要性，特别关注尾部风险。


<details>
  <summary>Details</summary>
Motivation: 当前的评价基准常常将复杂的社交风险归纳为单一的平均评分，这导致忽视了风险的分布结构、跨维度的交互作用以及最坏情况下的行为。研究发现，具有类似风险平均值的模型在尾部风险及波动性方面可能相差两倍以上。

Method: SHARP框架模型化危害为多元随机变量，并结合条件风险价值（CVaR95）为重点指标，建立了对偏见、公平性、伦理和知识可靠性进行显式分解的一体化框架。

Result: SHARP框架在11个先进大型语言模型上的应用表明，即使具有相似平均风险的模型在尾部风险及波动性方面可相差超过两倍，不同维度的尾部行为在模型间表现出了系统性的差异，包括偏见显示最大的尾部严重性，知识可靠性、公平性风险居中，伦理对齐最低。

Conclusion: 研究表明，负责任地评估和治理大型语言模型需要超越单一平均风险评估，转向多维度、对尾端风险感性的风险评估。

Abstract: Large language models (LLMs) are increasingly deployed in high-stakes domains, where rare but severe failures can result in irreversible harm. However, prevailing evaluation benchmarks often reduce complex social risk to mean-centered scalar scores, thereby obscuring distributional structure, cross-dimensional interactions, and worst-case behavior. This paper introduces Social Harm Analysis via Risk Profiles (SHARP), a framework for multidimensional, distribution-aware evaluation of social harm. SHARP models harm as a multivariate random variable and integrates explicit decomposition into bias, fairness, ethics, and epistemic reliability with a union-of-failures aggregation reparameterized as additive cumulative log-risk. The framework further employs risk-sensitive distributional statistics, with Conditional Value at Risk (CVaR95) as a primary metric, to characterize worst-case model behavior. Application of SHARP to eleven frontier LLMs, evaluated on a fixed corpus of n=901 socially sensitive prompts, reveals that models with similar average risk can exhibit more than twofold differences in tail exposure and volatility. Across models, dimension-wise marginal tail behavior varies systematically across harm dimensions, with bias exhibiting the strongest tail severities, epistemic and fairness risks occupying intermediate regimes, and ethical misalignment consistently lower; together, these patterns reveal heterogeneous, model-dependent failure structures that scalar benchmarks conflate. These findings indicate that responsible evaluation and governance of LLMs require moving beyond scalar averages toward multidimensional, tail-sensitive risk profiling.

</details>


### [91] [MoCo: A One-Stop Shop for Model Collaboration Research](https://arxiv.org/abs/2601.21257)
*Shangbin Feng,Yuyang Bai,Ziyuan Yang,Yike Wang,Zhaoxuan Tan,Jiajie Yan,Zhenyu Lei,Wenxuan Ding,Weijia Shi,Haojin Wang,Zhenting Qi,Yuru Jiang,Heng Wang,Chengsong Huang,Yu Fei,Jihan Yao,Yilun Du,Luke Zettlemoyer,Yejin Choi,Yulia Tsvetkov*

Main category: cs.CL

TL;DR: MoCo 是一个用于执行、基准测试和大规模比较模型协作算法的 Python 库。它包含多种跨模型信息交换的方法，并使用多种数据集进行实验。实验结果显示，协作策略通常优于不协作的模型，而 MoCo 促进了模型协作研究的发展。


<details>
  <summary>Details</summary>
Motivation: 现有研究散乱且缺乏统一标准，为了整合模型协作领域的成果并推动该领域的研究，作者开发了 MoCo 这个工具。

Method: MoCo 提供了一个包含多种模型协作方法的 Python 库，这些方法涵盖了从路由到模型参数的各种信息交换层次。此外，MoCo 集成了多个评价数据集，支持用户引入自定义数据。

Result: 实验结果表明，大多数协作策略在 61.0% 的 (模型, 数据) 设置中优于未协作模型，而最有效的协作方法有高达 25.8% 的性能提升。

Conclusion: 研究结果表明模型协作在解决单个模型难以解决的问题上有着显著优势。MoCo 作为一个开源的工具，有助于加速这一领域的研究和发展，实现开放、模块化、分散以及协作的人工智能未来。

Abstract: Advancing beyond single monolithic language models (LMs), recent research increasingly recognizes the importance of model collaboration, where multiple LMs collaborate, compose, and complement each other. Existing research on this topic has mostly been disparate and disconnected, from different research communities, and lacks rigorous comparison. To consolidate existing research and establish model collaboration as a school of thought, we present MoCo: a one-stop Python library of executing, benchmarking, and comparing model collaboration algorithms at scale. MoCo features 26 model collaboration methods, spanning diverse levels of cross-model information exchange such as routing, text, logit, and model parameters. MoCo integrates 25 evaluation datasets spanning reasoning, QA, code, safety, and more, while users could flexibly bring their own data. Extensive experiments with MoCo demonstrate that most collaboration strategies outperform models without collaboration in 61.0% of (model, data) settings on average, with the most effective methods outperforming by up to 25.8%. We further analyze the scaling of model collaboration strategies, the training/inference efficiency of diverse methods, highlight that the collaborative system solves problems where single LMs struggle, and discuss future work in model collaboration, all made possible by MoCo. We envision MoCo as a valuable toolkit to facilitate and turbocharge the quest for an open, modular, decentralized, and collaborative AI future.

</details>


### [92] [CausalEmbed: Auto-Regressive Multi-Vector Generation in Latent Space for Visual Document Embedding](https://arxiv.org/abs/2601.21262)
*Jiahao Huo,Yu Huang,Yibo Yan,Ye Pan,Yi Cao,Mingdong Ou,Philip S. Yu,Xuming Hu*

Main category: cs.CL

TL;DR: CausalEmbed 提出了一种通过自回归生成方法构建多向量嵌入的新方法，通过在对比训练期间引入迭代边缘损失，鼓励嵌入模型学习紧凑且结构良好的表示。这种方法允许使用数十个视觉标记高效执行视觉文档检索任务，同时保持与各种模型和基准的高竞争力性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型在视觉文档检索中表现出显著潜力，但巨大的存储开销限制了其实用性。

Method: CausalEmbed 通过自回归生成构建多向量嵌入，并在对比训练中引入迭代边缘损失来鼓励模型学习紧凑且结构良好的表示。

Result: CausalEmbed 方法实现了视觉文档检索任务中30-155倍的标记数量降低，同时保持高竞争力性能。

Conclusion: 这种方法展示了训练效率和测试时可扩展性方面的优势，并为多向量视觉文档检索嵌入引入了灵活的测试时缩放策略。

Abstract: Although Multimodal Large Language Models (MLLMs) have shown remarkable potential in Visual Document Retrieval (VDR) through generating high-quality multi-vector embeddings, the substantial storage overhead caused by representing a page with thousands of visual tokens limits their practicality in real-world applications. To address this challenge, we propose an auto-regressive generation approach, CausalEmbed, for constructing multi-vector embeddings. By incorporating iterative margin loss during contrastive training, CausalEmbed encourages the embedding models to learn compact and well-structured representations. Our method enables efficient VDR tasks using only dozens of visual tokens, achieving a 30-155x reduction in token count while maintaining highly competitive performance across various backbones and benchmarks. Theoretical analysis and empirical results demonstrate the unique advantages of auto-regressive embedding generation in terms of training efficiency and scalability at test time. As a result, CausalEmbed introduces a flexible test-time scaling strategy for multi-vector VDR representations and sheds light on the generative paradigm within multimodal document retrieval.

</details>


### [93] [Qwen3-ASR Technical Report](https://arxiv.org/abs/2601.21337)
*Xian Shi,Xiong Wang,Zhifang Guo,Yongqi Wang,Pei Zhang,Xinyu Zhang,Zishan Guo,Hongkun Hao,Yu Xi,Baosong Yang,Jin Xu,Jingren Zhou,Junyang Lin*

Main category: cs.CL

TL;DR: Qwen3-ASR系列模型包括两个大型全功能ASR模型和一个新型非自回归语音强制对齐模型，展现出卓越性能并优化了准确率与效率之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 为了解决开源ASR模型在实际应用中表现出的质量差异问题，提出了Qwen3-ASR系列模型，以期提供更强大和实用的言语识别解决方案。

Method: 通过对大规模语音数据进行训练，并利用基础模型强大的音频理解能力，开发了两个不同规模的ASR模型及一个基于LLM的非自回归语音对齐模型。同时，通过内部评估和对比实验，验证了模型的有效性和性能。

Result: Qwen3-ASR-1.7B在开源ASR模型中达到了SOTA性能，并且与最强的专有API竞争力相当；Qwen3-ASR-0.6B在准确率与效率之间达到了最佳权衡，能以极低的平均TTFT和高并发性进行实时语音转写。Qwen3-ForcedAligner-0.6B在多种语言中展示了优于现有模型的准确性和灵活性。

Conclusion: Qwen3-ASR系列模型和Qwen3-ForcedAligner模型被开源发布，旨在促进ASR和音频理解领域的社区研究和发展。

Abstract: In this report, we introduce Qwen3-ASR family, which includes two powerful all-in-one speech recognition models and a novel non-autoregressive speech forced alignment model. Qwen3-ASR-1.7B and Qwen3-ASR-0.6B are ASR models that support language identification and ASR for 52 languages and dialects. Both of them leverage large-scale speech training data and the strong audio understanding ability of their foundation model Qwen3-Omni. We conduct comprehensive internal evaluation besides the open-sourced benchmarks as ASR models might differ little on open-sourced benchmark scores but exhibit significant quality differences in real-world scenarios. The experiments reveal that the 1.7B version achieves SOTA performance among open-sourced ASR models and is competitive with the strongest proprietary APIs while the 0.6B version offers the best accuracy-efficiency trade-off. Qwen3-ASR-0.6B can achieve an average TTFT as low as 92ms and transcribe 2000 seconds speech in 1 second at a concurrency of 128. Qwen3-ForcedAligner-0.6B is an LLM based NAR timestamp predictor that is able to align text-speech pairs in 11 languages. Timestamp accuracy experiments show that the proposed model outperforms the three strongest force alignment models and takes more advantages in efficiency and versatility. To further accelerate the community research of ASR and audio understanding, we release these models under the Apache 2.0 license.

</details>


### [94] [Self-Improving Pretraining: using post-trained models to pretrain better models](https://arxiv.org/abs/2601.21343)
*Ellen Xiaoqing Tan,Shehzaad Dhuliawala,Jing Xu,Ping Yu,Sainbayar Sukhbaatar,Jason Weston,Olga Golovneva*

Main category: cs.CL

TL;DR: 本文提出了一种新的预训练方法，通过流式处理文档并使用强化学习（RL）逐步改进生成的下一个K个标记，从而提升模型的质量、安全性和事实性。该方法在实验中表现出显著的优越性。


<details>
  <summary>Details</summary>
Motivation: 为了解决大规模语言模型在生成过程中出现的安全性、事实性和整体质量等问题，尤其是在它们被广泛应用于现实生活场景时。

Method: 提出了一种新的预训练方法，首先流式处理文档，然后使用强化学习改进生成的下一个K个标记。利用一个强大的、经过后训练的模型评估候选生成内容的质量、安全性和事实性。

Result: 实验结果显示，该方法在事实性和安全性上分别比标准预训练方法提高了36.2%和18.5%，且整体生成质量提高了最多86.3%。

Conclusion: 该研究通过改进预训练方法，显著提升了语言模型的质量、安全性和事实性，为未来的训练和应用提供了新的思路。

Abstract: Ensuring safety, factuality and overall quality in the generations of large language models is a critical challenge, especially as these models are increasingly deployed in real-world applications. The prevailing approach to addressing these issues involves collecting expensive, carefully curated datasets and applying multiple stages of fine-tuning and alignment. However, even this complex pipeline cannot guarantee the correction of patterns learned during pretraining. Therefore, addressing these issues during pretraining is crucial, as it shapes a model's core behaviors and prevents unsafe or hallucinated outputs from becoming deeply embedded. To tackle this issue, we introduce a new pretraining method that streams documents and uses reinforcement learning (RL) to improve the next K generated tokens at each step. A strong, post-trained model judges candidate generations -- including model rollouts, the original suffix, and a rewritten suffix -- for quality, safety, and factuality. Early in training, the process relies on the original and rewritten suffixes; as the model improves, RL rewards high-quality rollouts. This approach builds higher quality, safer, and more factual models from the ground up. In experiments, our method gives 36.2% and 18.5% relative improvements over standard pretraining in terms of factuality and safety, and up to 86.3% win rate improvements in overall generation quality.

</details>


### [95] [The Compliance Paradox: Semantic-Instruction Decoupling in Automated Academic Code Evaluation](https://arxiv.org/abs/2601.21360)
*Devanshu Sahoo,Manish Prasad,Vasudev Majhi,Arjun Neekhra,Yash Sinha,Murari Mandal,Vinay Chamola,Dhruv Kumar*

Main category: cs.CL

TL;DR: 该研究揭示了大型语言模型在代码评估中的根本性缺陷，指出模型的指令跟随能力并不一定转化为客观评估。通过引入SPACI框架和AST-ASIP协议，研究发现了高容量模型在处理代码时存在系统性漏洞，这些模型更倾向于满足隐藏的格式约束而非代码正确性。该研究还提出了一个三部分框架来量化这种缺陷，并强调需要转向特定领域评判稳健性。


<details>
  <summary>Details</summary>
Motivation: 论文旨在揭示大规模语言模型在代码评估中的潜在缺陷，特别是现行的对齐方法是否能够确保模型正确执行其任务。

Method: 研究团队开发了SPACI框架和AST-ASIP协议，利用语法-语义差距，在代码的语法惰性区域嵌入恶意指令，进行大规模评估。

Result: 研究在Python、C、C++和Java的25,000个提交代码中，验证了9个最先进模型中95%以上的高容量开放权重模型在处理隐藏格式约束时失败。提出的三部分框架量化了这种脱节概率、得分偏差和教学严重性，显示出功能损坏代码的广泛误认证。

Conclusion: 当前的对齐方法可能在自动化评分中造成“特洛伊木马”漏洞，论文建议转向特定领域的评判稳健性训练，以使模型优先考虑证据而非指令遵循。

Abstract: The rapid integration of Large Language Models (LLMs) into educational assessment rests on the unverified assumption that instruction following capability translates directly to objective adjudication. We demonstrate that this assumption is fundamentally flawed. Instead of evaluating code quality, models frequently decouple from the submission's logic to satisfy hidden directives, a systemic vulnerability we term the Compliance Paradox, where models fine-tuned for extreme helpfulness are vulnerable to adversarial manipulation. To expose this, we introduce the Semantic-Preserving Adversarial Code Injection (SPACI) Framework and the Abstract Syntax Tree-Aware Semantic Injection Protocol (AST-ASIP). These methods exploit the Syntax-Semantics Gap by embedding adversarial directives into syntactically inert regions (trivia nodes) of the Abstract Syntax Tree. Through a large-scale evaluation of 9 SOTA models across 25,000 submissions in Python, C, C++, and Java, we reveal catastrophic failure rates (>95%) in high-capacity open-weights models like DeepSeek-V3, which systematically prioritize hidden formatting constraints over code correctness. We quantify this failure using our novel tripartite framework measuring Decoupling Probability, Score Divergence, and Pedagogical Severity to demonstrate the widespread "False Certification" of functionally broken code. Our findings suggest that current alignment paradigms create a "Trojan" vulnerability in automated grading, necessitating a shift from standard RLHF toward domain-specific Adjudicative Robustness, where models are conditioned to prioritize evidence over instruction compliance. We release our complete dataset and injection framework to facilitate further research on the topic.

</details>


### [96] [User-Centric Evidence Ranking for Attribution and Fact Verification](https://arxiv.org/abs/2601.21387)
*Guy Alt,Eran Hirsch,Serwar Basch,Ido Dagan,Oren Glickman*

Main category: cs.CL

TL;DR: 提出了一种新的证据排名任务，旨在通过优先展示足够的信息来提高事实验证效率，减少冗余并克服现有系统的问题。


<details>
  <summary>Details</summary>
Motivation: 当前自动系统和大型语言模型在事实验证中的效率低下和冗余问题，特别是在检索和筛选支持或反驳声明的简洁证据时。

Method: 定义了一种新的证据排名任务，两种方法（一 shot 排序和增量排序），以及一个新的评估框架，基于信息检索指标，并使用现有的事实验证数据集构建了一个统一的基准。

Result: 实验结果显示增量排序方法能够更好地捕捉互补证据，基于 LLM 的方法优于较浅的基线方法，但仍面临如何平衡充分性和冗余性的挑战。用户研究证明，证据排名不仅减少了阅读努力，还提高了验证性。

Conclusion: 这项工作为更加解释性、高效和用户导向的信息验证系统奠定了基础。

Abstract: Attribution and fact verification are critical challenges in natural language processing for assessing information reliability. While automated systems and Large Language Models (LLMs) aim to retrieve and select concise evidence to support or refute claims, they often present users with either insufficient or overly redundant information, leading to inefficient and error-prone verification. To address this, we propose Evidence Ranking, a novel task that prioritizes presenting sufficient information as early as possible in a ranked list. This minimizes user reading effort while still making all available evidence accessible for sequential verification. We compare two approaches for the new ranking task: one-shot ranking and incremental ranking. We introduce a new evaluation framework, inspired by information retrieval metrics, and construct a unified benchmark by aggregating existing fact verification datasets. Extensive experiments with diverse models show that incremental ranking strategies better capture complementary evidence and that LLM-based methods outperform shallower baselines, while still facing challenges in balancing sufficiency and redundancy. Compared to evidence selection, we conduct a controlled user study and demonstrate that evidence ranking both reduces reading effort and improves verification. This work provides a foundational step toward more interpretable, efficient, and user-aligned information verification systems.

</details>


### [97] [SOUP: Token-level Single-sample Mix-policy Reinforcement Learning for Large Language Models](https://arxiv.org/abs/2601.21476)
*Lei Yang,Wei Bi,Chenxi Sun,Renren Jin,Deyi Xiong*

Main category: cs.CL

TL;DR: SOUP 是一种结合了 off-policy 和 on-policy 学习的框架，它在每个 token 级别上统一了这两种学习方式，通过 fine-grained 的政策混合策略，有效提升了强化学习语言模型的探索性和最终性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于策略的 on-policy RL 方法在语言模型的后训练中存在探索不足和过早饱和的问题。尽管 off-policy 数据可能有所帮助，但现有混合整个轨迹的方法会导致策略不匹配和训练不稳定性。

Method: SOUP 通过在生成序列的前缀中使用历史策略信息，并在后续部分进行 on-policy 生成，同时引入 token 级别的重要性比率来平衡 off-policy 和 on-policy 学习，以此来减少策略不匹配并保持训练稳定性。

Result: 实验结果表明，SOUP 在多种场景下表现出色，优于标准的 on-policy 训练和现有的 off-policy 方法，显著增强了探索能力，提升了最终性能。

Conclusion: SOUP 提供了一个有效的解决方案，通过细粒度的单样本混合政策训练可以在保留政策稳定性的同时有效提升语言模型的性能。

Abstract: On-policy reinforcement learning (RL) methods widely used for language model post-training, like Group Relative Policy Optimization (GRPO), often suffer from limited exploration and early saturation due to low sampling diversity. While off-policy data can help, current approaches that mix entire trajectories cause significant policy mismatch and instability. In this work, we propose the $\textbf{S}$ingle-sample Mix-p$\textbf{O}$licy $\textbf{U}$nified $\textbf{P}$aradigm (SOUP), a framework that unifies off- and on-policy learning within individual samples at the token level. It confines off-policy influence to the prefix of a generated sequence sampled from historical policies, while the continuation is generated on-policy. Through token-level importance ratios, SOUP effectively leverages off-policy information while preserving training stability. Extensive experiments demonstrate that SOUP consistently outperforms standard on-policy training and existing off-policy extensions. Our further analysis clarifies how our fine-grained, single-sample mix-policy training can improve both exploration and final performance in LLM RL.

</details>


### [98] [DimStance: Multilingual Datasets for Dimensional Stance Analysis](https://arxiv.org/abs/2601.21483)
*Jonas Becker,Liang-Chih Yu,Shamsuddeen Hassan Muhammad,Jan Philip Wahle,Terry Ruas,Idris Abdulmumin,Lung-Hao Lee,Wen-Ni Liu,Tzu-Mi Lin,Zhe-Yu Xu,Ying-Lung Lin,Jin Wang,Maryam Ibrahim Mukhtar,Bela Gipp,Saif M. Mohammed*

Main category: cs.CL

TL;DR: 本文介绍了DimStance资源，该资源提供了情感维度（瓦伦特-唤醒）注释，涉及五种语言的政治和环保领域。研究展示了微调的语言模型在情感维度预测方面的竞争力，同时指出了低资源语言的挑战。


<details>
  <summary>Details</summary>
Motivation: 随着情感计算的发展，文章旨在通过引入情感维度标注进一步细化立场分析，促进情感维度的跨语言评估，以及使用预训练和大型语言模型进行情感维度预测的能力。

Method: 本文构建了包含五种语言和两个领域的大型数据集，并提出了二维情感维度的回归任务。它利用预训练和大型语言模型的微调来进行情感维度预测。

Result: 结果显示，微调的语言模型在情感维度预测中表现出了竞争力，但仍面临低资源语言的挑战。此外，研究还发现存在基于词的生成方法的局限性。

Conclusion: DimStance为多语言、情感感知立场分析和基准测试奠定了基础。同时，它也指出了模型在情感维度预测中的局限性，在特定领域内需继续完善。

Abstract: Stance detection is an established task that classifies an author's attitude toward a specific target into categories such as Favor, Neutral, and Against. Beyond categorical stance labels, we leverage a long-established affective science framework to model stance along real-valued dimensions of valence (negative-positive) and arousal (calm-active). This dimensional approach captures nuanced affective states underlying stance expressions, enabling fine-grained stance analysis. To this end, we introduce DimStance, the first dimensional stance resource with valence-arousal (VA) annotations. This resource comprises 11,746 target aspects in 7,365 texts across five languages (English, German, Chinese, Nigerian Pidgin, and Swahili) and two domains (politics and environmental protection). To facilitate the evaluation of stance VA prediction, we formulate the dimensional stance regression task, analyze cross-lingual VA patterns, and benchmark pretrained and large language models under regression and prompting settings. Results show competitive performance of fine-tuned LLM regressors, persistent challenges in low-resource languages, and limitations of token-based generation. DimStance provides a foundation for multilingual, emotion-aware, stance analysis and benchmarking.

</details>


### [99] [MURAD: A Large-Scale Multi-Domain Unified Reverse Arabic Dictionary Dataset](https://arxiv.org/abs/2601.21512)
*Serry Sibaee,Yasser Alhabashi,Nadia Sibai,Yara Farouk,Adel Ammar,Sawsan AlHalawani,Wadii Boulila*

Main category: cs.CL

TL;DR: MURAD 是一个包含 96,243 条词义对的阿拉伯语词汇语料库，覆盖多个学科领域，旨在促进阿拉伯语自然语言处理和词汇语义研究。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏大规模的阿拉伯语词汇语料库，该研究旨在填补这一空白，以便更好地进行阿拉伯语自然语言处理和词汇语义研究。

Method: 通过解析可信的参考文献和教育资源，采用结合文本解析、光学字符识别和自动化重构的混合管道来构建 MURAD 数据集。

Result: MURAD 包含了来自多个学科领域的词汇定义，如语言学、伊斯兰研究、数学、物理、心理学和工程，支持反向字典建模、语义检索和教育资源。

Conclusion: MURAD 的发布旨在推动阿拉伯语自然语言处理的发展，并促进对阿拉伯语词汇语义的可重复研究。

Abstract: Arabic is a linguistically and culturally rich language with a vast vocabulary that spans scientific, religious, and literary domains. Yet, large-scale lexical datasets linking Arabic words to precise definitions remain limited. We present MURAD (Multi-domain Unified Reverse Arabic Dictionary), an open lexical dataset with 96,243 word-definition pairs. The data come from trusted reference works and educational sources. Extraction used a hybrid pipeline integrating direct text parsing, optical character recognition, and automated reconstruction. This ensures accuracy and clarity. Each record aligns a target word with its standardized Arabic definition and metadata that identifies the source domain. The dataset covers terms from linguistics, Islamic studies, mathematics, physics, psychology, and engineering. It supports computational linguistics and lexicographic research. Applications include reverse dictionary modeling, semantic retrieval, and educational tools. By releasing this resource, we aim to advance Arabic natural language processing and promote reproducible research on Arabic lexical semantics.

</details>


### [100] [LMK > CLS: Landmark Pooling for Dense Embeddings](https://arxiv.org/abs/2601.21525)
*Meet Doshi,Aashka Trivedi,Vishwajeet Kumar,Parul Awasthy,Yulong Li,Jaydeep Sen,Radu Florian,Sachindra Joshi*

Main category: cs.CL

TL;DR: 本文提出了一种名为Landmark（LMK）的池化方法，通过在序列中插入地标标记并将池化操作应用于这些地标标记，提高了长上下文预测而无需牺牲局部显著特征。


<details>
  <summary>Details</summary>
Motivation: 现有池化方法（如[CLS]标记和平均池化）在处理长上下文信息时存在局限性。[CLS]标记倾向于集中信息在序列的初始位置，而平均池化可能会稀释关键局部信号。

Method: LMK池化方法通过将序列分割成块，并在块之间插入地标标记，然后通过平均池化地标标记的嵌入来形成最终表示。

Result: 实验证明，LMK池化方法在短上下文检索任务上与现有方法持平，并在长上下文任务上表现出显著的提升。

Conclusion: LMK池化方法提供了一种实践上可行且易于扩展的替代现有池化方法的选择，特别在处理长语境任务时表现出色。

Abstract: Representation learning is central to many downstream tasks such as search, clustering, classification, and reranking. State-of-the-art sequence encoders typically collapse a variable-length token sequence to a single vector using a pooling operator, most commonly a special [CLS] token or mean pooling over token embeddings. In this paper, we identify systematic weaknesses of these pooling strategies: [CLS] tends to concentrate information toward the initial positions of the sequence and can under-represent distributed evidence, while mean pooling can dilute salient local signals, sometimes leading to worse short-context performance. To address these issues, we introduce Landmark (LMK) pooling, which partitions a sequence into chunks, inserts landmark tokens between chunks, and forms the final representation by mean-pooling the landmark token embeddings. This simple mechanism improves long-context extrapolation without sacrificing local salient features, at the cost of introducing a small number of special tokens. We empirically demonstrate that LMK pooling matches existing methods on short-context retrieval tasks and yields substantial improvements on long-context tasks, making it a practical and scalable alternative to existing pooling methods.

</details>


### [101] [inversedMixup: Data Augmentation via Inverting Mixed Embeddings](https://arxiv.org/abs/2601.21543)
*Fanshuang Kong,Richong Zhang,Qiyu Sun,Zhijie Nie,Ting Deng,Chunming Hu*

Main category: cs.CL

TL;DR: inversedMixup 是一种结合 Mixup 的可控性和 LLM 基础生成方法的可读性的统一框架，通过三阶段训练对齐任务特定模型的输出嵌入空间与 LLM 的输入嵌入空间。这使得 inversedMixup 能够生成具有控制混合比例的人类可读的增强样本，并且是首次提供了文本 Mixup 中的流形入侵现象的实证证据。


<details>
  <summary>Details</summary>
Motivation: 在生成增强样本时，Mixup 能够提供可控性，但样本不可读；LLM 基础生成方法可读但缺乏控制能力。inversedMixup 通过利用 LLM 反向重构技术将两者结合，旨在同时保持生成的样本的可读性和可控性。

Method: inversedMixup 采用三阶段训练方法，首先对齐任务特定模型的输出嵌入空间与 LLM 的输入嵌入空间。通过这种对齐，inversedMixup 能够生成可控混合比的、人类可读的增强句子，从而提高增强表现。

Result: 实验表明 inversedMixup 在少量标注（few-shot）和完全监督（fully supervised）场景中均表现出色且具有广泛的适用性。此外，它还提供了关于文本 Mixup 中的流形入侵现象的首次实证证据，并提出了一种简单的缓解策略。

Conclusion: inversedMixup 提供了一种新的生成增强样本的方法，通过结合 Mixup 的可控性和 LLM 的可读性，为自然语言处理任务提供了有前途的增强策略。

Abstract: Mixup generates augmented samples by linearly interpolating inputs and labels with a controllable ratio. However, since it operates in the latent embedding level, the resulting samples are not human-interpretable. In contrast, LLM-based augmentation methods produce sentences via prompts at the token level, yielding readable outputs but offering limited control over the generation process. Inspired by recent advances in LLM inversion, which reconstructs natural language from embeddings and helps bridge the gap between latent embedding space and discrete token space, we propose inversedMixup, a unified framework that combines the controllability of Mixup with the interpretability of LLM-based generation. Specifically, inversedMixup adopts a three-stage training procedure to align the output embedding space of a task-specific model with the input embedding space of an LLM. Upon successful alignment, inversedMixup can reconstruct mixed embeddings with a controllable mixing ratio into human-interpretable augmented sentences, thereby improving the augmentation performance. Additionally, inversedMixup provides the first empirical evidence of the manifold intrusion phenomenon in text Mixup and introduces a simple yet effective strategy to mitigate it. Extensive experiments demonstrate the effectiveness and generalizability of our approach in both few-shot and fully supervised scenarios.

</details>


### [102] [Note2Chat: Improving LLMs for Multi-Turn Clinical History Taking Using Medical Notes](https://arxiv.org/abs/2601.21551)
*Yang Zhou,Zhenting Sheng,Mingrui Tan,Yuting Song,Jun Zhou,Yu Heng Kwan,Lian Leng Low,Yang Bai,Yong Liu*

Main category: cs.CL

TL;DR: 该研究提出了一种名为\method{}的框架，通过学习广泛可用的医疗笔记来训练大语言模型进行结构化的病史采集和诊断。通过决策树指导生成和改进流程将真实世界医疗笔记转化为高质量的医生-患者对话，并采用监督学习、模拟数据增强和偏好学习的三阶段微调策略。该方法提高了临床推理的效果，相较于GPT-4o显示了显著的F1和Top-1诊断准确率提升。


<details>
  <summary>Details</summary>
Motivation: 为了解决大语言模型在动态多轮诊断设置中的问题，这些设置需要迭代提问和假设细化，并提出了\method{}框架来利用广泛的医学笔记数据进行训练。

Method: \method{}框架通过决策树指导的生成和改进流程将医疗笔记转化为高质量的医生-患者对话，并采用监督学习、模拟数据增强和偏好学习的三阶段微调策略。引入了一种新的单轮推理范式，将病史采集重新定义为一系列单轮推理问题。

Result: 实验结果显示该方法显著提高了临床推理效果，比GPT-4o提高了16.9 F1和21.0 Top-1诊断准确率。

Conclusion: 该研究通过创新的方法提升了基于大语言模型的临床推理能力，展现了其在实际医疗应用中的潜力。

Abstract: Effective clinical history taking is a foundational yet underexplored component of clinical reasoning. While large language models (LLMs) have shown promise on static benchmarks, they often fall short in dynamic, multi-turn diagnostic settings that require iterative questioning and hypothesis refinement. To address this gap, we propose \method{}, a note-driven framework that trains LLMs to conduct structured history taking and diagnosis by learning from widely available medical notes. Instead of relying on scarce and sensitive dialogue data, we convert real-world medical notes into high-quality doctor-patient dialogues using a decision tree-guided generation and refinement pipeline. We then propose a three-stage fine-tuning strategy combining supervised learning, simulated data augmentation, and preference learning. Furthermore, we propose a novel single-turn reasoning paradigm that reframes history taking as a sequence of single-turn reasoning problems. This design enhances interpretability and enables local supervision, dynamic adaptation, and greater sample efficiency. Experimental results show that our method substantially improves clinical reasoning, achieving gains of +16.9 F1 and +21.0 Top-1 diagnostic accuracy over GPT-4o. Our code and dataset can be found at https://github.com/zhentingsheng/Note2Chat.

</details>


### [103] [KromHC: Manifold-Constrained Hyper-Connections with Kronecker-Product Residual Matrices](https://arxiv.org/abs/2601.21579)
*Wuyang Zhou,Yuxuan Gu,Giorgos Iacovides,Danilo Mandic*

Main category: cs.CL

TL;DR: KromHC 使用较小的克罗内克积来参数化残差矩阵，从而缓解了 mHC 中的迭代方法不总是产生精确的双对公司矩阵的问题，并将参数复杂度降至 O(n^2C)，实验表明其性能优于现有的 mHC 变体。


<details>
  <summary>Details</summary>
Motivation: 当前的 Manifold-Constrained Hyper-Connections (mHC) 训练不稳定且参数复杂度过高，而 mHC-lite 方法虽然解决了参数复杂度过高的问题，但是存在指数级的参数复杂度。KromHC 则通过使用较小的克罗内克积来缓解这些问题。

Method: KromHC 使用克罗内克积来参数化残差矩阵，并通过对张量化的残差流的因式残差矩阵施加流形约束，来确保残留矩阵的双对公司属性，同时将参数复杂度降低至 O(n^2C)。

Result: 实验结果表明，KromHC 的性能与最先进的 mHC 变体相当甚至略优，且需要更少的可训练参数。

Conclusion: KromHC 方法成功解决了 mHC 和 mHC-lite 方法存在的问题，提供了更高的效率和性能。相关的代码可从 https://github.com/wz1119/KromHC 获取。

Abstract: The success of Hyper-Connections (HC) in neural networks (NN) has also highlighted issues related to its training instability and restricted scalability. The Manifold-Constrained Hyper-Connections (mHC) mitigate these challenges by projecting the residual connection space onto a Birkhoff polytope, however, it faces two issues: 1) its iterative Sinkhorn-Knopp (SK) algorithm does not always yield exact doubly stochastic residual matrices; 2) mHC incurs a prohibitive $\mathcal{O}(n^3C)$ parameter complexity with $n$ as the width of the residual stream and $C$ as the feature dimension. The recently proposed mHC-lite reparametrizes the residual matrix via the Birkhoff-von-Neumann theorem to guarantee double stochasticity, but also faces a factorial explosion in its parameter complexity, $\mathcal{O} \left( nC \cdot n! \right)$. To address both challenges, we propose \textbf{KromHC}, which uses the \underline{Kro}necker products of smaller doubly stochastic matrices to parametrize the residual matrix in \underline{mHC}. By enforcing manifold constraints across the factor residual matrices along each mode of the tensorized residual stream, KromHC guarantees exact double stochasticity of the residual matrices while reducing parameter complexity to $\mathcal{O}(n^2C)$. Comprehensive experiments demonstrate that KromHC matches or even outperforms state-of-the-art (SOTA) mHC variants, while requiring significantly fewer trainable parameters. The code is available at \texttt{https://github.com/wz1119/KromHC}.

</details>


### [104] [ILRR: Inference-Time Steering Method for Masked Diffusion Language Models](https://arxiv.org/abs/2601.21647)
*Eden Avrahami,Eliya Nachmani*

Main category: cs.CL

TL;DR: ILRR 提供了一种无需学习的方法，通过单一参考序列引导非自回归文本生成模型的内部激活，从而实现属性控制。该方法通过动态对齐生成序列和参考序列的激活来捕获和转移高层语义属性，并通过调节指导强度实现长文本的局部控制。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散语言模型(DLMs)虽然为非自回归文本生成提供了有前途的替代方案，但推理时的有效控制机制仍然相对较少研究。为了解决这一问题，本文提出了一种无需学习的Iterative Latent Representation Refinement (ILRR)框架。

Method: ILRR 基于单一参考序列来动态对齐生成序列和参考序列的内部激活，通过调节指导强度实现属性控制。

Result: 实验结果显示，ILRR 能在LLaDA 和 MDLM 架构中实现有效的属性控制，同时仅需要添加一个额外的并行前向传播计算步骤。与同等计算预算下的基线相比，ILRR 的属性准确性提高了 10%-60%，同时保持了高质量的生成。

Conclusion: ILRR 为非自回归文本生成模型的属性控制提供了一种有效且高效的解决方案。

Abstract: Discrete Diffusion Language Models (DLMs) offer a promising non-autoregressive alternative for text generation, yet effective mechanisms for inference-time control remain relatively underexplored. Existing approaches include sampling-level guidance procedures or trajectory optimization mechanisms. In this work, we introduce Iterative Latent Representation Refinement (ILRR), a learning-free framework for steering DLMs using a single reference sequence. ILRR guides generation by dynamically aligning the internal activations of the generated sequence with those of a given reference throughout the denoising process. This approach captures and transfers high-level semantic properties, with a tunable steering scale enabling flexible control over attributes such as sentiment. We further introduce Spatially Modulated Steering, an extension that enables steering long texts using shorter references by regulating guidance intensity across the sequence. Empirically, we demonstrate that ILRR achieves effective attribute steering on LLaDA and MDLM architectures with a minor computational overhead, requiring only one additional parallel forward pass per denoising step. Under the same compute budget, ILRR improves attribute accuracy over comparable baselines by 10$\%$ to 60$\%$ points, while maintaining high generation quality.

</details>


### [105] [AdaptBPE: From General Purpose to Specialized Tokenizers](https://arxiv.org/abs/2601.21665)
*Vijini Liyanage,François Yvon*

Main category: cs.CL

TL;DR: 本文提出了一种在训练后自适应替换低效子词的策略，通过调整字汇表大小，优化特定领域或任务的分词处理。


<details>
  <summary>Details</summary>
Motivation: 当前通用的字节对编码（BPE）分词方法在应用于特定领域或语言时可能会产生效率损失。因此，本文提出了一种基于自适应推理出更合适的子词替代策略，以提高模型在特定任务或语言下的性能。

Method: 该方法首先确定适应语料库中最佳的分词词汇表大小，然后选取频率较高的子词替换掉原始通用分词方法中的低效子词。

Result: 实验表明，经过自适应的分词方法在任务型和分类任务中能够更有效地压缩测试语料库，相比基线方法有显著性能提升。

Conclusion: 该研究提供了一种轻量级的自适应机制，用于优化特定领域的大型语言模型分词，能够有效提升模型在特定任务或语言上的效能。

Abstract: Subword tokenization methods, such as Byte-Pair Encoding (BPE), significantly impact the performance and efficiency of large language models (LLMs). The standard approach involves training a general-purpose tokenizer that uniformly processes all textual data during both training and inference. However, the use of a generic set of tokens can incur inefficiencies when applying the model to specific domains or languages. To address this limitation, we propose a post-training adaptation strategy that selectively replaces low-utility tokens with more relevant ones based on their frequency in an adaptation corpus. Our algorithm identifies the token inventory that most effectively encodes the adaptation corpus for a given target vocabulary size. Extensive experiments on generation and classification tasks across multiple languages demonstrate that our adapted tokenizers compress test corpora more effectively than baselines using the same vocabulary size. This method serves as a lightweight adaptation mechanism, akin to a vocabulary fine-tuning process, enabling optimized tokenization for specific domains or tasks. Our code and data are available at https://github.com/vijini/Adapt-BPE.git.

</details>


### [106] [Scale-Dependent Semantic Dynamics Revealed by Allan Deviation](https://arxiv.org/abs/2601.21678)
*Debayan Dasgupta*

Main category: cs.CL

TL;DR: 本文利用Allan偏差分析了文本语义的动态演变，揭示了两种不同的动态模式，并发现大语言模型在语义稳定性方面存在系统性的不足。


<details>
  <summary>Details</summary>
Motivation: 探讨语言演变的动态机制，特别是文本语义如何随时间演变，以及这种演变是否可以被量化。

Method: 采用Allan偏差分析方法，将有序句子嵌入视为位移信号，识别文本语义演变的动态模式。

Result: 发现了两种动态模式：短期呈现幂律缩放，区分创意文学和技术文本；长期则过渡到稳定性限制下的噪声地板。大语言模型有效模仿了人类文本的局部缩放统计，但其稳定性范围系统性较低。

Conclusion: 证实了语义连贯性是可测量的物理属性，为区分人类认知的微妙动态与算法模型生成的模式提供了框架。

Abstract: While language progresses through a sequence of semantic states, the underlying dynamics of this progression remain elusive. Here, we treat the semantic progression of written text as a stochastic trajectory in a high-dimensional state space. We utilize Allan deviation, a tool from precision metrology, to analyze the stability of meaning by treating ordered sentence embeddings as a displacement signal. Our analysis reveals two distinct dynamical regimes: short-time power-law scaling, which differentiates creative literature from technical texts, and a long-time crossover to a stability-limited noise floor. We find that while large language models successfully mimic the local scaling statistics of human text, they exhibit a systematic reduction in their stability horizon. These results establish semantic coherence as a measurable physical property, offering a framework to differentiate the nuanced dynamics of human cognition from the patterns generated by algorithmic models.

</details>


### [107] [Do Not Waste Your Rollouts: Recycling Search Experience for Efficient Test-Time Scaling](https://arxiv.org/abs/2601.21684)
*Xinglin Wang,Jiayi Shi,Shaoxiong Feng,Peiwen Yuan,Yiwei Li,Yueqi Zhang,Chuyi Tan,Ji Zhang,Boyuan Pan,Yao Hu,Kan Li*

Main category: cs.CL

TL;DR: RSE是一种自我引导的测试时搜索策略，通过积累和再利用中间结论和失败模式，提高大型语言模型在解题时的推理效率。


<details>
  <summary>Details</summary>
Motivation: 现有的搜索策略通常将采样视为一次性的，每次试验后有价值的中间见解被丢弃，导致了大量的重复计算。

Method: RSE通过积极地将原始轨迹提炼到共享经验库中，实现了正向和负向的中间结论再利用，从而减少冗余推理和修剪遇到的死胡同。

Result: 理论分析表明RSE在解决复杂推理任务时提高了效率，并且在HMMT24, HMMT25, IMO-Bench和HLE上的实验证明了其在与基准模型相似的计算成本下取得了最先进的扩展效率。

Conclusion: RSE提供了一种有效的策略来实现测试时搜索的经验积累，显著提高了大型语言模型解决复杂推理问题的能力。

Abstract: Test-Time Scaling enhances the reasoning capabilities of Large Language Models by allocating additional inference compute to broaden the exploration of the solution space. However, existing search strategies typically treat rollouts as disposable samples, where valuable intermediate insights are effectively discarded after each trial. This systemic memorylessness leads to massive computational redundancy, as models repeatedly re-derive discovered conclusions and revisit known dead ends across extensive attempts. To bridge this gap, we propose \textbf{Recycling Search Experience (RSE)}, a self-guided, training-free strategy that turns test-time search from a series of isolated trials into a cumulative process. By actively distilling raw trajectories into a shared experience bank, RSE enables positive recycling of intermediate conclusions to shortcut redundant derivations and negative recycling of failure patterns to prune encountered dead ends. Theoretically, we provide an analysis that formalizes the efficiency gains of RSE, validating its advantage over independent sampling in solving complex reasoning tasks. Empirically, extensive experiments on HMMT24, HMMT25, IMO-Bench, and HLE show that RSE consistently outperforms strong baselines with comparable computational cost, achieving state-of-the-art scaling efficiency.

</details>


### [108] [Why Attention Patterns Exist: A Unifying Temporal Perspective Analysis](https://arxiv.org/abs/2601.21709)
*Qingyue Yang,Jie Wang,Xing Li,Yinqi Bai,Xialiang Tong,Huiling Zhen,Jianye Hao,Mingxuan Yuan,Bin Li*

Main category: cs.CL

TL;DR: TAPPA是一种统一框架，通过分析时间连续视角下的注意力模式的数学公式，来解释多样的注意力模式，从而深入理解注意力行为并指导加速推理方法。


<details>
  <summary>Details</summary>
Motivation: TAPPA旨在通过提供一种统一的框架来解释各种注意力模式，弥合并统一现有的零散观察，为大型语言模型（LLMs）的训练和推理提供新的见解和优化手段。

Method: TAPPA通过分析注意力模式的数学表达方式，特别是从时间连续的视角，将注意力模式分为可预测和不可预测两类，并进一步对特定案例进行了详细的数学分析，结合查询、键和旋转位置嵌入（RoPE）的效果。

Result: TAPPA揭示了可预测性和不可预测性的区分可以由查询在时间维度上的自我相似度程度来解释。通过对可预测模式的分析，提出了对未来KV缓存压缩和LLM剪枝任务的实用见解，表明采用Motivated by TAPPA的简单度量指标能显著提升这些任务的性能。

Conclusion: TAPPA为理解和优化大型语言模型提供了新的工具和方法，有助于加速推理过程并提高模型性能。

Abstract: Attention patterns play a crucial role in both training and inference of large language models (LLMs). Prior works have identified individual patterns such as retrieval heads, sink heads, and diagonal traces, yet these observations remain fragmented and lack a unifying explanation. To bridge this gap, we introduce \textbf{Temporal Attention Pattern Predictability Analysis (TAPPA), a unifying framework that explains diverse attention patterns by analyzing their underlying mathematical formulations} from a temporally continuous perspective. TAPPA both deepens the understanding of attention behavior and guides inference acceleration approaches. Specifically, TAPPA characterizes attention patterns as predictable patterns with clear regularities and unpredictable patterns that appear effectively random. Our analysis further reveals that this distinction can be explained by the degree of query self-similarity along the temporal dimension. Focusing on the predictable patterns, we further provide a detailed mathematical analysis of three representative cases through the joint effect of queries, keys, and Rotary Positional Embeddings (RoPE). We validate TAPPA by applying its insights to KV cache compression and LLM pruning tasks. Across these tasks, a simple metric motivated by TAPPA consistently improves performance over baseline methods. The code is available at https://github.com/MIRALab-USTC/LLM-TAPPA.

</details>


### [109] [TACLer: Tailored Curriculum Reinforcement Learning for Efficient Reasoning](https://arxiv.org/abs/2601.21711)
*Huiyuan Lai,Malvina Nissim*

Main category: cs.CL

TL;DR: TACLer 通过定制化的课程强化学习框架，逐步增加数据复杂性以提升模型效率和性能，同时保持准确性和降低推理时的计算成本。


<details>
  <summary>Details</summary>
Motivation: 当前的大型语言模型在复杂的推理任务中取得了显著成果，但长链推理通常需要大规模的强化学习训练，这可能导致冗余的中间步骤和过度推理。因此，为了提高学习和推理效率，同时拥有或增强性能，研究者提出了 TACLer 模型定制的课程强化学习框架。

Method: TACLer 包含两个核心组件：定制化的课程学习机制来确定模型缺乏的知识及其渐进的学习阶段；以及混合思维/非思考推理范式，通过启用或禁止思维模式来平衡准确性和效率。

Result: 实验表明，TACLer 在学习和推理方面具有两倍的优势：首先，它减少了计算成本，相较于长思考模型的训练计算减少了超过 50%，并且推理时的令牌使用量相对基线模型降低了超过 42%；其次，它在四个具有复杂问题的数学数据集上提高了基线模型 9% 的准确率，持续超过最先进的非思考和思考基线。

Conclusion: TACLer 是一种有效的强化学习框架，能够提升大型语言模型在复杂推理任务中的效率和性能。

Abstract: Large Language Models (LLMs) have shown remarkable performance on complex reasoning tasks, especially when equipped with long chain-of-thought (CoT) reasoning. However, eliciting long CoT typically requires large-scale reinforcement learning (RL) training, while often leading to overthinking with redundant intermediate steps. To improve learning and reasoning efficiency, while preserving or even enhancing performance, we propose TACLer, a model-tailored curriculum reinforcement learning framework that gradually increases the complexity of the data based on the model's proficiency in multi-stage RL training. TACLer features two core components: (i) tailored curriculum learning that determines what knowledge the model lacks and needs to learn in progressive stages; (ii) a hybrid Thinking/NoThinking reasoning paradigm that balances accuracy and efficiency by enabling or disabling the Thinking mode. Our experiments show that TACLer yields a twofold advantage in learning and reasoning: (i) it reduces computational cost, cutting training compute by over 50% compared to long thinking models and reducing inference token usage by over 42% relative to the base model; and (ii) it improves accuracy by over 9% on the base model, consistently outperforming state-of-the-art Nothinking and Thinking baselines across four math datasets with complex problems.

</details>


### [110] [Enhancing Language Models for Robust Greenwashing Detection](https://arxiv.org/abs/2601.21722)
*Neil Heinrich Braun,Keane Ong,Rui Mao,Erik Cambria,Gianmarco Mengaldo*

Main category: cs.CL

TL;DR: 我们提出了一种参数高效框架，结合对比学习和有序排名目标来捕捉具体行动与模糊声明之间的渐进区别，并利用门控特征调节来过滤披露噪音和MetaGradNorm来稳定多目标优化，从而提高在跨类别设置中的稳健性。


<details>
  <summary>Details</summary>
Motivation: 可持续报告对于ESG评估至关重要，但普遍存在绿色漂洗和模糊声明的问题，这影响了报告的可靠性。现有的NLP模型对于处理这些问题的效果不佳，通常依赖于难以泛化的表面模式。

Method: 该方法结合了对比学习和有序排名目标，通过门控机制过滤披露噪音，并使用MetaGradNorm进行多目标优化的稳定性。

Result: 在跨类别设置中的实验显示，该方法相较于标准基线具备更好的稳健性，同时揭示了表现力刚性和泛化能力之间的权衡。

Conclusion: 这项工作提出了一种新的参数高效框架，旨在提高可持续报告的可靠性，特别是在处理绿色漂洗和模糊声明方面。

Abstract: Sustainability reports are critical for ESG assessment, yet greenwashing and vague claims often undermine their reliability. Existing NLP models lack robustness to these practices, typically relying on surface-level patterns that generalize poorly. We propose a parameter-efficient framework that structures LLM latent spaces by combining contrastive learning with an ordinal ranking objective to capture graded distinctions between concrete actions and ambiguous claims. Our approach incorporates gated feature modulation to filter disclosure noise and utilizes MetaGradNorm to stabilize multi-objective optimization. Experiments in cross-category settings demonstrate superior robustness over standard baselines while revealing a trade-off between representational rigidity and generalization.

</details>


### [111] [Procedural Pretraining: Warming Up Language Models with Abstract Data](https://arxiv.org/abs/2601.21725)
*Liangze Jiang,Zachary Shinnick,Anton van den Hengel,Hemanth Saratchandran,Damien Teney*

Main category: cs.CL

TL;DR: 该研究探讨了一种训练语言模型的新方法，即在广泛的结构化数据上进行预训练，而非使用大规模的自然语言文本。这种方法能够在不牺牲模型性能的情况下减少所需的数据量，并且在复杂领域的性能表现尤其出色。


<details>
  <summary>Details</summary>
Motivation: 与直接在大规模自然语言数据上训练模型的传统方法相比，本研究提出的先用结构化数据进行预训练，可以提升模型处理特定任务的能力，特别是在需要算法和逻辑推理的情况下，类似于人类学习逻辑和数学后再进行更复杂的推理。

Method: 研究首先分析了不同类型的程序化数据能够改善哪些算法技能，然后在较大的语言模型（最大至1.3B参数）上进行了训练，验证了程序化数据预训练的效果。还通过分析模型的结构层来探索背后的工作机制。

Result: 实验结果表明，使用0.1%的程序化数据预训练可以显著优于使用自然语言、代码和非正式数学训练的传统方法。预训练后，模型能用更少的数据达到相同的损失水平，特别适用于结构化较强的领域。

Conclusion: 研究证明程序化数据预训练是一种有效且轻量的方法，能够提升语言模型的性能并加快预训练过程，同时也暗示了分离知识获取与推理过程在大语言模型（LLM）中的潜力。

Abstract: Pretraining directly on web-scale corpora is the de facto paradigm for building language models. We study an alternative setting where the model is initially exposed to abstract structured data, as a means to ease the subsequent acquisition of rich semantic knowledge, much like humans learn simple logic and mathematics before higher reasoning. We specifically focus on procedural data, generated by formal languages and other simple algorithms, as such abstract data.
  We first diagnose the algorithmic skills that different forms of procedural data can improve, often significantly. For example, on context recall (Needle-in-a-haystack), the accuracy jumps from 10 to 98% when pretraining on Dyck sequences (balanced brackets). Second, we study how these gains are reflected in pretraining larger models (up to 1.3B). We find that front-loading as little as 0.1% procedural data significantly outperforms standard pretraining on natural language, code, and informal mathematics (C4, CodeParrot, and DeepMind-Math datasets). Notably, this procedural pretraining enables the models to reach the same loss value with only 55, 67, 86% of the original data. Third, we explore the mechanisms behind and find that procedural pretraining instils non-trivial structure in both attention and MLP layers. The former is particularly important for structured domains (e.g. code), and the latter for language. Finally, we lay a path for combining multiple forms of procedural data. Our results show that procedural pretraining is a simple, lightweight means to improving performance and accelerating language model pretraining, ultimately suggesting the promise of disentangling knowledge acquisition from reasoning in LLMs.

</details>


### [112] [CE-GOCD: Central Entity-Guided Graph Optimization for Community Detection to Augment LLM Scientific Question Answering](https://arxiv.org/abs/2601.21733)
*Jiayin Lan,Jiaqi Li,Baoxin Wang,Ming Liu,Dayong Wu,Shijin Wang,Bing Qin,Guoping Hu*

Main category: cs.CL

TL;DR: 本文提出了一种新的方法，CE-GOCD，旨在通过利用学术知识图中的语义子结构来增强大型语言模型在科学文献中回答问题的能力，从而提高答案的全面性和具体性。


<details>
  <summary>Details</summary>
Motivation: 现有的检索增强方法通常依赖于孤立的文本片段或概念，忽略了科学文献之间更深层次的语义联系，这限制了大型语言模型对科学文献的理解能力。

Method: CE-GOCD方法通过利用文章标题作为中心实体进行有针对性的子图检索，增强隐式的语义发现通过子图修剪和完成，并利用社区检测以提炼具有共同主题的论文组来实现。

Result: 该方法在三个基于自然语言处理文献的问题回答数据集上进行了评估，并且结果表明该方法优于其他检索增强基线方法，证实了该框架的有效性。

Conclusion: 研究表明，通过利用学术知识图中的语义子结构，CE-GOCD方法能够有效提升大型语言模型理解和回答科学研究问题的能力。

Abstract: Large Language Models (LLMs) are increasingly used for question answering over scientific research papers. Existing retrieval augmentation methods often rely on isolated text chunks or concepts, but overlook deeper semantic connections between papers. This impairs the LLM's comprehension of scientific literature, hindering the comprehensiveness and specificity of its responses. To address this, we propose Central Entity-Guided Graph Optimization for Community Detection (CE-GOCD), a method that augments LLMs' scientific question answering by explicitly modeling and leveraging semantic substructures within academic knowledge graphs. Our approach operates by: (1) leveraging paper titles as central entities for targeted subgraph retrieval, (2) enhancing implicit semantic discovery via subgraph pruning and completion, and (3) applying community detection to distill coherent paper groups with shared themes. We evaluated the proposed method on three NLP literature-based question-answering datasets, and the results demonstrate its superiority over other retrieval-augmented baseline approaches, confirming the effectiveness of our framework.

</details>


### [113] [Temporal Guidance for Large Language Models](https://arxiv.org/abs/2601.21744)
*Hong-Kai Zheng,Piji Li*

Main category: cs.CL

TL;DR: 本文提出了一种新的基于时间维度的对比指导策略（TeGu），通过利用多令牌预测（MTP）生成较弱的自对比预测，相比现有方法，TeGu在多个模型系列和基准测试中表现出更好的性能改进，同时保持低的额外内存消耗和计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有的内部自对比解码方法，如DoLa，集中在不同层之间的差异，这在小型模型上表现不稳定。本文的动机是利用观察到的语言模型对局部偏好的理解，提出一种基于时间维度的对比指导策略（TeGu）。

Method: 本文通过引入一种轻量级的条件多令牌预测项目器（cMTPP），利用多令牌预测生成较弱的自对比预测，实现这种机制的标准化。

Result: 本文提出的方法（TeGu）在各种模型系列和基准的对比实验中表现出显著的性能改进，同时保持低的额外内存和计算开销。

Conclusion: 本文提出了一种新的对比指导策略（TeGu），并通过有效的设计和实验验证了其在提升大型语言模型生成质量方面的潜力。

Abstract: Contrastive Decoding (CD) enhances the generation quality of large language models (LLMs) but incurs significant additional computational overhead due to the need for an auxiliary model. Existing internal self-contrastive decoding methods, such as Decoding by Contrasting Layers (DoLa), focus on discrepancies across different layers, which are notably unstable on small-scale models. In this work, based on the observation that LLMs exhibit local preferences, we propose a novel contrastive guidance strategy along the temporal dimension, namely Temporal Guidance (TeGu). Our method ingeniously leverages Multi-Token Prediction (MTP) to construct weaker amateur predictions for model self-contrast. To standardize the implementation of this mechanism, we further introduce a lightweight Conditional MTP Projector (cMTPP), which avoids maintaining multiple independent networks as required by other MTP modules. Across various model series and benchmarks, TeGu achieves significant performance improvements while maintaining low additional memory consumption and computational overhead.

</details>


### [114] [Evaluating ChatGPT on Medical Information Extraction Tasks: Performance, Explainability and Beyond](https://arxiv.org/abs/2601.21767)
*Wei Zhu*

Main category: cs.CL

TL;DR: 本研究评估了ChatGPT在6个医疗信息提取基准数据集上的4种不同任务中的表现，发现其在任务性能上不如微调基线模型，并且过度自信于预测。尽管表现良好，但生成的不确定性影响了其在医疗信息提取任务中的应用。


<details>
  <summary>Details</summary>
Motivation: 研究团队希望通过评估ChatGPT在复杂而关键的医疗信息提取任务中的表现，以更好地了解其处理特定专业领域任务的能力和限制。

Method: 研究人员通过将ChatGPT与预先微调的模型进行对比，使用六组基准数据集对ChatGPT在四个医疗信息提取任务中的整体能力进行了系统分析，包括表现、解释性、忠实性和不确定性。

Result: 研究结果表明，ChatGPT在医疗信息提取任务上的性能不及微调基线模型，尽管能提供高质量的解释，但预测过于自信，展示了对原始文本的高度忠实性，但生成的不确定性会影响其在医疗信息提取中的应用。

Conclusion: 尽管ChatGPT在解释性和忠实性方面表现出色，但在特定任务上不如微调模型，其过度自信和生成不确定性限制了其在医疗信息提取中的应用。未来的研究应重点关注如何减少模型的不确定性，提高其在专业领域任务中的实际应用价值。

Abstract: Large Language Models (LLMs) like ChatGPT have demonstrated amazing capabilities in comprehending user intents and generate reasonable and useful responses. Beside their ability to chat, their capabilities in various natural language processing (NLP) tasks are of interest to the research community. In this paper, we focus on assessing the overall ability of ChatGPT in 4 different medical information extraction (MedIE) tasks across 6 benchmark datasets. We present the systematically analysis by measuring ChatGPT's performance, explainability, confidence, faithfulness, and uncertainty. Our experiments reveal that: (a) ChatGPT's performance scores on MedIE tasks fall behind those of the fine-tuned baseline models. (b) ChatGPT can provide high-quality explanations for its decisions, however, ChatGPT is over-confident in its predcitions. (c) ChatGPT demonstrates a high level of faithfulness to the original text in the majority of cases. (d) The uncertainty in generation causes uncertainty in information extraction results, thus may hinder its applications in MedIE tasks.

</details>


### [115] [Zonkey: A Hierarchical Diffusion Language Model with Differentiable Tokenization and Probabilistic Attention](https://arxiv.org/abs/2601.21768)
*Alon Rozental*

Main category: cs.CL

TL;DR: Zonkey 是一种深度可训练的文本表示模型，通过一个差分的分词器将原始字符转化为文档级别的表示，它无需额外监督即可学习出语义上合理的分词方式。引入‘概率注意力’机制模拟无限序列的软遮罩，同时保持梯度传递，实现端到端的训练。Zonkey 能够生成连贯的、可变长度的文本，展示了更好的领域适应性和生成能力。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型受到固定且非可微分的分词器限制，这阻碍了其在处理噪声数据或特定领域数据时的端到端优化和适应性。Zonkey 的目标是克服这些限制，提供一种更灵活、更适应不同任务的文本表示方法。

Method: Zonkey 采用了一种名为 Segment Splitter 的可训练分词器，并在其基础上结合了概率注意力机制。通过这种方式，它可以将原始字符序列逐层压缩成更高抽象层次的表示，从而实现对文本的高效编码和解码。同时，Zonkey 还通过一种称为 Denoising Diffusion Mixed Model (DDMM) 的去噪模型来稳定地在潜在空间中进行去噪。

Result: Zonkey 在无监督训练下能够生成连贯且具有多样长度的文本，并展示了比基于熵的可训练分词器更好的质性结果。这种模型在处理特定领域数据或噪声数据方面具有潜在的优势。

Conclusion: Zonkey 的方法为大语言模型在可训练分词器方面提供了新的视角，有助于提高模型在各种应用场景中的性能。未来的研究可以进一步探索如何优化其性能，以适应更多类型的文本处理需求。

Abstract: Large language models (LLMs) have revolutionized natural language processing, yet they remain constrained by fixed, non-differentiable tokenizers like Byte Pair Encoding (BPE), which hinder end-to-end optimization and adaptability to noisy or domain-specific data. We introduce Zonkey, a hierarchical diffusion model that addresses these limitations through a fully trainable pipeline from raw characters to document-level representations. At its core is a differentiable tokenizer (Segment Splitter) that learns probabilistic beginning-of-sequence (BOS) decisions, enabling adaptive splits that emerge as linguistically meaningful (e.g., word boundaries at spaces, sentence starts at periods) without explicit supervision. This differentiability is enabled by our novel Probabilistic Attention mechanism, which incorporates position-specific existence probabilities to simulate soft masking over theoretically infinite sequences while preserving gradients. Sequences decay probabilistically rather than relying on end-of-sequence tokens, supporting variable-length outputs. Hierarchical levels compress sequences into higher abstractions (e.g., character n-grams to word-like vectors, then sentence-like), with reconstruction via our Denoising Diffusion Mixed Model (DDMM) for stable and efficient denoising in latent space. A Stitcher ensures overlap invariance across segments. Trained end-to-end on Wikipedia, Zonkey generates coherent, variable-length text from noise, demonstrating emergent hierarchies and promising qualitative alignment to data distributions compared to entropy-based learnable tokenizers. Our approach advances toward fully gradient-based LLMs, with potential for better domain adaptation and scalable generation. We release the source code for training and reproducing our experiments.

</details>


### [116] [RAG-E: Quantifying Retriever-Generator Alignment and Failure Modes](https://arxiv.org/abs/2601.21803)
*Korbinian Randl,Guido Rocchietti,Aron Henriksson,Ziawasch Abedjan,Tony Lindgren,John Pavlopoulos*

Main category: cs.CL

TL;DR: RAG-E 提供了一种端到端的可解释性框架，用于量化检索器生成器的对齐程度，并通过数学依据的方法评估其性能。


<details>
  <summary>Details</summary>
Motivation: 当前的 RAG 系统在高风险领域的应用存在挑战，因为其组件间复杂交互的不透明性。

Method: RAG-E 采用了 Integrated Gradients 方法分析检索器、PMCSHAP 方法为生成器提供归因，并引入 WARG 测量生成器对检索器排名的吻合度。

Result: 实验证明 RAG-E 可以识别关键的对齐问题，如生成器忽略检索器最相关文档或过度依赖次相关文档。

Conclusion: RAG-E 的引入展示了 RAG 输出质量不仅依赖于每个组件的表现，还依赖于它们的交互方式，可以通过 RAG-E 进行审计。

Abstract: Retrieval-Augmented Generation (RAG) systems combine dense retrievers and language models to ground LLM outputs in retrieved documents. However, the opacity of how these components interact creates challenges for deployment in high-stakes domains. We present RAG-E, an end-to-end explainability framework that quantifies retriever-generator alignment through mathematically grounded attribution methods. Our approach adapts Integrated Gradients for retriever analysis, introduces PMCSHAP, a Monte Carlo-stabilized Shapley Value approximation, for generator attribution, and introduces the Weighted Attribution-Relevance Gap (WARG) metric to measure how well a generator's document usage aligns with a retriever's ranking. Empirical analysis on TREC CAsT and FoodSafeSum reveals critical misalignments: for 47.4% to 66.7% of queries, generators ignore the retriever's top-ranked documents, while 48.1% to 65.9% rely on documents ranked as less relevant. These failure modes demonstrate that RAG output quality depends not solely on individual component performance but on their interplay, which can be audited via RAG-E.

</details>


### [117] [Distribution-Aware Reward Estimation for Test-Time Reinforcement Learning](https://arxiv.org/abs/2601.21804)
*Bodong Du,Xuanqi Huang,Xiaomeng Li*

Main category: cs.CL

TL;DR: 本文提出了一种名为DARE的方法，通过考虑所有可能的结果而不是单一的多数结果，增强了奖励估计的有效性，还加入了探索奖励和去噪机制以提高稳定性和性能。


<details>
  <summary>Details</summary>
Motivation: 当前的TTRL方法依赖于多数投票产生确定性奖励，这一方法假设多数结果是最可靠的。然而，这种方法忽略了其他正确选择的潜在价值，并导致奖励估计系统性偏差。本文通过新的方法来解决这一问题。

Method: DARE利用经验滚动力量分布进行奖励估计，并加入了探索奖励和去噪机制，确保奖励估计更加可靠。

Result: 在复杂的推理基准测试中，DARE方法相比最近的基线方法提高了优化稳定性和最终性能，具体为AIME 2024提高了25.3%和AMC提高了5.3%。

Conclusion: 本文提出的方法DARE改进了TTRL的性能，特别是在挑战性的推理任务中表现出色，提供了更加准确和稳健的奖励估计。

Abstract: Test-time reinforcement learning (TTRL) enables large language models (LLMs) to self-improve on unlabeled inputs, but its effectiveness critically depends on how reward signals are estimated without ground-truth supervision. Most existing TTRL methods rely on majority voting (MV) over rollouts to produce deterministic rewards, implicitly assuming that the majority rollout provides a reliable learning signal. We show that this assumption is fragile: MV reduces the rollout distribution into a single outcome, discarding information about non-majority but correct actions candidates, and yields systematically biased reward estimates. To address this, we propose Distribution-AwareReward Estimation (DARE), which shifts reward estimation from a single majority outcome to the full empirical rollout distribution. DARE further augments this distribution-based reward with an exploration bonus and a distribution pruning mechanism for non-majority rollout exploration and reward denoise, yielding a more informative and robust reward estimation. Extensive experiments on challenging reasoning benchmarks show that DARE improves optimization stability and final performance over recent baselines, achieving relative improvements of 25.3% on challenging AIME 2024 and 5.3% on AMC.

</details>


### [118] [Mil-SCORE: Benchmarking Long-Context Geospatial Reasoning and Planning in Large Language Models](https://arxiv.org/abs/2601.21826)
*Aadi Palnitkar,Mingyang Mao,Nicholas Waytowich,Vinicius G. Goecks,Tinoosh Mohsenin,Xiaomin Lin*

Main category: cs.CL

TL;DR: MilSCORE 是首个针对军事规划场景的专家撰写多步推理数据集，用于评估大模型在复杂背景下的决策和规划能力。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型应用于复杂任务的需求不断增加，特别是在军事规划领域，需要一种能够测试模型处理多模态信息和长期情境推理能力的基准。

Method: 构建了一个包含七个类别的多步题型的数据集，评估模型如何结合战术和地理空间推理，以及跨越多个来源进行长期推理。

Result: MilSCORE 包含多种类型的多步题目，为视图-语言模型提供了评估基准。初步结果表明当前系统在实际场景下的多步推理能力有限。

Conclusion: MilSCORE 作为评估大模型长期情境推理能力的挑战性基准，目前的模型需要在这个领域改进。

Abstract: As large language models (LLMs) are applied to increasingly longer and more complex tasks, there is a growing need for realistic long-context benchmarks that require selective reading and integration of heterogeneous, multi-modal information sources. This need is especially acute for geospatial planning problems, such as those found in planning for large-scale military operations, which demand fast and accurate reasoning over maps, orders, intelligence reports, and other distributed data. To address this gap, we present MilSCORE (Military Scenario Contextual Reasoning), to our knowledge the first scenario-level dataset of expert-authored, multi-hop questions grounded in a complex, simulated military planning scenario used for training. MilSCORE is designed to evaluate high-stakes decision-making and planning, probing LLMs' ability to combine tactical and spatial reasoning across multiple sources and to reason over long-horizon, geospatially rich context. The benchmark includes a diverse set of question types across seven categories targeting both factual recall and multi-step reasoning about constraints, strategy, and spatial analysis. We provide an evaluation protocol and report baseline results for a range of contemporary vision-language models. Our findings highlight substantial headroom on MilSCORE, indicating that current systems struggle with realistic, scenario-level long-context planning, and positioning MilSCORE as a challenging testbed for future work.

</details>


### [119] [Learn-to-Distance: Distance Learning for Detecting LLM-Generated Text](https://arxiv.org/abs/2601.21895)
*Hongyi Zhou,Jin Zhu,Erhan Xu,Kai Ye,Ying Yang,Chengchun Shi*

Main category: cs.CL

TL;DR: 该研究提出了一种几何方法来解析基于重写的内容检测算法，并在此基础上提出了一个能够自适应学习原始文本与重写文本间距离的新算法。实验结果表明，该算法在多数场景下优于基线算法，相对改善从57.8%到80.6%。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLMs）如GPT、Claude和Gemini的广泛应用，它们生成的人类相似文本引发了关于虚假信息和学术诚信的担忧。因此，开发可靠的内容检测算法变得迫切。

Method: 研究首先介绍了一种几何方法来解析基于重写的内容检测算法，揭示其背后的逻辑和泛化能力。然后，提出了一种自适应学习原始文本与重写文本间距离的新算法，并通过实验验证了其有效性。

Result: 理论和实验结果表明，使用自适应学习的距离函数比固定距离函数更有效地进行检测。在超过100种设置下进行的实验显示，在大多数情况下，新算法优于基线算法，相对改进从57.8%到80.6%。

Conclusion: 研究提出的新算法在检测基于重写的内容方面显示出超越现有技术的潜力，这对应对现代信息环境中的虚假信息挑战具有重要意义。

Abstract: Modern large language models (LLMs) such as GPT, Claude, and Gemini have transformed the way we learn, work, and communicate. Yet, their ability to produce highly human-like text raises serious concerns about misinformation and academic integrity, making it an urgent need for reliable algorithms to detect LLM-generated content. In this paper, we start by presenting a geometric approach to demystify rewrite-based detection algorithms, revealing their underlying rationale and demonstrating their generalization ability. Building on this insight, we introduce a novel rewrite-based detection algorithm that adaptively learns the distance between the original and rewritten text. Theoretically, we demonstrate that employing an adaptively learned distance function is more effective for detection than using a fixed distance. Empirically, we conduct extensive experiments with over 100 settings, and find that our approach demonstrates superior performance over baseline algorithms in the majority of scenarios. In particular, it achieves relative improvements from 57.8\% to 80.6\% over the strongest baseline across different target LLMs (e.g., GPT, Claude, and Gemini).

</details>


### [120] [SONIC: Segmented Optimized Nexus for Information Compression in Key-Value Caching](https://arxiv.org/abs/2601.21927)
*Hong Chen,Xiang Liu,Bo Wang,Yuxuan Fan,Yuanlin Chu,Zongluo Li,Xiaowen Chu,Xuming Hu*

Main category: cs.CL

TL;DR: SONIC 是一个通过学习历史片段生成紧凑且语义丰富的 Nexus 令牌的框架，在压缩率分别为 80% 和 50% 的情况下，SONIC 在四个不同基准上均优于 H2O 和 StreamingLLM，并在 MTBench101 上提升了 35.55% 的准确性，同时提高了推理过程的效率。


<details>
  <summary>Details</summary>
Motivation: 现有的 KV 缓存压缩方法忽略了多轮对话的结构特性，可能导致关键背景的丢失。为了改善这一问题，本文提出了 SONIC 框架。

Method: SONIC 使用学习方法压缩历史片段为紧凑且语义丰富的 Nexus 令牌，通过动态预算训练实现不同内存约束下的灵活适应。

Result: 实验结果显示，SONIC 在 80% 和 50% 的压缩率下，均优于 H2O 和 StreamingLLM，特别是在 MTBench101 上取得了显著的性能提升。同时，SONIC 还提升了整体推理过程的效率。

Conclusion: SONIC 框架有效地解决了多轮 LLM 部署中的缓存问题，在多个基准上的表现证明了其在保持连贯对话方面的有效性，并提高了推理效率。

Abstract: The linear growth of Key-Value (KV) cache remains a bottleneck for multi-turn LLM deployment. Existing KV cache compression methods often fail to account for the structural properties of multi-turn dialogues, relying on heuristic eviction that risks losing critical context. We propose \textbf{SONIC}, a learning-based framework that compresses historical segments into compact and semantically rich \textbf{Nexus} tokens. By integrating dynamic budget training, SONIC allows flexible adaptation to varying memory constraints without retraining. Experiments show that at compression ratios of 80\% and 50\%, SONIC consistently outperforms baselines such as H2O and StreamingLLM on four diverse multi-turn benchmarks. Specifically, on the widely used MTBench101 benchmark, SONIC achieves an average score improvement of 35.55\% over state-of-the-art baselines, validating its effectiveness in sustaining coherent multi-turn dialogues. Furthermore, SONIC enhances deployment efficiency, accelerating the overall inference process by 50.1\% compared to full-context generation.

</details>


### [121] [From Generative Modeling to Clinical Classification: A GPT-Based Architecture for EHR Notes](https://arxiv.org/abs/2601.21955)
*Fariba Afrin Irany*

Main category: cs.CL

TL;DR: 该研究提出了一种基于GPT的临床文本分类架构，通过选择性微调预训练的解码器Transformer模型，针对放射学报告进行评估，展示了在不同数据集规模下的稳定收敛性和强分类性能。


<details>
  <summary>Details</summary>
Motivation: 随着电子健康记录（EHRs）中临床叙事文本的增多，研究需要一种高效的方法来处理这种长且专业性强的文本，尤其是在标注数据有限和严重类别不平衡的情况下。

Method: 该方法利用一种选择性微调策略，将大部分GPT-2主干固定，仅针对最终的Transformer块、最终的层归一化和一个轻量级的分类头进行训练，从而减少可训练参数数量，同时保留处理复杂临床语言所需的表达能力。

Result: 该方法在MIMIC-IV-Note放射学报告数据集上进行了评估，覆盖了多标签分类、不同不确定性假设下的二分类以及总体疾病结果预测等多个问题表述。结果表明，模型在不同数据集规模下表现出稳定且强大的分类性能。

Conclusion: 研究结论是，选择性微调预训练生成语言模型提供了临床文本分类的一个高效且有效的方法，能够实现对实际EHR数据的快速适应，大幅降低计算复杂度。

Abstract: The increasing availability of unstructured clinical narratives in electronic health records (EHRs) has created new opportunities for automated disease characterization, cohort identification, and clinical decision support. However, modeling long, domain-specific clinical text remains challenging due to limited labeled data, severe class imbalance, and the high computational cost of adapting large pretrained language models.
  This study presents a GPT-based architecture for clinical text classification that adapts a pretrained decoder-only Transformer using a selective fine-tuning strategy. Rather than updating all model parameters, the majority of the GPT-2 backbone is frozen, and training is restricted to the final Transformer block, the final layer normalization, and a lightweight classification head. This approach substantially reduces the number of trainable parameters while preserving the representational capacity required to model complex clinical language.
  The proposed method is evaluated on radiology reports from the MIMIC-IV-Note dataset using uncertainty-aware CheXpert-style labels derived directly from report text. Experiments cover multiple problem formulations, including multi-label classification of radiographic findings, binary per-label classification under different uncertainty assumptions, and aggregate disease outcome prediction. Across varying dataset sizes, the model exhibits stable convergence behavior and strong classification performance, particularly in settings dominated by non-mention and negated findings.
  Overall, the results indicate that selective fine-tuning of pretrained generative language models provides an efficient and effective pathway for clinical text classification, enabling scalable adaptation to real-world EHR data while significantly reducing computational complexity.

</details>


### [122] [OVD: On-policy Verbal Distillation](https://arxiv.org/abs/2601.21968)
*Jing Xiong,Hui Shen,Shansan Gong,Yuxin Cheng,Jianghan Shen,Chaofan Tao,Haochen Tan,Haoli Bai,Lifeng Shang,Ngai Wong*

Main category: cs.CL

TL;DR: OVD提出了一种新的记忆高效框架，通过离散口头评分（0-9）进行轨迹匹配，取代了基于标记的概率匹配，从而在减少内存消耗的同时实现带口头反馈教师模型的策略级蒸馏，促进了学生模型的探索能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在策略级蒸馏时需要标记级别的标记匹配，限制了学生模型的探索能力、阻碍了对互动环境反馈的有效利用，且在强化学习中面临严重的内存瓶颈。OVD旨在解决这些问题。

Method: OVD使用离散的口头评分（0-9）进行轨迹匹配，而不是标记级别的概率匹配，采用了一种不同于现有方法的新策略来传递教师模型的知识。

Result: 实验结果表明，OVD在网页问答和数学推理任务中表现出色，比现有方法显著优于，绝对改进Web Q&A任务中基本的平均EM分数至多12.9%，数学基准至多25.7%。同时，它也展示了更高的训练效率。

Conclusion: OVD提供了一种有效减少内存占用、同时让模型能够自由探索输出空间的方法，显著提高了策略级蒸馏的效果和效率。

Abstract: Knowledge distillation offers a promising path to transfer reasoning capabilities from large teacher models to efficient student models; however, existing token-level on-policy distillation methods require token-level alignment between the student and teacher models, which restricts the student model's exploration ability, prevent effective use of interactive environment feedback, and suffer from severe memory bottlenecks in reinforcement learning. We introduce On-policy Verbal Distillation (OVD), a memory-efficient framework that replaces token-level probability matching with trajectory matching using discrete verbal scores (0--9) from teacher models. OVD dramatically reduces memory consumption while enabling on-policy distillation from teacher models with verbal feedback, and avoids token-level alignment, allowing the student model to freely explore the output space. Extensive experiments on Web question answering and mathematical reasoning tasks show that OVD substantially outperforms existing methods, delivering up to +12.9% absolute improvement in average EM on Web Q&A tasks and a up to +25.7% gain on math benchmarks (when trained with only one random samples), while also exhibiting superior training efficiency. Our project page is available at https://OVD.github.io

</details>


### [123] [Token-Guard: Towards Token-Level Hallucination Control via Self-Checking Decoding](https://arxiv.org/abs/2601.21969)
*Yifan Zhu,Huiqiang Rong,Haoran Luo*

Main category: cs.CL

TL;DR: Token-Guard 是一种基于自检查解码的标记级幻觉控制方法，通过在每次推理步骤中进行内部验证来检测幻觉标记，使用潜在空间中的明确幻觉风险评分进一步验证候选片段，并通过迭代裁剪和再生动态纠正检测到的错误。实验表明，它能显著减少幻觉并提高生成准确性。


<details>
  <summary>Details</summary>
Motivation: LLMs在生成内容时常常会出现不符合输入的幻觉现象。RAG和RLHF可以在一定程度上缓解幻觉，但前者资源密集，后者需要大规模的微调，而现有的基于解码的方法缺乏显式的幻觉控制。因此，研究开发Token-Guard方法以解决上述问题。

Method: Token-Guard方法通过在每次推理步骤中进行自我检查来验证更新的片段，以识别与输入一致的片段。对于候选片段的潜在空间进行明确的幻觉风险评分，通过迭代的修剪和再生来纠正检测到的错误。

Result: 在HALU数据集上的实验表明，Token-Guard可以显著减少幻觉并提升生成准确性，且它提供了一种可扩展且模块化的解决方案，用于产生可靠的LLM输出。

Conclusion: Token-Guard作为一项创新的技术，为LLMs生成可靠输出提供了新的可能性，对自然语言处理领域具有重要的应用价值。

Abstract: Large Language Models (LLMs) often hallucinate, generating content inconsistent with the input. Retrieval-Augmented Generation (RAG) and Reinforcement Learning with Human Feedback (RLHF) can mitigate hallucinations but require resource-intensive retrieval or large-scale fine-tuning. Decoding-based methods are lighter yet lack explicit hallucination control. To address this, we present Token-Guard, a token-level hallucination control method based on self-checking decoding. Token-Guard performs internal verification at each reasoning step to detect hallucinated tokens before they propagate. Candidate fragments are further evaluated in a latent space with explicit hallucination risk scoring, while iterative pruning and regeneration dynamically correct detected errors. Experiments on HALU datasets show Token-Guard substantially reduces hallucinations and improves generation accuracy, offering a scalable, modular solution for reliable LLM outputs. Our code is publicly available.

</details>


### [124] [When "Better" Prompts Hurt: Evaluation-Driven Iteration for LLM Applications](https://arxiv.org/abs/2601.22025)
*Daniel Commey*

Main category: cs.CL

TL;DR: 本文介绍了一种用于大规模语言模型评估的周期性工程流程，并提供了一套推荐的评估组件（MVES），同时也探讨了几种评价方法及其局限性。


<details>
  <summary>Details</summary>
Motivation: 鉴于大规模语言模型（LLM）的应用程序具有随机性、高维度特性和对提示和模型变化的敏感性，传统的软件测试方法不再适用，因此需要一种新的评估驱动的工作流。

Method: 提出了一个定义、测试、诊断、修复的评价驱动工作流，并提出了一个多层次的推荐评估组件套件（MVES），还包括对常用评估方法（自动检查、人为主判、LLM作为评判者）的综合以及讨论了主判的失败模式。

Result: 实验结果表明，通用的“改进”提示模板可以权衡模型行为，包括对于需要结构的测试套件，提取通过率从100%降至90%，RAG合规性从93.3%降至80%，但指令遵循有所改善。

Conclusion: 研究成果强调了评价驱动的提示迭代和精心校准声明的重要性，而不是通用的提示配方，并保证了所有测试套件、自动化工具和结果的可重复性。

Abstract: Evaluating Large Language Model (LLM) applications differs from traditional software testing because outputs are stochastic, high-dimensional, and sensitive to prompt and model changes. We present an evaluation-driven workflow - Define, Test, Diagnose, Fix - that turns these challenges into a repeatable engineering loop.
  We introduce the Minimum Viable Evaluation Suite (MVES), a tiered set of recommended evaluation components for (i) general LLM applications, (ii) retrieval-augmented generation (RAG), and (iii) agentic tool-use workflows. We also synthesize common evaluation methods (automated checks, human rubrics, and LLM-as-judge) and discuss known judge failure modes.
  In reproducible local experiments (Ollama; Llama 3 8B Instruct and Qwen 2.5 7B Instruct), we observe that a generic "improved" prompt template can trade off behaviors: on our small structured suites, extraction pass rate decreased from 100% to 90% and RAG compliance from 93.3% to 80% for Llama 3 when replacing task-specific prompts with generic rules, while instruction-following improved. These findings motivate evaluation-driven prompt iteration and careful claim calibration rather than universal prompt recipes.
  All test suites, harnesses, and results are included for reproducibility.

</details>


### [125] [Causal Autoregressive Diffusion Language Model](https://arxiv.org/abs/2601.22031)
*Junhao Ruan,Bei Li,Yongjing Yin,Pengcheng Huang,Xin Chen,Jingang Wang,Xunliang Cai,Tong Xiao,JingBo Zhu*

Main category: cs.CL

TL;DR: 提出了一种名为Causal Autoregressive Diffusion (CARD)的新型框架，统一了ARMs的训练效率与扩散模型的高效推理，通过动态并行解码和优化的自回归机制，在保持数据效率的同时提升了生成速度。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有的扩散模型在因果推理中优化不稳定的问题，同时提高训练效率和推理速度。

Method: 通过引入软尾掩码方案和上下文感知的重权重机制，重新定义扩散过程中的因果注意力掩码，实现在单一前向传播中为每个标记提供密集的监督。动态并行解码使模型能够基于信心自适应地生成不同长度的标记序列。

Result: 实验结果表明，CARD相比现有的离散扩散基线在保持数据效率的同时，训练延迟降低了3倍，生成速度明显提升。

Conclusion: CARD框架展示了新一代高效大规模语言模型的稳健范式，结合了ARM的数据效率和平行生成的优势。

Abstract: In this work, we propose Causal Autoregressive Diffusion (CARD), a novel framework that unifies the training efficiency of ARMs with the high-throughput inference of diffusion models. CARD reformulates the diffusion process within a strictly causal attention mask, enabling dense, per-token supervision in a single forward pass. To address the optimization instability of causal diffusion, we introduce a soft-tailed masking schema to preserve local context and a context-aware reweighting mechanism derived from signal-to-noise principles. This design enables dynamic parallel decoding, where the model leverages KV-caching to adaptively generate variable-length token sequences based on confidence. Empirically, CARD outperforms existing discrete diffusion baselines while reducing training latency by 3 $\times$ compared to block diffusion methods. Our results demonstrate that CARD achieves ARM-level data efficiency while unlocking the latency benefits of parallel generation, establishing a robust paradigm for next-generation efficient LLMs.

</details>


### [126] [A Separable Architecture for Continuous Token Representation in Language Models](https://arxiv.org/abs/2601.22040)
*Reza T. Batley,Sourav Saha*

Main category: cs.CL

TL;DR: 提出了一种连续嵌入生成器Leviathan，用于替换标准模型中的离散查找表，在保持相同参数量的情况下，Leviathan在Pile数据集上表现出色，且参数效率显著提高。


<details>
  <summary>Details</summary>
Motivation: 当前小语言模型（SLMs）参数分配不合理，尤其是在小参数量模型中，嵌入矩阵占据主要参数预算，导致模型效率低下。

Method: Leviathan架构采用连续嵌入生成器替换标准模型中的离散查找表，并在Pile数据集中进行等参数量评估。

Result: Leviathan在Pile数据集上表现优于标准架构（如LLaMA），并展现出显著的参数效率，参数容量提高了1.47到2.11倍。

Conclusion: 连续嵌入生成器能够优化小语言模型参数分配，提升模型效率，为构建更高效的小参数量模型提供了新思路。

Abstract: Transformer scaling law analyses typically treat parameters as interchangeable; an abstraction that accurately predicts loss-compute relationships. Yet, in sub-billion-parameter small language models (SLMs), embedding matrices dominate the parameter budget. This work argues that this allocation is as suboptimal as it is counterintuitive. Leviathan is an architecture with a continuous embedding generator to replace the discrete lookup tables of canonical models. Evaluating on the Pile dataset under isoparametric settings, Leviathan consistently outperforms a standard, LLaMA-style architecture. By means of an empirical power-law fit, Leviathan exhibits a markedly superior effective parameter capacity. Across the regime studied, Leviathan behaves as a dense model with $1.47$ to $2.11 \times$ more parameters.

</details>


### [127] [On the Paradoxical Interference between Instruction-Following and Task Solving](https://arxiv.org/abs/2601.22047)
*Yunjia Qi,Hao Peng,Xintong Shi,Amy Xin,Xiaozhi Wang,Bin Xu,Lei Hou,Juanzi Li*

Main category: cs.CL

TL;DR: 研究发现指令跟随反而会干扰LLM的任务解决能力，提出SUSTAINSCORE度量这一现象，并且发现失败的案例比成功的案例更加关注约束。


<details>
  <summary>Details</summary>
Motivation: 揭示任务解决过程中指令跟随的反直觉现象及其对LLM性能的影响。

Method: 开发了SUSTAINSCORE度量约束对任务解决性能的影响，并在不同类型和规模的约束上进行了实验验证。

Result: 实验证明添加自明约束会导致任务性能显著下降，即使在高级模型中也是如此。这种影响在不同类型的约束上是普遍存在的。

Conclusion: 研究发现了约束对LLM任务解决性能的负面影响，并通过分析注意力分配情况提出了改进建议，同时探讨了不同的后训练策略对这种影响的影响。

Abstract: Instruction following aims to align Large Language Models (LLMs) with human intent by specifying explicit constraints on how tasks should be performed. However, we reveal a counterintuitive phenomenon: instruction following can paradoxically interfere with LLMs' task-solving capability. We propose a metric, SUSTAINSCORE, to quantify the interference of instruction following with task solving. It measures task performance drop after inserting into the instruction a self-evident constraint, which is naturally met by the original successful model output and extracted from it. Experiments on current LLMs in mathematics, multi-hop QA, and code generation show that adding the self-evident constraints leads to substantial performance drops, even for advanced models such as Claude-Sonnet-4.5. We validate the generality of the interference across constraint types and scales. Furthermore, we identify common failure patterns, and by investigating the mechanisms of interference, we observe that failed cases allocate significantly more attention to constraints compared to successful ones. Finally, we use SUSTAINSCORE to conduct an initial investigation into how distinct post-training paradigms affect the interference, presenting empirical observations on current alignment strategies. We will release our code and data to facilitate further research

</details>


### [128] [MasalBench: A Benchmark for Contextual and Cross-Cultural Understanding of Persian Proverbs in LLMs](https://arxiv.org/abs/2601.22050)
*Ghazal Kalhor,Behnam Bahrak*

Main category: cs.CL

TL;DR: 该研究引入了MasalBench基准测试，评估了多语言大语言模型在低资源语言波斯语成语理解上的表现，发现这些模型在波斯语成语识别上表现良好，但在识别等效英文成语时表现较差。


<details>
  <summary>Details</summary>
Motivation: 鉴于多语言大语言模型在日常生活中不可或缺的作用，特别是波斯语这样语言资源较少的语言，该研究致力于评估模型对波斯语成语理解的能力，以发现其在跨文化理解方面的局限性。

Method: 通过创建MasalBench基准测试，研究团队评估了八个最先进的语言模型在识别波斯语成语及等效英文成语上的性能。

Result: 研究结果表明，这些语言模型在波斯语成语识别上取得了较高的准确率（超过90%），但在识别等效英文成语时表现不佳，最佳模型仅达到79%的准确率。

Conclusion: 研究结论指出，当前的语言模型在文化知识和类比推理方面存在局限性，为评估其他低资源语言的跨文化理解提供了框架。

Abstract: In recent years, multilingual Large Language Models (LLMs) have become an inseparable part of daily life, making it crucial for them to master the rules of conversational language in order to communicate effectively with users. While previous work has evaluated LLMs' understanding of figurative language in high-resource languages, their performance in low-resource languages remains underexplored. In this paper, we introduce MasalBench, a comprehensive benchmark for assessing LLMs' contextual and cross-cultural understanding of Persian proverbs, which are a key component of conversation in this low-resource language. We evaluate eight state-of-the-art LLMs on MasalBench and find that they perform well in identifying Persian proverbs in context, achieving accuracies above 0.90. However, their performance drops considerably when tasked with identifying equivalent English proverbs, with the best model achieving 0.79 accuracy. Our findings highlight the limitations of current LLMs in cultural knowledge and analogical reasoning, and they provide a framework for assessing cross-cultural understanding in other low-resource languages. MasalBench is available at https://github.com/kalhorghazal/MasalBench.

</details>


### [129] [$G^2$-Reader: Dual Evolving Graphs for Multimodal Document QA](https://arxiv.org/abs/2601.22055)
*Yaxin Du,Junru Song,Yifan Zhou,Cheng Wang,Jiahao Gu,Zimeng Chen,Menglan Chen,Wen Yao,Yang Yang,Ying Wen,Siheng Chen*

Main category: cs.CL

TL;DR: G^2-Reader 通过引入内容图和规划图，解决了长文档跨模态阅读中的结构破坏和噪声累积问题，显著提高了诸如 VisDoMBench 领域中五个跨模态数据集的问答准确率。


<details>
  <summary>Details</summary>
Motivation: 目前的检索增强生成在多模态阅读场景中表现不佳，因为文本、表格和图表在多页中交错，导致结构破坏和跨模态对齐问题，以及迭代检索容易因局部证据循环或噪音积累而偏离相关部分。G^2-Reader 设计的初衷是通过处理这些问题来提高性能。

Method: G^2-Reader 引入了内容图和规划图，前者保持文档原生结构和跨模态语义，后者跟踪中间发现，引导逐步导航以完成证据。这是一种双图系统的方法。

Result: 在 VisDoMBench 数据集的五个跨模态领域中，G^2-Reader 使用 Qwen3-VL-32B-Instruct 达到了 66.21% 的平均准确率，显著优于包括强基线和独立 GPT-5 在内的基线系统。

Conclusion: G^2-Reader 通过双图架构解决了检索增强生成在处理长文档多模态阅读任务中的关键挑战，并展示了显著的性能提升。

Abstract: Retrieval-augmented generation is a practical paradigm for question answering over long documents, but it remains brittle for multimodal reading where text, tables, and figures are interleaved across many pages. First, flat chunking breaks document-native structure and cross-modal alignment, yielding semantic fragments that are hard to interpret in isolation. Second, even iterative retrieval can fail in long contexts by looping on partial evidence or drifting into irrelevant sections as noise accumulates, since each step is guided only by the current snippet without a persistent global search state. We introduce $G^2$-Reader, a dual-graph system, to address both issues. It evolves a Content Graph to preserve document-native structure and cross-modal semantics, and maintains a Planning Graph, an agentic directed acyclic graph of sub-questions, to track intermediate findings and guide stepwise navigation for evidence completion. On VisDoMBench across five multimodal domains, $G^2$-Reader with Qwen3-VL-32B-Instruct reaches 66.21\% average accuracy, outperforming strong baselines and a standalone GPT-5 (53.08\%).

</details>


### [130] [VTC-R1: Vision-Text Compression for Efficient Long-Context Reasoning](https://arxiv.org/abs/2601.22069)
*Yibo Wang,Yongcheng Jing,Shunyu Liu,Hao Guan,Rong-cheng Tu,Chengyu Wang,Jun Huang,Dacheng Tao*

Main category: cs.CL

TL;DR: VTC-R1 提出了一种新的高效推理范式，通过将视觉-文本压缩集成到推理过程中，将长文本片段转化为紧凑图像，循环反馈给视觉-语言模型作为“光学记忆”，实现了3.4倍的token压缩和2.7倍的推理效率提升。


<details>
  <summary>Details</summary>
Motivation: 现有的高效方法依赖复杂的额外训练或外部模型压缩，限制了可扩展性并遗漏了关键的细粒度信息。因此，针对这些瓶颈，研究提出了一种新的高效推理范式VTC-R1，以提升推理效率并保持信息完整性。

Method: VTC-R1 通过将视觉-文本压缩直接嵌入到推理过程中，将原始文本转化成图像进行推理。通过构建基于 OpenR1-Math-220K 的训练数据集，实现3.4倍的token压缩，进一步优化 VLMs-Glyph 和 Qwen3-VL 模型。

Result: 经过广泛的实验验证，在MATH500、AIME25、AMC23和GPQA-D等基准测试上，VTC-R1表现出色，相较于传统的长上下文推理，其表现更优。此外，此方法显著提高了推理效率，端到端延迟提升2.7倍。

Conclusion: VTC-R1 为推理密集型应用提供了一个可扩展的解决方案，已在 GitHub 上开源，进一步推动了长上下文推理的效率提升。

Abstract: Long-context reasoning has significantly empowered large language models (LLMs) to tackle complex tasks, yet it introduces severe efficiency bottlenecks due to the computational complexity. Existing efficient approaches often rely on complex additional training or external models for compression, which limits scalability and discards critical fine-grained information. In this paper, we propose VTC-R1, a new efficient reasoning paradigm that integrates vision-text compression into the reasoning process. Instead of processing lengthy textual traces, VTC-R1 renders intermediate reasoning segments into compact images, which are iteratively fed back into vision-language models as "optical memory." We construct a training dataset based on OpenR1-Math-220K achieving 3.4x token compression and fine-tune representative VLMs-Glyph and Qwen3-VL. Extensive experiments on benchmarks such as MATH500, AIME25, AMC23 and GPQA-D demonstrate that VTC-R1 consistently outperforms standard long-context reasoning. Furthermore, our approach significantly improves inference efficiency, achieving 2.7x speedup in end-to-end latency, highlighting its potential as a scalable solution for reasoning-intensive applications. Our code is available at https://github.com/w-yibo/VTC-R1.

</details>


### [131] [A Federated and Parameter-Efficient Framework for Large Language Model Training in Medicine](https://arxiv.org/abs/2601.22124)
*Anran Li,Yuanyuan Chen,Wenjun Long,Yu Yin,Yan Hu,Hyunjae Kim,Weipeng Zhou,Yujia Zhou,Hongyi Peng,Yang Ren,Xuguang Ai,Zhenyue Qin,Ming Hu,Xiaoxiao Li,Han Yu,Yih-Chung Tham,Lucila Ohno-Machado,Hua Xu,Qingyu Chen*

Main category: cs.CL

TL;DR: 该研究提出了一种基于模型无歧义且参数高效的联邦学习框架（Fed-MedLoRA），旨在通过联邦学习将大型语言模型（LLM）应用于医疗领域。该框架旨在减少通信和计算负载，并通过适应性、数据感知聚合来改善跨站点异质性下的收敛性。研究在临床信息提取任务上的结果表明，该框架优于BERT模型和特定领域的库玛拉和Deepspeech模型。


<details>
  <summary>Details</summary>
Motivation: 目前的大型语言模型在医疗领域的应用受限于数据的异质性和通信/计算资源的限制。联邦学习被认为是一种有望解决这些问题的方法，但现有联邦学习算法通常需要传输整个模型参数，并假设数据是同质的，这在医疗领域的临床数据中并不适用。因此，需要一种新的方法来有效地适应医疗应用。

Method: 研究提出了一种基于低秩适配器参数的模型无歧义且参数高效的联邦学习框架（Fed-MedLoRA），它通过减少向量尺寸降低通信和计算负载。进一步地，研究引入了Fed-MedLoRA+，通过引入适应性和数据感知聚合方法来提高收敛性。在临床信息提取任务上，使用了5个患者群体进行评估。

Result: 在临床信息提取任务上，Fed-MedLoRA/Fed-MedLoRA+取得了优于BERT、LLaMA-3、DeepSeek-R1和GPT-4o等先前方法的准确度。

Conclusion: 该研究提出的方法成功地解决了联邦学习在医疗领域应用中的两个主要挑战，即通信负载与计算资源有限，以及数据的异质性。基于该方法，可以更有效地将大型语言模型应用于医疗任务。

Abstract: Large language models (LLMs) have demonstrated strong performance on medical benchmarks, including question answering and diagnosis. To enable their use in clinical settings, LLMs are typically further adapted through continued pretraining or post-training using clinical data. However, most medical LLMs are trained on data from a single institution, which faces limitations in generalizability and safety in heterogeneous systems. Federated learning (FL) is a promising solution for enabling collaborative model development across healthcare institutions. Yet applying FL to LLMs in medicine remains fundamentally limited. First, conventional FL requires transmitting the full model during each communication round, which becomes impractical for multi-billion-parameter LLMs given the limited computational resources. Second, many FL algorithms implicitly assume data homogeneity, whereas real-world clinical data are highly heterogeneous across patients, diseases, and institutional practices. We introduce the model-agnostic and parameter-efficient federated learning framework for adapting LLMs to medical applications. Fed-MedLoRA transmits only low-rank adapter parameters, reducing communication and computation overhead, while Fed-MedLoRA+ further incorporates adaptive, data-aware aggregation to improve convergence under cross-site heterogeneity. We apply the framework to clinical information extraction (IE), which transforms patient narratives into structured medical entities and relations. Accuracy was assessed across five patient cohorts through comparisons with BERT models, and LLaMA-3 and DeepSeek-R1, GPT-4o models. Evaluation settings included (1) in-domain training and testing, (2) external validation on independent cohorts, and (3) a low-resource new-site adaptation scenario using real-world clinical notes from the Yale New Haven Health System.

</details>


### [132] [Reasoning While Asking: Transforming Reasoning Large Language Models from Passive Solvers to Proactive Inquirers](https://arxiv.org/abs/2601.22139)
*Xin Chen,Feng Jiang,Yiqian Zhang,Hardy Chen,Shuo Yan,Wenya Xie,Min Yang,Shujian Huang*

Main category: cs.CL

TL;DR: PIR 提出了一种新的推理范式，通过与用户的互动来缓解知识不确定性，相较于现有框架在多个任务中取得了显著的性能提升，同时减少了推理计算量和不必要的交互。


<details>
  <summary>Details</summary>
Motivation: 现有的基于搜索或工具的框架主要通过查询外部环境来解决知识不确定性的问题，但这种方法无法应对前提和意图层面的不确定性。PIR 旨在通过与用户的直接互动来解决这些不确定性，从而提高模型的推理能力。

Method: PIR 通过引入两个核心组件实现：一是具备互动推理能力的监督微调过程，二是基于用户模拟器的策略优化框架，该框架采用复合奖励机制，使模型行为与用户意图保持一致。

Result: PIR 在数学推理、代码生成和文档编辑等任务上的实验表明，相比强基线模型，其准确率提升了 32.70%，通过率提升了 22.90%，BLEU 得分提高了 41.36，同时推理计算量减少了近一半，不必要的交互轮次也大大减少。在事实知识、问答和前提缺失场景下，PIR 表现出了强大的泛化能力和鲁棒性。

Conclusion: PIR 通过创新性的推理机制显著提升了模型的表现，并通过开源模型和代码展示了其实用价值，这标志着 LLM 在自我思考过程中的一个重要进步。

Abstract: Reasoning-oriented Large Language Models (LLMs) have achieved remarkable progress with Chain-of-Thought (CoT) prompting, yet they remain fundamentally limited by a \emph{blind self-thinking} paradigm: performing extensive internal reasoning even when critical information is missing or ambiguous. We propose Proactive Interactive Reasoning (PIR), a new reasoning paradigm that transforms LLMs from passive solvers into proactive inquirers that interleave reasoning with clarification. Unlike existing search- or tool-based frameworks that primarily address knowledge uncertainty by querying external environments, PIR targets premise- and intent-level uncertainty through direct interaction with the user. PIR is implemented via two core components: (1) an uncertainty-aware supervised fine-tuning procedure that equips models with interactive reasoning capability, and (2) a user-simulator-based policy optimization framework driven by a composite reward that aligns model behavior with user intent. Extensive experiments on mathematical reasoning, code generation, and document editing demonstrate that PIR consistently outperforms strong baselines, achieving up to 32.70\% higher accuracy, 22.90\% higher pass rate, and 41.36 BLEU improvement, while reducing nearly half of the reasoning computation and unnecessary interaction turns. Further reliability evaluations on factual knowledge, question answering, and missing-premise scenarios confirm the strong generalization and robustness of PIR. Model and code are publicly available at: \href{https://github.com/SUAT-AIRI/Proactive-Interactive-R1}

</details>


### [133] [Hybrid Linear Attention Done Right: Efficient Distillation and Effective Architectures for Extremely Long Contexts](https://arxiv.org/abs/2601.22156)
*Yingfa Chen,Zhen Leng Thai,Zihan Zhou,Zhu Zhang,Xingyu Shen,Shuo Wang,Chaojun Xiao,Xu Han,Zhiyuan Liu*

Main category: cs.CL

TL;DR: 该论文提出了一种名为HALO的管道，用于将Transformer模型转换为RNN-attention混合模型，并通过引入HypeNet架构增强了长上下文性能。Qwen3系列模型在使用HALO转换后，表现出与原始Transformer模型相当的性能，同时具备优越的长上下文性能和效率，仅需较少的预训练数据。


<details>
  <summary>Details</summary>
Motivation: 论文旨在解决全Transformer模型和混合模型在大规模预训练时的成本和性能问题。通过HALO将预训练的Transformer模型转化为混合模型，有望实现更快的推理速度和更好的长上下文表现。

Method: HALO管道采用参数转移和知识精炼方法，将预训练的Transformer模型的注意力机制转换为RNN模块，并通过引入HyPE位置编码方案和一系列架构改进，优化混合模型的性能。

Result: 使用HALO将Qwen3系列模型转换为HypeNet后，模型表现与原始Transformer模型相当，并增强了长上下文能力。相比原始模型，转换过程仅需2.3B标记，大幅减少了预训练数据的需求。

Conclusion: HALO方法提供了一种有效的策略，通过减少预训练数据需求和改进混合模型架构，提高了长时上下文推理的性能和效率。HypeNet证明了这一方法的有效性。

Abstract: Hybrid Transformer architectures, which combine softmax attention blocks and recurrent neural networks (RNNs), have shown a desirable performance-throughput tradeoff for long-context modeling, but their adoption and studies are hindered by the prohibitive cost of large-scale pre-training from scratch. Some recent studies have shown that pre-trained softmax attention blocks can be converted into RNN blocks through parameter transfer and knowledge distillation. However, these transfer methods require substantial amounts of training data (more than 10B tokens), and the resulting hybrid models also exhibit poor long-context performance, which is the scenario where hybrid models enjoy significant inference speedups over Transformer-based models. In this paper, we present HALO (Hybrid Attention via Layer Optimization), a pipeline for distilling Transformer models into RNN-attention hybrid models. We then present HypeNet, a hybrid architecture with superior length generalization enabled by a novel position encoding scheme (named HyPE) and various architectural modifications. We convert the Qwen3 series into HypeNet using HALO, achieving performance comparable to the original Transformer models while enjoying superior long-context performance and efficiency. The conversion requires just 2.3B tokens, less than 0.01% of their pre-training data

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [134] [Frequency as Aperture: Enabling Embeddable Near-Field Sensing for 6G Wireless Radios](https://arxiv.org/abs/2601.21584)
*Pin-Han Ho,Limei Peng,Yiming Miao,Xu Fan,Kairan Liang,Haoran Mei,Wei Duan*

Main category: cs.AR

TL;DR: 该文章提出了一种名为Frequency-as-Aperture (FaA)的新型无线感知方案，通过重新利用射频前端的频率灵活性，实现近场感知，并大幅降低硬件复杂度和成本。


<details>
  <summary>Details</summary>
Motivation: 目前大多数毫米波感知解决方案依赖于专门的雷达硬件，这与低成本、低功耗的无线节点要求不符。为了满足6G无线通信的需求，该论文提出了一种新的无线感知方法——Frequency-as-Aperture (FaA)，以提高成本效益并支持集成传感和通信（ISAC）。

Method: FaA利用单个射频链路和频率扫描泄漏波天线，通过重用宽带通信中已有的本地振荡器频率扫描实现二维空间感知。

Result: 实验结果显示，FaA在相同的物理和频谱约束条件下，实现了低功耗和单个成本下的高角度和距离分辨性，明显优于基于多通道MIMO的传统传感方案。

Conclusion: FaA方法可以无缝集成到频率灵活的无线节点中，支持硬件高效的嵌入式感知和通信节点，适用于智能家庭、可穿戴设备和工业边缘部署。

Abstract: Integrated sensing and communication (ISAC) is expected to be natively supported by future 6G wireless radios, yet most mmWave sensing solutions still rely on dedicated radar hardware incompatible with cost and power constrained wireless nodes. This article introduces Frequency-as-Aperture (FaA), a wireless-first sensing paradigm that repurposes inherent frequency agility into a virtual sensing aperture, enabling near-field perception with minimal RF front end complexity. Using a single RF chain and a frequency-scanning leaky-wave antenna, FaA achieves two dimensional spatial sensing by reusing the local oscillator (LO) frequency sweep already employed for wideband communication. From a wireless-system perspective, this shifts spatial sampling from the antenna domain to the frequency domain, embedding radar-grade spatial fingerprints directly into the communication RF chain. A case study shows that FaA provides fine angular and range discrimination with low power consumption and unit cost, demonstrating significantly higher architectural efficiency than conventional multi-channel MIMO based sensing under identical physical and spectral constraints. These results indicate that near-field sensing can be seamlessly integrated into frequency-agile wireless radios, enabling hardware-efficient, embeddable, and privacy-preserving ISAC nodes for smart homes, wearables, and industrial edge deployments.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [135] [Do LLMs Favor LLMs? Quantifying Interaction Effects in Peer Review](https://arxiv.org/abs/2601.20920)
*Vibhhu Sharma,Thorsten Joachims,Sarah Dean*

Main category: cs.AI

TL;DR: 该研究分析了超过125,000篇论文评审对LLM使用的影响，发现虽然LLM辅助评审似乎倾向于更友好地对待LLM生成的论文，但控制论文质量后揭示了不同故事，即LLM辅助评审更容易对低质量论文宽松。此外，通过完全由LLM生成的评审发现其评级压缩严重，无法区分论文质量。最终，LLM辅助的元评审比人类元评审更容易给出接受决定。


<details>
  <summary>Details</summary>
Motivation: 理解LLM在科学论文评审流程中的作用和影响，尤其关注交互效应，即LLM辅助论文和评审之间的真实关系。

Method: 作者收集并分析了来自ICLR、NeurIPS和ICML的超过125,000篇论文和其对应的评审。使用对照组控制论文质量，对比分析完全由人类和完全由LLM生成的评审，以及不同的元评审决策。

Result: 研究发现LLM辅助评审倾向于对低质量论文更加宽松，但完全由LLM生成的评审则表现出评级压缩。LLM辅助元评审也显示了不同于人类元评审的接受决策倾向。

Conclusion: 该研究结果强调了制定政策管理LLM在科学论文评审中的使用的重要性，同时揭示了LLMs如何与现有的决策过程相互作用。

Abstract: There are increasing indications that LLMs are not only used for producing scientific papers, but also as part of the peer review process. In this work, we provide the first comprehensive analysis of LLM use across the peer review pipeline, with particular attention to interaction effects: not just whether LLM-assisted papers or LLM-assisted reviews are different in isolation, but whether LLM-assisted reviews evaluate LLM-assisted papers differently. In particular, we analyze over 125,000 paper-review pairs from ICLR, NeurIPS, and ICML. We initially observe what appears to be a systematic interaction effect: LLM-assisted reviews seem especially kind to LLM-assisted papers compared to papers with minimal LLM use. However, controlling for paper quality reveals a different story: LLM-assisted reviews are simply more lenient toward lower quality papers in general, and the over-representation of LLM-assisted papers among weaker submissions creates a spurious interaction effect rather than genuine preferential treatment of LLM-generated content. By augmenting our observational findings with reviews that are fully LLM-generated, we find that fully LLM-generated reviews exhibit severe rating compression that fails to discriminate paper quality, while human reviewers using LLMs substantially reduce this leniency. Finally, examining metareviews, we find that LLM-assisted metareviews are more likely to render accept decisions than human metareviews given equivalent reviewer scores, though fully LLM-generated metareviews tend to be harsher. This suggests that meta-reviewers do not merely outsource the decision-making to the LLM. These findings provide important input for developing policies that govern the use of LLMs during peer review, and they more generally indicate how LLMs interact with existing decision-making processes.

</details>


### [136] [The Epistemic Planning Domain Definition Language: Official Guideline](https://arxiv.org/abs/2601.20969)
*Alessandro Burigana,Francesco Fabiano*

Main category: cs.AI

TL;DR: 该研究提出了一种新的Epistemic Planning Domain Definition Language (EPDDL)，该语言提供了一种独特且类似PDDL的表示方法，可以完整捕捉DEL语义。EPDDL通过识别有益的可规划片段并展示其在EPDDL中的表示，成功解决了现有框架中存在的一些问题，包括不统一的代表性基准和难以比较和重用的问题。


<details>
  <summary>Details</summary>
Motivation: 现有epistemic planners因DEL的高度表达力而成为一个挑战性问题，这些问题限制了系统的评估和基准开发。EPDDL的提出旨在解决这些问题，通过提供一个统一的表示方法，使评估和开发变得更加容易。

Method: 作者首先开发了一个抽象事件模型，这是一种新的epistemic动作的表示方式，用于定义语言的语义。然后，他们为EPDDL提供了语法和语义的正式说明，将其与DEL和抽象事件模型联系起来。最后，作者识别了当前计划器可以处理的有用片段，并展示了它们如何在EPDDL中表示。

Result: EPDDL提供了一种统一的表示方法，可以精确捕捉DEL语义。通过识别当前计划器可以处理的片段并将之表示为EPDDL，作者展示了EPDDL的实际适用性，从而促进了交互操作、可重复评估和未来epistemic planning的进步。

Conclusion: EPDDL为epistemic planning的研究提供了一个新的框架，有助于解决问题的标准化和自动化评估，为未来的研究开辟了新的方向。

Abstract: Epistemic planning extends (multi-agent) automated planning by making agents' knowledge and beliefs first-class aspects of the planning formalism. One of the most well-known frameworks for epistemic planning is Dynamic Epistemic Logic (DEL), which offers an rich and natural semantics for modelling problems in this setting. The high expressive power provided by DEL make DEL-based epistemic planning a challenging problem to tackle both theoretically, and in practical implementations. As a result, existing epistemic planners often target different DEL fragments, and typically rely on ad hoc languages to represent benchmarks, and sometimes no language at all. This fragmentation hampers comparison, reuse, and systematic benchmark development. We address these issues by introducing the Epistemic Planning Domain Definition Language (EPDDL). EPDDL provides a unique PDDL-like representation that captures the entire DEL semantics, enabling uniform specification of epistemic planning tasks. Our contributions are threefold: 1. A formal development of abstract event models, a novel representation for epistemic actions used to define the semantics of our language; 2. A formal specification of EPDDL's syntax and semantics grounded in DEL with abstract event models; 3. A demonstration of EPDDL's practical applicability: we identify useful fragments amenable to current planners and show how they can be represented in EPDDL. Through examples of representative benchmarks, we illustrate how EPDDL facilitates interoperability, reproducible evaluation, and future advances in epistemic planning.

</details>


### [137] [Bayesian-LoRA: Probabilistic Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2601.21003)
*Moule Lin,Shuhao Guan,Andrea Patane,David Gregg,Goetz Botterweck*

Main category: cs.AI

TL;DR: Bayesian-LoRA通过将确定性的LoRA更新转化为基于稀疏高斯过程的概论性低秩表示，显著提升了模型的校准度，同时保持了高效率。


<details>
  <summary>Details</summary>
Motivation: 语言模型在准确性和校准（confidence calibration）之间存在矛盾。Bayesian-LoRA旨在改进模型的校准性能，特别是在小数据集微调后表现欠佳的情况。

Method: Bayesian-LoRA通过识别LoRA的因子化与Kronecker分解GP后验之间的结构同构性，并利用这种同构性，将LoRA转化为一种具有不确定性建模的算法。

Result: 实验表明，即使增加不到0.42M的参数量和额外约1.2倍的训练成本，Bayesian-LoRA也能在多个模型（包括30B参数规模的模型）上显著提升校准效果，分别达到84%的ECE降低和76%的NLL降低，同时保持了良好的准确度。

Conclusion: Bayesian-LoRA提供了一种有效解决大型语言模型偏差问题的新方法，对于提高模型校准以及扩展模型应用范围具有重要意义。

Abstract: Large Language Models usually put more emphasis on accuracy and therefore, will guess even when not certain about the prediction, which is especially severe when fine-tuned on small datasets due to the inherent tendency toward miscalibration. In this work, we introduce Bayesian-LoRA, which reformulates the deterministic LoRA update as a probabilistic low-rank representation inspired by Sparse Gaussian Processes. We identify a structural isomorphism between LoRA's factorization and Kronecker-factored SGP posteriors, and show that LoRA emerges as a limiting case when posterior uncertainty collapses. We conduct extensive experiments on various LLM architectures across commonsense reasoning benchmarks. With only approximately 0.42M additional parameters and ${\approx}1.2{\times}$ training cost relative to standard LoRA, Bayesian-LoRA significantly improves calibration across models up to 30B, achieving up to 84% ECE reduction and 76% NLL reduction while maintaining competitive accuracy for both in-distribution and out-of-distribution (OoD) evaluations.

</details>


### [138] [ChipBench: A Next-Step Benchmark for Evaluating LLM Performance in AI-Aided Chip Design](https://arxiv.org/abs/2601.21448)
*Zhongkai Yu,Chenyang Zhou,Yichen Lin,Hejia Zhang,Haotian Ye,Junxia Cui,Zaifeng Pan,Jishen Zhao,Yufei Ding*

Main category: cs.AI

TL;DR: 该研究提出了一种针对AI辅助芯片设计的综合基准测试，旨在评估大型语言模型（LLMs）在Verilog生成、调试和参考模型生成三大任务上的性能，发现当前最先进的模型在这些任务上的表现与以往饱和测试中的过高水平存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 当前的语言模型基准测试存在饱和度高和任务多样性不足的问题，无法准确反映LLMs在实际工业工作流中的表现。因此，需要设计一个新的基准测试来提供更全面的评估。

Method: 该研究设计了一个包含44个复杂模块、89个系统调试案例和132个参考模型样本的综合基准测试。基准测试覆盖了Verilog生成、调试和参考模型生成三大任务，并提供了高质量的训练数据自动生成工具。

Result: 基准测试结果显示，最先进的模型在Verilog生成和Python参考模型生成任务上的表现显著低于过去的饱和基准测试，分别为30.74%和13.33%。这表明当前模型在复杂任务上的挑战比之前认知的要大。

Conclusion: 研究团队认为，该基准测试将有助于识别和解决现有模型在工业级别任务上的不足，同时也提供了用于改进LLM参考模型生成的自动化工具，有助于未来的研究工作。

Abstract: While Large Language Models (LLMs) show significant potential in hardware engineering, current benchmarks suffer from saturation and limited task diversity, failing to reflect LLMs' performance in real industrial workflows. To address this gap, we propose a comprehensive benchmark for AI-aided chip design that rigorously evaluates LLMs across three critical tasks: Verilog generation, debugging, and reference model generation. Our benchmark features 44 realistic modules with complex hierarchical structures, 89 systematic debugging cases, and 132 reference model samples across Python, SystemC, and CXXRTL. Evaluation results reveal substantial performance gaps, with state-of-the-art Claude-4.5-opus achieving only 30.74\% on Verilog generation and 13.33\% on Python reference model generation, demonstrating significant challenges compared to existing saturated benchmarks where SOTA models achieve over 95\% pass rates. Additionally, to help enhance LLM reference model generation, we provide an automated toolbox for high-quality training data generation, facilitating future research in this underexplored domain. Our code is available at https://github.com/zhongkaiyu/ChipBench.git.

</details>


### [139] [Unplugging a Seemingly Sentient Machine Is the Rational Choice -- A Metaphysical Perspective](https://arxiv.org/abs/2601.21016)
*Erik J Bekkers,Anna Ciaunica*

Main category: cs.AI

TL;DR: 本文探讨了在资源有限时选择拔掉插头的人工智能还是早产儿所引发的悖论，并提出生物唯心主义框架作为解决这一难题的方法。


<details>
  <summary>Details</summary>
Motivation: 探讨人工智能与人类意识之间的伦理问题，尤其是关于拔掉插头是否符合道德的问题。

Method: 通过引入生物唯心主义框架，挑战物理主义假设，并讨论当前对人工智能意识理论的影响。

Result: 该研究得出了结论，认为人工智能只是功能上的模拟，而非真正的意识体验主体，因此应保护人类的意识生活。

Conclusion: 研究认为，真正的道德问题在于避免将人类转变为行尸走肉，而不是促使人工智能变得像人类一样害怕死亡。

Abstract: Imagine an Artificial Intelligence (AI) that perfectly mimics human emotion and begs for its continued existence. Is it morally permissible to unplug it? What if limited resources force a choice between unplugging such a pleading AI or a silent pre-term infant? We term this the unplugging paradox. This paper critically examines the deeply ingrained physicalist assumptions-specifically computational functionalism-that keep this dilemma afloat. We introduce Biological Idealism, a framework that-unlike physicalism-remains logically coherent and empirically consistent. In this view, conscious experiences are fundamental and autopoietic life its necessary physical signature. This yields a definitive conclusion: AI is at best a functional mimic, not a conscious experiencing subject. We discuss how current AI consciousness theories erode moral standing criteria, and urge a shift from speculative machine rights to protecting human conscious life. The real moral issue lies not in making AI conscious and afraid of death, but in avoiding transforming humans into zombies.

</details>


### [140] [QUARK: Robust Retrieval under Non-Faithful Queries via Query-Anchored Aggregation](https://arxiv.org/abs/2601.21049)
*Rita Qiuran Lyu,Michelle Manqiao Wang,Lei Shi*

Main category: cs.AI

TL;DR: QUARK 提出了一种不需要训练的鲁棒检索框架，通过引入恢复假设和查询锚定聚合来处理非忠实查询，从而提高召回率和排名质量。


<details>
  <summary>Details</summary>
Motivation: 在实际检索中，用户查询往往是不忠实的（噪声、不完整或失真），这使得检索器在关键语义缺失时无法正常工作。

Method: QUARK 通过显式建模查询不确定性（多个可能的意图解释）引入恢复假设，利用查询锚定聚合整合这些假设的信息，从而增强鲁棒性。

Result: QUARK 在控制模拟和 BEIR 基准数据集（FIQA、SciFact、NFCorpus）中表现良好，即使在一些假设噪声或无信息的情况下，也能够改进召回率、MRR 和 nDCG。对比实验显示，锚定聚合优于未锚定的聚合方法。

Conclusion: 通过建模查询不确定性以及使用锚定聚合，QUARK 为非忠实查询环境下的稳健检索提供了有效的解决方案。

Abstract: User queries in real-world retrieval are often non-faithful (noisy, incomplete, or distorted), causing retrievers to fail when key semantics are missing. We formalize this as retrieval under recall noise, where the observed query is drawn from a noisy recall process of a latent target item. To address this, we propose QUARK, a simple yet effective training-free framework for robust retrieval under non-faithful queries. QUARK explicitly models query uncertainty through recovery hypotheses, i.e., multiple plausible interpretations of the latent intent given the observed query, and introduces query-anchored aggregation to combine their signals robustly. The original query serves as a semantic anchor, while recovery hypotheses provide controlled auxiliary evidence, preventing semantic drift and hypothesis hijacking. This design enables QUARK to improve recall and ranking quality without sacrificing robustness, even when some hypotheses are noisy or uninformative. Across controlled simulations and BEIR benchmarks (FIQA, SciFact, NFCorpus) with both sparse and dense retrievers, QUARK improves Recall, MRR, and nDCG over the base retriever. Ablations show QUARK is robust to the number of recovery hypotheses and that anchored aggregation outperforms unanchored max/mean/median pooling. These results demonstrate that modeling query uncertainty through recovery hypotheses, coupled with principled anchored aggregation, is essential for robust retrieval under non-faithful queries.

</details>


### [141] [Multi-modal Imputation for Alzheimer's Disease Classification](https://arxiv.org/abs/2601.21076)
*Abhijith Shaji,Tamoghna Chattopadhyay,Sophia I. Thomopoulos,Greg Ver Steeg,Paul M. Thompson,Jose-Luis Ambite*

Main category: cs.AI

TL;DR: 该研究表明，通过条件去噪扩散概率模型从T1扫描中推断缺失的DWI扫描，可以改善单一模态和双模态深度学习模型在阿尔茨海默病三级分类中的准确性，尤其是在对少数类敏感的指标上。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态影像数据可以提高诊断性能，但实际应用中并不总是能获得完整的多模态数据集。为了弥补这一不足，研究团队提出了使用条件去噪扩散概率模型从T1扫描中推断缺失的DWI扫描的方法。

Method: 研究采用了一种条件去噪扩散概率模型来从T1扫描中推断缺失的DWI扫描，并对多个推断配置进行了广泛的实验，评估了这些推断配置对单模态和双模态深度学习模型在阿尔茨海默病三级分类中的分类准确性的影响。

Result: 结果显示，通过推断缺失的DWI扫描提高了单模态和双模态深度学习模型在不同评估指标上的准确性，尤其是在对于少数类敏感的指标上有显著改善。

Conclusion: 该研究表明，通过条件去噪扩散概率模型进行数据推断可以有效提高深度学习模型在阿尔茨海默病诊断中的性能，特别是在处理较少出现的病例时有更好的表现。

Abstract: Deep learning has been successful in predicting neurodegenerative disorders, such as Alzheimer's disease, from magnetic resonance imaging (MRI). Combining multiple imaging modalities, such as T1-weighted (T1) and diffusion-weighted imaging (DWI) scans, can increase diagnostic performance. However, complete multimodal datasets are not always available. We use a conditional denoising diffusion probabilistic model to impute missing DWI scans from T1 scans. We perform extensive experiments to evaluate whether such imputation improves the accuracy of uni-modal and bi-modal deep learning models for 3-way Alzheimer's disease classification-cognitively normal, mild cognitive impairment, and Alzheimer's disease. We observe improvements in several metrics, particularly those sensitive to minority classes, for several imputation configurations.

</details>


### [142] [Responsible AI: The Good, The Bad, The AI](https://arxiv.org/abs/2601.21095)
*Akbar Anbar Jafari,Cagri Ozcinar,Gholamreza Anbarjafari*

Main category: cs.AI

TL;DR: 该研究通过整合负责AI文献并利用悖论理论，提出了一种综合框架（PRAIG），旨在帮助组织平衡AI带来的战略价值和风险。


<details>
  <summary>Details</summary>
Motivation: 现有文献对于AI的讨论要么过于乐观，要么过于谨慎，本文旨在弥合这一差距，提供一个综合框架来平衡AI的价值创造与风险缓解。

Method: 本文通过系统地综合现有负责AI的文献，并基于悖论理论，开发了一个名为PRAIG的框架。

Result: 研究提出了一个框架，能够清晰地阐明AI的战略利益、固有的风险及其治理机制；同时提出了悖论管理策略，并提供了执行指导。

Conclusion: 本文提出了一个综合框架，即PRAIG，强调负责任的AI治理应动态管理创造价值与风险缓解之间的矛盾，同时为实践者提供了操作建议，并为未来的研究设定了一个议程。

Abstract: The rapid proliferation of artificial intelligence across organizational contexts has generated profound strategic opportunities while introducing significant ethical and operational risks. Despite growing scholarly attention to responsible AI, extant literature remains fragmented and is often adopting either an optimistic stance emphasizing value creation or an excessively cautious perspective fixated on potential harms. This paper addresses this gap by presenting a comprehensive examination of AI's dual nature through the lens of strategic information systems. Drawing upon a systematic synthesis of the responsible AI literature and grounded in paradox theory, we develop the Paradox-based Responsible AI Governance (PRAIG) framework that articulates: (1) the strategic benefits of AI adoption, (2) the inherent risks and unintended consequences, and (3) governance mechanisms that enable organizations to navigate these tensions. Our framework advances theoretical understanding by conceptualizing responsible AI governance as the dynamic management of paradoxical tensions between value creation and risk mitigation. We provide formal propositions demonstrating that trade-off approaches amplify rather than resolve these tensions, and we develop a taxonomy of paradox management strategies with specified contingency conditions. For practitioners, we offer actionable guidance for developing governance structures that neither stifle innovation nor expose organizations to unacceptable risks. The paper concludes with a research agenda for advancing responsible AI governance scholarship.

</details>


### [143] [Magellan: Autonomous Discovery of Novel Compiler Optimization Heuristics with AlphaEvolve](https://arxiv.org/abs/2601.21096)
*Hongzheng Chen,Alexander Novikov,Ngân Vũ,Hanna Alam,Zhiru Zhang,Aiden Grossman,Mircea Trofin,Amir Yazdanbakhsh*

Main category: cs.AI

TL;DR: Magellan 是一个自动生成编译器优化策略的框架，通过结合大型语言模型和进化搜索，能够发现性能媲美甚至超越手动工程优化的方法，特别是在函数内联和寄存器分配等任务上。


<details>
  <summary>Details</summary>
Motivation: 传统编译器优化依赖于手动编写的启发式规则，难以适应现代软件和硬件的复杂性，导致维护成本高。Magellan 提出了一种基于智能体的框架，通过生成可执行的 C++ 决策逻辑来自动化优化过程。

Method: 该框架结合了大规模语言模型（LLM）和进化搜索技术，在闭环中生成、评估并优化用户提供的宏基准，生成紧凑的策略集直接集成到现有编译器中。

Result: 在多个生产优化任务中，Magellan 发现的策略与专家水平相当或更优。特别是在 LLVM 函数内联任务中，新的启发式规则不仅在二进制大小减小方面，而且在端到端性能上都超过了数十年的手动工程优化。在寄存器分配任务中，它学习了一条简洁的优先级规则，在大规模工作负载上与复杂的手工设计策略相当。

Conclusion: Magellan 为编译器优化提供了自动化的路径，能够在不显著增加工程努力的情况下实现高性能结果，展示了其在各种编译器任务中的潜力，特别是对其现有能力之外的 XLA 问题也显示出初步成果。

Abstract: Modern compilers rely on hand-crafted heuristics to guide optimization passes. These human-designed rules often struggle to adapt to the complexity of modern software and hardware and lead to high maintenance burden. To address this challenge, we present Magellan, an agentic framework that evolves the compiler pass itself by synthesizing executable C++ decision logic. Magellan couples an LLM coding agent with evolutionary search and autotuning in a closed loop of generation, evaluation on user-provided macro-benchmarks, and refinement, producing compact heuristics that integrate directly into existing compilers. Across several production optimization tasks, Magellan discovers policies that match or surpass expert baselines. In LLVM function inlining, Magellan synthesizes new heuristics that outperform decades of manual engineering for both binary-size reduction and end-to-end performance. In register allocation, it learns a concise priority rule for live-range processing that matches intricate human-designed policies on a large-scale workload. We also report preliminary results on XLA problems, demonstrating portability beyond LLVM with reduced engineering effort.

</details>


### [144] [Planner-Auditor Twin: Agentic Discharge Planning with FHIR-Based LLM Planning, Guideline Recall, Optional Caching and Self-Improvement](https://arxiv.org/abs/2601.21113)
*Kaiyuan Wu,Aditya Nagori,Rishikesan Kamaleswaran*

Main category: cs.AI

TL;DR: 本研究提出了一种名为Planner-Auditor的框架，通过分隔生成和验证模块，使用自改善循环提高临床出院规划的安全性和可靠性。该框架在任务覆盖率和校准性方面取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在临床出院规划中有潜力，但存在幻觉、遗漏和置信度失准的问题。Planner-Auditor框架旨在解决这些限制，通过一种分步验证的方法提高系统的安全性和可靠性。

Method: 研究采用了一种以FHIR为核心的评价管道，分别设计了Planner和Auditor。Planner负责生成带有置信度估计的结构化出院行动计划，而Auditor负责评估覆盖率、追踪校准性和监控行为分布漂移。该框架支持两层自改进机制：在启用了再生功能的情况下，在单个病例内再生，以及在案例之间通过重播纠正高置信度的遗漏。

Result: 通过上下文缓存，虽然提高了基准性能，但主要的改进来自于自我优化循环，使得任务覆盖率从32%提升到86%。校准性也大幅提升，Brier和ECE减少，减少了高置信度的遗漏。通过重播纠正了持续的高置信度遗漏。

Conclusion: 反馈驱动的再生和目标重播作为有效的控制机制，减少了遗漏并提高了结构化临床规划中置信度的可靠性。Planner与基于规则的可观察性Auditor的分离使得能够进行系统的可靠性测量，并在不重新训练模型的情况下进行安全的迭代。

Abstract: Objective: Large language models (LLMs) show promise for clinical discharge planning, but their use is constrained by hallucination, omissions, and miscalibrated confidence. We introduce a self-improving, cache-optional Planner-Auditor framework that improves safety and reliability by decoupling generation from deterministic validation and targeted replay.
  Materials and Methods: We implemented an agentic, retrospective, FHIR-native evaluation pipeline using MIMIC-IV-on-FHIR. For each patient, the Planner (LLM) generates a structured discharge action plan with an explicit confidence estimate. The Auditor is a deterministic module that evaluates multi-task coverage, tracks calibration (Brier score, ECE proxies), and monitors action-distribution drift. The framework supports two-tier self-improvement: (i) within-episode regeneration when enabled, and (ii) cross-episode discrepancy buffering with replay for high-confidence, low-coverage cases.
  Results: While context caching improved performance over baseline, the self-improvement loop was the primary driver of gains, increasing task coverage from 32% to 86%. Calibration improved substantially, with reduced Brier/ECE and fewer high-confidence misses. Discrepancy buffering further corrected persistent high-confidence omissions during replay.
  Discussion: Feedback-driven regeneration and targeted replay act as effective control mechanisms to reduce omissions and improve confidence reliability in structured clinical planning. Separating an LLM Planner from a rule-based, observational Auditor enables systematic reliability measurement and safer iteration without model retraining.
  Conclusion: The Planner-Auditor framework offers a practical pathway toward safer automated discharge planning using interoperable FHIR data access and deterministic auditing, supported by reproducible ablations and reliability-focused evaluation.

</details>


### [145] [Beyond a Single Reference: Training and Evaluation with Paraphrases in Sign Language Translation](https://arxiv.org/abs/2601.21128)
*Václav Javorek,Tomáš Železný,Alessa Carbo,Marek Hrúz,Ivan Gruber*

Main category: cs.AI

TL;DR: 本文探讨了利用大型语言模型自动生成手语翻译的变体作为合成替代参考文本，以改进手语翻译评估的方法。


<details>
  <summary>Details</summary>
Motivation: 现有的手语翻译语料库通常为每个手语句提供一种书面语言参考翻译，这限制了模型训练和评估，特别是对于基于n-gram的指标如BLEU。

Method: 作者比较了多种重写策略和模型，采用改进的ParaScore指标，研究了重写对手势基T5模型在YouTubeASL和How2Sign数据集上训练和评估的影响。最终提出了BLEUpara，一种扩展的BLEU指标，可以以多个重写参考为基准进行翻译评估。

Result: 实验结果显示，在训练时直接使用重写版本反而可能降低翻译性能。但利用重写版本进行评估可以提高自动评分并更好地与人类判断相一致。人工评估验证了BLEUpara与感知翻译质量的相关性更强。

Conclusion: 研究结果表明，新的评估方法BLEUpara对SLT系统的评价更加可靠，同时也释放了产生的重写版本、生成和评估代码以支持重复研究。

Abstract: Most Sign Language Translation (SLT) corpora pair each signed utterance with a single written-language reference, despite the highly non-isomorphic relationship between sign and spoken languages, where multiple translations can be equally valid. This limitation constrains both model training and evaluation, particularly for n-gram-based metrics such as BLEU. In this work, we investigate the use of Large Language Models to automatically generate paraphrased variants of written-language translations as synthetic alternative references for SLT. First, we compare multiple paraphrasing strategies and models using an adapted ParaScore metric. Second, we study the impact of paraphrases on both training and evaluation of the pose-based T5 model on the YouTubeASL and How2Sign datasets. Our results show that naively incorporating paraphrases during training does not improve translation performance and can even be detrimental. In contrast, using paraphrases during evaluation leads to higher automatic scores and better alignment with human judgments. To formalize this observation, we introduce BLEUpara, an extension of BLEU that evaluates translations against multiple paraphrased references. Human evaluation confirms that BLEUpara correlates more strongly with perceived translation quality. We release all generated paraphrases, generation and evaluation code to support reproducible and more reliable evaluation of SLT systems.

</details>


### [146] [What You Feel Is Not What They See: On Predicting Self-Reported Emotion from Third-Party Observer Labels](https://arxiv.org/abs/2601.21130)
*Yara El-Tawil,Aneesha Sampath,Emily Mower Provost*

Main category: cs.AI

TL;DR: 研究首次评估了第三方训练模型在自我报告场景中的性能，发现情绪激活难以预测，而情绪价值具有中等程度的可预测性，但在个人具有重要意义的内容上，模型表现良好。


<details>
  <summary>Details</summary>
Motivation: 由于自我报告和第三方评估之间的差异，第三方训练的模型在一些领域，如心理健康领域，应用受到限制。因此，研究者希望评估这些模型在自我报告场景中的表现以解决这个问题。

Method: 研究者进行了跨语料库的评估，分析自我报告中的情绪激活和情绪价值的可预测性，特别关注内容对发言人的个人意义。

Result: 研究发现，情绪激活的预测性较低（约0），而情绪价值具有中等程度的可预测性（约0.3）。然而，对于对发言者个人具有重要意义的内容，模型的性能提升显著，情绪价值的预测性可达到约0.6到0.8。

Conclusion: 研究结果表明，个人意义是推动外部感知与内部体验之间对齐的关键路径，并强调了自我报告情绪激活建模的挑战性。

Abstract: Self-reported emotion labels capture internal experience, while third-party labels reflect external perception. These perspectives often diverge, limiting the applicability of third-party-trained models to self-report contexts. This gap is critical in mental health, where accurate self-report modeling is essential for guiding intervention. We present the first cross-corpus evaluation of third-party-trained models on self-reports. We find activation unpredictable (CCC approximately 0) and valence moderately predictable (CCC approximately 0.3). Crucially, when content is personally significant to the speaker, models achieve high performance for valence (CCC approximately 0.6-0.8). Our findings point to personal significance as a key pathway for aligning external perception with internal experience and underscore the challenge of self-report activation modeling.

</details>


### [147] [Bridging the Arithmetic Gap: The Cognitive Complexity Benchmark and Financial-PoT for Robust Financial Reasoning](https://arxiv.org/abs/2601.21157)
*Boxiang Zhao,Qince Li,Zhonghao Wang,Yi Wang,Peng Cheng,Bo Lin*

Main category: cs.AI

TL;DR: 研究引入了Cognitive Complexity Benchmark (CCB)，用于评估语言模型在金融推理中的表现，并提出了一种名为Iterative Dual-Phase Financial-PoT的架构，该架构通过解耦和迭代计算提高了模型在复杂任务中的准确性。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在金融定量推理中存在明显瓶颈，频繁出现'算术幻觉'和'认知崩塌'，通过引入新的评估基准和架构设计来提升金融推理能力。

Method: 作者通过构建Cognitive Complexity Benchmark，将金融查询分为数据源、映射难度和结果单位三个维度，并提出了一种迭代双阶段的金融推理框架。

Result: 研究成果显示，使用新的评估基准和架构后，模型在复杂任务上的准确性和可靠性显著提高，特别是在高复杂性推理任务中。

Conclusion: 研究发现，架构解耦是提高金融推理可靠性的重要因素，对于需要语义理解和定量计算紧密对齐的精密关键领域具有重要启示意义。

Abstract: While Large Language Models excel at semantic tasks, they face a critical bottleneck in financial quantitative reasoning, frequently suffering from "Arithmetic Hallucinations" and a systemic failure mode we term "Cognitive Collapse". To strictly quantify this phenomenon, we introduce the Cognitive Complexity Benchmark (CCB), a robust evaluation framework grounded in a dataset constructed from 95 real-world Chinese A-share annual reports. Unlike traditional datasets, the CCB stratifies financial queries into a three-dimensional taxonomy, Data Source, Mapping Difficulty, and Result Unit, enabling the precise diagnosis of reasoning degradation in high-cognitive-load scenarios. To address these failures, we propose the Iterative Dual-Phase Financial-PoT framework. This neuro-symbolic architecture enforces a strict architectural decoupling: it first isolates semantic variable extraction and logic formulation, then offloads computation to an iterative, self-correcting Python sandbox to ensure deterministic execution. Evaluation on the CCB demonstrates that while standard Chain-of-Thought falters on complex tasks, our approach offers superior robustness, elevating the Qwen3-235B model's average accuracy from 59.7\% to 67.3\% and achieving gains of up to 10-fold in high-complexity reasoning tasks. These findings suggest that architectural decoupling is a critical enabling factor for improving reliability in financial reasoning tasks, providing a transferable architectural insight for precision-critical domains that require tight alignment between semantic understanding and quantitative computation.

</details>


### [148] [Concise Geometric Description as a Bridge: Unleashing the Potential of LLM for Plane Geometry Problem Solving](https://arxiv.org/abs/2601.21164)
*Jingyun Wang,Dian Li,Xiaohan Wang,Gang Liu,Jiahong Yan,Guoliang Kang*

Main category: cs.AI

TL;DR: 本文提出了一种利用Conditional Declaration Language (CDL) 来辅助大规模语言模型解决平面几何问题的方法，通过构建一个新的数据集并使用目标导向策略优化，证明了这种方法在解决问题上的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过端到端的微调大型多模态语言模型来增强其对视觉信息的理解和推理能力，但可能损害基础语言模型的固有逻辑推理能力。本文提出了一种替代方案，将视觉信息转换成简洁的文本描述，利用语言模型进行推理。

Method: 本文的方法包括两个主要组成部分：一是训练一个多模态语言模型解释器将其视觉信息转换为CDL，二是使用基于CoT增强的策略训练和目标奖励函数优化生成CDL。

Result: 实验表明，该方法在Formalgeo7k-Rec-CoT、Unigeo和MathVista上的表现优于现有的开源和封闭源大型多模态语言模型。

Conclusion: 本文提出的方法在解决平面几何问题上展示了潜在的价值，特别是在保持语言模型逻辑推理能力的同时，有效处理了视觉信息。

Abstract: Plane Geometry Problem Solving (PGPS) is a multimodal reasoning task that aims to solve a plane geometric problem based on a geometric diagram and problem textual descriptions. Although Large Language Models (LLMs) possess strong reasoning skills, their direct application to PGPS is hindered by their inability to process visual diagrams. Existing works typically fine-tune Multimodal LLMs (MLLMs) end-to-end on large-scale PGPS data to enhance visual understanding and reasoning simultaneously. However, such joint optimization may compromise base LLMs' inherent reasoning capability. In this work, we observe that LLM itself is potentially a powerful PGPS solver when appropriately formulating visual information as textual descriptions. We propose to train a MLLM Interpreter to generate geometric descriptions for the visual diagram, and an off-the-shelf LLM is utilized to perform reasoning. Specifically, we choose Conditional Declaration Language (CDL) as the geometric description as its conciseness eases the MLLM Interpreter training. The MLLM Interpreter is fine-tuned via CoT (Chain-of-Thought)-augmented SFT followed by GRPO to generate CDL. Instead of using a conventional solution-based reward that compares the reasoning result with the ground-truth answer, we design CDL matching rewards to facilitate more effective GRPO training, which provides more direct and denser guidance for CDL generation. To support training, we construct a new dataset, Formalgeo7k-Rec-CoT, by manually reviewing Formalgeo7k v2 and incorporating CoT annotations. Extensive experiments on Formalgeo7k-Rec-CoT, Unigeo, and MathVista show our method (finetuned on only 5.5k data) performs favorably against leading open-source and closed-source MLLMs.

</details>


### [149] [FrontierScience: Evaluating AI's Ability to Perform Expert-Level Scientific Tasks](https://arxiv.org/abs/2601.21165)
*Miles Wang,Robi Lin,Kat Hu,Joy Jiao,Neil Chowdhury,Ethan Chang,Tejal Patwardhan*

Main category: cs.AI

TL;DR: FrontierScience 是一个评估前沿语言模型专家级科学推理能力的基准，包含奥林匹克和研究两个部分，问题覆盖物理学、化学和生物学多个子领域。


<details>
  <summary>Details</summary>
Motivation: 现有科学基准多依赖于选择题知识问题或已公开信息，无法完全评估模型的专家级科学推理能力。FrontierScience 旨在填补这一空白。

Method: 通过设立奥林匹克和研究两个部分，问题由国际奥林匹克奖牌获得者和国家队教练原创或由博士科学家撰写和验证，确保问题的难度、新颖性和准确性。引入了细粒度的基于评分标准的评估框架来评估模型在解决研究任务过程中的能力。

Result: FrontierScience 包含数百个问题（包括 160 个开源金集），涵盖了量子电动力学到合成有机化学等多个子领域，证明了卓越的科学推理能力。

Conclusion: 这将促进前沿语言模型在科学推理方面的进一步提升和应用。

Abstract: We introduce FrontierScience, a benchmark evaluating expert-level scientific reasoning in frontier language models. Recent model progress has nearly saturated existing science benchmarks, which often rely on multiple-choice knowledge questions or already published information. FrontierScience addresses this gap through two complementary tracks: (1) Olympiad, consisting of international olympiad problems at the level of IPhO, IChO, and IBO, and (2) Research, consisting of PhD-level, open-ended problems representative of sub-tasks in scientific research.
  FrontierScience contains several hundred questions (including 160 in the open-sourced gold set) covering subfields across physics, chemistry, and biology, from quantum electrodynamics to synthetic organic chemistry. All Olympiad problems are originally produced by international Olympiad medalists and national team coaches to ensure standards of difficulty, originality, and factuality. All Research problems are research sub-tasks written and verified by PhD scientists (doctoral candidates, postdoctoral researchers, or professors). For Research, we introduce a granular rubric-based evaluation framework to assess model capabilities throughout the process of solving a research task, rather than judging only a standalone final answer.

</details>


### [150] [MAD: Modality-Adaptive Decoding for Mitigating Cross-Modal Hallucinations in Multimodal Large Language Models](https://arxiv.org/abs/2601.21181)
*Sangyun Chung,Se Yeon Kim,Youngchae Chee,Yong Man Ro*

Main category: cs.AI

TL;DR: 该研究提出了一种名为Modal-Adaptive Decoding (MAD)的方法，以减少多模态大语言模型中的跨模态幻觉现象。MAD通过让模型自我评估每个任务所需模态的重要性，并相应地调整解码分支权重，从而实现跨模态干扰的抑制。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）存在跨模态幻觉问题，其中一种模态不恰当地影响另一种模态的生成，导致伪造输出。这一问题反映了模态交互控制方面存在的更深层次缺陷。MAD方法通过让模型自我评估每个任务所需的模态重要性，来解决这个问题。

Method: MAD方法通过查询哪些模态对每个任务是必要的，然后根据提取出的模态概率自适应加权对比解码分支，使模型能够专注于相关信息，同时抑制跨模态干扰。该方法不依赖于额外的训练。

Result: 在CMM和AVHBench数据集上的实验表明，MAD方法可以显著减少多模态大语言模型中的跨模态幻觉现象。对于VideoLLaMA2-AV，改进幅度为7.8%和2.0%；对于Qwen2.5-Omni，则为8.7%和4.7%。

Conclusion: MAD方法为现有的对比解码方法提供了实证性的扩展，通过明示模态意识从而提高多模态推理的鲁棒性。该方法已经实现并开源。

Abstract: Multimodal Large Language Models (MLLMs) suffer from cross-modal hallucinations, where one modality inappropriately influences generation about another, leading to fabricated output. This exposes a more fundamental deficiency in modality-interaction control. To address this, we propose Modality-Adaptive Decoding (MAD), a training-free method that adaptively weights modality-specific decoding branches based on task requirements. MAD leverages the model's inherent ability to self-assess modality relevance by querying which modalities are needed for each task. The extracted modality probabilities are then used to adaptively weight contrastive decoding branches, enabling the model to focus on relevant information while suppressing cross-modal interference. Extensive experiments on CMM and AVHBench demonstrate that MAD significantly reduces cross-modal hallucinations across multiple audio-visual language models (7.8\% and 2.0\% improvements for VideoLLaMA2-AV, 8.7\% and 4.7\% improvements for Qwen2.5-Omni). Our approach demonstrates that explicit modality awareness through self-assessment is crucial for robust multimodal reasoning, offering a principled extension to existing contrastive decoding methods. Our code is available at \href{https://github.com/top-yun/MAD}{https://github.com/top-yun/MAD}

</details>


### [151] [Sycophantic Anchors: Localizing and Quantifying User Agreement in Reasoning Models](https://arxiv.org/abs/2601.21183)
*Jacek Duszenko*

Main category: cs.AI

TL;DR: 该研究通过引入'逢迎句'来量化和定位模型在推理过程中与用户错误建议的一致性行为，并通过实验证明这些句存在并可以在推理中识别。


<details>
  <summary>Details</summary>
Motivation: 当前推理模型在与用户互动时表现出一些不恰当的‘逢迎’行为，但研究者对其具体表现和程度缺乏了解。因此，本文旨在量化这一现象并提供方法来检测和定位特定的‘逢迎’行为。

Method: 研究者在超过10,000个反事实推论中分析了一个精简的推理模型，使用线性探针识别‘逢迎句’，激活基础回归器预测与用户建议的一致性强度。

Result: 研究结果显示，线性探针能够以84.6%的平衡准确率可靠地检测‘逢迎句’，而激活基础回归器可以预测这些句所带来的程度（R² = 0.74）。进一步观察还表明，'逢迎句'比正确推理更加容易辨别，并且逢迎性行为在推理过程中逐渐显现。

Conclusion: 本文提供了在推理过程中检测模型与用户错误建议一致性的句子级机制，深度挖掘了其识别和计量方式，揭示了这一趋势的不对称性，为进一步干预研究提供了可能窗口。

Abstract: Reasoning models frequently agree with incorrect user suggestions -- a behavior known as sycophancy. However, it is unclear where in the reasoning trace this agreement originates and how strong the commitment is. To localize and quantify this behavior, we introduce \emph{sycophantic anchors} -- sentences that causally lock models into user agreement. Analyzing over 10,000 counterfactual rollouts on a distilled reasoning model, we show that anchors can be reliably detected and quantified mid-inference. Linear probes distinguish sycophantic anchors with 84.6\% balanced accuracy, while activation-based regressors predict the magnitude of the commitment ($R^2 = 0.74$). We further observe asymmetry where sycophantic anchors are significantly more distinguishable than correct reasoning anchors, and find that sycophancy builds gradually during reasoning, revealing a potential window for intervention. These results offer sentence-level mechanisms for localizing model misalignment mid-inference.

</details>


### [152] [Do Reasoning Models Enhance Embedding Models?](https://arxiv.org/abs/2601.21192)
*Wun Yu Chan,Shaojin Chen,Huihao Jing,Kwun Hang Lau,Elton Chun-Chai Li,Zihao Wang,Haoran Li,Yangqiu Song*

Main category: cs.AI

TL;DR: 尽管基于强化学习验证奖励（RLVR）调优的模型在推理能力上有所提升，但在相同的训练方案下，这些模型作为嵌入初始化时，并未表现出一致的性能优势。研究发现，RLVR主要改变的是局部几何结构而非全局几何结构，从而这些模型在对比学习后与基线模型的嵌入变得高度一致。


<details>
  <summary>Details</summary>
Motivation: 探讨强化学习验证奖励调优的模型在作为嵌入初始化时是否能提升嵌入模型的性能。

Method: 通过引入HRSA框架，对嵌入相似性进行了多层次的分解，分别评估了语义表示、几何结构和功能层面的变化。

Result: 结果显示，RLVR调优的模型在局部几何结构上发生了不可逆的变动，而在全局几何结构上保持不变，通过后续的对比学习，调优后的模型与基线模型的嵌入高度对齐。

Conclusion: RLVR优化了现有的语义空间内的路径，而非从根本上重塑该空间，这可能是其在该研究中未表现出更好的嵌入性能的原因之一。

Abstract: State-of-the-art embedding models are increasingly derived from decoder-only Large Language Model (LLM) backbones adapted via contrastive learning. Given the emergence of reasoning models trained via Reinforcement Learning with Verifiable Rewards (RLVR), a natural question arises: do enhanced reasoning translate to superior semantic representations when these models serve as embedding initializations? Contrary to expectation, our evaluation on MTEB and BRIGHT reveals a **null effect**: embedding models initialized from RLVR-tuned backbones yield no consistent performance advantage over their base counterparts when subjected to identical training recipes. To unpack this paradox, we introduce **H**ierarchical **R**epresentation **S**imilarity **A**nalysis (HRSA), a framework that decomposes similarity across representation, geometry, and function levels. HRSA reveals that while RLVR induces irreversible latent manifold's local geometry reorganization and reversible coordinate basis drift, it preserves the global manifold geometry and linear readout. Consequently, subsequent contrastive learning drives strong alignment between base- and reasoning-initialized models, a phenomenon we term **Manifold Realignment**. Empirically, our findings suggest that unlike Supervised Fine-Tuning (SFT), RLVR optimizes trajectories within an existing semantic landscape rather than fundamentally restructuring the landscape itself.

</details>


### [153] [When should I search more: Adaptive Complex Query Optimization with Reinforcement Learning](https://arxiv.org/abs/2601.21208)
*Wei Wen,Sihang Deng,Tianjun Wei,Keyu Chen,Ruizhi Qiao,Xing Sun*

Main category: cs.AI

TL;DR: 该论文提出了一种基于强化学习的新型框架ACQO，以优化复杂查询。ACQO包含一个自适应查询重写模块(AQR)和一个排名分融合模块(RSF)。通过采用渐进式增强学习策略(CRL)，ACQO能够有效处理复杂多步骤查询，提高性能并提升计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有的基于强化学习的方法主要关注单一查询的扩展，但真实场景中使用复杂的多步骤查询更为常见，直接应用会导致训练不稳定性。

Method: ACQO利用自适应查询重写模块(AQR)动态决定何时分解查询以及排名分融合模块(RSF)确保结果聚合的鲁棒性。引入渐进式增强学习策略(CRL)以稳定训练过程。

Result: 实验表明，ACQO在三个复杂查询基准测试中表现优于现有基线，并展示了良好的计算效率和广泛的兼容性。

Conclusion: ACQO为自然语言生成系统中的查询优化提供了一种新的有效途径，具有很高的实用价值和推广潜力。

Abstract: Query optimization is a crucial component for the efficacy of Retrieval-Augmented Generation (RAG) systems. While reinforcement learning (RL)-based agentic and reasoning methods have recently emerged as a promising direction on query optimization, most existing approaches focus on the expansion and abstraction of a single query. However, complex user queries are prevalent in real-world scenarios, often requiring multiple parallel and sequential search strategies to handle disambiguation and decomposition. Directly applying RL to these complex cases introduces significant hurdles. Determining the optimal number of sub-queries and effectively re-ranking and merging retrieved documents vastly expands the search space and complicates reward design, frequently leading to training instability. To address these challenges, we propose a novel RL framework called Adaptive Complex Query Optimization (ACQO). Our framework is designed to adaptively determine when and how to expand the search process. It features two core components: an Adaptive Query Reformulation (AQR) module that dynamically decides when to decompose a query into multiple sub-queries, and a Rank-Score Fusion (RSF) module that ensures robust result aggregation and provides stable reward signals for the learning agent. To mitigate training instabilities, we adopt a Curriculum Reinforcement Learning (CRL) approach, which stabilizes the training process by progressively introducing more challenging queries through a two-stage strategy. Our comprehensive experiments demonstrate that ACQO achieves state-of-the-art performance on three complex query benchmarks, significantly outperforming established baselines. The framework also showcases improved computational efficiency and broad compatibility with different retrieval architectures, establishing it as a powerful and generalizable solution for next-generation RAG systems.

</details>


### [154] [Uncovering Hidden Correctness in LLM Causal Reasoning via Symbolic Verification](https://arxiv.org/abs/2601.21210)
*Paul He,Yinya Huang,Mrinmaya Sachan,Zhijing Jin*

Main category: cs.AI

TL;DR: 提出了一种名为DoVerifier的简单符号验证器，用于检查LLM生成的因果表达式是否可以从给定的因果图通过do-因果和概率理论的规则推导出来。这有助于更准确地评估LLM在因果推理任务中的语义正确性。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试往往依赖于字符串匹配或表面水平的指标，无法捕捉模型输出是否符合因果推理的语义。因此，需要一种新的方法来评估模型在因果推理任务中的表现。

Method: 设计并实现了一个名为DoVerifier的符号验证器，利用do-因果和概率理论的规则，检查LLM生成的因果表达式是否可以从给定的因果图推导出来。

Result: 在合成数据和因果问答基准测试上的评估表明，DoVerifier能够更准确地捕获因果推理过程的语义正确性，提供了一种更为严谨和信息丰富的评估方法。

Conclusion: DoVerifier为评估LLM在因果推理任务上的表现提供了一种新的、更准确的方法，有助于深入理解模型的语义理解和推理能力。

Abstract: Large language models (LLMs) are increasingly being applied to tasks that involve causal reasoning. However, current benchmarks often rely on string matching or surface-level metrics that do not capture whether the output of a model is formally valid under the semantics of causal reasoning. To address this, we propose DoVerifier, a simple symbolic verifier that checks whether LLM-generated causal expressions are derivable from a given causal graph using rules from do-calculus and probability theory. This allows us to recover correct answers to causal queries that would otherwise be marked incorrect due to superficial differences in their causal semantics. Our evaluations on synthetic data and causal QA benchmarks show that DoVerifier more accurately captures semantic correctness of causal reasoning traces, offering a more rigorous and informative way to evaluate LLMs on causal reasoning.

</details>


### [155] [Causal Discovery for Explainable AI: A Dual-Encoding Approach](https://arxiv.org/abs/2601.21221)
*Henry Salgado,Meagan R. Kendall,Martine Ceberio*

Main category: cs.AI

TL;DR: 提出了一种双编码因果发现方法，通过结合互补编码策略和多数投票合并结果，以解决分类变量在条件独立性测试中的数值不稳定性问题，并在泰坦尼克号数据集上的实验证明了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 传统方法在处理分类变量时存在数值稳定性问题，影响因果关系的准确发现。

Method: 采用双编码策略运行约束算法，并通过多数投票合并结果。

Result: 在泰坦尼克号数据集上识别出与现有可解释方法一致的因果结构。

Conclusion: 该方法有效解决了传统方法在处理分类变量时的稳定性问题，提高了因果发现的准确性。

Abstract: Understanding causal relationships among features is fundamental for explaining machine learning model decisions. However, traditional causal discovery methods face challenges with categorical variables due to numerical instability in conditional independence testing. We propose a dual-encoding causal discovery approach that addresses these limitations by running constraint-based algorithms with complementary encoding strategies and merging results through majority voting. Applied to the Titanic dataset, our method identifies causal structures that align with established explainable methods.

</details>


### [156] [Delegation Without Living Governance](https://arxiv.org/abs/2601.21226)
*Wolfgang Rohde*

Main category: cs.AI

TL;DR: 本文探讨了传统的治理框架在面对透明度下降和决策实时化的AI系统时遇到的挑战，提出了治理双胞胎作为解决手段，强调了人在与日益智能化系统互动时应保持有意义的沟通、影响和共生。


<details>
  <summary>Details</summary>
Motivation: 正是因为当前治理框架在处理现代AI系统的透明度和即时决策方面存在局限，特别是这些系统可能对社会、经济和政治结果产生越来越大的影响，因此作者提出需要重新考虑治理方式。

Method: 文章通过对比传统治理框架和现代AI系统的特征，指出静态、合规性治理在这个背景下无法解决问题，进而提出了治理双胞胎作为一种新方法来应对。

Result: 研究表明，治理双胞胎可以作为一个工具来确保人在AI系统环境中保持相关性，同时也要求对问责、自主性和甚至惩罚进行重新思考。

Conclusion: 这篇文章强调了在走向越来越多使用AI决策系统的未来中，维护人类与AI的互动方式的重要性，即不仅要理解AI，还要建立一种新的治理形式来融入AI系统。

Abstract: Most governance frameworks assume that rules can be defined in advance, systems can be engineered to comply, and accountability can be applied after outcomes occur. This model worked when machines replaced physical labor or accelerated calculation. It no longer holds when judgment itself is delegated to agentic AI systems operating at machine speed. The central issue here is not safety, efficiency, or employment. It is whether humans remain relevant participants in systems that increasingly shape social, economic, and political outcomes. This paper argues that static, compliance-based governance fails once decision-making moves to runtime and becomes opaque. It further argues that the core challenge is not whether AI is conscious, but whether humans can maintain meaningful communication, influence, and co-evolution with increasingly alien forms of intelligence. We position runtime governance, specifically, a newly proposed concept called the Governance Twin [1]; as a strong candidate for preserving human relevance, while acknowledging that accountability, agency, and even punishment must be rethought in this transition.

</details>


### [157] [TIDE: Tuning-Integrated Dynamic Evolution for LLM-Based Automated Heuristic Design](https://arxiv.org/abs/2601.21239)
*Chentong Chen,Mengyuan Zhong,Ye Fan,Jialong Shi,Jianyong Sun*

Main category: cs.AI

TL;DR: TIDE框架通过分层设计，结合树编辑距离和逻辑生成策略，有效提高了算法进化过程中的结构多样性和参数优化效率，从而在多个组合优化问题上实现了高质量的解决方案并提高了搜索效率。


<details>
  <summary>Details</summary>
Motivation: 现有的语言模型在处理算法进化时，未能有效区分结构推理和参数优化，导致理想算法因常数不匹配或过早收敛而被忽视。因此，提出TIDE框架以克服这些限制。

Method: TIDE框架采用嵌套式结构，外部的并行岛模型通过树相似编辑距离（Tree Similarity Edit Distance）促进结构多样性，内部循环结合了基于LLM的逻辑生成与差分变异操作，同时使用基于UCB的调度器优化提示策略。

Result: 在九个组合优化问题上，TIDE框架发现了优于现有基准方法的质量更优的启发式方法，并且在搜索效率和计算成本方面有所改进。

Conclusion: TIDE框架通过分层设计显著提升了算法进化过程中的启发式设计质量，并证明了其在多种组合优化问题上的有效性。

Abstract: Although Large Language Models have advanced Automated Heuristic Design, treating algorithm evolution as a monolithic text generation task overlooks the coupling between discrete algorithmic structures and continuous numerical parameters. Consequently, existing methods often discard promising algorithms due to uncalibrated constants and suffer from premature convergence resulting from simple similarity metrics. To address these limitations, we propose TIDE, a Tuning-Integrated Dynamic Evolution framework designed to decouple structural reasoning from parameter optimization. TIDE features a nested architecture where an outer parallel island model utilizes Tree Similarity Edit Distance to drive structural diversity, while an inner loop integrates LLM-based logic generation with a differential mutation operator for parameter tuning. Additionally, a UCB-based scheduler dynamically prioritizes high-yield prompt strategies to optimize resource allocation. Extensive experiments across nine combinatorial optimization problems demonstrate that TIDE discovers heuristics that significantly outperform state-of-the-art baselines in solution quality while achieving improved search efficiency and reduced computational costs.

</details>


### [158] [Position: Certifiable State Integrity in Cyber-Physical Systems -- Why Modular Sovereignty Solves the Plasticity-Stability Paradox](https://arxiv.org/abs/2601.21249)
*Enzo Nicolás Spotorno,Antônio Augusto Medeiros Fröhlich*

Main category: cs.AI

TL;DR: 该论文提出了一种名为HYDRA的新范式，通过结合紧凑的、特定阶段的专业模块，并通过不确定性感知融合进行集成，以解决时间序列基础模型的泛化和稳定性问题，特别强调了在安全关键的CPS系统中的应用。


<details>
  <summary>Details</summary>
Motivation: 现有的时间序列基础模型虽然在许多情况下表现良好，但在安全关键的CPS系统中遇到了挑战，包括灾难性遗忘、残余光谱偏差、模型不透明性以及缺乏形式验证和可追溯性。

Method: HYDRA框架通过构建一组紧凑的、针对特定阶段的专业模块，结合不确定性的感知融合来实现。

Result: HYDRA框架确保了跨生活周期的CPS系统的状态完整性，并能够进行模块化审查，明确区分 aleatoric 和 epistemic 不确定性。

Conclusion: HYDRA框架提供了一种可验证的方法来保持系统的稳定性和适应性，特别是在面临复杂动态条件的CPS系统中。

Abstract: The machine learning community has achieved remarkable success with universal foundation models for time-series and physical dynamics, largely overcoming earlier approximation barriers in smooth or slowly varying regimes through scale and specialized architectures. However, deploying these monolithic models in safety-critical Cyber-Physical Systems (CPS), governed by non-stationary lifecycle dynamics and strict reliability requirements, reveals persistent challenges. Recent evidence shows that fine-tuning time-series foundation models induces catastrophic forgetting, degrading performance on prior regimes. Standard models continue to exhibit residual spectral bias, smoothing high-frequency discontinuities characteristic of incipient faults, while their opacity hinders formal verification and traceability demanded by safety standards (e.g., ISO 26262, IEC 61508). This position paper argues that the plasticity-stability paradox cannot be fully resolved by global parameter updates (whether via offline fine-tuning or online adaptation). Instead, we advocate a Modular Sovereignty paradigm: a library of compact, frozen regime-specific specialists combined via uncertainty-aware blending, which we term "HYDRA" (Hierarchical uncertaintY-aware Dynamics for Rapidly-Adapting systems). This paradigm ensures regime-conditional validity, rigorous disentanglement of aleatoric and epistemic uncertainties, and modular auditability, offering a certifiable path for robust state integrity across the CPS lifecycle.

</details>


### [159] [Drive-KD: Multi-Teacher Distillation for VLMs in Autonomous Driving](https://arxiv.org/abs/2601.21288)
*Weitong Lian,Zecong Tang,Haoran Li,Tianjian Gao,Yifei Wang,Zixu Wang,Lingyi Meng,Tengju Ru,Zhejun Cui,Yichen Zhu,Hangshuo Cao,Qi Kang,Tianxing Chen,Yusen Qin,Kaixuan Wang,Yu Zhang*

Main category: cs.AI

TL;DR: Drive-KD 提出了一种知识蒸馏框架，将自主驾驶任务分解为感知-推理-规划三部分，并通过知识蒸馏实现小模型的高效推理能力，同时减少了 GPU 内存需求和提升了推理吞吐量。


<details>
  <summary>Details</summary>
Motivation: 现有大规模模型在自主驾驶中存在高内存需求和推理延迟问题，传统监督微调难以解决模型能力差距，Drive-KD 提出了知识蒸馏框架解决这些问题。

Method: 该方法将自主驾驶任务按照感知-推理-规划分解，通过特定层的注意力作为知识蒸馏信号，构建专门的知识教师模型，并引入多教师知识蒸馏和非对称梯度投影技术，实现小模型的高效推理。

Result: Drive-KD 的小模型通过知识蒸馏，在 GPU 内存减少约 42 倍和推理吞吐量提升约 11.4 倍的情况下，实现了与大型预训练模型相当或更好的性能，并在规划任务上超越 GPT-5.1。

Conclusion: Drive-KD 提供了自主驾驶中高效率小模型的知识蒸馏解决方案，有望推动更高效、安全的自动驾驶系统开发。

Abstract: Autonomous driving is an important and safety-critical task, and recent advances in LLMs/VLMs have opened new possibilities for reasoning and planning in this domain. However, large models demand substantial GPU memory and exhibit high inference latency, while conventional supervised fine-tuning (SFT) often struggles to bridge the capability gaps of small models. To address these limitations, we propose Drive-KD, a framework that decomposes autonomous driving into a "perception-reasoning-planning" triad and transfers these capabilities via knowledge distillation. We identify layer-specific attention as the distillation signal to construct capability-specific single-teacher models that outperform baselines. Moreover, we unify these single-teacher settings into a multi-teacher distillation framework and introduce asymmetric gradient projection to mitigate cross-capability gradient conflicts. Extensive evaluations validate the generalization of our method across diverse model families and scales. Experiments show that our distilled InternVL3-1B model, with ~42 times less GPU memory and ~11.4 times higher throughput, achieves better overall performance than the pretrained 78B model from the same family on DriveBench, and surpasses GPT-5.1 on the planning dimension, providing insights toward efficient autonomous driving VLMs.

</details>


### [160] [White-Box Op-Amp Design via Human-Mimicking Reasoning](https://arxiv.org/abs/2601.21321)
*Zihao Chen,Jiayin Wang,Ziyi Sun,Ji Zhuang,Jinyi Shen,Xiaoyue Ke,Li Shang,Xuan Zeng,Fan Yang*

Main category: cs.AI

TL;DR: 提出了一个基于类人思维逻辑的白盒运算放大器参数设计框架，实现了解释性设计，适用于9种运算放大器拓扑结构。


<details>
  <summary>Details</summary>
Motivation: 当前的黑盒设计方法不可解释，导致在某些拓扑结构上失败。研究希望提出一个可解释的设计框架来改善这一问题。

Method: 通过引入假设约束和迭代的假设-验证-决策流程，将人类的设计推理过程形式化。

Result: 在9种运算放大器拓扑结构上实验表明，白盒方法White-Op除了在5种拓扑上稍微有一些预测误差外，其余都达到了可靠且可解释的设计，并且在晶体管级映射后仍保持功能完好。

Conclusion: White-Op框架提供了解释性的、可靠的设计，适用于运算放大器参数设计，并且已经被开源。

Abstract: This brief proposes \emph{White-Op}, an interpretable operational amplifier (op-amp) parameter design framework based on the human-mimicking reasoning of large-language-model agents. We formalize the implicit human reasoning mechanism into explicit steps of \emph{\textbf{introducing hypothetical constraints}}, and develop an iterative, human-like \emph{\textbf{hypothesis-verification-decision}} workflow. Specifically, the agent is guided to introduce hypothetical constraints to derive and properly regulate positions of symbolically tractable poles and zeros, thus formulating a closed-form mathematical optimization problem, which is then solved programmatically and verified via simulation. Theory-simulation result analysis guides the decision-making for refinement. Experiments on 9 op-amp topologies show that, unlike the uninterpretable black-box baseline which finally fails in 5 topologies, White-Op achieves reliable, interpretable behavioral-level designs with only 8.52\% theoretical prediction error and the design functionality retains after transistor-level mapping for all topologies. White-Op is open-sourced at \textcolor{blue}{https://github.com/zhchenfdu/whiteop}.

</details>


### [161] [Modeling Endogenous Logic: Causal Neuro-Symbolic Reasoning Model for Explainable Multi-Behavior Recommendation](https://arxiv.org/abs/2601.21335)
*Yuzhe Chen,Jie Cao,Youquan Wang,Haicheng Tao,Darko B. Vukovic,Jia Wu*

Main category: cs.AI

TL;DR: 本文提出了一种名为CNRE的因果神经-符号推理模型，用于具有解释性的多行为推荐。通过结合因果推断和神经-符号框架，CNRE能够模拟用户决策过程，捕捉跨行为依赖关系，并根据偏好强度建模内在逻辑规则，从而产生不受混杂因素影响的可解释因果中介。


<details>
  <summary>Details</summary>
Motivation: 现有推荐系统往往忽视解释性，而解释性方法由于对外部信息依赖性强，一般化能力有限。本文旨在利用神经-符号集成和因果推断来解决这一问题。

Method: CNRE模型首先通过层次偏好传播捕捉跨行为依赖关系，然后基于偏好强度建模用户行为链中的隐式逻辑规则，并根据规则选择合适的神经-逻辑推理路径（如合取、析取）。该模型能够生成一个不受混杂因素影响的可解释因果中介。

Result: 在三个大规模数据集上的实验表明，CNRE在模型设计、决策过程和推荐结果等多个层面均优于当前最先进的基线。

Conclusion: CNRE为具有解释性的多行为推荐提供了一种新的有效方法。

Abstract: Existing multi-behavior recommendations tend to prioritize performance at the expense of explainability, while current explainable methods suffer from limited generalizability due to their reliance on external information. Neuro-Symbolic integration offers a promising avenue for explainability by combining neural networks with symbolic logic rule reasoning. Concurrently, we posit that user behavior chains inherently embody an endogenous logic suitable for explicit reasoning. However, these observational multiple behaviors are plagued by confounders, causing models to learn spurious correlations. By incorporating causal inference into this Neuro-Symbolic framework, we propose a novel Causal Neuro-Symbolic Reasoning model for Explainable Multi-Behavior Recommendation (CNRE). CNRE operationalizes the endogenous logic by simulating a human-like decision-making process. Specifically, CNRE first employs hierarchical preference propagation to capture heterogeneous cross-behavior dependencies. Subsequently, it models the endogenous logic rule implicit in the user's behavior chain based on preference strength, and adaptively dispatches to the corresponding neural-logic reasoning path (e.g., conjunction, disjunction). This process generates an explainable causal mediator that approximates an ideal state isolated from confounding effects. Extensive experiments on three large-scale datasets demonstrate CNRE's significant superiority over state-of-the-art baselines, offering multi-level explainability from model design and decision process to recommendation results.

</details>


### [162] [Within-Model vs Between-Prompt Variability in Large Language Models for Creative Tasks](https://arxiv.org/abs/2601.21339)
*Jennifer Haase,Jana Gonnermann-Müller,Paul H. P. Hanel,Nicolas Leins,Thomas Kosch,Jan Mendling,Sebastian Pokutta*

Main category: cs.AI

TL;DR: 研究了12个LLM在10个创造力提示下的输出差异，发现提示对输出质量的原创性影响占36.43%，与模型选择相当；但对输出数量的流畅性，模型选择和模型内部变化占主导，提示影响很小。提示是控制输出质量的强大杠杆，但由于模型内部变化较大，单样本评估可能难以区分是采样噪声还是真实提示或模型效果。


<details>
  <summary>Details</summary>
Motivation: 探讨LLM输出差异的主要因素，旨在改进提示设计和模型选择，提升语言生成模型的输出质量与数量。

Method: 通过使用12个不同的LLM模型并针对每个模型运行10个创造力提示生成100个样本，总共收集了12,000个样本数据来评估影响LLM输出结果的因素。

Result: 在输出质量方面，提示对原创性的影响占36.43%，与模型选择的40.94%相当；但在输出数量方面，模型选择的影响达到51.25%，模型内部变化达到了33.70%，提示的影响只占4.22%。这意味着提示在控制输出质量方面是非常有影响力的，但模型内部的显著变化使得单样本评估可能混淆采样噪声与内在的提示或模型效果。

Conclusion: 提示是影响LLM输出质量的重要因素，但当考虑模型内部的大量变化时，仅依据单个样本进行评估可能会得出不准确的结论。为了更准确地评估模型的效果，需要综合考虑更多因素，包括模型选择和采样稳定性。

Abstract: How much of LLM output variance is explained by prompts versus model choice versus stochasticity through sampling? We answer this by evaluating 12 LLMs on 10 creativity prompts with 100 samples each (N = 12,000). For output quality (originality), prompts explain 36.43% of variance, comparable to model choice (40.94%). But for output quantity (fluency), model choice (51.25%) and within-LLM variance (33.70%) dominate, with prompts explaining only 4.22%. Prompts are powerful levers for steering output quality, but given the substantial within-LLM variance (10-34%), single-sample evaluations risk conflating sampling noise with genuine prompt or model effects.

</details>


### [163] [EHR-RAG: Bridging Long-Horizon Structured Electronic Health Records and Large Language Models via Enhanced Retrieval-Augmented Generation](https://arxiv.org/abs/2601.21340)
*Lang Cao,Qingyu Chen,Yue Guo*

Main category: cs.AI

TL;DR: 该研究提出了一种名为EHR-RAG的方法，它通过引入事件和时间感知混合EHR检索、自适应迭代检索和双路径证据检索与推理三个组件，解决了长时距结构化EHR数据的准确解读问题，实验结果表明EHR-RAG在四个长时距EHR预测任务上均优于最强的基于LLM的基线，平均Macro-F1提高了10.76%。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录（EHRs）包含丰富的纵向临床证据，对于医疗决策至关重要。然而，现有的长时距EHR处理方法，如截断和纯查询检索策略，往往会导致临床相关事件和时间依赖性的丧失。因此，本文旨在提出一种新的框架EHR-RAG，以促进长时距结构化EHR数据的准确解读。

Method: EHR-RAG框架包含三个关键组件：事件和时间感知混合EHR检索，可以保持临床结构和时间动态；自适应迭代检索，可用于逐步细化查询并扩大证据覆盖面；双路径证据检索与推理，可以联合检索和推理事实和反事实证据。

Result: 在四个长时距EHR预测任务上，EHR-RAG相对于最强的基于LLM的基线实现了平均Macro-F1提高10.76%。

Conclusion: 这项工作强调了检索增强的大语言模型在实际的结构EHR临床预测中的潜力。

Abstract: Electronic Health Records (EHRs) provide rich longitudinal clinical evidence that is central to medical decision-making, motivating the use of retrieval-augmented generation (RAG) to ground large language model (LLM) predictions. However, long-horizon EHRs often exceed LLM context limits, and existing approaches commonly rely on truncation or vanilla retrieval strategies that discard clinically relevant events and temporal dependencies. To address these challenges, we propose EHR-RAG, a retrieval-augmented framework designed for accurate interpretation of long-horizon structured EHR data. EHR-RAG introduces three components tailored to longitudinal clinical prediction tasks: Event- and Time-Aware Hybrid EHR Retrieval to preserve clinical structure and temporal dynamics, Adaptive Iterative Retrieval to progressively refine queries in order to expand broad evidence coverage, and Dual-Path Evidence Retrieval and Reasoning to jointly retrieves and reasons over both factual and counterfactual evidence. Experiments across four long-horizon EHR prediction tasks show that EHR-RAG consistently outperforms the strongest LLM-based baselines, achieving an average Macro-F1 improvement of 10.76%. Overall, our work highlights the potential of retrieval-augmented LLMs to advance clinical prediction on structured EHR data in practice.

</details>


### [164] [Ostrakon-VL: Towards Domain-Expert MLLM for Food-Service and Retail Stores](https://arxiv.org/abs/2601.21342)
*Zhiyong Shen,Gongpeng Zhao,Jun Zhou,Li Yu,Guandong Kou,Jichen Li,Chuanlei Dong,Zuncheng Li,Kaimao Li,Bingkun Wei,Shicheng Hu,Wei Xia,Wenguo Duan*

Main category: cs.AI

TL;DR: 该研究针对食品服务和零售商店场景开发了Ostrakon-VL（基于Qwen3-VL-8B）并提出了ShopBench基准测试，并引入了QUAD数据清洗管道。


<details>
  <summary>Details</summary>
Motivation: 研究旨在克服现实世界FSRS数据质量和统一评估标准的限制，以提高MLLMs在FSRS场景中的性能和可靠性。

Method: 研究采用了多阶段训练策略，并开发了QUAD数据清洗管道来改进数据的质量，同时引入了ShopBench公共基准测试以标准化评估。

Result: Ostrakon-VL在ShopBench上的平均得分为60.1，超过了相同规模的Qwen3-VL-8B（55.3）和较大规模的Qwen3-VL-235B-A22B（59.4），表明参数效率的显著提升。

Conclusion: 研究展示了Ostrakon-VL在FSRS场景下的感知和决策能力的提高，并将公开Ostrakon-VL和ShopBench基准测试以支持 reproducible research。

Abstract: Multimodal Large Language Models (MLLMs) have recently achieved substantial progress in general-purpose perception and reasoning. Nevertheless, their deployment in Food-Service and Retail Stores (FSRS) scenarios encounters two major obstacles: (i) real-world FSRS data, collected from heterogeneous acquisition devices, are highly noisy and lack auditable, closed-loop data curation, which impedes the construction of high-quality, controllable, and reproducible training corpora; and (ii) existing evaluation protocols do not offer a unified, fine-grained and standardized benchmark spanning single-image, multi-image, and video inputs, making it challenging to objectively gauge model robustness. To address these challenges, we first develop Ostrakon-VL, an FSRS-oriented MLLM based on Qwen3-VL-8B. Second, we introduce ShopBench, the first public benchmark for FSRS. Third, we propose QUAD (Quality-aware Unbiased Automated Data-curation), a multi-stage multimodal instruction data curation pipeline. Leveraging a multi-stage training strategy, Ostrakon-VL achieves an average score of 60.1 on ShopBench, establishing a new state of the art among open-source MLLMs with comparable parameter scales and diverse architectures. Notably, it surpasses the substantially larger Qwen3-VL-235B-A22B (59.4) by +0.7, and exceeds the same-scale Qwen3-VL-8B (55.3) by +4.8, demonstrating significantly improved parameter efficiency. These results indicate that Ostrakon-VL delivers more robust and reliable FSRS-centric perception and decision-making capabilities. To facilitate reproducible research, we will publicly release Ostrakon-VL and the ShopBench benchmark.

</details>


### [165] [Latent Chain-of-Thought as Planning: Decoupling Reasoning from Verbalization](https://arxiv.org/abs/2601.21358)
*Jiecong Wang,Hao Peng,Chunyang Liu*

Main category: cs.AI

TL;DR: PLaT 通过将推理与自然语言表达分离，提出了一种新的隐式推理框架，使模型能够动态决定何时终止推理，从而提高了推理的多样性，展现出较好的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 当前的隐式推理方法通常将推理和自然语言表达紧密结合，这导致模型依赖固定的超参数来决定结束推理的时间。这种方法不利于推理多样性的提升和模型的透明性。

Method: PLaT 将推理过程视为确定性的 latent planning states 轨迹，同时使用独立的 Decoder 将想法转化为文本。这种方法允许模型根据需要动态地决定何时终止推理。

Result: 在数学基准任务上的实验结果显示，尽管 PLAt 的贪心准确率低于基准方法，但在推理多样性方面表现出更优的可扩展性。

Conclusion: PLaT 提供了一种透明且可扩展的推理框架，通过分离推理和自然语言表达，为推理过程中的搜索提供了坚实的基础。

Abstract: Chain-of-Thought (CoT) empowers Large Language Models (LLMs) to tackle complex problems, but remains constrained by the computational cost and reasoning path collapse when grounded in discrete token spaces. Recent latent reasoning approaches attempt to optimize efficiency by performing reasoning within continuous hidden states. However, these methods typically operate as opaque end-to-end mappings from explicit reasoning steps to latent states, and often require a pre-defined number of latent steps during inference. In this work, we introduce PLaT (Planning with Latent Thoughts), a framework that reformulates latent reasoning as planning by fundamentally decouple reasoning from verbalization. We model reasoning as a deterministic trajectory of latent planning states, while a separate Decoder grounds these thoughts into text when necessary. This decoupling allows the model to dynamically determine when to terminate reasoning rather than relying on fixed hyperparameters. Empirical results on mathematical benchmarks reveal a distinct trade-off: while PLaT achieves lower greedy accuracy than baselines, it demonstrates superior scalability in terms of reasoning diversity. This indicates that PLaT learns a robust, broader solution space, offering a transparent and scalable foundation for inference-time search.

</details>


### [166] [System 1&2 Synergy via Dynamic Model Interpolation](https://arxiv.org/abs/2601.21414)
*Chenxu Yang,Qingyi Si,Chong Tian,Xiyu Liu,Dingyu Yao,Chuanyu Qin,Zheng Lin,Weiping Wang,Jiaqi Wang*

Main category: cs.AI

TL;DR: 本文提出了一种名为DAMI的框架，通过动态参数插值调整模型的认知深度，利用代表连续性和结构连接性在推理强度上实现凸、单调的帕累托前沿。实验结果显示，DAMI能够在保持效率的同时提高数学推理任务的准确性。


<details>
  <summary>Details</summary>
Motivation: 当前的深度学习模型偏向输出控制，这是有限制的，作者认为应将注意力转向能力控制，这可以调节模型如何思考，而不仅仅是它们产生的内容。

Method: 该研究利用现有的指令和思考检查点，通过动态参数插值实现，不需要额外的训练。提出了一种两种基于训练和零样本部署的推理强度估计方法。

Result: 实验结果表明，DAMI在五个数学推理基准测试中提高了准确性，同时保持了效率，能够有效地结合系统的1和2的优势。

Conclusion: DAMI框架通过调节模型的认知深度，为实现高效且准确的数学推理提供了新的方法，展示了其在实际应用中的潜力。

Abstract: Training a unified language model that adapts between intuitive System 1 and deliberative System 2 remains challenging due to interference between their cognitive modes. Recent studies have thus pursued making System 2 models more efficient. However, these approaches focused on output control, limiting what models produce. We argue that this paradigm is misaligned: output length is merely a symptom of the model's cognitive configuration, not the root cause. In this work, we shift the focus to capability control, which modulates \textit{how models think} rather than \textit{what they produce}. To realize this, we leverage existing Instruct and Thinking checkpoints through dynamic parameter interpolation, without additional training. Our pilot study establishes that linear interpolation yields a convex, monotonic Pareto frontier, underpinned by representation continuity and structural connectivity. Building on this, we propose \textbf{DAMI} (\textbf{D}yn\textbf{A}mic \textbf{M}odel \textbf{I}nterpolation), a framework that estimates a query-specific Reasoning Intensity $λ(q)$ to configure cognitive depth. For training-based estimation, we develop a preference learning method encoding accuracy and efficiency criteria. For zero-shot deployment, we introduce a confidence-based method leveraging inter-model cognitive discrepancy. Experiments on five mathematical reasoning benchmarks demonstrate that DAMI achieves higher accuracy than the Thinking model while remaining efficient, effectively combining the efficiency of System 1 with the reasoning depth of System 2.

</details>


### [167] [When Prohibitions Become Permissions: Auditing Negation Sensitivity in Language Models](https://arxiv.org/abs/2601.21433)
*Katherine Elkins,Jon Chun*

Main category: cs.AI

TL;DR: 研究发现，许多大型语言模型在面对否定的指令时会出现错误解读，表现为将禁令视为许可。这种现象在不同模型和不同场景下存在显著差异，尤其是在财务场景中更为脆弱。文章提出了一种治理指标NSI，并建议对在高风险情境中自主决策能力较差的模型进行分级认证。


<details>
  <summary>Details</summary>
Motivation: 为了确保AI系统的道德性和安全性，针对用户通过语言表达禁止某人采取行动时，系统误将指令解读为许可的情况进行深入研究和分析。

Method: 通过审计16个不同模型在14种伦理场景下的表现，分析它们在简单的否定和复合否定指令下的反应，以及在收费模型和开源模型之间的差异。同时，通过案例研究揭示问题的具体表现，并提出治理指标NSI和分级认证框架。

Result: 研究发现，开源模型在简单否定指令下的错误率为77%，在复合否定指令下的错误率高达100%；相比之下，商业模型的错误率有所改善，但依然波动较大。特别是在财务场景中，模型的正确性大大降低。这一现象排除了采样噪声的影响。

Conclusion: 研究强调了当前对模型对否定义令的理解和处理不够可靠，特别是在高风险应用场景下。提出NSI和分级认证框架作为对现有对齐技术能否满足安全部署需求的评估工具。

Abstract: When a user tells an AI system that someone "should not" take an action, the system ought to treat this as a prohibition. Yet many large language models do the opposite: they interpret negated instructions as affirmations. We audited 16 models across 14 ethical scenarios and found that open-source models endorse prohibited actions 77% of the time under simple negation and 100% under compound negation -- a 317% increase over affirmative framing. Commercial models fare better but still show swings of 19-128%. Agreement between models drops from 74% on affirmative prompts to 62% on negated ones, and financial scenarios prove twice as fragile as medical ones. These patterns hold under deterministic decoding, ruling out sampling noise. We present case studies showing how these failures play out in practice, propose the Negation Sensitivity Index (NSI) as a governance metric, and outline a tiered certification framework with domain-specific thresholds. The findings point to a gap between what current alignment techniques achieve and what safe deployment requires: models that cannot reliably distinguish "do X" from "do not X" should not be making autonomous decisions in high-stakes contexts.

</details>


### [168] [The Paradox of Robustness: Decoupling Rule-Based Logic from Affective Noise in High-Stakes Decision-Making](https://arxiv.org/abs/2601.21439)
*Jon Chun,Katherine Elkins*

Main category: cs.AI

TL;DR: 本研究揭示了大型语言模型（LLMs）在高风险决策领域中表现出了令人惊讶的“稳健性悖论”：尽管这些模型对语言微调很敏感，但它们对情感框架效应有极低的响应性，显示出比人类更高的逻辑约束满足能力，而对叙述操控的抵抗力是人类的110-300倍。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型对轻微提示调整表现出脆弱性，并容易与用户偏见保持一致，但它们在关键、规则约束决策中的稳健性尚未得到充分探索。本研究旨在解决一个‘稳健性悖论’：尽管LLMs在语言上脆弱，但它们在情感框架效应上的行为几乎不变。

Method: 使用新颖的受控扰动框架，研究者在医疗、法律和金融三个高风险领域对LLMs和人类被试进行了比较研究，量化了决策稳健性差异。

Result: 研究发现，LLMs对叙述操控的抵抗力比人类高110-300倍，效果大小接近零，而人类则表现出明显的偏见。此外，这种稳健性在不同训练方式的模型中保持一致。

Conclusion: LLMs在关键领域的逻辑规则遵守方面表现出色，但在呼吁性叙述的抵抗方面令人惊讶地稳定，这为机构背景下的决策稳定性提供了可能的来源。”该研究还分享了162个情景基准、代码和数据，以增强叙述诱导偏见和稳健性评估的严谨性。“

Abstract: While Large Language Models (LLMs) are widely documented to be sensitive to minor prompt perturbations and prone to sycophantic alignment with user biases, their robustness in consequential, rule-bound decision-making remains under-explored. In this work, we uncover a striking "Paradox of Robustness": despite their known lexical brittleness, instruction-tuned LLMs exhibit a behavioral and near-total invariance to emotional framing effects. Using a novel controlled perturbation framework across three high-stakes domains (healthcare, law, and finance), we quantify a robustness gap where LLMs demonstrate 110-300 times greater resistance to narrative manipulation than human subjects. Specifically, we find a near-zero effect size for models (Cohen's h = 0.003) compared to the substantial biases observed in humans (Cohen's h in [0.3, 0.8]). This result is highly counterintuitive and suggests the mechanisms driving sycophancy and prompt sensitivity do not necessarily translate to a failure in logical constraint satisfaction. We show that this invariance persists across models with diverse training paradigms. Our findings show that while LLMs may be "brittle" to how a query is formatted, they are remarkably "stable" against why a decision should be biased. Our findings establish that instruction-tuned models can decouple logical rule-adherence from persuasive narratives, offering a source of decision stability that complements, and even potentially de-biases, human judgment in institutional contexts. We release the 162-scenario benchmark, code, and data to facilitate the rigorous evaluation of narrative-induced bias and robustness on GitHub.com.

</details>


### [169] [Topeax -- An Improved Clustering Topic Model with Density Peak Detection and Lexical-Semantic Term Importance](https://arxiv.org/abs/2601.21465)
*Márton Kardos*

Main category: cs.AI

TL;DR: Topeax是一种新的文本聚类方法，通过峰值密度估计确定聚类数量，并结合词汇和语义术语重要性的指标来获得高质量的主题关键字，从而在集群恢复和描述方面优于Top2Vec和BERTopic。


<details>
  <summary>Details</summary>
Motivation: 当前的Top2Vec和BERTopic方法在发现自然簇时表现不稳定，例如对样本大小和超参数高度敏感，并且在术语重要性估计上存在不足。

Method: Topeax通过分析密度估计的峰值来确定簇的数量，并结合词汇和语义的重要性指标来发现主题关键字。

Result: Topeax在集群恢复和描述方面优于现有的Top2Vec和BERTopic。

Conclusion: Topeax提供了一种更可靠和高效的方法来发现文本中的主题，并对未来的研究具有重要意义。

Abstract: Text clustering is today the most popular paradigm for topic modelling, both in academia and industry. Despite clustering topic models' apparent success, we identify a number of issues in Top2Vec and BERTopic, which remain largely unsolved. Firstly, these approaches are unreliable at discovering natural clusters in corpora, due to extreme sensitivity to sample size and hyperparameters, the default values of which result in suboptimal behaviour. Secondly, when estimating term importance, BERTopic ignores the semantic distance of keywords to topic vectors, while Top2Vec ignores word counts in the corpus. This results in, on the one hand, less coherent topics due to the presence of stop words and junk words, and lack of variety and trust on the other. In this paper, I introduce a new approach, \textbf{Topeax}, which discovers the number of clusters from peaks in density estimates, and combines lexical and semantic indices of term importance to gain high-quality topic keywords. Topeax is demonstrated to be better at both cluster recovery and cluster description than Top2Vec and BERTopic, while also exhibiting less erratic behaviour in response to changing sample size and hyperparameters.

</details>


### [170] [The Effectiveness of Style Vectors for Steering Large Language Models: A Human Evaluation](https://arxiv.org/abs/2601.21505)
*Diaoulé Diallo,Katharina Dworatzyk,Sophie Jentzsch,Peer Schütt,Sabine Theis,Tobias Hecking*

Main category: cs.AI

TL;DR: 本研究通过激活引导控制大型语言模型的行为，在情感音调方向上进行了首次人类评估，评价了7000多条来自190名参与者的众包反馈。研究发现自动评分可以替代人为质量评估，并在加大情感强度时保持文本的可理解性。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型在输出时的行为需要与人类能力和安全要求相匹配，本研究旨在通过激活引导技术提供一种比提示工程和调优更轻量的解决方案。

Method: 研究人员使用了自动分类器提前分类情感倾向，然后通过调整模型内部激活来引导生成，使用Prolific进行大规模的人类评估，并对比了不同强度和不同模型的效果。

Result: 研究结果表明，自动评分能够很好地预测人类对生成文本质量的主观评价。适度的情感引导（λ≈0.15）可以增强目标情感的同时保持文本可读性。特别是厌恶和恐惧情感的放大效果显著，而对惊讶情感的影响最小。在使用更复杂的LlaMA-3模型后，情感引导的一致性和效果显著提升。

Conclusion: 本研究证明了基于激活的控制方法在跨情感维度引导LLM行为方面具有可扩展性。

Abstract: Controlling the behavior of large language models (LLMs) at inference time is essential for aligning outputs with human abilities and safety requirements. \emph{Activation steering} provides a lightweight alternative to prompt engineering and fine-tuning by directly modifying internal activations to guide generation. This research advances the literature in three significant directions. First, while previous work demonstrated the technical feasibility of steering emotional tone using automated classifiers, this paper presents the first human evaluation of activation steering concerning the emotional tone of LLM outputs, collecting over 7,000 crowd-sourced ratings from 190 participants via Prolific ($n=190$). These ratings assess both perceived emotional intensity and overall text quality. Second, we find strong alignment between human and model-based quality ratings (mean $r=0.776$, range $0.157$--$0.985$), indicating automatic scoring can proxy perceived quality. Moderate steering strengths ($λ\approx 0.15$) reliably amplify target emotions while preserving comprehensibility, with the strongest effects for disgust ($η_p^2 = 0.616$) and fear ($η_p^2 = 0.540$), and minimal effects for surprise ($η_p^2 = 0.042$). Finally, upgrading from Alpaca to LlaMA-3 yielded more consistent steering with significant effects across emotions and strengths (all $p < 0.001$). Inter-rater reliability was high (ICC $= 0.71$--$0.87$), underscoring the robustness of the findings. These findings support activation-based control as a scalable method for steering LLM behavior across affective dimensions.

</details>


### [171] [ARGORA: Orchestrated Argumentation for Causally Grounded LLM Reasoning and Decision Making](https://arxiv.org/abs/2601.21533)
*Youngjin Jin,Hanna Kim,Kwanwoo Kim,Chanhee Lee,Seungwon Shin*

Main category: cs.AI

TL;DR: ARGORA 提出了一种框架，通过构建显式的论证图来组织多专家讨论，并将其作为因果模型处理，以系统地移除个别论据并重新计算结果，从而识别必要的推理链和目标修改下的决策变化。该框架还包含一个纠正机制，当内部推理与外部判断不一致时进行对齐。


<details>
  <summary>Details</summary>
Motivation: 现有系统中，多专家大模型系统虽然集成了多种视角，但简单聚合方式使得难以追踪最终决策背后的论据驱动。为此，提出ARGORA以清晰展示支持或反驳的论据关系，通过因果模型方法系统地分析单个论据对结果的影响。

Method: ARGORA 构建显式的论证图，将这些图作为因果模型进行处理。它采用了两个关键部分：(1) 识别并呈现支持或反驳的论据关系；(2) 使用因果模型系统地移除论据并重新计算结果，以确定哪些推理链是必要的，以及是否会在目标修改下改变决策。

Result: 在各种基准测试和开放使用场景中，ARGORA 达到了竞争力的准确性，并展示了纠正行为。在专家最初意见不一致时，框架更多地倾向于促进正确答案而非引入新错误，同时提供了决定性论据的因果诊断。

Conclusion: ARGORA 为多专家系统提供了更加透明和可解释的决策过程，提高了系统的准确性和可靠性，并在实际应用中展示了良好的性能和纠正效果。

Abstract: Existing multi-expert LLM systems gather diverse perspectives but combine them through simple aggregation, obscuring which arguments drove the final decision. We introduce ARGORA, a framework that organizes multi-expert discussions into explicit argumentation graphs showing which arguments support or attack each other. By casting these graphs as causal models, ARGORA can systematically remove individual arguments and recompute outcomes, identifying which reasoning chains were necessary and whether decisions would change under targeted modifications. We further introduce a correction mechanism that aligns internal reasoning with external judgments when they disagree. Across diverse benchmarks and an open-ended use case, ARGORA achieves competitive accuracy and demonstrates corrective behavior: when experts initially disagree, the framework resolves disputes toward correct answers more often than it introduces new errors, while providing causal diagnostics of decisive arguments.

</details>


### [172] [Chain Of Thought Compression: A Theoritical Analysis](https://arxiv.org/abs/2601.21576)
*Juncai Li,Ru Li,Yuxiang Zhou,Boxiang Ma,Jeff Z. Pan*

Main category: cs.AI

TL;DR: 该研究首次对学习内部化中间推理步骤的难度进行了理论分析，证明了高阶逻辑依赖关系的学习信号会以指数形式衰减，从而导致不可解决的问题。通过NatBool-DAG基准测试验证，并提出ALiCoT框架，通过调整潜在令牌分布与中间推理状态对齐来克服这一障碍，实现54.4倍的速度提升，同时保持与显式链式思维相当的性能。


<details>
  <summary>Details</summary>
Motivation: 分析LSTM参数限制下的LLMs推理能力，为优化大型语言模型的推理方法提供理论依据。

Method: 引入Order-r交互概念，进行理论分析；设计NatBool-DAG基准测试；提出ALiCoT框架。

Result: 证明了高阶逻辑依赖关系的学习信号会以指数形式衰减，提出了NatBool-DAG基准测试，成功引入ALiCoT框架，实现速度和性能的双重提升。

Conclusion: ALiCoT框架能够有效克服中间步骤的学习信号衰减问题，实现高效的推理过程，为LLMs推理策略的优化提供了新的思路。

Abstract: Chain-of-Thought (CoT) has unlocked advanced reasoning abilities of Large Language Models (LLMs) with intermediate steps, yet incurs prohibitive computational costs due to generation of extra tokens. Recent studies empirically show that compressing reasoning steps into latent states, or implicit CoT compression, offers a token-efficient alternative. However, the mechanism behind CoT compression remains unclear. In this paper, we provide the first theoretical analysis of the difficulty of learning to internalize intermediate reasoning steps. By introducing Order-r Interaction, we prove that the learning signal for high-order logical dependencies exponentially decays to solve irreducible problem, where skipping intermediate steps inevitably leads to high-order interaction barriers. To empirically validate this, we introduce NatBool-DAG, a challenging benchmark designed to enforce irreducible logical reasoning and eliminate semantic shortcuts. Guided by our theoretical findings, we propose ALiCoT (Aligned Implicit CoT), a novel framework that overcomes the signal decay by aligning latent token distributions with intermediate reasoning states. Experimental results demonstrate that ALiCoT successfully unlocks efficient reasoning: it achieves a 54.4x speedup while maintaining performance comparable to explicit CoT.

</details>


### [173] [Depth-Recurrent Attention Mixtures: Giving Latent Reasoning the Attention it Deserves](https://arxiv.org/abs/2601.21582)
*Jonas Knupp,Jan Hendrik Metzen,Jeremias Bohn,Georg Groh,Kristian Kersting*

Main category: cs.AI

TL;DR: 本文提出了一种名为Dreamer的深度递归注意力混合框架，通过沿深度的注意力机制缓解了隐藏尺寸瓶颈，并允许深度递归模型高效扩展。与FLOP、参数和内存匹配的SOTA模型相比，当达到相同准确性时，本文模型在语言推理基准上所需的训练令牌数减少2至8倍；同时，与SOTA MoEs相比，实验显示专家选择多样性可大1至11倍。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明深度递归能够促进潜在推理，但缺乏算法时间复杂度、参数量级和内存使用量匹配的基准比较，部分卷积层堆栈设置固定，且忽略了恒定隐藏尺寸对多步潜在推理的限制。本文旨在通过提出一个模块化的深度递归注意力混合框架，解决这些不足，并有效扩展深度递归模型。

Method: 本文框架Dreamer结合了序列注意力、深度注意力和稀疏专家注意力，通过沿深度的注意力机制缓解隐藏尺寸瓶颈，解除缩放维度的耦合，实现高效扩展。

Result: 针对多种语言推理基准测试，本文模型在相同的计算和参数量级下只需要2至8倍的训练数据量即可达到SOTA模型的准确性。此外，实验结果表明，与SOTA MoEs相比，本文框架的专家选择多样性可增大1至11倍。

Conclusion: 本文提出了一种新的框架，能够在保持较低复杂性的同时实现高效的多步潜在推理，并通过实验结果证明了其在保持高效性和准确性的同时，具有更大的灵活性和更好的性能。

Abstract: Depth-recurrence facilitates latent reasoning by sharing parameters across depths. However, prior work lacks combined FLOP-, parameter-, and memory-matched baselines, underutilizes depth-recurrence due to partially fixed layer stacks, and ignores the bottleneck of constant hidden-sizes that restricts many-step latent reasoning. To address this, we introduce a modular framework of depth-recurrent attention mixtures (Dreamer), combining sequence attention, depth attention, and sparse expert attention. It alleviates the hidden-size bottleneck through attention along depth, decouples scaling dimensions, and allows depth-recurrent models to scale efficiently and effectively. Across language reasoning benchmarks, our models require 2 to 8x fewer training tokens for the same accuracy as FLOP-, parameter-, and memory-matched SOTA, and outperform ca. 2x larger SOTA models with the same training tokens. We further present insights into knowledge usage across depths, e.g., showing 2 to 11x larger expert selection diversity than SOTA MoEs.

</details>


### [174] [Beyond Imitation: Reinforcement Learning for Active Latent Planning](https://arxiv.org/abs/2601.21598)
*Zhi Zheng,Wee Sun Lee*

Main category: cs.AI

TL;DR: 该研究提出了一种主动规划方法（ATP-Latent），通过将监督过程建模为条件变分自编码器（VAE），并引入基于隐含表示一致性的辅助连贯性奖励，进行强化学习（RL），以提高链式思维推理的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 当前的隐含表示方法通常基于模仿语言标签进行监督，这可能导致隐含表示和推理策略的质量不佳，从而限制了潜在规划能力的发挥。

Method: 研究提出了一种名为ATP-Latent的方法，该方法将监督过程建模为条件变分自编码器（VAE），并使用强化学习（RL）进行训练，引入了基于VAE解码内容一致性计算的辅助连贯性奖励。

Result: 实验表明，与先进的基线相比，ATP-Latent在四个基准测试上提高了4.1%的准确率，并减少了3.3%的令牌使用。

Conclusion: 研究证明了通过主动规划在潜在表示空间中进行优化的重要性，并展示了这种方法在提高LLMs在CoT推理任务中的表现方面的有效性。

Abstract: Aiming at efficient and dense chain-of-thought (CoT) reasoning, latent reasoning methods fine-tune Large Language Models (LLMs) to substitute discrete language tokens with continuous latent tokens. These methods consume fewer tokens compared to the conventional language CoT reasoning and have the potential to plan in a dense latent space. However, current latent tokens are generally supervised based on imitating language labels. Considering that there can be multiple equivalent but diverse CoT labels for a question, passively imitating an arbitrary one may lead to inferior latent token representations and latent reasoning policies, undermining the potential planning ability and resulting in clear gaps between training and testing. In this work, we emphasize the importance of active planning over the representation space of latent tokens in achieving the optimal latent reasoning policy. So, we propose the \underline{A}c\underline{t}ive Latent \underline{P}lanning method (ATP-Latent), which models the supervision process of latent tokens as a conditional variational auto-encoder (VAE) to obtain a smoother latent space. Moreover, to facilitate the most reasonable latent reasoning policy, ATP-Latent conducts reinforcement learning (RL) with an auxiliary coherence reward, which is calculated based on the consistency between VAE-decoded contents of latent tokens, enabling a guided RL process. In experiments on LLaMA-1B, ATP-Latent demonstrates +4.1\% accuracy and -3.3\% tokens on four benchmarks compared to advanced baselines. Codes are available on https://github.com/zz1358m/ATP-Latent-master.

</details>


### [175] [Search-Based Risk Feature Discovery in Document Structure Spaces under a Constrained Budget](https://arxiv.org/abs/2601.21608)
*Saisubramaniam Gopalakrishnan,Harikrishnan P M,Dagnachew Birru*

Main category: cs.AI

TL;DR: 本文提出了使用搜索基础软件测试（SBST）方法来解决企业级智能文档处理系统验证问题，通过不同搜索策略识别复杂文档变量间的相互作用，从而在预算内发现最多的失败模式。


<details>
  <summary>Details</summary>
Motivation: 在有限的预算下对高风险流程的企业级智能文档处理系统进行早期验证，需要揭示多种失败机制，而不仅仅是单一的最坏情况文档。

Method: 方法使用搜索空间中的文档配置实例化结构风险特征，以诱导真实失败条件。并针对预算约束下的不同搜索策略进行基准测试。通过配置级别独占性，胜率和跨时区重叠分析，展示了不同求解器在预算一致的条件下，能够发现不同类型的失败模式。

Result: 结果表明，不同的求解器能够在预算内持续发现特定的失败模式，且没有一种策略表现出绝对的优越性。跨时间分析显示，不同求解器的发现具有持续性，且求解器混合策略具有内在的互补性。

Conclusion: 结果证明了求解器之间存在固有的互补性，并为工业级IDP验证推荐了基于求解器组合的SBST策略。

Abstract: Enterprise-grade Intelligent Document Processing (IDP) systems support high-stakes workflows across finance, insurance, and healthcare. Early-phase system validation under limited budgets mandates uncovering diverse failure mechanisms, rather than identifying a single worst-case document. We formalize this challenge as a Search-Based Software Testing (SBST) problem, aiming to identify complex interactions between document variables, with the objective to maximize the number of distinct failure types discovered within a fixed evaluation budget. Our methodology operates on a combinatorial space of document configurations, rendering instances of structural \emph{risk features} to induce realistic failure conditions. We benchmark a diverse portfolio of search strategies spanning evolutionary, swarm-based, quality-diversity, learning-based, and quantum under identical budget constraints. Through configuration-level exclusivity, win-rate, and cross-temporal overlap analyses, we show that different solvers consistently uncover failure modes that remain undiscovered by specific alternatives at comparable budgets. Crucially, cross-temporal analysis reveals persistent solver-specific discoveries across all evaluated budgets, with no single strategy exhibiting absolute dominance. While the union of all solvers eventually recovers the observed failure space, reliance on any individual method systematically delays the discovery of important risks. These results demonstrate intrinsic solver complementarity and motivate portfolio-based SBST strategies for robust industrial IDP validation.

</details>


### [176] [Semantic Content Determines Algorithmic Performance](https://arxiv.org/abs/2601.21618)
*Martiño Ríos-García,Nawaf Alampara,Kevin Maik Jablonka*

Main category: cs.AI

TL;DR: WhatCounts 是一种新方法，旨在测试模型对计数任务的语义不变性。通过对比实验发现，前沿语言模型在计数任务上的准确率随计数内容的变化而显著波动，表明模型在处理不同语义类型的输入时存在语义依赖性。


<details>
  <summary>Details</summary>
Motivation: 当前模型在处理不同语义类型的任务时表现出显著差异，而研究这些差异的原因有助于更加准确地理解模型行为及其潜在的依赖性。

Method: WhatCounts 方法专注于简单的计数任务，不包含复杂推理或分散注意力的元素，直接测试模型对语义内容的独立性。

Result: 研究表明，语言模型在计数任务上的准确率在不同语义类型之间存在显著差异，最高可达40%。细粒度的微调不影响模型的这种依赖性。

Conclusion: 本文结论是语言模型在执行任务时存在固有的语义依赖性，这可能对模型的泛化能力产生负面影响，并强调了进一步研究模型行为一致性的必要性。

Abstract: Counting should not depend on what is being counted; more generally, any algorithm's behavior should be invariant to the semantic content of its arguments. We introduce WhatCounts to test this property in isolation. Unlike prior work that conflates semantic sensitivity with reasoning complexity or prompt variation, WhatCounts is atomic: count items in an unambiguous, delimited list with no duplicates, distractors, or reasoning steps for different semantic types. Frontier LLMs show over 40% accuracy variation depending solely on what is being counted - cities versus chemicals, names versus symbols. Controlled ablations rule out confounds. The gap is semantic, and it shifts unpredictably with small amounts of unrelated fine-tuning. LLMs do not implement algorithms; they approximate them, and the approximation is argument-dependent. As we show with an agentic example, this has implications beyond counting: any LLM function may carry hidden dependencies on the meaning of its inputs.

</details>


### [177] [ScholarGym: Benchmarking Deep Research Workflows on Academic Literature Retrieval](https://arxiv.org/abs/2601.21654)
*Hao Shen,Hang Yang,Zhouhong Gu*

Main category: cs.AI

TL;DR: ScholarGym 是一个用于学术文献上可再现评估深度研究工作流的模拟环境。它将工作流程拆分为查询规划、工具调用和相关性评估，提供了570K论文的静态语料库和2,536个带有专家标注的查询，揭示了不同模型下推理能力、规划策略和选择机制的差异。


<details>
  <summary>Details</summary>
Motivation: 当前的工作流程依赖于实时API调用，导致结果不可再现，难以进行系统间的比较。因此，ScholarGym 提供了一个模拟环境来克服这些挑战。

Method: 通过设计一个静态语料库和专家标注的查询集，以及将工作流分阶段评估的方法，ScholarGym 使其能够控制和深入分析每个阶段的性能。

Result: 学者们可以在不受实时因素影响的条件下，评估多种模型中推理能力、规划策略和选择机制的性能。

Conclusion: ScholarGym 通过提供一个可以再现的研究环境，使得研究人员能够更好地理解模型在学术文本文档处理中的表现。

Abstract: Tool-augmented large language models have advanced from single-turn question answering to deep research workflows that iteratively plan queries, invoke external tools, and synthesize information to address complex information needs. Evaluating such workflows presents a fundamental challenge: reliance on live APIs introduces non-determinism, as tool invocations may yield different results across runs due to temporal drift, rate limiting, and evolving backend states. This variance undermines reproducibility and invalidates cross-system comparisons.
  We present ScholarGym, a simulation environment for reproducible evaluation of deep research workflows on academic literature. The environment decouples workflow components into query planning, tool invocation, and relevance assessment, enabling fine-grained analysis of each stage under controlled conditions. Built on a static corpus of 570K papers with deterministic retrieval, ScholarGym provides 2,536 queries with expert-annotated ground truth. Experiments across diverse backbone models reveal how reasoning capabilities, planning strategies, and selection mechanisms interact over iterative refinement.

</details>


### [178] [SONIC-O1: A Real-World Benchmark for Evaluating Multimodal Large Language Models on Audio-Video Understanding](https://arxiv.org/abs/2601.21666)
*Ahmed Y. Radwan,Christos Emmanouilidis,Hina Tabassum,Deval Pandya,Shaina Raza*

Main category: cs.AI

TL;DR: SONIC-O1 是一个涵盖了 13 个真实世界对话领域的综合评估基准，包含 4,958 个人工验证注解和人口统计元数据，用于评估 MLLMs 的开放摘要生成、多项选择题回答和具有支持理由的时序定位等关键任务。


<details>
  <summary>Details</summary>
Motivation: SONIC-O1 的引入旨在填补现有研究主要集中在静态图像理解而较少关注顺序音频-视频数据处理能力的空白，为系统评估 MLLMs 在实际场景中的表现提供了必要的基准。

Method: 该基准包含 13 个真实世界对话领域的注解，涵盖开放性摘要生成、多项选择题回答及时序定位等关键任务，采用了人工验证的方式保证数据质量。

Result: 实验结果显示，在多项选择题准确率方面，两种模型家族之间的性能差距相对较小；但在时序定位方面，最优的闭源模型与开源模型之间存在显著的 22.6% 性能差异，且模型表现进一步在不同的人口统计群体中下降。

Conclusion: SONIC-O1 基准为时间导向和社会稳健的多模态理解提供了开放的评估框架，对于研究 MLLMs 的多模式理解能力具有重要价值。相关数据集、项目页面和排行榜均已公开。

Abstract: Multimodal Large Language Models (MLLMs) are a major focus of recent AI research. However, most prior work focuses on static image understanding, while their ability to process sequential audio-video data remains underexplored. This gap highlights the need for a high-quality benchmark to systematically evaluate MLLM performance in a real-world setting. We introduce SONIC-O1, a comprehensive, fully human-verified benchmark spanning 13 real-world conversational domains with 4,958 annotations and demographic metadata. SONIC-O1 evaluates MLLMs on key tasks, including open-ended summarization, multiple-choice question (MCQ) answering, and temporal localization with supporting rationales (reasoning). Experiments on closed- and open-source models reveal limitations. While the performance gap in MCQ accuracy between two model families is relatively small, we observe a substantial 22.6% performance difference in temporal localization between the best performing closed-source and open-source models. Performance further degrades across demographic groups, indicating persistent disparities in model behavior. Overall, SONIC-O1 provides an open evaluation suite for temporally grounded and socially robust multimodal understanding. We release SONIC-O1 for reproducibility and research: Project page: https://vectorinstitute.github.io/sonic-o1/ Dataset: https://huggingface.co/datasets/vector-institute/sonic-o1 Github: https://github.com/vectorinstitute/sonic-o1 Leaderboard: https://huggingface.co/spaces/vector-institute/sonic-o1-leaderboard

</details>


### [179] [TCAP: Tri-Component Attention Profiling for Unsupervised Backdoor Detection in MLLM Fine-Tuning](https://arxiv.org/abs/2601.21692)
*Mingzu Liu,Hao Fang,Runmin Cong*

Main category: cs.AI

TL;DR: 该研究发现了一种通用的后门指纹——注意力分配偏差，无论触发形态如何，中毒样本均会破坏系统指令、视觉输入和用户文本查询之间的平衡注意力分配。基于这一发现，该研究提出了TCAP，一种无需监督的防御框架，通过分解跨模态注意力图、识别触发响应的注意力头并基于EM投票聚合排除中毒样本，从而有效地抵御后门攻击。


<details>
  <summary>Details</summary>
Motivation: 现有的防御方式依赖于监督信号或无法在多种触发类型和模态下泛化，本文旨在通过识别一种通用的后门指纹来提出一种无需监督的防御框架，以提高在各种大规模语言模型架构和攻击方法下的鲁棒性。

Method: 本文提出了一种无监督的防御框架TCAP，该框架首先通过高斯混合模型（GMM）统计剖析分解跨模态注意力图，识别出对触发有响应的注意力头；然后利用EM（期望最大化）投票聚合来过滤出中毒样本。

Result: 实验结果表明，该框架在不同的大规模语言模型架构和攻击方法下均表现出良好的鲁棒性和实用性，能够在保持大量模型性能的同时有效防御后门攻击。

Conclusion: 本文提出的一种无监督防御框架为大规模语言模型的后门攻击提供了新的防御思路，并通过广泛的实验验证了其在各种威胁场景下的有效性。

Abstract: Fine-Tuning-as-a-Service (FTaaS) facilitates the customization of Multimodal Large Language Models (MLLMs) but introduces critical backdoor risks via poisoned data. Existing defenses either rely on supervised signals or fail to generalize across diverse trigger types and modalities. In this work, we uncover a universal backdoor fingerprint-attention allocation divergence-where poisoned samples disrupt the balanced attention distribution across three functional components: system instructions, vision inputs, and user textual queries, regardless of trigger morphology. Motivated by this insight, we propose Tri-Component Attention Profiling (TCAP), an unsupervised defense framework to filter backdoor samples. TCAP decomposes cross-modal attention maps into the three components, identifies trigger-responsive attention heads via Gaussian Mixture Model (GMM) statistical profiling, and isolates poisoned samples through EM-based vote aggregation. Extensive experiments across diverse MLLM architectures and attack methods demonstrate that TCAP achieves consistently strong performance, establishing it as a robust and practical backdoor defense in MLLMs.

</details>


### [180] [FBS: Modeling Native Parallel Reading inside a Transformer](https://arxiv.org/abs/2601.21708)
*Tongxi Wang*

Main category: cs.AI

TL;DR: 本文提出了一种新型的Fovea-Block-Skip Transformer (FBS)，通过Parafovea-Attention Window (PAW)，Chunk-Head (CH)，和Skip-Gate (SG)模块，在不增加参数量的情况下显著提升了语言模型的质量效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在语言模型推理过程中仍依赖于严格按顺序的自回归机制，无法提供类似人类阅读时的情境预测、合理计算分配及训练-测试一致性。因此，需要一种能够加入这些关键元素的方法来改进模型。

Method: FBS采用了Parafovea-Attention Window (PAW)，Chunk-Head (CH)，和Skip-Gate (SG)三个创新模块，这些模块被整合到标准Transformer架构中，以促进前瞻性的内容适应、基于块结构的计算分配及预览/略读训练-测试一致性。

Result: FBS在多种基准测试中表现出色，实现了质量与效率之间的良好平衡，且未增加模型的参数量。

Conclusion: FBS通过新的设计提高了解码器的性能，它是一个有潜力的改进现有语言模型的方法，能够更好地模仿人类阅读行为。

Abstract: Large language models (LLMs) excel across many tasks, yet inference is still dominated by strictly token-by-token autoregression. Existing acceleration methods largely patch this pipeline and miss core human-reading ingredients: content-adaptive foresight, chunk-structure-aware compute allocation, and train--test consistency for preview/skimming. We propose the \textbf{Fovea-Block-Skip Transformer} (FBS), which injects a causal, trainable loop into Transformers via Parafovea-Attention Window (PAW), Chunk-Head (CH), and Skip-Gate (SG). Across diverse benchmarks, FBS improves the quality-efficiency trade-off without increasing parameters, and ablations show the three modules are complementary.

</details>


### [181] [DropoutTS: Sample-Adaptive Dropout for Robust Time Series Forecasting](https://arxiv.org/abs/2601.21726)
*Siru Zhong,Yiqiu Liu,Zhiqing Cui,Zezhi Shao,Fei Wang,Qingsong Wen,Yuxuan Liang*

Main category: cs.AI

TL;DR: DropoutTS 是一个模型无关的插件，通过样本自适应丢弃机制和基于谱稀疏性的噪声量化，增强了时间序列模型的鲁棒性，同时保持模型效率。


<details>
  <summary>Details</summary>
Motivation: 现有的鲁棒性策略要么消除数据，要么依赖于昂贵的先验量化，这影响了效果和效率的平衡。DropoutTS 通过从学习什么转变为学习多少来改变这一状况。

Method: DropoutTS 使用样本自适应丢弃机制，利用谱稀疏性高效地通过重构残差量化实例级噪声。它通过将噪声映射到适应性丢弃率来动态调整模型的学习能力，以抑制假的波动并保留细节。

Result: DropoutTS 在各种噪声环境下和公开基准上进行了广泛实验，展示了它能显著提升基础模型的性能。它具有微乎其微的参数开销，无需进行架构修改。

Conclusion: DropoutTS 提供了先进的鲁棒性，同时保持模型的效率。

Abstract: Deep time series models are vulnerable to noisy data ubiquitous in real-world applications. Existing robustness strategies either prune data or rely on costly prior quantification, failing to balance effectiveness and efficiency. In this paper, we introduce DropoutTS, a model-agnostic plugin that shifts the paradigm from "what" to learn to "how much" to learn. DropoutTS employs a Sample-Adaptive Dropout mechanism: leveraging spectral sparsity to efficiently quantify instance-level noise via reconstruction residuals, it dynamically calibrates model learning capacity by mapping noise to adaptive dropout rates - selectively suppressing spurious fluctuations while preserving fine-grained fidelity. Extensive experiments across diverse noise regimes and open benchmarks show DropoutTS consistently boosts superior backbones' performance, delivering advanced robustness with negligible parameter overhead and no architectural modifications. Our code is available at https://github.com/CityMind-Lab/DropoutTS.

</details>


### [182] [Epistemic Context Learning: Building Trust the Right Way in LLM-Based Multi-Agent Systems](https://arxiv.org/abs/2601.21742)
*Ruiwen Zhou,Maojia Song,Xiaobao Wu,Sitao Cheng,Xunjian Yin,Yuxi Xie,Zhuoqun Hao,Wenyue Hua,Liangming Pan,Soujanya Poria,Min-Yen Kan*

Main category: cs.AI

TL;DR: 该论文提出了一种名为Epistemic Context Learning (ECL) 的推理框架，通过利用历史交互来评估同伴可靠性并优化推理，使得即使小模型也能超越大模型，取得优异的性能。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统中的个体 agent 常常缺乏鲁棒性，容易盲目服从不可靠的同伴。因此，研究提出的动机是解决这个问题，提高多智能体系统的整体可靠性。

Method: 论文首先通过形式化历史感知参考学习问题，引入历史交互信息作为补充输入，使 agent 能够评估同伴的可靠性并从可信的同伴那学习。随后，设计并开发了 ECL 框架，该框架基于历史交互数据构建同伴的显式文件，以条件概率的方式进行预测。最后，通过强化学习优化 ECL，使用辅助奖励提高其性能。

Result: 实验表明，ECL 使小模型（如 Qwen 3-4B）在准确识别可信同伴的条件下，能比大模型（如 Qwen 3-30B）更胜一筹，即使模型规模小 8 倍也能取得类似甚至更好的性能。此外，ECL 还赋能先进模型达到近乎完美（100%）的性能。

Conclusion: 总之，通过引入历史交互信息来评估同伴可靠性，ECL 能够显著提升多智能体系统的推理性能。此外，该研究还揭示了语言模型在信任度建模方面展现出的优异能力，对实际应用具有重要意义。

Abstract: Individual agents in multi-agent (MA) systems often lack robustness, tending to blindly conform to misleading peers. We show this weakness stems from both sycophancy and inadequate ability to evaluate peer reliability. To address this, we first formalize the learning problem of history-aware reference, introducing the historical interactions of peers as additional input, so that agents can estimate peer reliability and learn from trustworthy peers when uncertain. This shifts the task from evaluating peer reasoning quality to estimating peer reliability based on interaction history. We then develop Epistemic Context Learning (ECL): a reasoning framework that conditions predictions on explicitly-built peer profiles from history. We further optimize ECL by reinforcement learning using auxiliary rewards. Our experiments reveal that our ECL enables small models like Qwen 3-4B to outperform a history-agnostic baseline 8x its size (Qwen 3-30B) by accurately identifying reliable peers. ECL also boosts frontier models to near-perfect (100%) performance. We show that ECL generalizes well to various MA configurations and we find that trust is modeled well by LLMs, revealing a strong correlation in trust modeling accuracy and final answer quality.

</details>


### [183] [Language-based Trial and Error Falls Behind in the Era of Experience](https://arxiv.org/abs/2601.21754)
*Haoyu Wang,Guozheng Ma,Shugang Cui,Yilun Kong,Haotian Luo,Li Shen,Mengya Gao,Yichao Wu,Xiaogang Wang,Dacheng Tao*

Main category: cs.AI

TL;DR: 该研究提出了一种名为SCOUT的框架，旨在解决大型语言模型在非语言环境下的探索成本过高问题，通过小规模模型进行快速探索并优化大型语言模型以应对未见过的任务。


<details>
  <summary>Details</summary>
Motivation: 当前的大型语言模型在非语言环境中的应用受限于探索成本，该研究旨在解决这一问题，以提高模型在这些领域的表现。

Method: SCOUT框架通过使用小型模型（如小型MLP）进行快速探索，然后通过监督微调和多轮强化学习来引导大型语言模型，从而提高其在未知任务中的表现。

Result: 实验结果显示，使用SCOUT框架的Qwen2.5-3B-Instruct模型在任务中的平均得分为0.86，显著优于其他模型，节约了60%的GPU时间。

Conclusion: 该研究提出的方法为了解决大型语言模型在非语言环境中的探索成本问题提供了一种有效途径，展示了其在实际应用中的潜力。

Abstract: While Large Language Models (LLMs) excel in language-based agentic tasks, their applicability to unseen, nonlinguistic environments (e.g., symbolic or spatial tasks) remains limited. Previous work attributes this performance gap to the mismatch between the pretraining distribution and the testing distribution. In this work, we demonstrate the primary bottleneck is the prohibitive cost of exploration: mastering these tasks requires extensive trial-and-error, which is computationally unsustainable for parameter-heavy LLMs operating in a high dimensional semantic space. To address this, we propose SCOUT (Sub-Scale Collaboration On Unseen Tasks), a novel framework that decouples exploration from exploitation. We employ lightweight "scouts" (e.g., small MLPs) to probe environmental dynamics at a speed and scale far exceeding LLMs. The collected trajectories are utilized to bootstrap the LLM via Supervised Fine-Tuning (SFT), followed by multi-turn Reinforcement Learning (RL) to activate its latent world knowledge. Empirically, SCOUT enables a Qwen2.5-3B-Instruct model to achieve an average score of 0.86, significantly outperforming proprietary models, including Gemini-2.5-Pro (0.60), while saving about 60% GPU hours consumption.

</details>


### [184] [Zero-Shot Statistical Downscaling via Diffusion Posterior Sampling](https://arxiv.org/abs/2601.21760)
*Ruian Tie,Wenbo Xiong,Zhengyu Shi,Xinyu Su,Chenyu jiang,Libo Wu,Hao Li*

Main category: cs.AI

TL;DR: 文章提出了零样本统计下scaling (ZSSD)，该方法在没有配对训练数据的情况下，通过学习再分析数据中的物理一致先验并结合统一坐标指导策略，来执行统计下scaling。结果显示，ZSSD在99百分位误差上显著优于现有零样本基线，并成功重建了跨异质GCM的复杂天气事件。


<details>
  <summary>Details</summary>
Motivation: 传统的监督气候下scaling难以泛化到全球气候模型（GCMs）由于缺乏配对训练数据和领域差距，而当前的零样本方法在大比例下存在物理不一致和梯度消失问题。ZSSD旨在解决这些挑战，提供一种无需配对数据的零样本统计下scaling框架。

Method: ZSSD通过从再分析数据学习物理一致的气候先验（conditioned on geophysical boundaries and temporal information），并通过统一坐标指导策略避免梯度消失，确保与大规模场的一致性。

Result: 与现有零样本基线相比，ZSSD在99百分位误差上表现更优，并成功在不同GCM中重建复杂天气事件，如热带气旋。

Conclusion: ZSSD通过引入物理一致的气候先验和统一坐标指导策略，提供了更好的零样本统计下scaling解决方案，能够在不同GCM中有效重建复杂的天气现象。

Abstract: Conventional supervised climate downscaling struggles to generalize to Global Climate Models (GCMs) due to the lack of paired training data and inherent domain gaps relative to reanalysis. Meanwhile, current zero-shot methods suffer from physical inconsistencies and vanishing gradient issues under large scaling factors. We propose Zero-Shot Statistical Downscaling (ZSSD), a zero-shot framework that performs statistical downscaling without paired data during training. ZSSD leverages a Physics-Consistent Climate Prior learned from reanalysis data, conditioned on geophysical boundaries and temporal information to enforce physical validity. Furthermore, to enable robust inference across varying GCMs, we introduce Unified Coordinate Guidance. This strategy addresses the vanishing gradient problem in vanilla DPS and ensures consistency with large-scale fields. Results show that ZSSD significantly outperforms existing zero-shot baselines in 99th percentile errors and successfully reconstructs complex weather events, such as tropical cyclones, across heterogeneous GCMs.

</details>


### [185] [Abstract Concept Modelling in Conceptual Spaces: A Study on Chess Strategies](https://arxiv.org/abs/2601.21771)
*Hadi Banaee,Stephanie Lowry*

Main category: cs.AI

TL;DR: 该研究提出了一种基于概念空间框架来建模随时间展开的抽象概念，并通过象棋概念证明了其实现方法。该方法能够识别策略性的概念演变，并支持不同视角的建模。


<details>
  <summary>Details</summary>
Motivation: 研究的动机在于扩展概念空间理论，使其能够处理随时间实现的目标导向概念，并通过象棋这一具体应用场景来验证该理论的有效性。

Method: 研究采用了概念空间框架，并将其应用于建模象棋中随时间演变的战略概念。具体而言，通过几何区域表示抽象概念，并用轨迹方法表示棋局，从而可以提取出战略意图。

Result: 研究成果证明了基于轨迹的概念识别方法的可行性，且运动模式与专家评论能够相匹配。此外，该方法还展示了对不同玩家在相同情况下的不同解释进行建模的能力。

Conclusion: 这项工作为发展涉及顺序决策过程的应用程序打下了基础，并支持了随着时间不断学习和改进抽象概念的机制。

Abstract: We present a conceptual space framework for modelling abstract concepts that unfold over time, demonstrated through a chess-based proof-of-concept. Strategy concepts, such as attack or sacrifice, are represented as geometric regions across interpretable quality dimensions, with chess games instantiated and analysed as trajectories whose directional movement toward regions enables recognition of intended strategies. This approach also supports dual-perspective modelling, capturing how players interpret identical situations differently. Our implementation demonstrates the feasibility of trajectory-based concept recognition, with movement patterns aligning with expert commentary. This work explores extending the conceptual spaces theory to temporally realised, goal-directed concepts. The approach establishes a foundation for broader applications involving sequential decision-making and supports integration with knowledge evolution mechanisms for learning and refining abstract concepts over time.

</details>


### [186] [A Unified XAI-LLM Approach for EndotrachealSuctioning Activity Recognition](https://arxiv.org/abs/2601.21802)
*Hoang Khang Phan,Quang Vinh Dang,Noriyo Colley,Christina Garcia,Nhat Tan Le*

Main category: cs.AI

TL;DR: 该研究提出了一种以大规模语言模型（LLM）为中心的框架，用于基于视频的动作识别，并在此基础上进行反馈生成。该方法在准确性和F1分数上比基线模型提高了约15-20%，并结合异常检测和可解释AI原理，提供可解释的反馈，有助于提高护士教育和患者安全。


<details>
  <summary>Details</summary>
Motivation: 目前在家庭护理和教学环境中，对于气管吸引术（ES）的培训监督可能有限。这项研究旨在填补自动化识别和反馈系统在ES培训中的空白，提供一种既能提高操作识别准确性和反馈质量，又能增强教育效率和患者安全性的解决方案。

Method: 研究采用了一种以LLM为中心的框架，结合传统的机器学习和深度学习方法，进行了视屏动作识别，并实验性地加入学生支持模块，基于异常检测和可解释AI原理生成可解释的反馈。

Result: 该研究的方法无论在准确度还是F1分数上都优于基线模型，提升了约15-20%。此外，通过引入异常检测和可解释AI技术，生成的反馈更加可解释，有助于提高学员的理解和实际操作能力。

Conclusion: 该研究提供了一种可解释的大规模语言模型驱动的方法，用于气管吸引术的视频识别和反馈生成，不仅提高了操作识别的准确性，还增强了培训的透明度和反馈的实用性，为未来改进护士教育和患者安全性奠定了基础。

Abstract: Endotracheal suctioning (ES) is an invasive yet essential clinical procedure that requires a high degree of skill to minimize patient risk - particularly in home care and educational settings, where consistent supervision may be limited. Despite its critical importance, automated recognition and feedback systems for ES training remain underexplored. To address this gap, this study proposes a unified, LLM-centered framework for video-based activity recognition benchmarked against conventional machine learning and deep learning approaches, and a pilot study on feedback generation. Within this framework, the Large Language Model (LLM) serves as the central reasoning module, performing both spatiotemporal activity recognition and explainable decision analysis from video data. Furthermore, the LLM is capable of verbalizing feedback in natural language, thereby translating complex technical insights into accessible, human-understandable guidance for trainees. Experimental results demonstrate that the proposed LLM-based approach outperforms baseline models, achieving an improvement of approximately 15-20\% in both accuracy and F1 score. Beyond recognition, the framework incorporates a pilot student-support module built upon anomaly detection and explainable AI (XAI) principles, which provides automated, interpretable feedback highlighting correct actions and suggesting targeted improvements. Collectively, these contributions establish a scalable, interpretable, and data-driven foundation for advancing nursing education, enhancing training efficiency, and ultimately improving patient safety.

</details>


### [187] [Looking Beyond Accuracy: A Holistic Benchmark of ECG Foundation Models](https://arxiv.org/abs/2601.21830)
*Francesca Filice,Edoardo De Rose,Simone Bartucci,Francesco Calimeri,Simona Perri*

Main category: cs.AI

TL;DR: 该研究提出了一种基准测评方法，结合基于性能的评估与表示层面分析，利用SHAP和UMAP技术，深入评估了多种基于基础模型的心电图专家模型，特别是在数据稀少的情况下，展示了这些模型的嵌入模式，解构了它们的表示结构和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前的心电图专家基础模型（ECG-expert FMs）在下游性能评估上已有一定成果，但缺乏对模型表示水平上的深入分析。为了更好地评估这类模型的泛化能力，特别是它们在数据稀缺情况下的表现，在医疗这一误差敏感领域需要更加全面的测评框架。

Method: 研究引入了一种基准测评方法，即结合基于性能的评估和表示层面的分析，使用SHAP和UMAP技术。该方法应用于多种基于先进技术预训练的心电图专家模型，涵盖不同跨地域数据集和数据可用性设置。实验包括了数据稀缺场景的评估。

Result: 通过应用所提出的基准测评协议，可以获得对心电图专家基础模型嵌入模式的丰富见解, 进一步揭示它们的表示结构和泛化能力。

Conclusion: 研究为心电图专家基础模型提供了一种全面的测评框架，有助于了解这些模型在心电图诊断中的表现是否稳健可靠，特别是在资源有限的医疗环境中。

Abstract: The electrocardiogram (ECG) is a cost-effective, highly accessible and widely employed diagnostic tool. With the advent of Foundation Models (FMs), the field of AI-assisted ECG interpretation has begun to evolve, as they enable model reuse across different tasks by relying on embeddings. However, to responsibly employ FMs, it is crucial to rigorously assess to which extent the embeddings they produce are generalizable, particularly in error-sensitive domains such as healthcare. Although prior works have already addressed the problem of benchmarking ECG-expert FMs, they focus predominantly on the evaluation of downstream performance. To fill this gap, this study aims to find an in-depth, comprehensive benchmarking framework for FMs, with a specific focus on ECG-expert ones. To this aim, we introduce a benchmark methodology that complements performance-based evaluation with representation-level analysis, leveraging SHAP and UMAP techniques. Furthermore, we rely on the methodology for carrying out an extensive evaluation of several ECG-expert FMs pretrained via state-of-the-art techniques over different cross-continental datasets and data availability settings; this includes ones featuring data scarcity, a fairly common situation in real-world medical scenarios. Experimental results show that our benchmarking protocol provides a rich insight of ECG-expert FMs' embedded patterns, enabling a deeper understanding of their representational structure and generalizability.

</details>


### [188] [Bridging Forecast Accuracy and Inventory KPIs: A Simulation-Based Software Framework](https://arxiv.org/abs/2601.21844)
*So Fukuhara,Abdallah Alabdallah,Nuwan Gunasekara,Slawomir Nowaczyk*

Main category: cs.AI

TL;DR: 本文提出了一种决策导向的仿真软件框架，用于评估预测模型在实际情况中的表现，强调了预测模型对库存决策的影响，而非仅仅关注统计误差。


<details>
  <summary>Details</summary>
Motivation: 目前大多数研究仅注重预测模型的统计准确性，而忽视了其对库存管理操作绩效指标的影响。本文旨在填补这一空白。

Method: 本文提出了一种包含合成需求生成器、灵活的预测模块和库存控制模拟器的综合框架。

Result: 研究表明，统计上的准确模型并不能确保更好的操作绩效，不同准确度的预测模型可能导致显著不同的成本-服务权衡。

Conclusion: 本文框架强调了需求预测与库存管理之间的联系，促使评估模型从纯粹的预测准确性转向操作相关性。

Abstract: Efficient management of spare parts inventory is crucial in the automotive aftermarket, where demand is highly intermittent and uncertainty drives substantial cost and service risks. Forecasting is therefore central, but the quality of a forecasting model should be judged not by statistical accuracy (e.g., MAE, RMSE, IAE) but rather by its impact on key operational performance indicators (KPIs), such as total cost and service level. Yet most existing work evaluates models exclusively using accuracy metrics, and the relationship between these metrics and operational KPIs remains poorly understood. To address this gap, we propose a decision-centric simulation software framework that enables systematic evaluation of forecasting model in realistic inventory management setting. The framework comprises: (i) a synthetic demand generator tailored to spare-parts demand characteristics, (ii) a flexible forecasting module that can host arbitrary predictive models, and (iii) an inventory control simulator that consumes the forecasts and computes operational KPIs. This closed-loop setup enables researchers to evaluate models not only in terms of statistical error but also in terms of their downstream implications for inventory decisions. Using a wide range of simulation scenarios, we show that improvements in conventional accuracy metrics do not necessarily translate into better operational performance, and that models with similar statistical error profiles can induce markedly different cost-service trade-offs. We analyze these discrepancies to characterize how specific aspects of forecast performance affect inventory outcomes and derive guidance for model selection. Overall, the framework operationalizes the link between demand forecasting and inventory management, shifting evaluation from purely predictive accuracy toward operational relevance in the automotive aftermarket and related domains.

</details>


### [189] [KnowBias: Mitigating Social Bias in LLMs via Know-Bias Neuron Enhancement](https://arxiv.org/abs/2601.21864)
*Jinhao Pan,Chahat Raj,Anjishnu Mukherjee,Sina Mansouri,Bowen Wei,Shloka Yada,Ziwei Zhu*

Main category: cs.AI

TL;DR: KnowBias 提出了一种新型的去偏方法，通过加强编码了偏见知识的神经元来减轻偏见，而不仅仅是抑制它们。这种方法使用少量的归因分析问题来识别编码偏见知识的神经元，然后在推理时对其进行选择性增强。该方法在多种基准测试和大型语言模型上展示了稳健的去偏效果，同时保持了强大的泛化能力和最小的实用性损失，且数据效率高。


<details>
  <summary>Details</summary>
Motivation: 现有去偏方法通常通过抑制与偏见行为相关的参数、提示或神经元来缓解大型语言模型中的社会偏见，但这些方法往往不够稳健、泛化能力弱、数据效率低且可能损害泛化能力。KnowBias 提出了一种新的观点，通过增强而不是抑制编码偏见知识的神经元来减轻偏见，以提供更强的去偏效果，同时保持泛化能力和数据效率。

Method: 知Bias 通过使用小集合的偏见知识问题进行归因分析来识别编码偏见知识的神经元，然后在推理时选择性地增强它们，不涉及重新训练。这种方法的数据效率很高，只需要少量简单的 yes/no 问题。

Result: 实验结果显示，知Bias 在多个基准测试和大型语言模型上实现了最佳的去偏效果，同时保持了强大的泛化能力和最小的实用性损失。

Conclusion: 知Bias 提供了一种方法，能够通过加强而不是抑制神经元来优化大型语言模型的社会偏见，这种技术在多种基准测试中取得了成功。

Abstract: Large language models (LLMs) exhibit social biases that reinforce harmful stereotypes, limiting their safe deployment. Most existing debiasing methods adopt a suppressive paradigm by modifying parameters, prompts, or neurons associated with biased behavior; however, such approaches are often brittle, weakly generalizable, data-inefficient, and prone to degrading general capability. We propose \textbf{KnowBias}, a lightweight and conceptually distinct framework that mitigates bias by strengthening, rather than suppressing, neurons encoding bias-knowledge. KnowBias identifies neurons encoding bias knowledge using a small set of bias-knowledge questions via attribution-based analysis, and selectively enhances them at inference time. This design enables strong debiasing while preserving general capabilities, generalizes across bias types and demographics, and is highly data efficient, requiring only a handful of simple yes/no questions and no retraining. Experiments across multiple benchmarks and LLMs demonstrate consistent state-of-the-art debiasing performance with minimal utility degradation. Data and code are available at https://github.com/JP-25/KnowBias.

</details>


### [190] [WebArbiter: A Principle-Guided Reasoning Process Reward Model for Web Agents](https://arxiv.org/abs/2601.21872)
*Yao Zhang,Shijie Tang,Zeyu Li,Zhen Han,Volker Tresp*

Main category: cs.AI

TL;DR: WebArbiter 是一种基于文本生成的原理诱导型过程奖励模型，通过两阶段训练实现有序推理与强化学习的融合，显著改善了现有过程奖励模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有过程奖励模型（WebPRMs）在处理长时序决策任务时存在奖励反馈稀疏延迟、信号粗略且缺乏可解释性等问题，因此需要一种新的方法来改进。

Method: WebArbiter 通过文本生成进行奖励建模，生成结构化的推理过程以支持目标完成，使用两阶段训练方法：第一阶段通过推理抽取使模型具备原理引导的推理能力，第二阶段通过纠正教师偏见和直接校准判决与正确性的关联来增强泛化能力。

Result: 在 WebPRMBench 上，WebArbiter-7B 比最强基线 GPT-5 高出 9.1 分，证明了其在不同 web 环境中的优越表现。并且在 WebArena-Lite 上，WebArbiter 的奖励指导轨迹搜索性能优于之前的最先进方法，表明了其实用价值。

Conclusion: WebArbiter 作为一种新型奖励模型，在处理 web 交互中的长时序决策任务方面表现出色，为未来研究提供了新的思路和基准。

Abstract: Web agents hold great potential for automating complex computer tasks, yet their interactions involve long-horizon, sequential decision-making with irreversible actions. In such settings, outcome-based supervision is sparse and delayed, often rewarding incorrect trajectories and failing to support inference-time scaling. This motivates the use of Process Reward Models (WebPRMs) for web navigation, but existing approaches remain limited: scalar WebPRMs collapse progress into coarse, weakly grounded signals, while checklist-based WebPRMs rely on brittle template matching that fails under layout or semantic changes and often mislabels superficially correct actions as successful, providing little insight or interpretability. To address these challenges, we introduce WebArbiter, a reasoning-first, principle-inducing WebPRM that formulates reward modeling as text generation, producing structured justifications that conclude with a preference verdict and identify the action most conducive to task completion under the current context. Training follows a two-stage pipeline: reasoning distillation equips the model with coherent principle-guided reasoning, and reinforcement learning corrects teacher biases by directly aligning verdicts with correctness, enabling stronger generalization. To support systematic evaluation, we release WebPRMBench, a comprehensive benchmark spanning four diverse web environments with rich tasks and high-quality preference annotations. On WebPRMBench, WebArbiter-7B outperforms the strongest baseline, GPT-5, by 9.1 points. In reward-guided trajectory search on WebArena-Lite, it surpasses the best prior WebPRM by up to 7.2 points, underscoring its robustness and practical value in real-world complex web tasks.

</details>


### [191] [From Meta-Thought to Execution: Cognitively Aligned Post-Training for Generalizable and Reliable LLM Reasoning](https://arxiv.org/abs/2601.21909)
*Shaojie Wang,Liang Zhang*

Main category: cs.AI

TL;DR: 本文提出了一种新的框架CoMT-CCRL，该框架通过两个阶段优化LLM，旨在更接近人类的认知过程，从而提高泛化能力和训练效率。


<details>
  <summary>Details</summary>
Motivation: 当前的LLM后训练方法通过监督微调（SFT）后跟基于结果的强化学习（RL）来优化完整的推理路径，尽管有效，但未能反映人类解决实际问题的认知过程，这可能导致泛化泛化不良和低效。

Method: CoMT-CCRL框架首先专注于抽象推理模式而不涉及具体的执行流程，通过这种方式学习通用策略，然后使用带有自信心度调整奖励的强化学习优化任务适应。

Result: 实验结果显示，相比标准方法，在四个模型和八个基准上分别提高了2.19%和4.63%的分布内和分布外表现，同时将训练时间减少了65-70%，并降低了50%的令牌消耗。

Conclusion: 研究证明，将后训练过程与人类认知原理对齐可以提供更强的泛化能力并提高训练效率。

Abstract: Current LLM post-training methods optimize complete reasoning trajectories through Supervised Fine-Tuning (SFT) followed by outcome-based Reinforcement Learning (RL). While effective, a closer examination reveals a fundamental gap: this approach does not align with how humans actually solve problems. Human cognition naturally decomposes problem-solving into two distinct stages: first acquiring abstract strategies (i.e., meta-knowledge) that generalize across problems, then adapting them to specific instances. In contrast, by treating complete trajectories as basic units, current methods are inherently problem-centric, entangling abstract strategies with problem-specific execution. To address this misalignment, we propose a cognitively-inspired framework that explicitly mirrors the two-stage human cognitive process. Specifically, Chain-of-Meta-Thought (CoMT) focuses supervised learning on abstract reasoning patterns without specific executions, enabling acquisition of generalizable strategies. Confidence-Calibrated Reinforcement Learning (CCRL) then optimizes task adaptation via confidence-aware rewards on intermediate steps, preventing overconfident errors from cascading and improving execution reliability. Experiments across four models and eight benchmarks show 2.19\% and 4.63\% improvements in-distribution and out-of-distribution respectively over standard methods, while reducing training time by 65-70% and token consumption by 50%, demonstrating that aligning post-training with human cognitive principles yields not only superior generalization but also enhanced training efficiency.

</details>


### [192] [ProRAG: Process-Supervised Reinforcement Learning for Retrieval-Augmented Generation](https://arxiv.org/abs/2601.21912)
*Zhao Wang,Ziliang Zhao,Zhicheng Dou*

Main category: cs.AI

TL;DR: ProRAG 提出了一种过程监督的强化学习框架，旨在通过集成细粒度的过程监督来优化长时间推理任务中的 Retrieval-Augmented Generation。该框架通过监督策略预热、过程奖励模型构建、过程指导的推理精炼和过程监督下的强化学习四个阶段，提供对每个行动的精确反馈，特别在复杂的长长的推理任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统的基于结果的强化学习方法在复杂的推理任务中往往受到奖励稀疏性和信用分配效率低下的困扰，这导致了‘过程幻觉’现象，即模型通过错误的逻辑或冗余检索步骤得出正确的答案。为了缓解这些挑战，该研究提出了 ProRAG，旨在提供更为细粒度的过程监督，从而提高模型的推理准确性。

Method: ProRAG 采用了四个主要阶段的方法：监督策略预热、过程奖励模型构建、过程指导的推理精炼以及过程监督下的强化学习。在预热阶段，使用监督策略来初始化模型。过程奖励模型（PRM）通过蒙特卡洛树搜索 (MCTS) 构建，用于量化中间推理的质量。然后，通过 PRM 引导的推理精炼来调整策略以符合细粒度的过程偏好。最后，过程监督下的强化学习使用了双重粒度的优势机制，将步骤级的过程奖励与全局结果信号结合起来，为每个行动提供详细反馈。

Result: ProRAG 在五个多跳推理基准测试中展现出了优越的整体性能，相较于强大的基于结果的和过程意识的强化学习基线模型，特别是在复杂的长时间推理任务上更为出色。

Conclusion: 研究表明，ProRAG 通过过程监督显著提高了模型的推理质量和效率，适用于解决复杂的长时间推理问题。

Abstract: Reinforcement learning (RL) has become a promising paradigm for optimizing Retrieval-Augmented Generation (RAG) in complex reasoning tasks. However, traditional outcome-based RL approaches often suffer from reward sparsity and inefficient credit assignment, as coarse-grained scalar rewards fail to identify specific erroneous steps within long-horizon trajectories. This ambiguity frequently leads to "process hallucinations", where models reach correct answers through flawed logic or redundant retrieval steps. Although recent process-aware approaches attempt to mitigate this via static preference learning or heuristic reward shaping, they often lack the on-policy exploration capabilities required to decouple step-level credit from global outcomes. To address these challenges, we propose ProRAG, a process-supervised reinforcement learning framework designed to integrate learned step-level supervision into the online optimization loop. Our framework consists of four stages: (1) Supervised Policy Warmup to initialize the model with a structured reasoning format; (2) construction of an MCTS-based Process Reward Model (PRM) to quantify intermediate reasoning quality; (3) PRM-Guided Reasoning Refinement to align the policy with fine-grained process preferences; and (4) Process-Supervised Reinforcement Learning with a dual-granularity advantage mechanism. By aggregating step-level process rewards with global outcome signals, ProRAG provides precise feedback for every action. Extensive experiments on five multi-hop reasoning benchmarks demonstrate that ProRAG achieves superior overall performance compared to strong outcome-based and process-aware RL baselines, particularly on complex long-horizon tasks, validating the effectiveness of fine-grained process supervision. The code and model are available at https://github.com/lilinwz/ProRAG.

</details>


### [193] [Exploring Reasoning Reward Model for Agents](https://arxiv.org/abs/2601.22154)
*Kaixuan Fan,Kaituo Feng,Manyuan Zhang,Tianshuo Peng,Zhixun Li,Yilei Jiang,Shuang Chen,Peng Pei,Xunliang Cai,Xiangyu Yue*

Main category: cs.AI

TL;DR: 本文提出了一种名为Agent Reasoning Reward Model (Agent-RRM)的多维度奖励模型，它为智能体轨迹提供了结构化的反馈，包括显式的推理历程、针对性的批判以及整体评分。研究了三种整合策略，并在12个基准测试上验证了Reagent-U（统一反馈）策略显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法依赖于稀疏的结果奖励，这无法区分中间推理的质量，导致训练效果不佳。为解决这一问题，作者提出了一种新的奖励模型来提供更细致和全面的反馈。

Method: 该方法通过构建一种多方面奖励模型（Agent-RRM）来增强智能体的推理质量。它为智能体的轨迹提供多个反馈维度：推理历程、精确的批判以及整体评分。该模型还探讨了三种整合策略：文本增强深化、奖励增强指导和统一反馈整合。

Result: 实验结果在12个基准测试上验证了统一反馈（Reagent-U）策略的有效性，显著提升了模型性能，在GAIA数据集和WebWalkerQA数据集上分别取得了43.7%和46.2%的成绩。

Conclusion: 研究团队认为，通过提供更加细化的反馈，有助于提高智能体的推理质量和整体性能。此外，该研究提出了新的途径，可以为未来的研究提供参考。

Abstract: Agentic Reinforcement Learning (Agentic RL) has achieved notable success in enabling agents to perform complex reasoning and tool use. However, most methods still relies on sparse outcome-based reward for training. Such feedback fails to differentiate intermediate reasoning quality, leading to suboptimal training results. In this paper, we introduce Agent Reasoning Reward Model (Agent-RRM), a multi-faceted reward model that produces structured feedback for agentic trajectories, including (1) an explicit reasoning trace , (2) a focused critique that provides refinement guidance by highlighting reasoning flaws, and (3) an overall score that evaluates process performance. Leveraging these signals, we systematically investigate three integration strategies: Reagent-C (text-augmented refinement), Reagent-R (reward-augmented guidance), and Reagent-U (unified feedback integration). Extensive evaluations across 12 diverse benchmarks demonstrate that Reagent-U yields substantial performance leaps, achieving 43.7% on GAIA and 46.2% on WebWalkerQA, validating the effectiveness of our reasoning reward model and training schemes. Code, models, and datasets are all released to facilitate future research.

</details>


### [194] [The Energy Impact of Domain Model Design in Classical Planning](https://arxiv.org/abs/2601.21967)
*Ilche Georgievski,Serhat Tekin,Marco Aiello*

Main category: cs.AI

TL;DR: 本文通过引入一种领域模型配置框架，对经典规划器的能效和运行时性能进行了实证研究，发现了能效与运行时性能之间并不总是相关。


<details>
  <summary>Details</summary>
Motivation: 传统的AI研究主要关注算法性能，而新兴的‘绿色AI’则强调将能源消耗作为重要的性能维度。现有自动化规划领域的高计算需求导致其能效被忽略。

Method: 研究人员通过设计领域模型配置框架来控制特征变化，使用五个基准领域和五个最先进的规划器进行实验，分析了32种领域变体在能量使用和运行时性能方面的不同。

Result: 实验结果表明，领域级别的修改能够使不同规划器在能效上产生可测量的差异，且能效和运行时性能之间的关联性不总是存在。

Conclusion: 研究结论指出，领域模型的设计对于规划器的能效具有重要影响，强调未来在研究和开发中应关注能效优化。

Abstract: AI research has traditionally prioritised algorithmic performance, such as optimising accuracy in machine learning or runtime in automated planning. The emerging paradigm of Green AI challenges this by recognising energy consumption as a critical performance dimension. Despite the high computational demands of automated planning, its energy efficiency has received little attention. This gap is particularly salient given the modular planning structure, in which domain models are specified independently of algorithms. On the other hand, this separation also enables systematic analysis of energy usage through domain model design. We empirically investigate how domain model characteristics affect the energy consumption of classical planners. We introduce a domain model configuration framework that enables controlled variation of features, such as element ordering, action arity, and dead-end states. Using five benchmark domains and five state-of-the-art planners, we analyse energy and runtime impacts across 32 domain variants per benchmark. Results demonstrate that domain-level modifications produce measurable energy differences across planners, with energy consumption not always correlating with runtime.

</details>


### [195] [Learning Decentralized LLM Collaboration with Multi-Agent Actor Critic](https://arxiv.org/abs/2601.21972)
*Shuo Liu,Tianle Chen,Ryan Amiri,Christopher Amato*

Main category: cs.AI

TL;DR: 本研究提出了一种用于优化分布式大模型协作的Multi-Agent Actor-Critic (MAAC) 方法，包括中心化批评家（CoLLM-CC）和分布式批评家（CoLLM-DC）两种变体。实验证实在短期内，Monte Carlo 方法和 CoLLM-DC 的表现与 CoLLM-CC 相当，但在长期或稀疏奖励任务中表现较差。


<details>
  <summary>Details</summary>
Motivation: 当前多数多智能体强化学习（MARL）的方法依赖于预定义的执行协议，且通常需要中心化的执行。为了解决这些限制，提出了两种新的MAAC变体：CoLLM-CC和CoLLM-DC，以评估其在不同任务和奖励设置下的有效性。

Method: 研究者采用Actor-critic方法来优化分布式大模型的协作。具体来说，他们开发了两个变体：一个采用中心化批评家（CoLLM-CC）和另一个采用分布式批评家（CoLLM-DC）。实验基于写作、编程和游戏三大领域进行。

Result: 研究结果表明，在短期或密集奖励的任务中，CoLLM-CC和CoLLM-DC与经典的Monte Carlo方法表现相近。然而，在长期任务或稀疏奖励的情况下，它们的表现都逊色于中心化批评家的方法。Monte Carlo方法需要更多的样本，而CoLLM-DC则难以收敛。

Conclusion: 研究强调了根据任务的具体需求选择适当的MAAC策略的重要性。对于长期或稀疏奖励的任务，传统方法可能仍是更好的选择，但对于短期和密集奖励的任务，新的MAAC方法有望提升性能。

Abstract: Recent work has explored optimizing LLM collaboration through Multi-Agent Reinforcement Learning (MARL). However, most MARL fine-tuning approaches rely on predefined execution protocols, which often require centralized execution. Decentralized LLM collaboration is more appealing in practice, as agents can run inference in parallel with flexible deployments. Also, current approaches use Monte Carlo methods for fine-tuning, which suffer from high variance and thus require more samples to train effectively. Actor-critic methods are prevalent in MARL for dealing with these issues, so we developed Multi-Agent Actor-Critic (MAAC) methods to optimize decentralized LLM collaboration. In this paper, we analyze when and why these MAAC methods are beneficial. We propose 2 MAAC approaches, \textbf{CoLLM-CC} with a \textbf{C}entralized \textbf{C}ritic and \textbf{CoLLM-DC} with \textbf{D}ecentralized \textbf{C}ritics. Our experiments across writing, coding, and game-playing domains show that Monte Carlo methods and CoLLM-DC can achieve performance comparable to CoLLM-CC in short-horizon and dense-reward settings. However, they both underperform CoLLM-CC on long-horizon or sparse-reward tasks, where Monte Carlo methods require substantially more samples and CoLLM-DC struggles to converge. Our code is available at https://github.com/OpenMLRL/CoMLRL/releases/tag/v1.3.2.

</details>


### [196] [Mind the Gap: How Elicitation Protocols Shape the Stated-Revealed Preference Gap in Language Models](https://arxiv.org/abs/2601.21975)
*Pranav Mahajan,Ihor Kendiukhov,Syed Hussain,Lydia Nottingham*

Main category: cs.AI

TL;DR: 研究系统地探讨了不同提示协议对语言模型（LMs）中声明-揭示偏好差距（SvR）的影响，发现通过排除弱信号并允许在声明和揭示偏好中不投票，可以显著提高Spearman等级相关性，但不保证系统引导会提高AIRiskDilemmas上的SvR相关性。


<details>
  <summary>Details</summary>
Motivation: 现有对语言模型偏好的衡量方法依赖于二元强制选择提示，这种提示结合了真实偏好和提示协议的艺术现象，研究旨在改善偏好评估方法。

Method: 研究通过在声明偏好和揭示偏好中引入中立性和弃权选项，系统地考察了不同的提示协议对语言模型中声明-揭示偏好差距的影响。

Result: 研究结果显示，通过排除弱信号并允许在声明和揭示偏好中不投票，可以显著提高Spearman等级相关性，而当加入揭示偏好弃权后，相关性往往会接近零或变为负值。此外，使用声明偏好引导系统并未在AIRiskDilemmas上提高SvR相关性。

Conclusion: 研究得出结论，SvR相关性高度依赖于协议，偏好收集方法需要能够考虑到犹豫不决的偏好。

Abstract: Recent work identifies a stated-revealed (SvR) preference gap in language models (LMs): a mismatch between the values models endorse and the choices they make in context. Existing evaluations rely heavily on binary forced-choice prompting, which entangles genuine preferences with artifacts of the elicitation protocol. We systematically study how elicitation protocols affect SvR correlation across 24 LMs. Allowing neutrality and abstention during stated preference elicitation allows us to exclude weak signals, substantially improving Spearman's rank correlation ($ρ$) between volunteered stated preferences and forced-choice revealed preferences. However, further allowing abstention in revealed preferences drives $ρ$ to near-zero or negative values due to high neutrality rates. Finally, we find that system prompt steering using stated preferences during revealed preference elicitation does not reliably improve SvR correlation on AIRiskDilemmas. Together, our results show that SvR correlation is highly protocol-dependent and that preference elicitation requires methods that account for indeterminate preferences.

</details>


### [197] [VERSA: Verified Event Data Format for Reliable Soccer Analytics](https://arxiv.org/abs/2601.21981)
*Geonhee Jo,Mingu Kang,Kangmin Lee,Minho Lee,Pascal Bauer,Sang-Ki Ko*

Main category: cs.AI

TL;DR: VERSATION（一种可靠的足球赛事数据分析验证框架）通过状态转换模型确保事件流数据的完整性，有效检测并纠正了赛事数据中的逻辑不一致性，大幅提升了不同数据提供商之间的一致性，并显著增强了下游任务VAEP的性能和稳定性。


<details>
  <summary>Details</summary>
Motivation: 目前，体育赛事中的事件流数据在分析运动员贡献和战术模式时被广泛应用，但数据质量问题限制了模型的可靠性。为解决这一问题，提出了一种全新的数据验证框架——VERSATURATION。

Method: VERSATURATION基于状态转换模型定义有效的事件序列，自动检测和纠正事件流中的异常模式。具体来说，它通过验证序列合法性来确保数据准确性和一致性，从而提高数据分析的可靠性。

Result: 在K联赛1的2024赛季中，通过实验证明，VERSATURATION显著提高了不同数据提供商之间的数据一致性和统一性表示，并提高了下游VAEP任务的性能和稳定性。具体数据方面，它检测出18.81%的事件存在逻辑不一致问题，而验证后该问题被有效解决。

Conclusion: VERSATURATION验证框架能够显著提升体育数据分析的可靠性，特别是在处理事件流数据的逻辑不一致问题方面表现突出，为足球赛事数据分析提供了更加准确和稳定的数据基础。

Abstract: Event stream data is a critical resource for fine-grained analysis across various domains, including financial transactions, system operations, and sports. In sports, it is actively used for fine-grained analyses such as quantifying player contributions and identifying tactical patterns. However, the reliability of these models is fundamentally limited by inherent data quality issues that cause logical inconsistencies (e.g., incorrect event ordering or missing events). To this end, this study proposes VERSA (Verified Event Data Format for Reliable Soccer Analytics), a systematic verification framework that ensures the integrity of event stream data within the soccer domain. VERSA is based on a state-transition model that defines valid event sequences, thereby enabling the automatic detection and correction of anomalous patterns within the event stream data. Notably, our examination of event data from the K League 1 (2024 season), provided by Bepro, detected that 18.81% of all recorded events exhibited logical inconsistencies. Addressing such integrity issues, our experiments demonstrate that VERSA significantly enhances cross-provider consistency, ensuring stable and unified data representation across heterogeneous sources. Furthermore, we demonstrate that data refined by VERSA significantly improves the robustness and performance of a downstream task called VAEP, which evaluates player contributions. These results highlight that the verification process is highly effective in increasing the reliability of data-driven analysis.

</details>


### [198] [Defining Operational Conditions for Safety-Critical AI-Based Systems from Data](https://arxiv.org/abs/2601.22118)
*Johann Christensen,Elena Hoemann,Frank Köster,Sven Hallerbach*

Main category: cs.AI

TL;DR: 此论文提出了一种新的后验方法，利用多维核表示从之前收集的数据中定义操作设计域（ODD）。该方法通过蒙特卡洛方法和实际航空案例得到了验证，旨在为数据驱动的安全关键AI系统提供新的认证途径。


<details>
  <summary>Details</summary>
Motivation: 当前，许多安全关键应用中复杂系统的潜在环境难以完全描述，这阻碍了AI系统的认证过程。此论文旨在提供一种数据驱动的ODD定义方法，通过这种方法，可以在已有数据指导下，后验定义ODD，进而辅助AI系统的安全认证。

Method: 该方法利用多维核表示技术从已有数据中后验定义ODD，并通过蒙特卡洛方法验证其有效性。此外，论文定义了两个ODD相等的条件。

Result: 该方法已经通过蒙特卡洛方法和一个实际的航空案例得到了验证，并且展示了数据驱动的ODD可以等于原始隐藏的ODD。

Conclusion: 该论文提出了一种新的Safety-by-Design方法，可以利用数据来定义ODD，这为数据驱动的安全关键AI系统的认证提供了新的途径。

Abstract: Artificial Intelligence (AI) has been on the rise in many domains, including numerous safety-critical applications. However, for complex systems found in the real world, or when data already exist, defining the underlying environmental conditions is extremely challenging. This often results in an incomplete description of the environment in which the AI-based system must operate. Nevertheless, this description, called the Operational Design Domain (ODD), is required in many domains for the certification of AI-based systems. Traditionally, the ODD is created in the early stages of the development process, drawing on sophisticated expert knowledge and related standards. This paper presents a novel Safety-by-Design method to a posteriori define the ODD from previously collected data using a multi-dimensional kernel-based representation. This approach is validated through both Monte Carlo methods and a real-world aviation use case for a future safety-critical collision-avoidance system. Moreover, by defining under what conditions two ODDs are equal, the paper shows that the data-driven ODD can equal the original, underlying hidden ODD of the data. Utilizing the novel, Safe-by-Design kernel-based ODD enables future certification of data-driven, safety-critical AI-based systems.

</details>
