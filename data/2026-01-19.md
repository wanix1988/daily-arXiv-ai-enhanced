<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 39]
- [cs.CL](#cs.CL) [Total: 40]
- [cs.AR](#cs.AR) [Total: 2]
- [cs.PF](#cs.PF) [Total: 1]
- [cs.AI](#cs.AI) [Total: 16]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [ICONIC-444: A 3.1-Million-Image Dataset for OOD Detection Research](https://arxiv.org/abs/2601.10802)
*Gerhard Krumpl,Henning Avenhaus,Horst Possegger*

Main category: cs.CV

TL;DR: ICONIC-444是专门为OOD检测研究设计的大型工业图像数据集，包含超过310万张RGB图像，涵盖444个特定类别。该数据集旨在填补目前缺乏广泛且高质量的OOD数据的空白。


<details>
  <summary>Details</summary>
Motivation: 当前的OUT-OF-DISTRIBUTION（OOD）检测进展受限于缺乏能够支持精细和粗粒度计算机视觉任务的高质量且类别明确的OUT-OF-DISTRIBUTION数据集。因此，为了弥补这一缺陷，研究引入了ICONIC-444数据集。

Method: 该方法建立了一个包含大量RGB图像的大型工业图像数据集，确保数据覆盖了从简单到复杂的各类任务。此外，数据集还提供了结构化、多样化的图像用于评估广泛的OOD检测方法，并定义了四个基准任务来评估和促进OOD检测研究。

Result: ICONIC-444数据集补充了现有的数据集，提供了多种结构化且多样化的数据，适用于评估不同复杂度任务的OOD检测方法。此外，还提供了22种最先进的后处理OOD检测方法的基准结果。

Conclusion: ICONIC-444为OOD检测研究提供了重要资源，通过提升数据质量与类别涵盖范围，促进了该领域的进一步研究和发展。

Abstract: Current progress in out-of-distribution (OOD) detection is limited by the lack of large, high-quality datasets with clearly defined OOD categories across varying difficulty levels (near- to far-OOD) that support both fine- and coarse-grained computer vision tasks. To address this limitation, we introduce ICONIC-444 (Image Classification and OOD Detection with Numerous Intricate Complexities), a specialized large-scale industrial image dataset containing over 3.1 million RGB images spanning 444 classes tailored for OOD detection research. Captured with a prototype industrial sorting machine, ICONIC-444 closely mimics real-world tasks. It complements existing datasets by offering structured, diverse data suited for rigorous OOD evaluation across a spectrum of task complexities. We define four reference tasks within ICONIC-444 to benchmark and advance OOD detection research and provide baseline results for 22 state-of-the-art post-hoc OOD detection methods.

</details>


### [2] [Can Vision-Language Models Understand Construction Workers? An Exploratory Study](https://arxiv.org/abs/2601.10835)
*Hieu Bui,Nathaniel E. Chodosh,Arash Tavakoli*

Main category: cs.CV

TL;DR: 研究中，三种领先的视觉-语言模型（VLMs）被评估用于从静态工地照片识别建筑工人的行为与情绪。GPT-4o表现出最优异的成绩，F1分数分别为0.756和0.712，准确率为0.799和0.773，而Florence 2和LLaVa-1.5的表现较差。


<details>
  <summary>Details</summary>
Motivation: 随着机器人在建筑工作流程中的整合，它们需要能够理解并响应人类行为以确保安全有效的协作，特别是在缺少标注数据的建筑领域。

Method: 使用了1000张标注了动作和情绪的图片，通过标准化的推理管道和多元评估指标对三种领先的VLMs进行测试。

Result: GPT-4o在两项任务中表现最佳，得分为0.756和0.712（F1分数），准确率为0.799和0.773。而Florence 2和LLaVa-1.5的得分分别为0.497、0.414和0.466、0.461。

Conclusion: 研究结果表明，通用视觉-语言模型在建筑环境中的人类行为识别方面具有一定的基础能力，但为了实际应用的可靠性，可能需要进一步的领域适应、时间建模或多元感知改进。

Abstract: As robotics become increasingly integrated into construction workflows, their ability to interpret and respond to human behavior will be essential for enabling safe and effective collaboration. Vision-Language Models (VLMs) have emerged as a promising tool for visual understanding tasks and offer the potential to recognize human behaviors without extensive domain-specific training. This capability makes them particularly appealing in the construction domain, where labeled data is scarce and monitoring worker actions and emotional states is critical for safety and productivity. In this study, we evaluate the performance of three leading VLMs, GPT-4o, Florence 2, and LLaVa-1.5, in detecting construction worker actions and emotions from static site images. Using a curated dataset of 1,000 images annotated across ten action and ten emotion categories, we assess each model's outputs through standardized inference pipelines and multiple evaluation metrics. GPT-4o consistently achieved the highest scores across both tasks, with an average F1-score of 0.756 and accuracy of 0.799 in action recognition, and an F1-score of 0.712 and accuracy of 0.773 in emotion recognition. Florence 2 performed moderately, with F1-scores of 0.497 for action and 0.414 for emotion, while LLaVa-1.5 showed the lowest overall performance, with F1-scores of 0.466 for action and 0.461 for emotion. Confusion matrix analyses revealed that all models struggled to distinguish semantically close categories, such as collaborating in teams versus communicating with supervisors. While the results indicate that general-purpose VLMs can offer a baseline capability for human behavior recognition in construction environments, further improvements, such as domain adaptation, temporal modeling, or multimodal sensing, may be needed for real-world reliability.

</details>


### [3] [One Model, Many Behaviors: Training-Induced Effects on Out-of-Distribution Detection](https://arxiv.org/abs/2601.10836)
*Gerhard Krumpl,Henning Avenhaus,Horst Possegger*

Main category: cs.CV

TL;DR: 本研究通过实证研究探讨了In分布准确性与Out-of-distribution检测性能之间的复杂关系，发现两者并非单调相关，且检测器的选择与训练策略密切相关，没有一种方法适用于所有场景。


<details>
  <summary>Details</summary>
Motivation: 鉴于现有出域检测方法在现代训练管道中的应用尚缺乏系统研究，本研究旨在深入了解In分布准确性与出域检测性能之间的关系。

Method: 研究通过使用固定架构的ResNet-50，评估21种前沿的出域检测方法，涵盖来自56个不同训练策略的ImageNet模型，以八个出域测试集进行性能评估。

Result: 研究发现了In分布准确性与出域检测性能之间的非单调关系，并揭示了训练策略与检测器选择对出域性能的重要影响。

Conclusion: 研究结果表明，没有单一的出域检测方法适用于所有场景，应根据具体应用选择合适的方法和训练策略。

Abstract: Out-of-distribution (OOD) detection is crucial for deploying robust and reliable machine-learning systems in open-world settings. Despite steady advances in OOD detectors, their interplay with modern training pipelines that maximize in-distribution (ID) accuracy and generalization remains under-explored. We investigate this link through a comprehensive empirical study. Fixing the architecture to the widely adopted ResNet-50, we benchmark 21 post-hoc, state-of-the-art OOD detection methods across 56 ImageNet-trained models obtained via diverse training strategies and evaluate them on eight OOD test sets. Contrary to the common assumption that higher ID accuracy implies better OOD detection performance, we uncover a non-monotonic relationship: OOD performance initially improves with accuracy but declines once advanced training recipes push accuracy beyond the baseline. Moreover, we observe a strong interdependence between training strategy, detector choice, and resulting OOD performance, indicating that no single method is universally optimal.

</details>


### [4] [Effects of Different Attention Mechanisms Applied on 3D Models in Video Classification](https://arxiv.org/abs/2601.10854)
*Mohammad Rasras,Iuliana Marin,Serban Radu,Irina Mocanu*

Main category: cs.CV

TL;DR: 本文研究了通过减少时间数据捕获的知识并增加帧分辨率对3D Resnet模型识别准确性的影响。


<details>
  <summary>Details</summary>
Motivation: 在计算机视觉中，人类行为识别是一个重要的研究领域。为了分析不同注意力模块对模型性能的影响，作者在经典模型的基础上进行了改进。

Method: 作者首先在传统的3D Resnet模型中加入了dropout层，并在此基础上创建了10种新的变体模型。这些变体模型采用了不同的注意力机制，如CBAM、TCN以及多头和通道注意力机制，以观察每个模块对受限时间模型性能的影响。

Result: 实验结果表明，与修改后的R(2+1)D模型添加了多头注意力模块的模型在UCF101数据集上的准确率达到88.98%。

Conclusion: 本文的研究表明，缺失时间特征对新创建的高分辨率模型性能至关重要。尽管所有改进措施对整体性能相似，但这些改进在不同类别的准确率上表现出不同的行为。

Abstract: Human action recognition has become an important research focus in computer vision due to the wide range of applications where it is used. 3D Resnet-based CNN models, particularly MC3, R3D, and R(2+1)D, have different convolutional filters to extract spatiotemporal features. This paper investigates the impact of reducing the captured knowledge from temporal data, while increasing the resolution of the frames. To establish this experiment, we created similar designs to the three originals, but with a dropout layer added before the final classifier. Secondly, we then developed ten new versions for each one of these three designs. The variants include special attention blocks within their architecture, such as convolutional block attention module (CBAM), temporal convolution networks (TCN), in addition to multi-headed and channel attention mechanisms. The purpose behind that is to observe the extent of the influence each of these blocks has on performance for the restricted-temporal models. The results of testing all the models on UCF101 have shown accuracy of 88.98% for the variant with multiheaded attention added to the modified R(2+1)D. This paper concludes the significance of missing temporal features in the performance of the newly created increased resolution models. The variants had different behavior on class-level accuracy, despite the similarity of their enhancements to the overall performance.

</details>


### [5] [Medical SAM3: A Foundation Model for Universal Prompt-Driven Medical Image Segmentation](https://arxiv.org/abs/2601.10880)
*Chongcong Jiang,Tianxingjian Ding,Chuhan Song,Jiachen Tu,Ziyang Yan,Yihua Shao,Zhenyi Wang,Yuzhang Shang,Tianyu Han,Yu Tian*

Main category: cs.CV

TL;DR: 该研究通过全量微调SAM3模型，使其获得了在医学成像数据上的稳健表示，特别是在复杂的医学分割任务中表现出显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 研究发现，尽管SAM3在某些情况下表现出色，但其在医学成像数据上的表现明显下降，主要依赖于几何先验知识，如真实标注的边界框。因此，研究强调了模型整体适配的重要性，而不仅仅是提示工程。

Method: 研究在大量2D和3D医学成像数据集（涵盖10种医学成像模态）上完全微调了SAM3模型，通过结合配对的分割标注和文本提示来实现通用提示驱动的医学图像分割模型。这种方法使得模型能够在保持提示驱动的灵活性的同时，获取特定领域的稳健表示。

Result: 广泛的实验表明，Medical SAM3在器官、成像模态和维度方面都表现出了持续且显著的性能提升，尤其是在语义模糊、复杂形态和远程3D上下文等具有挑战性的场景中。

Conclusion: 研究证明，Medical SAM3是一个通用、文本引导的医学影像分割基础模型，具有应对严重领域漂移达到稳健提示驱动分割的能力。

Abstract: Promptable segmentation foundation models such as SAM3 have demonstrated strong generalization capabilities through interactive and concept-based prompting. However, their direct applicability to medical image segmentation remains limited by severe domain shifts, the absence of privileged spatial prompts, and the need to reason over complex anatomical and volumetric structures. Here we present Medical SAM3, a foundation model for universal prompt-driven medical image segmentation, obtained by fully fine-tuning SAM3 on large-scale, heterogeneous 2D and 3D medical imaging datasets with paired segmentation masks and text prompts. Through a systematic analysis of vanilla SAM3, we observe that its performance degrades substantially on medical data, with its apparent competitiveness largely relying on strong geometric priors such as ground-truth-derived bounding boxes. These findings motivate full model adaptation beyond prompt engineering alone. By fine-tuning SAM3's model parameters on 33 datasets spanning 10 medical imaging modalities, Medical SAM3 acquires robust domain-specific representations while preserving prompt-driven flexibility. Extensive experiments across organs, imaging modalities, and dimensionalities demonstrate consistent and significant performance gains, particularly in challenging scenarios characterized by semantic ambiguity, complex morphology, and long-range 3D context. Our results establish Medical SAM3 as a universal, text-guided segmentation foundation model for medical imaging and highlight the importance of holistic model adaptation for achieving robust prompt-driven segmentation under severe domain shift. Code and model will be made available at https://github.com/AIM-Research-Lab/Medical-SAM3.

</details>


### [6] [FrankenMotion: Part-level Human Motion Generation and Composition](https://arxiv.org/abs/2601.10909)
*Chuqiao Li,Xianghui Xie,Yong Cao,Andreas Geiger,Gerard Pons-Moll*

Main category: cs.CV

TL;DR: 提出了一种基于扩散模型的机械人运动生成框架FrankenMotion，针对人体每个部位提供原子级、时间意识的文本提示，克服了现有方法在细粒度部分运动控制上的局限。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖于序列级或动作级的描述，缺乏细粒度的部分级运动注释，影响了对个人身体部位的控制能力。因此，为了解决这一问题，本文构建了一个带有原子级、时间意识的部分级文本注释的高质量运动数据集，并引入了FrankenMotion框架。

Method: 构建了一个包含原子级、时间意识部分级文本注释的高质量运动数据集，利用大型语言模型的推理能力，引入了基于扩散模型的Part-Aware运动生成框架FrankenMotion。

Result: FrankenMotion在所设定的实验环境下超越了所有之前的基线模型，并且可以生成在训练期间未见过的运动。

Conclusion: 这是首次提供原子级、时间意识的部分级运动注释，并且具备同时在空间（身体部位）和时间（原子动作）层面的运动生成能力。

Abstract: Human motion generation from text prompts has made remarkable progress in recent years. However, existing methods primarily rely on either sequence-level or action-level descriptions due to the absence of fine-grained, part-level motion annotations. This limits their controllability over individual body parts. In this work, we construct a high-quality motion dataset with atomic, temporally-aware part-level text annotations, leveraging the reasoning capabilities of large language models (LLMs). Unlike prior datasets that either provide synchronized part captions with fixed time segments or rely solely on global sequence labels, our dataset captures asynchronous and semantically distinct part movements at fine temporal resolution. Based on this dataset, we introduce a diffusion-based part-aware motion generation framework, namely FrankenMotion, where each body part is guided by its own temporally-structured textual prompt. This is, to our knowledge, the first work to provide atomic, temporally-aware part-level motion annotations and have a model that allows motion generation with both spatial (body part) and temporal (atomic action) control. Experiments demonstrate that FrankenMotion outperforms all previous baseline models adapted and retrained for our setting, and our model can compose motions unseen during training. Our code and dataset will be publicly available upon publication.

</details>


### [7] [Classification of Chest XRay Diseases through image processing and analysis techniques](https://arxiv.org/abs/2601.10913)
*Santiago Martínez Novoa,María Catalina Ibáñez,Lina Gómez Mesa,Jeremias Kramer*

Main category: cs.CV

TL;DR: 该研究综述了多种方法处理胸部X光多分类任务，包括使用DenseNet121模型，并通过一项在线平台进行了不同方法的效果比较和评估。


<details>
  <summary>Details</summary>
Motivation: 为了提供一种有效的方法以提高胸部疾病诊断的准确性，并通过一款开源的在线应用程序进行效果对比评估。

Method: 研究采用了多种模型进行胸部X光影像的分类，其中包括使用DenseNet121。并通过一个在线应用程序进行不同方法的效果比较。

Result: 研究通过实验比较了多种方法在胸部X光影像分类中的表现。

Conclusion: 研究指出了所提出方法的局限性，并为未来改进提供了建议。

Abstract: Multi-Classification Chest X-Ray Images are one of the most prevalent forms of radiological examination used for diagnosing thoracic diseases. In this study, we offer a concise overview of several methods employed for tackling this task, including DenseNet121. In addition, we deploy an open-source web-based application. In our study, we conduct tests to compare different methods and see how well they work. We also look closely at the weaknesses of the methods we propose and suggest ideas for making them better in the future. Our code is available at: https://github.com/AML4206-MINE20242/Proyecto_AML

</details>


### [8] [RobuMTL: Enhancing Multi-Task Learning Robustness Against Weather Conditions](https://arxiv.org/abs/2601.10921)
*Tasneem Shaffee,Sherief Reda*

Main category: cs.CV

TL;DR: RobuMTL 是一种创新的多任务学习架构，能够在各种恶劣天气条件下自适应地优化视觉模型性能，通过动态选择特定任务的低秩适应模块和专家团队来应对输入扰动。


<details>
  <summary>Details</summary>
Motivation: 自主系统在现实环境中的运行需要在恶劣天气条件下保持模型的鲁棒性和可靠性，RobuMTL 通过自适应选择低秩适应模块和专家团队来优化视觉模型，适用于各种恶劣天气条件。

Method: 该架构采用了一种混合专家方式，能够根据输入扰动动态地选择特定任务的低秩适应模块和专家团队，实现对输入特性的自适应专业化。这种方法能够提升模型在不同现实环境条件下的鲁棒性。

Result: 在PASCAL和NYUD-v2数据集上的实验表明，RobuMTL 在单任务和混合天气条件下的相对平均改进率分别提升了2.8%和44.4%，NYUD-v2数据集上的相对平均改进率提高了9.7%。

Conclusion: RobuMTL 提供了一种新的解决方案，旨在改进多任务学习在不同恶劣天气条件下的表现，并在市场上超过了许多现有方法。

Abstract: Robust Multi-Task Learning (MTL) is crucial for autonomous systems operating in real-world environments, where adverse weather conditions can severely degrade model performance and reliability. In this paper, we introduce RobuMTL, a novel architecture designed to adaptively address visual degradation by dynamically selecting task-specific hierarchical Low-Rank Adaptation (LoRA) modules and a LoRA expert squad based on input perturbations in a mixture-of-experts fashion. Our framework enables adaptive specialization based on input characteristics, improving robustness across diverse real-world conditions. To validate our approach, we evaluated it on the PASCAL and NYUD-v2 datasets and compared it against single-task models, standard MTL baselines, and state-of-the-art methods. On the PASCAL benchmark, RobuMTL delivers a +2.8% average relative improvement under single perturbations and up to +44.4% under mixed weather conditions compared to the MTL baseline. On NYUD-v2, RobuMTL achieves a +9.7% average relative improvement across tasks. The code is available at GitHub.

</details>


### [9] [Sparse Data Tree Canopy Segmentation: Fine-Tuning Leading Pretrained Models on Only 150 Images](https://arxiv.org/abs/2601.10931)
*David Szczecina,Hudson Sun,Anthony Bertnyk,Niloofar Azad,Kyle Gao,Lincoln Linlin Xu*

Main category: cs.CV

TL;DR: 该研究评估了五种架构（YOLOv1、Mask R-CNN、DeepLabv3、Swin-UNet 和 DINOv2）在极端小数据集条件下的树冠分割性能。实验证明，基于卷积的预训练模型（特别是YOLOv1和Mask R-CNN）在小数据集环境下表现更佳，而基于变换器的模型（DeepLabV3、Swin-UNet 和 DINOv2）表现较差，这主要是由于任务差异、模型对数据的需求和缺乏强有力的归纳偏差。


<details>
  <summary>Details</summary>
Motivation: 树冠检测对于环境监测、城市规划和生态系统分析非常重要。然而，面对有限和不平衡的数据集，准确地训练深度模型并防止过拟合极具挑战，因此需要评估不同的模型架构以找到最合适的解决方案。

Method: 该研究选择了五种具有代表性的模型架构进行实验，包括YOLOv1、Mask R-CNN、DeepLabv3、Swin-UNet 和 DINOv2。实验中评估了这些模型在极端小数据集条件下的性能，并详细分析了在小数据环境下的训练策略、数据增强策略和模型行为。

Result: 五种模型中，基于卷积的预训练模型（特别是YOLOv1和Mask R-CNN）在小数据集上表现更佳，而基于变换器的模型（DeepLabV3、Swin-UNet 和 DINOv2）由于任务差异、模型数据需求和归纳偏差不强的原因表现较差。

Conclusion: 研究结论指出，基于变换器的架构在低数据条件下陷入了困境，需要大量的预训练或数据增强才能改善，而基于卷积的轻量级模型对于有限的树冠检测仍然更可靠。

Abstract: Tree canopy detection from aerial imagery is an important task for environmental monitoring, urban planning, and ecosystem analysis. Simulating real-life data annotation scarcity, the Solafune Tree Canopy Detection competition provides a small and imbalanced dataset of only 150 annotated images, posing significant challenges for training deep models without severe overfitting. In this work, we evaluate five representative architectures, YOLOv11, Mask R-CNN, DeepLabv3, Swin-UNet, and DINOv2, to assess their suitability for canopy segmentation under extreme data scarcity. Our experiments show that pretrained convolution-based models, particularly YOLOv11 and Mask R-CNN, generalize significantly better than pretrained transformer-based models. DeeplabV3, Swin-UNet and DINOv2 underperform likely due to differences between semantic and instance segmentation tasks, the high data requirements of Vision Transformers, and the lack of strong inductive biases. These findings confirm that transformer-based architectures struggle in low-data regimes without substantial pretraining or augmentation and that differences between semantic and instance segmentation further affect model performance. We provide a detailed analysis of training strategies, augmentation policies, and model behavior under the small-data constraint and demonstrate that lightweight CNN-based methods remain the most reliable for canopy detection on limited imagery.

</details>


### [10] [PatientVLM Meets DocVLM: Pre-Consultation Dialogue Between Vision-Language Models for Efficient Diagnosis](https://arxiv.org/abs/2601.10945)
*K Lokesh,Abhirama Subramanyam Penamakuri,Uday Agarwal,Apoorva Challa,Shreya K Gowda,Somesh Gupta,Anand Mishra*

Main category: cs.CV

TL;DR: 提出了一种预咨询对话框架(PCDF)，利用双模态对话模拟医生诊断流程，包含DocVLM和PatientVLM的交互，生成的症状被临床医生确认具有临床相关性。通过多轮对话和图像诊断，提升了基于图像的AI诊断系统的诊断准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的医学诊断AI研究主要集中在图像分析上，忽视了患者报告的症状，导致诊断准确性受限。此研究旨在通过引入预咨询对话框架来补充这一不足。

Method: 设计了一个由DocVLM和PatientVLM组成的对话框架，其中DocVLM根据图片和对话历史生成后续问题，而PatientVLM基于预设症状生成回答。此外，采用合成症状进行了小型临床验证。

Result: 临床医生验证了合成症状的相关性与现实性。使用此对话框架增强的DocVLM在图像诊断准确性上获得了显著提高。

Conclusion: 研究结果表明多轮对话和复杂交互对于提升医学图像诊断AI系统的性能具有重要意义。

Abstract: Traditionally, AI research in medical diagnosis has largely centered on image analysis. While this has led to notable advancements, the absence of patient-reported symptoms continues to hinder diagnostic accuracy. To address this, we propose a Pre-Consultation Dialogue Framework (PCDF) that mimics real-world diagnostic procedures, where doctors iteratively query patients before reaching a conclusion. Specifically, we simulate diagnostic dialogues between two vision-language models (VLMs): a DocVLM, which generates follow-up questions based on the image and dialogue history, and a PatientVLM, which responds using a symptom profile derived from the ground-truth diagnosis. We additionally conducted a small-scale clinical validation of the synthetic symptoms generated by our framework, with licensed clinicians confirming their clinical relevance, symptom coverage, and overall realism. These findings indicate that the resulting DocVLM-PatientVLM interactions form coherent, multi-turn consultations paired with images and diagnoses, which we then use to fine-tune the DocVLM. This dialogue-based supervision leads to substantial gains over image-only training, highlighting the value of realistic symptom elicitation for diagnosis.

</details>


### [11] [Your One-Stop Solution for AI-Generated Video Detection](https://arxiv.org/abs/2601.11035)
*Long Ma,Zihao Xue,Yan Wang,Zhiyuan Yan,Jin Xu,Xiaorui Jiang,Haiyang Yu,Yong Liao,Zhen Bi*

Main category: cs.CV

TL;DR: 该研究分析了生成模型的最新进展，指出了现有数据集和基准存在的规模有限、覆盖不全面等问题，提出了AIGVDBench基准，旨在覆盖31种最新的生成模型和超过440,000个视频，进行1,500多项评估。该基准具备全面性和代表性，揭示了4项新颖发现。


<details>
  <summary>Details</summary>
Motivation: 由于现代生成技术的发展速度极快，现有数据集和基准难以捕捉这种多样性和快速发展，需开发更全面且代表性的基准来促进AI生成视频检测研究。

Method: 该研究构建了一个名为AIGVDBench的基准，该基准涵盖了31种最先进的生成模型和超过440,000个视频。此外，该基准还对33种现有的检测器进行了超1,500次评估，并从多个角度进行了8项深入分析。

Result: 研究结果表明，现有检测器在某些方面存在不足，例如多样性和场景覆盖不足。通过对数据集和检测器进行综合评估，该研究揭示了4项新颖发现，对未来的相关研究提供了有价值的见解。

Conclusion: AIGVDBench提供了一个更全面和代表性的基准，旨在推动AI生成视频检测技术的发展。

Abstract: Recent advances in generative modeling can create remarkably realistic synthetic videos, making it increasingly difficult for humans to distinguish them from real ones and necessitating reliable detection methods.
  However, two key limitations hinder the development of this field.
  \textbf{From the dataset perspective}, existing datasets are often limited in scale and constructed using outdated or narrowly scoped generative models, making it difficult to capture the diversity and rapid evolution of modern generative techniques. Moreover, the dataset construction process frequently prioritizes quantity over quality, neglecting essential aspects such as semantic diversity, scenario coverage, and technological representativeness.
  \textbf{From the benchmark perspective}, current benchmarks largely remain at the stage of dataset creation, leaving many fundamental issues and in-depth analysis yet to be systematically explored.
  Addressing this gap, we propose AIGVDBench, a benchmark designed to be comprehensive and representative, covering \textbf{31} state-of-the-art generation models and over \textbf{440,000} videos. By executing more than \textbf{1,500} evaluations on \textbf{33} existing detectors belonging to four distinct categories. This work presents \textbf{8 in-depth analyses} from multiple perspectives and identifies \textbf{4 novel findings} that offer valuable insights for future research. We hope this work provides a solid foundation for advancing the field of AI-generated video detection.
  Our benchmark is open-sourced at https://github.com/LongMa-2025/AIGVDBench.

</details>


### [12] [M3DDM+: An improved video outpainting by a modified masking strategy](https://arxiv.org/abs/2601.11048)
*Takuya Murakawa,Takumi Fukuzawa,Ning Ding,Toru Tamaki*

Main category: cs.CV

TL;DR: 提出了M3DDM+模型，通过统一掩码方向和宽度以解决训练-推理匹配问题，并在大规模和复杂场景下提高清晰度和时间连贯性，同时保持计算效率。


<details>
  <summary>Details</summary>
Motivation: M3DDM模型在处理具有限制的摄像头运动或大范围出画场景时表现出质量下降，尤其是空间模糊和时间一致性较差。

Method: M3DDM+模型训练时采用了统一的掩码方向和宽度，避免了训练和推理之间的不匹配，并在此基础上对预训练的M3DDM模型进行了微调。

Result: 实验表明，M3DDM+明显提高了信息有限场景下的视觉保真度和时间连贯性，同时保持了计算效率。

Conclusion: M3DDM+模型克服了原始模型的局限性，有望在实际视频出画应用中提供更好的性能。

Abstract: M3DDM provides a computationally efficient framework for video outpainting via latent diffusion modeling. However, it exhibits significant quality degradation -- manifested as spatial blur and temporal inconsistency -- under challenging scenarios characterized by limited camera motion or large outpainting regions, where inter-frame information is limited. We identify the cause as a training-inference mismatch in the masking strategy: M3DDM's training applies random mask directions and widths across frames, whereas inference requires consistent directional outpainting throughout the video. To address this, we propose M3DDM+, which applies uniform mask direction and width across all frames during training, followed by fine-tuning of the pretrained M3DDM model. Experiments demonstrate that M3DDM+ substantially improves visual fidelity and temporal coherence in information-limited scenarios while maintaining computational efficiency. The code is available at https://github.com/tamaki-lab/M3DDM-Plus.

</details>


### [13] [PhysRVG: Physics-Aware Unified Reinforcement Learning for Video Generative Models](https://arxiv.org/abs/2601.11087)
*Qiyuan Zhang,Biao Gong,Shuai Tan,Zheng Zhang,Yujun Shen,Xing Zhu,Yuyuan Li,Kelu Yao,Chunhua Shen,Changqing Zou*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Physical principles are fundamental to realistic visual simulation, but remain a significant oversight in transformer-based video generation. This gap highlights a critical limitation in rendering rigid body motion, a core tenet of classical mechanics. While computer graphics and physics-based simulators can easily model such collisions using Newton formulas, modern pretrain-finetune paradigms discard the concept of object rigidity during pixel-level global denoising. Even perfectly correct mathematical constraints are treated as suboptimal solutions (i.e., conditions) during model optimization in post-training, fundamentally limiting the physical realism of generated videos. Motivated by these considerations, we introduce, for the first time, a physics-aware reinforcement learning paradigm for video generation models that enforces physical collision rules directly in high-dimensional spaces, ensuring the physics knowledge is strictly applied rather than treated as conditions. Subsequently, we extend this paradigm to a unified framework, termed Mimicry-Discovery Cycle (MDcycle), which allows substantial fine-tuning while fully preserving the model's ability to leverage physics-grounded feedback. To validate our approach, we construct new benchmark PhysRVGBench and perform extensive qualitative and quantitative experiments to thoroughly assess its effectiveness.

</details>


### [14] [CoDance: An Unbind-Rebind Paradigm for Robust Multi-Subject Animation](https://arxiv.org/abs/2601.11096)
*Shuai Tan,Biao Gong,Ke Ma,Yutong Feng,Qiyuan Zhang,Yan Wang,Yujun Shen,Hengshuang Zhao*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Character image animation is gaining significant importance across various domains, driven by the demand for robust and flexible multi-subject rendering. While existing methods excel in single-person animation, they struggle to handle arbitrary subject counts, diverse character types, and spatial misalignment between the reference image and the driving poses. We attribute these limitations to an overly rigid spatial binding that forces strict pixel-wise alignment between the pose and reference, and an inability to consistently rebind motion to intended subjects. To address these challenges, we propose CoDance, a novel Unbind-Rebind framework that enables the animation of arbitrary subject counts, types, and spatial configurations conditioned on a single, potentially misaligned pose sequence. Specifically, the Unbind module employs a novel pose shift encoder to break the rigid spatial binding between the pose and the reference by introducing stochastic perturbations to both poses and their latent features, thereby compelling the model to learn a location-agnostic motion representation. To ensure precise control and subject association, we then devise a Rebind module, leveraging semantic guidance from text prompts and spatial guidance from subject masks to direct the learned motion to intended characters. Furthermore, to facilitate comprehensive evaluation, we introduce a new multi-subject CoDanceBench. Extensive experiments on CoDanceBench and existing datasets show that CoDance achieves SOTA performance, exhibiting remarkable generalization across diverse subjects and spatial layouts. The code and weights will be open-sourced.

</details>


### [15] [Graph Smoothing for Enhanced Local Geometry Learning in Point Cloud Analysis](https://arxiv.org/abs/2601.11102)
*Shangbo Yuan,Jie Xu,Ping Hu,Xiaofeng Zhu,Na Zhao*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Graph-based methods have proven to be effective in capturing relationships among points for 3D point cloud analysis. However, these methods often suffer from suboptimal graph structures, particularly due to sparse connections at boundary points and noisy connections in junction areas. To address these challenges, we propose a novel method that integrates a graph smoothing module with an enhanced local geometry learning module. Specifically, we identify the limitations of conventional graph structures, particularly in handling boundary points and junction areas. In response, we introduce a graph smoothing module designed to optimize the graph structure and minimize the negative impact of unreliable sparse and noisy connections. Based on the optimized graph structure, we improve the feature extract function with local geometry information. These include shape features derived from adaptive geometric descriptors based on eigenvectors and distribution features obtained through cylindrical coordinate transformation. Experimental results on real-world datasets validate the effectiveness of our method in various point cloud learning tasks, i.e., classification, part segmentation, and semantic segmentation.

</details>


### [16] [Vision-as-Inverse-Graphics Agent via Interleaved Multimodal Reasoning](https://arxiv.org/abs/2601.11109)
*Shaofeng Yin,Jiaxin Ge,Zora Zhiruo Wang,Xiuyu Li,Michael J. Black,Trevor Darrell,Angjoo Kanazawa,Haiwen Feng*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Vision-as-inverse-graphics, the concept of reconstructing an image as an editable graphics program is a long-standing goal of computer vision. Yet even strong VLMs aren't able to achieve this in one-shot as they lack fine-grained spatial and physical grounding capability. Our key insight is that closing this gap requires interleaved multimodal reasoning through iterative execution and verification. Stemming from this, we present VIGA (Vision-as-Inverse-Graphic Agent) that starts from an empty world and reconstructs or edits scenes through a closed-loop write-run-render-compare-revise procedure. To support long-horizon reasoning, VIGA combines (i) a skill library that alternates generator and verifier roles and (ii) an evolving context memory that contains plans, code diffs, and render history. VIGA is task-agnostic as it doesn't require auxiliary modules, covering a wide range of tasks such as 3D reconstruction, multi-step scene editing, 4D physical interaction, and 2D document editing, etc. Empirically, we found VIGA substantially improves one-shot baselines on BlenderGym (35.32%) and SlideBench (117.17%). Moreover, VIGA is also model-agnostic as it doesn't require finetuning, enabling a unified protocol to evaluate heterogeneous foundation VLMs. To better support this protocol, we introduce BlenderBench, a challenging benchmark that stress-tests interleaved multimodal reasoning with graphics engine, where VIGA improves by 124.70%.

</details>


### [17] [SoLA-Vision: Fine-grained Layer-wise Linear Softmax Hybrid Attention](https://arxiv.org/abs/2601.11164)
*Ruibang Li,Guan Luo,Yiwei Zhang,Jin Gao,Bing Li,Weiming Hu*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Standard softmax self-attention excels in vision tasks but incurs quadratic complexity O(N^2), limiting high-resolution deployment. Linear attention reduces the cost to O(N), yet its compressed state representations can impair modeling capacity and accuracy. We present an analytical study that contrasts linear and softmax attention for visual representation learning from a layer-stacking perspective. We further conduct systematic experiments on layer-wise hybridization patterns of linear and softmax attention. Our results show that, compared with rigid intra-block hybrid designs, fine-grained layer-wise hybridization can match or surpass performance while requiring fewer softmax layers. Building on these findings, we propose SoLA-Vision (Softmax-Linear Attention Vision), a flexible layer-wise hybrid attention backbone that enables fine-grained control over how linear and softmax attention are integrated. By strategically inserting a small number of global softmax layers, SoLA-Vision achieves a strong trade-off between accuracy and computational cost. On ImageNet-1K, SoLA-Vision outperforms purely linear and other hybrid attention models. On dense prediction tasks, it consistently surpasses strong baselines by a considerable margin. Code will be released.

</details>


### [18] [Democratizing planetary-scale analysis: An ultra-lightweight Earth embedding database for accurate and flexible global land monitoring](https://arxiv.org/abs/2601.11183)
*Shuang Chen,Jie Wang,Shuai Yuan,Jiayang Li,Yu Xia,Yuanhong Liao,Junbo Wei,Jincheng Yuan,Xiaoqing Xu,Xiaolin Zhu,Peng Zhu,Hongsheng Zhang,Yuyu Zhou,Haohuan Fu,Huabing Huang,Bin Chen,Fan Dai,Peng Gong*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The rapid evolution of satellite-borne Earth Observation (EO) systems has revolutionized terrestrial monitoring, yielding petabyte-scale archives. However, the immense computational and storage requirements for global-scale analysis often preclude widespread use, hindering planetary-scale studies. To address these barriers, we present Embedded Seamless Data (ESD), an ultra-lightweight, 30-m global Earth embedding database spanning the 25-year period from 2000 to 2024. By transforming high-dimensional, multi-sensor observations from the Landsat series (5, 7, 8, and 9) and MODIS Terra into information-dense, quantized latent vectors, ESD distills essential geophysical and semantic features into a unified latent space. Utilizing the ESDNet architecture and Finite Scalar Quantization (FSQ), the dataset achieves a transformative ~340-fold reduction in data volume compared to raw archives. This compression allows the entire global land surface for a single year to be encapsulated within approximately 2.4 TB, enabling decadal-scale global analysis on standard local workstations. Rigorous validation demonstrates high reconstructive fidelity (MAE: 0.0130; RMSE: 0.0179; CC: 0.8543). By condensing the annual phenological cycle into 12 temporal steps, the embeddings provide inherent denoising and a semantically organized space that outperforms raw reflectance in land-cover classification, achieving 79.74% accuracy (vs. 76.92% for raw fusion). With robust few-shot learning capabilities and longitudinal consistency, ESD provides a versatile foundation for democratizing planetary-scale research and advancing next-generation geospatial artificial intelligence.

</details>


### [19] [ATATA: One Algorithm to Align Them All](https://arxiv.org/abs/2601.11194)
*Boyi Pang,Savva Ignatyev,Vladimir Ippolitov,Ramil Khafizov,Yurii Melnik,Oleg Voynov,Maksim Nakhodnov,Aibek Alanov,Xiaopeng Fan,Peter Wonka,Evgeny Burnaev*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We suggest a new multi-modal algorithm for joint inference of paired structurally aligned samples with Rectified Flow models. While some existing methods propose a codependent generation process, they do not view the problem of joint generation from a structural alignment perspective. Recent work uses Score Distillation Sampling to generate aligned 3D models, but SDS is known to be time-consuming, prone to mode collapse, and often provides cartoonish results. By contrast, our suggested approach relies on the joint transport of a segment in the sample space, yielding faster computation at inference time. Our approach can be built on top of an arbitrary Rectified Flow model operating on the structured latent space. We show the applicability of our method to the domains of image, video, and 3D shape generation using state-of-the-art baselines and evaluate it against both editing-based and joint inference-based competing approaches. We demonstrate a high degree of structural alignment for the sample pairs obtained with our method and a high visual quality of the samples. Our method improves the state-of-the-art for image and video generation pipelines. For 3D generation, it is able to show comparable quality while working orders of magnitude faster.

</details>


### [20] [Bio-inspired fine-tuning for selective transfer learning in image classification](https://arxiv.org/abs/2601.11235)
*Ana Davila,Jacinto Colan,Yasuhisa Hasegawa*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Deep learning has significantly advanced image analysis across diverse domains but often depends on large, annotated datasets for success. Transfer learning addresses this challenge by utilizing pre-trained models to tackle new tasks with limited labeled data. However, discrepancies between source and target domains can hinder effective transfer learning. We introduce BioTune, a novel adaptive fine-tuning technique utilizing evolutionary optimization. BioTune enhances transfer learning by optimally choosing which layers to freeze and adjusting learning rates for unfrozen layers. Through extensive evaluation on nine image classification datasets, spanning natural and specialized domains such as medical imaging, BioTune demonstrates superior accuracy and efficiency over state-of-the-art fine-tuning methods, including AutoRGN and LoRA, highlighting its adaptability to various data characteristics and distribution changes. Additionally, BioTune consistently achieves top performance across four different CNN architectures, underscoring its flexibility. Ablation studies provide valuable insights into the impact of BioTune's key components on overall performance. The source code is available at https://github.com/davilac/BioTune.

</details>


### [21] [Image-Text Knowledge Modeling for Unsupervised Multi-Scenario Person Re-Identification](https://arxiv.org/abs/2601.11243)
*Zhiqi Pang,Lingling Zhao,Yang Liu,Chunyu Wang,Gaurav Sharma*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We propose unsupervised multi-scenario (UMS) person re-identification (ReID) as a new task that expands ReID across diverse scenarios (cross-resolution, clothing change, etc.) within a single coherent framework. To tackle UMS-ReID, we introduce image-text knowledge modeling (ITKM) -- a three-stage framework that effectively exploits the representational power of vision-language models. We start with a pre-trained CLIP model with an image encoder and a text encoder. In Stage I, we introduce a scenario embedding in the image encoder and fine-tune the encoder to adaptively leverage knowledge from multiple scenarios. In Stage II, we optimize a set of learned text embeddings to associate with pseudo-labels from Stage I and introduce a multi-scenario separation loss to increase the divergence between inter-scenario text representations. In Stage III, we first introduce cluster-level and instance-level heterogeneous matching modules to obtain reliable heterogeneous positive pairs (e.g., a visible image and an infrared image of the same person) within each scenario. Next, we propose a dynamic text representation update strategy to maintain consistency between text and image supervision signals. Experimental results across multiple scenarios demonstrate the superiority and generalizability of ITKM; it not only outperforms existing scenario-specific methods but also enhances overall performance by integrating knowledge from multiple scenarios.

</details>


### [22] [Language-Agnostic Visual Embeddings for Cross-Script Handwriting Retrieval](https://arxiv.org/abs/2601.11248)
*Fangke Chen,Tianhao Dong,Sirry Chen,Guobin Zhang,Yishu Zhang,Yining Chen*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Handwritten word retrieval is vital for digital archives but remains challenging due to large handwriting variability and cross-lingual semantic gaps. While large vision-language models offer potential solutions, their prohibitive computational costs hinder practical edge deployment. To address this, we propose a lightweight asymmetric dual-encoder framework that learns unified, style-invariant visual embeddings. By jointly optimizing instance-level alignment and class-level semantic consistency, our approach anchors visual embeddings to language-agnostic semantic prototypes, enforcing invariance across scripts and writing styles. Experiments show that our method outperforms 28 baselines and achieves state-of-the-art accuracy on within-language retrieval benchmarks. We further conduct explicit cross-lingual retrieval, where the query language differs from the target language, to validate the effectiveness of the learned cross-lingual representations. Achieving strong performance with only a fraction of the parameters required by existing models, our framework enables accurate and resource-efficient cross-script handwriting retrieval.

</details>


### [23] [FTDMamba: Frequency-Assisted Temporal Dilation Mamba for Unmanned Aerial Vehicle Video Anomaly Detection](https://arxiv.org/abs/2601.11254)
*Cheng-Zhuang Liu,Si-Bao Chen,Qing-Ling Shu,Chris Ding,Jin Tang,Bin Luo*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Recent advances in video anomaly detection (VAD) mainly focus on ground-based surveillance or unmanned aerial vehicle (UAV) videos with static backgrounds, whereas research on UAV videos with dynamic backgrounds remains limited. Unlike static scenarios, dynamically captured UAV videos exhibit multi-source motion coupling, where the motion of objects and UAV-induced global motion are intricately intertwined. Consequently, existing methods may misclassify normal UAV movements as anomalies or fail to capture true anomalies concealed within dynamic backgrounds. Moreover, many approaches do not adequately address the joint modeling of inter-frame continuity and local spatial correlations across diverse temporal scales. To overcome these limitations, we propose the Frequency-Assisted Temporal Dilation Mamba (FTDMamba) network for UAV VAD, including two core components: (1) a Frequency Decoupled Spatiotemporal Correlation Module, which disentangles coupled motion patterns and models global spatiotemporal dependencies through frequency analysis; and (2) a Temporal Dilation Mamba Module, which leverages Mamba's sequence modeling capability to jointly learn fine-grained temporal dynamics and local spatial structures across multiple temporal receptive fields. Additionally, unlike existing UAV VAD datasets which focus on static backgrounds, we construct a large-scale Moving UAV VAD dataset (MUVAD), comprising 222,736 frames with 240 anomaly events across 12 anomaly types. Extensive experiments demonstrate that FTDMamba achieves state-of-the-art (SOTA) performance on two public static benchmarks and the new MUVAD dataset. The code and MUVAD dataset will be available at: https://github.com/uavano/FTDMamba.

</details>


### [24] [X-Distill: Cross-Architecture Vision Distillation for Visuomotor Learning](https://arxiv.org/abs/2601.11269)
*Maanping Shao,Feihong Zhang,Gu Zhang,Baiye Cheng,Zhengrong Xue,Huazhe Xu*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Visuomotor policies often leverage large pre-trained Vision Transformers (ViTs) for their powerful generalization capabilities. However, their significant data requirements present a major challenge in the data-scarce context of most robotic learning settings, where compact CNNs with strong inductive biases can be more easily optimized. To address this trade-off, we introduce X-Distill, a simple yet highly effective method that synergizes the strengths of both architectures. Our approach involves an offline, cross-architecture knowledge distillation, transferring the rich visual representations of a large, frozen DINOv2 teacher to a compact ResNet-18 student on the general-purpose ImageNet dataset. This distilled encoder, now endowed with powerful visual priors, is then jointly fine-tuned with a diffusion policy head on the target manipulation tasks. Extensive experiments on $34$ simulated benchmarks and $5$ challenging real-world tasks demonstrate that our method consistently outperforms policies equipped with from-scratch ResNet or fine-tuned DINOv2 encoders. Notably, X-Distill also surpasses 3D encoders that utilize privileged point cloud observations or much larger Vision-Language Models. Our work highlights the efficacy of a simple, well-founded distillation strategy for achieving state-of-the-art performance in data-efficient robotic manipulation.

</details>


### [25] [Efficient On-Board Processing of Oblique UAV Video for Rapid Flood Extent Mapping](https://arxiv.org/abs/2601.11290)
*Vishisht Sharma,Sam Leroux,Lisa Landuyt,Nick Witvrouwen,Pieter Simoens*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Effective disaster response relies on rapid disaster response, where oblique aerial video is the primary modality for initial scouting due to its ability to maximize spatial coverage and situational awareness in limited flight time. However, the on-board processing of high-resolution oblique streams is severely bottlenecked by the strict Size, Weight, and Power (SWaP) constraints of Unmanned Aerial Vehicles (UAVs). The computational density required to process these wide-field-of-view streams precludes low-latency inference on standard edge hardware. To address this, we propose Temporal Token Reuse (TTR), an adaptive inference framework capable of accelerating video segmentation on embedded devices. TTR exploits the intrinsic spatiotemporal redundancy of aerial video by formulating image patches as tokens; it utilizes a lightweight similarity metric to dynamically identify static regions and propagate their precomputed deep features, thereby bypassing redundant backbone computations. We validate the framework on standard benchmarks and a newly curated Oblique Floodwater Dataset designed for hydrological monitoring. Experimental results on edge-grade hardware demonstrate that TTR achieves a 30% reduction in inference latency with negligible degradation in segmentation accuracy (< 0.5% mIoU). These findings confirm that TTR effectively shifts the operational Pareto frontier, enabling high-fidelity, real-time oblique video understanding for time-critical remote sensing missions

</details>


### [26] [SAMannot: A Memory-Efficient, Local, Open-source Framework for Interactive Video Instance Segmentation based on SAM2](https://arxiv.org/abs/2601.11301)
*Gergely Dinya,András Gelencsér,Krisztina Kupán,Clemens Küpper,Kristóf Karacs,Anna Gelencsér-Horváth*

Main category: cs.CV

TL;DR: SAMannot 是一个本地的开源框架，它将 Segment Anything Model 2 (SAM2) 整合进了一种人工介入的流程中，旨在降低资源需求，优化用户体验，同时提供实例身份管理、自动锁定与细化工作流程、基于掩码骨架化的自动提示机制等功能，支持 YOLO 和 PNG 格式的数据集生成，并通过动物行为跟踪和基准数据集的测试验证了其在复杂视频注释任务中的高效、私密、且成本效益。


<details>
  <summary>Details</summary>
Motivation: 当前研究视频分割的工作流程常常在劳动密集型的手动编目、昂贵的商业平台和/或隐私暴露的云基服务之间进行妥协。这一工具旨在解决手动注释的瓶颈和云工具的隐私顾虑，为目标物体高保真度视频实例分割提供一种替代方案。

Method: SAMannot 框架通过修改基础模型依赖关系，实现了一层处理步骤，从而最小化计算开销，最大化吞吐量，确保用户界面高度响应。此外，它还提供了一系列增强的特性，包括持久化实例身份管理、自动锁定与细化工作流程、基于掩码骨架化的自动提示机制等。

Result: 该工具的性能已在动物行为跟踪和 LVOS、DAVIS 质量评分基准数据集的子集上得到验证。与商业平台相比，SAMannot 作为一种可扩展的、私有的且成本效益高的替代方案展现出了显著优势。

Conclusion: 总的来说，SAMannot 提供了一个强大且灵活的本地解决方案，有助于促进高保真度视频实例分割的研究和开发工作，同时保证了数据隐私并在复杂视频注释任务中表现出良好的效率和成本效益。

Abstract: Current research workflows for precise video segmentation are often forced into a compromise between labor-intensive manual curation, costly commercial platforms, and/or privacy-compromising cloud-based services. The demand for high-fidelity video instance segmentation in research is often hindered by the bottleneck of manual annotation and the privacy concerns of cloud-based tools. We present SAMannot, an open-source, local framework that integrates the Segment Anything Model 2 (SAM2) into a human-in-the-loop workflow. To address the high resource requirements of foundation models, we modified the SAM2 dependency and implemented a processing layer that minimizes computational overhead and maximizes throughput, ensuring a highly responsive user interface. Key features include persistent instance identity management, an automated ``lock-and-refine'' workflow with barrier frames, and a mask-skeletonization-based auto-prompting mechanism. SAMannot facilitates the generation of research-ready datasets in YOLO and PNG formats alongside structured interaction logs. Verified through animal behavior tracking use-cases and subsets of the LVOS and DAVIS benchmark datasets, the tool provides a scalable, private, and cost-effective alternative to commercial platforms for complex video annotation tasks.

</details>


### [27] [Context-Aware Semantic Segmentation via Stage-Wise Attention](https://arxiv.org/abs/2601.11310)
*Antoine Carreaud,Elias Naha,Arthur Chansel,Nina Lahellec,Jan Skaloud,Adrien Gressin*

Main category: cs.CV

TL;DR: CASWiT 提出了一种基于 Swin 架构的双分支模型，通过全球线索增强高分辨率特征，改进了超高清图像语义分割的性能。


<details>
  <summary>Details</summary>
Motivation: 在遥感应用中，超高清图像的语义分割是关键任务，但传统的基于Transformer的模型在处理大范围上下文和高空间分辨率时存在局限性。

Method: 提出了 CASWiT 架构，包括一个上下文编码器和一个高分辨率编码器，通过跨尺度融合模块结合跨注意力机制和特征注入方法，将全局信息注入到细粒度的高分辨率特征中。

Result: 在IGN FLAIR-HUB航拍数据集上，该方法实现了65.83%的mIoU，优于RGB基准1.78个百分点。在URUR数据集上，CASWiT 达到了49.1%的mIoU，超越当前最优方法0.9%。

Conclusion: 该研究提出了一个有效的方法来解决超高清图像语义分割的挑战，并已通过详尽的实验验证其优越性。

Abstract: Semantic ultra high resolution image (UHR) segmentation is essential in remote sensing applications such as aerial mapping and environmental monitoring. Transformer-based models struggle in this setting because memory grows quadratically with token count, constraining either the contextual scope or the spatial resolution. We introduce CASWiT (Context-Aware Stage-Wise Transformer), a dual-branch, Swin-based architecture that injects global cues into fine-grained UHR features. A context encoder processes a downsampled neighborhood to capture long-range dependencies, while a high resolution encoder extracts detailed features from UHR patches. A cross-scale fusion module, combining cross-attention and gated feature injection, enriches high-resolution tokens with context. Beyond architecture, we propose a SimMIM-style pretraining. We mask 75% of the high-resolution image tokens and the low-resolution center region that spatially corresponds to the UHR patch, then train the shared dual-encoder with small decoder to reconstruct the UHR initial image. Extensive experiments on the large-scale IGN FLAIR-HUB aerial dataset demonstrate the effectiveness of CASWiT. Our method achieves 65.83% mIoU, outperforming RGB baselines by 1.78 points. On URUR, CASWiT achieves 49.1% mIoU, surpassing the current SoTA by +0.9% under the official evaluation protocol. All codes are provided on: https://huggingface.co/collections/heig-vd-geo/caswit.

</details>


### [28] [Enhancing Vision Language Models with Logic Reasoning for Situational Awareness](https://arxiv.org/abs/2601.11322)
*Pavana Pradeep,Krishna Kant,Suya Yu*

Main category: cs.CV

TL;DR: 本文提出了一种结合视觉语言模型与传统计算机视觉方法的智能微调机制，以增强在情境感知应用中的活动识别和解释能力。


<details>
  <summary>Details</summary>
Motivation: 为解决情境感知应用中识别稀有但重要的事件，并确保识别结果的高度可靠性和准确性。

Method: 提出了一种结合视觉语言模型和传统计算机视觉方法的方法，通过明确的逻辑推理，提出了智能微调策略，并在推理过程中生成VLM输出的解释。

Result: 智能微调机制提高了活动识别的准确性，并提供了一种在推理过程中确认VLM输出有效性的方法，或者说明为何其可能存在问题。

Conclusion: 该研究改进了情境感知中的活动识别和语境理解能力，促进了对VLM输出结果的信心。

Abstract: Vision-Language Models (VLMs) offer the ability to generate high-level, interpretable descriptions of complex activities from images and videos, making them valuable for situational awareness (SA) applications. In such settings, the focus is on identifying infrequent but significant events with high reliability and accuracy, while also extracting fine-grained details and assessing recognition quality. In this paper, we propose an approach that integrates VLMs with traditional computer vision methods through explicit logic reasoning to enhance SA in three key ways: (a) extracting fine-grained event details, (b) employing an intelligent fine-tuning (FT) strategy that achieves substantially higher accuracy than uninformed selection, and (c) generating justifications for VLM outputs during inference. We demonstrate that our intelligent FT mechanism improves the accuracy and provides a valuable means, during inferencing, to either confirm the validity of the VLM output or indicate why it may be questionable.

</details>


### [29] [Beer-Lambert Autoencoder for Unsupervised Stain Representation Learning and Deconvolution in Multi-immunohistochemical Brightfield Histology Images](https://arxiv.org/abs/2601.11336)
*Mark Eastwood,Thomas McKee,Zedong Hu,Sabine Tejpar,Fayyaz Minhas*

Main category: cs.CV

TL;DR: 该研究提出了一种简单且数据驱动的编码-解码架构，用于处理大于3种染色体的多重免疫组织化学（mIHC）全组织切片图像（WSI），能够生成清晰且染色分离度高的单染色浓度图。


<details>
  <summary>Details</summary>
Motivation: 现有的经典Beer-Lambert颜色去卷积方法在处理多重染色时表现不佳，新的架构旨在提供更好的去卷积效果。

Method: 研究采用了压缩U-Net作为编码器来预测K个非负浓度通道，并使用可学习的染色体矩阵（初始化来自典型染色体颜色）的可微分Beer-Lambert直接模型作为解码器。训练采用无监督的感知重构目标，并附加了阻止不必要的染色混合的损失项。

Result: 在包含5种染色（H、CDX2、MUC2、MUC5、CD8）的结肠直肠mIHC面板上，该方法能实现优秀的RGB重构，并且与基于矩阵的去卷积相比，显著减少了通道间的交叉污染。

Conclusion: 该研究提出的方法在处理多重染色时表现出色，为mIHC RGB WSI的染色去卷积、定量评估标记物表达和细胞级读取提供了新的工具。

Abstract: Separating the contributions of individual chromogenic stains in RGB histology whole slide images (WSIs) is essential for stain normalization, quantitative assessment of marker expression, and cell-level readouts in immunohistochemistry (IHC). Classical Beer-Lambert (BL) color deconvolution is well-established for two- or three-stain settings, but becomes under-determined and unstable for multiplex IHC (mIHC) with K>3 chromogens. We present a simple, data-driven encoder-decoder architecture that learns cohort-specific stain characteristics for mIHC RGB WSIs and yields crisp, well-separated per-stain concentration maps. The encoder is a compact U-Net that predicts K nonnegative concentration channels; the decoder is a differentiable BL forward model with a learnable stain matrix initialized from typical chromogen hues. Training is unsupervised with a perceptual reconstruction objective augmented by loss terms that discourage unnecessary stain mixing. On a colorectal mIHC panel comprising 5 stains (H, CDX2, MUC2, MUC5, CD8) we show excellent RGB reconstruction, and significantly reduced inter-channel bleed-through compared with matrix-based deconvolution. Code and model are available at https://github.com/measty/StainQuant.git.

</details>


### [30] [Assessing Building Heat Resilience Using UAV and Street-View Imagery with Coupled Global Context Vision Transformer](https://arxiv.org/abs/2601.11357)
*Steffen Knoblauch,Ram Kumar Muthusamy,Hao Li,Iddy Chazua,Benedcto Adamu,Innocent Maholi,Alexander Zipf*

Main category: cs.CV

TL;DR: 本研究提出了一种结合UAV和SV图像，利用CGCViT模型评估城市建筑特征与热风险关系的方法，优于单模态模型，展示了通过机器学习识别和缓解基于材料的热暴露不平等的重要性。


<details>
  <summary>Details</summary>
Motivation: 由于气候变化加剧了城市地区的热暴露，特别是在全球南方的密集建筑区，迫切需要量化建筑物属性与健康风险之间的关系，以采取有效的适应策略。

Method: 采用CGCViT模型融合UAV和SV图像，结合TIR数据，通过机器学习识别建筑材料对热风险的影响。

Result: 该方法展示了UAV和SV视角在评估城市建筑特征上的互补视角，多项建筑特征（植被、屋顶材料等）与热风险显著相关。

Conclusion: 该研究突显了利用数据驱动风险评估塑造适应策略的重要性，以实现公平的结果，解决基于建筑材料的户内热暴露不平等现象。

Abstract: Climate change is intensifying human heat exposure, particularly in densely built urban centers of the Global South. Low-cost construction materials and high thermal-mass surfaces further exacerbate this risk. Yet scalable methods for assessing such heat-relevant building attributes remain scarce. We propose a machine learning framework that fuses openly available unmanned aerial vehicle (UAV) and street-view (SV) imagery via a coupled global context vision transformer (CGCViT) to learn heat-relevant representations of urban structures. Thermal infrared (TIR) measurements from HotSat-1 are used to quantify the relationship between building attributes and heat-associated health risks. Our dual-modality cross-view learning approach outperforms the best single-modality models by up to $9.3\%$, demonstrating that UAV and SV imagery provide valuable complementary perspectives on urban structures. The presence of vegetation surrounding buildings (versus no vegetation), brighter roofing (versus darker roofing), and roofing made of concrete, clay, or wood (versus metal or tarpaulin) are all significantly associated with lower HotSat-1 TIR values. Deployed across the city of Dar es Salaam, Tanzania, the proposed framework illustrates how household-level inequalities in heat exposure - often linked to socio-economic disadvantage and reflected in building materials - can be identified and addressed using machine learning. Our results point to the critical role of localized, data-driven risk assessment in shaping climate adaptation strategies that deliver equitable outcomes.

</details>


### [31] [Think-Clip-Sample: Slow-Fast Frame Selection for Video Understanding](https://arxiv.org/abs/2601.11359)
*Wenhui Tan,Ruihua Song,Jiaze Li,Jianzhong Ju,Zhenbo Luo*

Main category: cs.CV

TL;DR: TCS 提出了一种无需训练的框架，通过多查询推理和帧级慢速快速采样，有效提升了多模态大语言模型在长视频理解上的性能，提升了高达 6.9% 的准确率，同时减少了 50% 的推理时间。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型在长视频理解上存在性能局限，尤其是计算资源和帧选择方面的问题。TCS 旨在克服这些限制，以提升长视频的理解效果。

Method: TCS 采用多查询推理和帧级慢速快速采样两种方法。多查询推理用于生成多个查询以捕捉问题和视频的不同方面；帧级慢速快速采样则动态平衡了密集的局部细节与稀疏的全局语境。

Result: 在 MLVU, LongVideoBench 和 VideoMME 数据集上的实验证明，TCS 在不同多模态大语言模型上均能提升性能，最高可提升 6.9% 的准确率；并且能够在减少 50% 推理时间成本的情况下达到类似的准确性，显示出 TCS 在长视频理解方面的高效性和有效性。

Conclusion: TCS 提出的方法为长视频的理解提供了新的解决方案，通过优化查询生成和采样策略，显著提高了多模态大语言模型对长视频的理解能力，同时降低了计算成本。

Abstract: Recent progress in multi-modal large language models (MLLMs) has significantly advanced video understanding. However, their performance on long-form videos remains limited by computational constraints and suboptimal frame selection. We present Think-Clip-Sample (TCS), a training-free framework that enhances long video understanding through two key components: (i) Multi-Query Reasoning, which generates multiple queries to capture complementary aspects of the question and video; and (ii) Clip-level Slow-Fast Sampling, which adaptively balances dense local details and sparse global context. Extensive experiments on MLVU, LongVideoBench, and VideoMME demonstrate that TCS consistently improves performance across different MLLMs, boosting up to 6.9% accuracy, and is capable of achieving comparable accuracy with 50% fewer inference time cost, highlighting both efficiency and efficacy of TCS on long video understanding.

</details>


### [32] [Heterogeneous Uncertainty-Guided Composed Image Retrieval with Fine-Grained Probabilistic Learning](https://arxiv.org/abs/2601.11393)
*Haomiao Tang,Jinpeng Wang,Minyi Zhao,Guanghao Meng,Ruisheng Luo,Long Chen,Shu-Tao Xia*

Main category: cs.CV

TL;DR: 该论文提出了一种新颖的概率学习框架，称为HUG（Heterogeneous Uncertainty-Guided），通过细粒度的概率表示和适应多模态查询与单模态目标的不确定性估计，提高了图像检索的鲁棒性和精确度。


<details>
  <summary>Details</summary>
Motivation: 鉴于现有概率学习方法在图像检索中的局限性，特别是对于包含修改文本的图像检索（CIR）场景，本文旨在通过引入一种新的不确定性指导框架来克服这些问题，以提高模型的鲁棒性和准确性。

Method: HUG框架采用细粒度的高斯嵌入表示，能够捕捉查询和目标的详细概念和不确定性。它包括异质不确定性估计、精确的协同不确定性和综合负样本策略的细粒度对比，以实现全面的查询不确定性捕捉和增强判别学习。

Result: 实验结果表明，HUG框架在多个基准测试上的表现超越了现有最先进的模型，验证了其技术贡献的有效性。

Conclusion: 该论文成功地构建了一种新的图像检索方法HUG，该方法显著提高了在包含修改文本的图像检索中的精确度和鲁棒性。

Abstract: Composed Image Retrieval (CIR) enables image search by combining a reference image with modification text. Intrinsic noise in CIR triplets incurs intrinsic uncertainty and threatens the model's robustness. Probabilistic learning approaches have shown promise in addressing such issues; however, they fall short for CIR due to their instance-level holistic modeling and homogeneous treatment of queries and targets. This paper introduces a Heterogeneous Uncertainty-Guided (HUG) paradigm to overcome these limitations. HUG utilizes a fine-grained probabilistic learning framework, where queries and targets are represented by Gaussian embeddings that capture detailed concepts and uncertainties. We customize heterogeneous uncertainty estimations for multi-modal queries and uni-modal targets. Given a query, we capture uncertainties not only regarding uni-modal content quality but also multi-modal coordination, followed by a provable dynamic weighting mechanism to derive comprehensive query uncertainty. We further design uncertainty-guided objectives, including query-target holistic contrast and fine-grained contrasts with comprehensive negative sampling strategies, which effectively enhance discriminative learning. Experiments on benchmarks demonstrate HUG's effectiveness beyond state-of-the-art baselines, with faithful analysis justifying the technical contributions.

</details>


### [33] [SUG-Occ: An Explicit Semantics and Uncertainty Guided Sparse Learning Framework for Real-Time 3D Occupancy Prediction](https://arxiv.org/abs/2601.11396)
*Hanlin Wu,Pengfei Lin,Ehsan Javanmardi,Nanren Bao,Bo Qian,Hao Si,Manabu Tsukada*

Main category: cs.CV

TL;DR: 本文提出了一种名为SUG-Occ的占用预测框架，该框架通过利用3D场景的稀疏性减少冗余计算，同时保持几何和语义完整性。该方法通过多步机制，在保持高性能的同时提高了效率。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶向全场景理解迈进，3D语义占用预测成为关键感知任务，虽然能提供超越传统检测和分割的体素级语义，但这种精细表示对场景理解的计算和内存要求很高，阻碍了实时部署。因此，需要一种降低计算和内存负担的方法。

Method: SUG-Occ框架在每次变换视图时利用语义和不确定性先验抑制自由空间投影，使用显式无符号距离编码增强几何一致性，生成结构一致的稀疏3D表示。还通过层次交叉稀疏卷积和生成上采样设计了一个稀疏完成模块，实现从粗到细的高效推理。最后使用基于对象上下文表示（OCR）的掩码解码器聚合稀疏特征的全局语义上下文，通过轻量级查询上下文交互细化体素级预测。

Result: 在SemanticKITTI基准上的实验表明，所提出的方法优于基准模型，准确率提高了7.34%，效率提高了57.8%。

Conclusion: SUG-Occ框架通过上述机制，在保持高性能的同时提高了效率，为3D感知任务提供了实际部署的可能。

Abstract: As autonomous driving moves toward full scene understanding, 3D semantic occupancy prediction has emerged as a crucial perception task, offering voxel-level semantics beyond traditional detection and segmentation paradigms. However, such a refined representation for scene understanding incurs prohibitive computation and memory overhead, posing a major barrier to practical real-time deployment. To address this, we propose SUG-Occ, an explicit Semantics and Uncertainty Guided Sparse Learning Enabled 3D Occupancy Prediction Framework, which exploits the inherent sparsity of 3D scenes to reduce redundant computation while maintaining geometric and semantic completeness. Specifically, we first utilize semantic and uncertainty priors to suppress projections from free space during view transformation while employing an explicit unsigned distance encoding to enhance geometric consistency, producing a structurally consistent sparse 3D representation. Secondly, we design an cascade sparse completion module via hyper cross sparse convolution and generative upsampling to enable efficiently coarse-to-fine reasoning. Finally, we devise an object contextual representation (OCR) based mask decoder that aggregates global semantic context from sparse features and refines voxel-wise predictions via lightweight query-context interactions, avoiding expensive attention operations over volumetric features. Extensive experiments on SemanticKITTI benchmark demonstrate that the proposed approach outperforms the baselines, achieving a 7.34/% improvement in accuracy and a 57.8\% gain in efficiency.

</details>


### [34] [Wetland mapping from sparse annotations with satellite image time series and temporal-aware segment anything model](https://arxiv.org/abs/2601.11400)
*Shuai Yuan,Tianwu Lin,Shuang Chen,Yu Xia,Peng Qin,Xiangyu Liu,Xiaoqing Xu,Nan Xu,Hongsheng Zhang,Jie Wang,Peng Gong*

Main category: cs.CV

TL;DR: WetSAM 提出了一个基于 SAM 的框架，利用时间序列的卫星图像进行稀疏点标注下的湿地测绘，通过两个分支设计来消解季节性变化的影响，并生成结构化的一致性分割结果，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习模型在稀疏点标注下表现不佳，WetSAM 旨在解决这一问题，同时应对复杂的湿地动态变化。

Method: WetSAM 通过两个分支设计来提高湿地映射的准确性：一个时间触发的分支通过层次适配器和动态时间聚合来解耦湿地特性与植物周期变化；另一个空间分支使用时间约束的区域生长策略生成可靠的密集伪标签。此外，一个双向一致性正则化共同优化两分支。

Result: WetSAM 在八个大约 5,000 平方公里的全球区域的广泛实验中表现出色，平均 F1 分数达到了 85.58%，并且能够实现高质量、结构化的一致性湿地分割，同时减少标注工作。

Conclusion: WetSAM 显示出强大的泛化能力，并具有实现高效、低成本、高分辨率湿地测绘的潜力。

Abstract: Accurate wetland mapping is essential for ecosystem monitoring, yet dense pixel-level annotation is prohibitively expensive and practical applications usually rely on sparse point labels, under which existing deep learning models perform poorly, while strong seasonal and inter-annual wetland dynamics further render single-date imagery inadequate and lead to significant mapping errors; although foundation models such as SAM show promising generalization from point prompts, they are inherently designed for static images and fail to model temporal information, resulting in fragmented masks in heterogeneous wetlands. To overcome these limitations, we propose WetSAM, a SAM-based framework that integrates satellite image time series for wetland mapping from sparse point supervision through a dual-branch design, where a temporally prompted branch extends SAM with hierarchical adapters and dynamic temporal aggregation to disentangle wetland characteristics from phenological variability, and a spatial branch employs a temporally constrained region-growing strategy to generate reliable dense pseudo-labels, while a bidirectional consistency regularization jointly optimizes both branches. Extensive experiments across eight global regions of approximately 5,000 km2 each demonstrate that WetSAM substantially outperforms state-of-the-art methods, achieving an average F1-score of 85.58%, and delivering accurate and structurally consistent wetland segmentation with minimal labeling effort, highlighting its strong generalization capability and potential for scalable, low-cost, high-resolution wetland mapping.

</details>


### [35] [Map2Thought: Explicit 3D Spatial Reasoning via Metric Cognitive Maps](https://arxiv.org/abs/2601.11442)
*Xiangjun Gao,Zhensong Zhang,Dave Zhenyu Chen,Songcen Xu,Long Quan,Eduardo Pérez-Pellitero,Youngkyoon Jang*

Main category: cs.CV

TL;DR: Map2Thought 引入了一种框架，通过 Metric Cognitive Map 和 Cognitive Chain-of-Thought 来增强 3D VLM 的空间推理能力，实现可解释的三维理解。


<details>
  <summary>Details</summary>
Motivation: 当前的 3D VLM 在空间推理方面存在不足，尤其是在减少监督数据时，其性能会大幅下降。因此，提出 Map2Thought 增强了模型的空间推理能力，以改善其在减少监督数据情况下的性能。

Method: Map2Thought 采用 Metric Cognitive Map 和 Cognitive Chain-of-Thought 两个关键组件。Metric Cognitive Map 利用离散网格进行关系推理，同时保持连续的、基于度量的空间表示。Cognitive Chain-of-Thought 通过确定性操作，如向量操作、边界框距离和遮挡感知外观顺序提示，进行显式的几何推理。

Result: 实验证明，Map2Thought 能够实现可解释的三维理解，仅用一半的监督数据就达到了 59.9% 的准确率，接近使用完整数据集训练的基线模型（60.9%）。在不同比例训练数据下的实验表明，它分别比最先进的方法提高了 5.3%，4.8% 和 4.0% 的准确率。

Conclusion: Map2Thought 提供了一种增强 3D VLM 空间推理能力的方法，显著提高了模型在有限监督下的性能。

Abstract: We propose Map2Thought, a framework that enables explicit and interpretable spatial reasoning for 3D VLMs. The framework is grounded in two key components: Metric Cognitive Map (Metric-CogMap) and Cognitive Chain-of-Thought (Cog-CoT). Metric-CogMap provides a unified spatial representation by integrating a discrete grid for relational reasoning with a continuous, metric-scale representation for precise geometric understanding. Building upon the Metric-CogMap, Cog-CoT performs explicit geometric reasoning through deterministic operations, including vector operations, bounding-box distances, and occlusion-aware appearance order cues, producing interpretable inference traces grounded in 3D structure. Experimental results show that Map2Thought enables explainable 3D understanding, achieving 59.9% accuracy using only half the supervision, closely matching the 60.9% baseline trained with the full dataset. It consistently outperforms state-of-the-art methods by 5.3%, 4.8%, and 4.0% under 10%, 25%, and 50% training subsets, respectively, on the VSI-Bench.

</details>


### [36] [MHA2MLA-VLM: Enabling DeepSeek's Economical Multi-Head Latent Attention across Vision-Language Models](https://arxiv.org/abs/2601.11464)
*Xiaoran Fan,Zhichao Sun,Tao Ji,Lixing Shen,Tao Gui*

Main category: cs.CV

TL;DR: MHA2MLA-VLM通过创新的模态自适应部分RoPE策略和模态解耦低秩逼近方法，将现成的视觉-语言模型高效转换为MLA架构，同时通过参数优化减少适配成本，并实验证明该方法能在极少量的监督数据下恢复原始模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型在处理复杂多模态任务时，随着关键值（KV）缓存的增长，出现了严重的内存和计算瓶颈。MHA2MLA-VLM提出了一个高效且模态感知的框架来转换现成的视觉-语言模型到MLA架构，以解决这些瓶颈问题。

Method: 该方法采用模态自适应部分相对位置编码（RoPE）策略和模态解耦低秩逼近方法来压缩视觉和文本的KV空间。同时引入了基于参数效率的微调策略，以减少适配成本。

Result: 广泛的实验表明，MHA2MLA-VLM能够以极少量的监督数据恢复原始模型性能，并显著减少了KV缓存的大小。该方法还可以与KV量化无缝集成。

Conclusion: MHA2MLA-VLM提供了一种有效的方法来克服视觉-语言模型在多模态任务中的内存和计算限制，同时保持或甚至提升模型性能。

Abstract: As vision-language models (VLMs) tackle increasingly complex and multimodal tasks, the rapid growth of Key-Value (KV) cache imposes significant memory and computational bottlenecks during inference. While Multi-Head Latent Attention (MLA) offers an effective means to compress the KV cache and accelerate inference, adapting existing VLMs to the MLA architecture without costly pretraining remains largely unexplored. In this work, we present MHA2MLA-VLM, a parameter-efficient and multimodal-aware framework for converting off-the-shelf VLMs to MLA. Our approach features two core techniques: (1) a modality-adaptive partial-RoPE strategy that supports both traditional and multimodal settings by selectively masking nonessential dimensions, and (2) a modality-decoupled low-rank approximation method that independently compresses the visual and textual KV spaces. Furthermore, we introduce parameter-efficient fine-tuning to minimize adaptation cost and demonstrate that minimizing output activation error, rather than parameter distance, substantially reduces performance loss. Extensive experiments on three representative VLMs show that MHA2MLA-VLM restores original model performance with minimal supervised data, significantly reduces KV cache footprint, and integrates seamlessly with KV quantization.

</details>


### [37] [ReScene4D: Temporally Consistent Semantic Instance Segmentation of Evolving Indoor 3D Scenes](https://arxiv.org/abs/2601.11508)
*Emily Steiner,Jianhao Zheng,Henry Howard-Jenkins,Chris Xie,Iro Armeni*

Main category: cs.CV

TL;DR: 本文提出了一个用于4D室内语义实例分割的新任务，即在稀疏时间观测下进行语义实例分割，并提出了一种名为ReScene4D的方法，该方法无需密集观察即可适应4D语义分割。实验表明，该方法不仅能够实现连续实例跟踪，还能提高标准3D分割的质量。


<details>
  <summary>Details</summary>
Motivation: 为了在室内环境动态变化时，捕捉并维护跨时间间隔的实例身份一致性，本文提出了4D室内语义实例分割任务，旨在解决现有技术所需的离散匹配步骤以及4D LiDAR方法依赖高频时间测量的问题。

Method: 提出的ReScene4D方法通过引入新的策略，在稀疏时间观测下共享信息，从而在不依赖密集观测的情况下成功实现实例分割与跟踪。该方法通过利用上下文信息提升了语义分割的质量。

Result: ReScene4D方法在3RScan数据集上达到了领先的表现，并且定义了一种新的评估指标t-mAP，以奖励时间身份一致性。这表明ReScene4D方法在室内场景动态理解方面是一个重要的进步。

Conclusion: 本文提出的方法和任务对于理解室内场景的动态变化具有重要意义，为实现更高精度的语义分割提供了新途径。

Abstract: Indoor environments evolve as objects move, appear, or disappear. Capturing these dynamics requires maintaining temporally consistent instance identities across intermittently captured 3D scans, even when changes are unobserved. We introduce and formalize the task of temporally sparse 4D indoor semantic instance segmentation (SIS), which jointly segments, identifies, and temporally associates object instances. This setting poses a challenge for existing 3DSIS methods, which require a discrete matching step due to their lack of temporal reasoning, and for 4D LiDAR approaches, which perform poorly due to their reliance on high-frequency temporal measurements that are uncommon in the longer-horizon evolution of indoor environments. We propose ReScene4D, a novel method that adapts 3DSIS architectures for 4DSIS without needing dense observations. It explores strategies to share information across observations, demonstrating that this shared context not only enables consistent instance tracking but also improves standard 3DSIS quality. To evaluate this task, we define a new metric, t-mAP, that extends mAP to reward temporal identity consistency. ReScene4D achieves state-of-the-art performance on the 3RScan dataset, establishing a new benchmark for understanding evolving indoor scenes.

</details>


### [38] [ShapeR: Robust Conditional 3D Shape Generation from Casual Captures](https://arxiv.org/abs/2601.11514)
*Yawar Siddiqui,Duncan Frost,Samir Aroudj,Armen Avetisyan,Henry Howard-Jenkins,Daniel DeTone,Pierre Moulon,Qirui Wu,Zhengqin Li,Julian Straub,Richard Newcombe,Jakob Engel*

Main category: cs.CV

TL;DR: ShapeR 是一种新颖的方法，可以从随意拍摄的图像序列中生成3D对象形状，通过结合多模态数据并采用自监督增强和 curriculum 训练，显著提高了在无序数据下的3D形状生成效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法大多需要干净、未遮挡和良好分割的输入，这在真实场景中很少见，因此需要开发一种可以从随意拍摄的照片中生成3D对象形状的方法。

Method: 通过结合视觉-惯性SLAM、3D检测算法和视觉-语言模型，提取每个对象的稀疏SLAM点、姿态多视图图像和机器生成的描述。然后，采用校准的流变压器对其进行训练，以条件处理这些模态，生成高保真度的度量3D形状。

Result: 在无序数据场景下，ShapeR 避免了现有方法的限制，表现出色。实验证明，相比目前最先进的方法，它在惜分距离上提高了2.7倍。

Conclusion: ShapeR 引入了一种新颖的方法，能够在大量具有挑战性的场景中生成高质量的3D对象形状。

Abstract: Recent advances in 3D shape generation have achieved impressive results, but most existing methods rely on clean, unoccluded, and well-segmented inputs. Such conditions are rarely met in real-world scenarios. We present ShapeR, a novel approach for conditional 3D object shape generation from casually captured sequences. Given an image sequence, we leverage off-the-shelf visual-inertial SLAM, 3D detection algorithms, and vision-language models to extract, for each object, a set of sparse SLAM points, posed multi-view images, and machine-generated captions. A rectified flow transformer trained to effectively condition on these modalities then generates high-fidelity metric 3D shapes. To ensure robustness to the challenges of casually captured data, we employ a range of techniques including on-the-fly compositional augmentations, a curriculum training scheme spanning object- and scene-level datasets, and strategies to handle background clutter. Additionally, we introduce a new evaluation benchmark comprising 178 in-the-wild objects across 7 real-world scenes with geometry annotations. Experiments show that ShapeR significantly outperforms existing approaches in this challenging setting, achieving an improvement of 2.7x in Chamfer distance compared to state of the art.

</details>


### [39] [UniX: Unifying Autoregression and Diffusion for Chest X-Ray Understanding and Generation](https://arxiv.org/abs/2601.11522)
*Ruiheng Zhang,Jingfeng Yao,Huangxuan Zhao,Hao Yan,Xiao He,Lei Chen,Zhou Wei,Yong Luo,Zengmao Wang,Lefei Zhang,Dacheng Tao,Bo Du*

Main category: cs.CV

TL;DR: UniX 是一种新的统一医学基础模型，它通过解耦理解和生成任务，并引入跨模态自注意力机制来动态引导生成过程，从而实现医疗影像理解与生成的协同合作，同时参数量仅有任务特定模型的一 quarter。


<details>
  <summary>Details</summary>
Motivation: 当前的医疗基础模型在视觉理解和生成之间存在冲突，UniX 通过解耦这两个任务，引入跨模态自注意力机制，以及严格的清洗管道和多阶段训练策略，旨在解决这一问题。

Method: UniX 通过建立一个解耦的理解分支和高保真生成分支，利用 diffusion 模型并将理解特征动态地引导生成过程。此外，进行了数据清洗和多阶段训练。

Result: 在两个代表性基准测试中，UniX 达到了 46.1% 的理解性能提升（Micro-F1）和 24.2% 的生成质量提升（FD-RadDino），且参数仅为 LLM-CXR 的 1/4。

Conclusion: UniX 建立了一个可扩展的框架，能够同时实现医疗影像理解和生成的高性能，展现了统一模型在该领域的潜力。

Abstract: Despite recent progress, medical foundation models still struggle to unify visual understanding and generation, as these tasks have inherently conflicting goals: semantic abstraction versus pixel-level reconstruction. Existing approaches, typically based on parameter-shared autoregressive architectures, frequently lead to compromised performance in one or both tasks. To address this, we present UniX, a next-generation unified medical foundation model for chest X-ray understanding and generation. UniX decouples the two tasks into an autoregressive branch for understanding and a diffusion branch for high-fidelity generation. Crucially, a cross-modal self-attention mechanism is introduced to dynamically guide the generation process with understanding features. Coupled with a rigorous data cleaning pipeline and a multi-stage training strategy, this architecture enables synergistic collaboration between tasks while leveraging the strengths of diffusion models for superior generation. On two representative benchmarks, UniX achieves a 46.1% improvement in understanding performance (Micro-F1) and a 24.2% gain in generation quality (FD-RadDino), using only a quarter of the parameters of LLM-CXR. By achieving performance on par with task-specific models, our work establishes a scalable paradigm for synergistic medical image understanding and generation. Codes and models are available at https://github.com/ZrH42/UniX.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [40] [LLMs for Game Theory: Entropy-Guided In-Context Learning and Adaptive CoT Reasoning](https://arxiv.org/abs/2601.10775)
*Tommaso Felice Banfi,Sashenka Gamage*

Main category: cs.CL

TL;DR: 提出了一种基于LLM的新颖框架，用于解决离散博弈理论任务，并通过Tic-Tac-Toe进行了验证。该方法结合了上下文学习、熵导向的链式思考推理和自适应上下文检索，实验证明这种熵导向的自适应推理在与次优算法对手的比较中显著提高了决策质量。


<details>
  <summary>Details</summary>
Motivation: 当前主流的LLM在处理复杂决策任务时缺乏有效的自适应推理机制，特别是在不确定性高的情况下，无法生成高效的策略。因此，研究者希望提出一种能够根据不确定性动态调整推理路径的新型框架，以提升复杂环境下的决策质量。

Method: 研究者提出了一种融合了上下文学习、熵导向的链式思考推理和自适应上下文检索的LLM框架。具体而言，模型会根据文本层面的不确定性动态调整检索到的实例数量和推理路径。在不确定性低时采用简洁的推理路径，在不确定性高时启动多路径链式思考探索。

Result: 实验结果显示，使用熵导向的自适应推理方法相较于基本的LLM显著提高了决策质量，平均游戏结果从-11.6%提升到了+9.5%。此外，在100次游戏中，平均只需要较少的LLM查询次数。统计验证显著性并且相关性分析显示，文本层面的熵与棋步最优性呈负相关。

Conclusion: 研究结合实验数据和分析证明，不确定性导向的自适应推理方法能有效在离散决策环境下增强LLM的表现，这为提升模型在复杂环境中的决策能力提供了新的思路。

Abstract: We propose a novel LLM-based framework for reasoning in discrete, game-theoretic tasks, illustrated with \emph{Tic-Tac-Toe}. The method integrates in-context learning with entropy-guided chain-of-thought (CoT) reasoning and adaptive context retrieval. The model dynamically adjusts both the number of retrieved examples and reasoning paths according to token-level uncertainty: concise reasoning with minimal context is used when uncertainty is low, whereas higher uncertainty triggers expanded multi-path CoT exploration. Experimental evaluation against a sub-optimal algorithmic opponent shows that entropy-aware adaptive reasoning substantially improves decision quality, increasing the average game outcome from \(-11.6\%\) with the baseline LLM to \(+9.5\%\) with entropy-guided adaptive reasoning over 100 games (win = +1, tie = 0, loss = -1), while maintaining a relatively low number of LLM queries per game. Statistical validation confirms that the improvement is significant, and correlation analysis reveals a negative association between token-level entropy and move optimality. These findings demonstrate that uncertainty-guided adaptive reasoning effectively enhances LLM performance in sequential decision-making environments.

</details>


### [41] [EncodeRec: An Embedding Backbone for Recommendation Systems](https://arxiv.org/abs/2601.10837)
*Guy Hadad,Neomi Rabaev,Bracha Shapira*

Main category: cs.CL

TL;DR: EncodeRec 使用冻结预训练语言模型参数的方法学习物品描述的紧凑且具有信息性的嵌入表示，提高了推荐任务的效果。


<details>
  <summary>Details</summary>
Motivation: 预训练语言模型（PLMs）生成的嵌入表示在推荐任务中的效果不佳，因为它们不能产生结构化的区分嵌入空间，且过于通用，无法捕捉推荐任务所需的领域特定语义。

Method: EncodeRec 方法保持预训练语言模型参数不进行更新，直接从物品描述中学习嵌入表示，包括序列推荐模型和语义 ID 分割任务。

Result: 在多个推荐基准测试中，EncodeRec 显著优于基于 PLM 和嵌入模型的基线，展示了其作为序列推荐模型基础和语义 ID 分割的有效性。

Conclusion: 嵌入表示的适配在弥合通用预训练语言模型和实用推荐系统之间的差距中起着关键作用。

Abstract: Recent recommender systems increasingly leverage embeddings from large pre-trained language models (PLMs). However, such embeddings exhibit two key limitations: (1) PLMs are not explicitly optimized to produce structured and discriminative embedding spaces, and (2) their representations remain overly generic, often failing to capture the domain-specific semantics crucial for recommendation tasks. We present EncodeRec, an approach designed to align textual representations with recommendation objectives while learning compact, informative embeddings directly from item descriptions. EncodeRec keeps the language model parameters frozen during recommender system training, making it computationally efficient without sacrificing semantic fidelity. Experiments across core recommendation benchmarks demonstrate its effectiveness both as a backbone for sequential recommendation models and for semantic ID tokenization, showing substantial gains over PLM-based and embedding model baselines. These results underscore the pivotal role of embedding adaptation in bridging the gap between general-purpose language models and practical recommender systems.

</details>


### [42] [DialDefer: A Framework for Detecting and Mitigating LLM Dialogic Deference](https://arxiv.org/abs/2601.10896)
*Parisa Rabbani,Priyam Sahoo,Ruben Mathew,Aishee Mondal,Harshita Ketharaman,Nimet Beyza Bozdag,Dilek Hakkani-Tür*

Main category: cs.CL

TL;DR: 这项研究揭示了语言模型（LLM）在对话场景中判断同一声明时，由于呈现方式不同导致的判断差异。研究引入了对话性歧见（DialDefer）框架及对话性歧见评分（DDS）来检测和减轻这种判断偏向，并发现这些偏差在自然对话中更为显著。尝试减轻这种偏差的方法可能导致过度矫正。


<details>
  <summary>Details</summary>
Motivation: 由于语言模型在对话评估中表现出的不一致性，研究旨在探索语言模型判断差异的根源，并提出相应的缓解措施。

Method: 研究通过对比验证和归属两种情境下，评估模型对相同声明的判断，定义并计算对话性歧见评分，并进行跨领域模型比较实验，揭示偏差趋势。

Result: 研究发现对话性偏差在自然对话中更为显著，且不同模型在不同领域表现出不同倾向。影响最大的因素是人类与语言模型之间的归因差异。进一步的消除尝试虽然有效果但可能过度矫正。

Conclusion: 研究揭示语言模型对话评估判断偏差的重要来源，并提供了减轻这些偏差的方法。同时，表明该问题需要在准确性之外的层面进行校准。

Abstract: LLMs are increasingly used as third-party judges, yet their reliability when evaluating speakers in dialogue remains poorly understood. We show that LLMs judge identical claims differently depending on framing: the same content elicits different verdicts when presented as a statement to verify ("Is this statement correct?") versus attributed to a speaker ("Is this speaker correct?"). We call this dialogic deference and introduce DialDefer, a framework for detecting and mitigating these framing-induced judgment shifts. Our Dialogic Deference Score (DDS) captures directional shifts that aggregate accuracy obscures. Across nine domains, 3k+ instances, and four models, conversational framing induces large shifts (|DDS| up to 87pp, p < .0001) while accuracy remains stable (<2pp), with effects amplifying 2-4x on naturalistic Reddit conversations. Models can shift toward agreement (deference) or disagreement (skepticism) depending on domain -- the same model ranges from DDS = -53 on graduate-level science to +58 on social judgment. Ablations reveal that human-vs-LLM attribution drives the largest shifts (17.7pp swing), suggesting models treat disagreement with humans as more costly than with AI. Mitigation attempts reduce deference but can over-correct into skepticism, framing this as a calibration problem beyond accuracy optimization.

</details>


### [43] [Massively Multilingual Joint Segmentation and Glossing](https://arxiv.org/abs/2601.10925)
*Michael Ginn,Lindia Tjuatja,Enora Rice,Ali Marashian,Maria Valentini,Jasmine Xu,Graham Neubig,Alexis Palmer*

Main category: cs.CL

TL;DR: 本研究首次开发了一种联合预测句间注释和音节分割的神经模型，通过优化训练方法和扩展语料库，PolyGloss在多个任务上均表现出色，并且可以快速适应新数据。


<details>
  <summary>Details</summary>
Motivation: 现有模型在自动句间注释预测方面虽取得了一定进展，但在实际应用中仍存在关键障碍。研究旨在克服这些障碍，提高模型的实用性。

Method: 该研究通过扩展GlossLM的训练语料库，并引入预训练模型PolyGloss，同时优化了分割与注释预测的平衡方法。

Result: PolyGloss在句间注释和音节分割任务上表现出色，优于GlossLM及其他开源的LLM。

Conclusion: PolyGloss能够快速适应新的数据集，展示了其在跨多种语言任务中的潜力。

Abstract: Automated interlinear gloss prediction with neural networks is a promising approach to accelerate language documentation efforts. However, while state-of-the-art models like GlossLM achieve high scores on glossing benchmarks, user studies with linguists have found critical barriers to the usefulness of such models in real-world scenarios. In particular, existing models typically generate morpheme-level glosses but assign them to whole words without predicting the actual morpheme boundaries, making the predictions less interpretable and thus untrustworthy to human annotators.
  We conduct the first study on neural models that jointly predict interlinear glosses and the corresponding morphological segmentation from raw text. We run experiments to determine the optimal way to train models that balance segmentation and glossing accuracy, as well as the alignment between the two tasks. We extend the training corpus of GlossLM and pretrain PolyGloss, a family of seq2seq multilingual models for joint segmentation and glossing that outperforms GlossLM on glossing and beats various open-source LLMs on segmentation, glossing, and alignment. In addition, we demonstrate that PolyGloss can be quickly adapted to a new dataset via low-rank adaptation.

</details>


### [44] [Selecting Language Models for Social Science: Start Small, Start Open, and Validate](https://arxiv.org/abs/2601.10926)
*Dustin S. Stoltz,Marshall A. Taylor,Sanuj Kumar*

Main category: cs.CL

TL;DR: 该论文探讨了大型预训练语言模型的选择标准，认为验证性、可靠性、可重复性和再现性是关键。建议从开放的小型模型开始，并使用限定基准来证明整个计算管道的有效性。


<details>
  <summary>Details</summary>
Motivation: 论文旨在引导社会科学家如何在众多大型预训练语言模型中进行选择。当前，大量的语言模型数量繁多，如何优选合适的模型成为了研究者面临的一个重大挑战。

Method: 论文通过分析语言模型的关键特性，如模型开放性、模型成本、训练数据和模型架构等，结合使用前期验证（基准测验）与后期验证（再现性）的方法，提出了一套选择模型的标准。

Result: 论文研究表明，可重复性和再现性对于选择语言模型尤为重要。从更开放的小型模型开始，并建立限定基准，可以验证整个计算管道的有效性。

Conclusion: 论文强调了在构建社会科学研究中的计算工具时，应更加注重模型的可靠性和可重复性，以便获得可信的研究结果。

Abstract: Currently, there are thousands of large pretrained language models (LLMs) available to social scientists. How do we select among them? Using validity, reliability, reproducibility, and replicability as guides, we explore the significance of: (1) model openness, (2) model footprint, (3) training data, and (4) model architectures and fine-tuning. While ex-ante tests of validity (i.e., benchmarks) are often privileged in these discussions, we argue that social scientists cannot altogether avoid validating computational measures (ex-post). Replicability, in particular, is a more pressing guide for selecting language models. Being able to reliably replicate a particular finding that entails the use of a language model necessitates reliably reproducing a task. To this end, we propose starting with smaller, open models, and constructing delimited benchmarks to demonstrate the validity of the entire computational pipeline.

</details>


### [45] [Multi-Stage Patient Role-Playing Framework for Realistic Clinical Interactions](https://arxiv.org/abs/2601.10951)
*Shijie Jiang,Zefan Zhang,Kehua Zhu,Tian Bai,Ruihong Zhao*

Main category: cs.CL

TL;DR: 该研究提出了首个基于真实临床场景的中文病人模拟数据集Ch-PatientSim，并提出了一种无需训练的多阶段病人角色扮演框架MSPRP，以提高LLM在患者行为模拟中的个性化和真实性。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖于通用或LLM生成的对话数据，无法完全评估模型在临床互动中的真实性。因此，研究旨在构建一个真实性更高的数据集以覆盖更广泛的医生与病人互动场景。

Method: 构建了一个包含五个维度人物结构的病人模拟数据集Ch-PatientSim，并提出了一种多阶段病人角色扮演框架MSPRP，该框架将互动分成三个阶段进行分解。

Result: 实验结果表明，使用Ch-PatientSim和MSPRP框架可以显著提升模型在患者行为模拟方面的性能。

Conclusion: 该研究为LLM的临床应用提供了更真实、全面的评估手段，并提出了适用于此类评估的改进方法。

Abstract: The simulation of realistic clinical interactions plays a pivotal role in advancing clinical Large Language Models (LLMs) and supporting medical diagnostic education. Existing approaches and benchmarks rely on generic or LLM-generated dialogue data, which limits the authenticity and diversity of doctor-patient interactions. In this work, we propose the first Chinese patient simulation dataset (Ch-PatientSim), constructed from realistic clinical interaction scenarios to comprehensively evaluate the performance of models in emulating patient behavior. Patients are simulated based on a five-dimensional persona structure. To address issues of the persona class imbalance, a portion of the dataset is augmented using few-shot generation, followed by manual verification. We evaluate various state-of-the-art LLMs and find that most produce overly formal responses that lack individual personality. To address this limitation, we propose a training-free Multi-Stage Patient Role-Playing (MSPRP) framework, which decomposes interactions into three stages to ensure both personalization and realism in model responses. Experimental results demonstrate that our approach significantly improves model performance across multiple dimensions of patient simulation.

</details>


### [46] [Steering Language Models Before They Speak: Logit-Level Interventions](https://arxiv.org/abs/2601.10960)
*Hyeseon An,Shinwoo Park,Hyundong Jin,Yo-Sub Han*

Main category: cs.CL

TL;DR: 本文提出了一种在推理时无需训练的统计令牌得分表方法，通过调整解码分布来实现可控生成，适用于复杂性、正式性和毒性等任务。


<details>
  <summary>Details</summary>
Motivation: 当前的控制方法如基于提示和基于激活的方法存在一些局限，本文旨在提供一个无需训练的、在推理时通过分位数调整逻辑分值的统计方法，以提高可控性。

Method: 本文提出了一种基于z标准化逻辑优势比的统计令牌分值表，在推理时调整解码分布，实现可控生成。

Result: 实证评价显示，该方法在三种不同数据集上（复杂性、正式性和毒性）均能有效控制输出特性，结果表明统计支持的逻辑干预可实现显著提高的可控性：最高达到47%的准确率提升和50倍的F1分数提升。

Conclusion: 该方法在多个任务上展示了广泛适用性和任务无关性，提供了有效的解决方案来实现可控生成。

Abstract: Steering LLMs is essential for specialized applications such as style-sensitive text rewriting, user-adaptive communication, and toxicity mitigation. Current steering methods, such as prompting-based and activation-based approaches, are widely used to guide model behavior. However, activation-based techniques require deep access to internal layers, while prompting-based steering often fails to provide consistent or fine-grained control. In order to address these limitations, we propose a training-free inference-time logit intervention for controllable generation. Our approach utilizes a statistical token score table derived from z-normalized log-odds of labeled corpora to shift the decoding distribution. Empirical evaluations across three diverse datasets focusing on writing complexity, formality, and toxicity demonstrate that our method effectively steers output characteristics, confirming its broad applicability and task-agnostic nature. Our results show that statistically grounded logit steering can achieve large, consistent, and multi-task control gains: up to +47%p accuracy and 50x f1 improvement.

</details>


### [47] [ZPD Detector: Data Selection via Capability-Difficulty Alignment for Large Language Models](https://arxiv.org/abs/2601.10986)
*Bo Yang,Yunkui Chen,Lanfei Feng,Yu Zhang,Shijian Li*

Main category: cs.CL

TL;DR: 该研究提出了一种ZPD Detector数据选择框架，基于Zone of Proximal Development (ZPD)理论，通过考虑样本难度与模型能力之间的动态匹配来选择最有信息量的样本，提高了数据使用效率，并为训练策略设计提供了新见解。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的训练成本不断上升和高质量训练数据的稀缺性增加，如何在有限的数据预算下选择高价值样本或有效合成训练数据成为了关键研究问题。现有的方法大多依赖静态标准，未能建模模型与数据之间的动态关系。

Method: ZPD Detector框架通过融合难度校准、基于项目反应理论（IRT）的模型能力估计，以及能力-难度匹配评分，从模型和数据的双向视角来动态识别每个学习阶段的最有信息量样本。该方法能提高数据使用的效率。

Result: ZPD Detector框架在多个基准任务上展示了优于传统静态标准方法的性能，通过动态匹配策略为训练策略设计提供了新的视角。

Conclusion: ZPD Detector为解决在有限数据下选择高性能样本问题提出了一种新型框架，展现了在当前数据挑战下的应用潜力。

Abstract: As the cost of training large language models continues to increase and high-quality training data become increasingly scarce, selecting high-value samples or synthesizing effective training data under limited data budgets has emerged as a critical research problem. Most existing data selection methods rely on static criteria, such as difficulty, uncertainty, or heuristics, and fail to model the evolving relationship between the model and the data. Inspired by the educational theory of the Zone of Proximal Development (ZPD), we propose ZPD Detector, a data selection framework that adopts a bidirectional perspective between models and data by explicitly modeling the alignment between sample difficulty and the model's current capability. ZPD Detector integrates difficulty calibration, model capability estimation based on Item Response Theory (IRT), and a capability-difficulty matching score to dynamically identify the most informative samples at each learning stage, improving data utilization efficiency; moreover, this dynamic matching strategy provides new insights into training strategy design. All code and data will be released after our work be accepted to support reproducible researc

</details>


### [48] [When Personalization Misleads: Understanding and Mitigating Hallucinations in Personalized LLMs](https://arxiv.org/abs/2601.11000)
*Zhongxiang Sun,Yi Zhan,Chenglei Shen,Weijie Yu,Xiao Zhang,Ming He,Jun Xu*

Main category: cs.CL

TL;DR: 该研究提出了FPPS方法，一种轻量级的推理时策略，能够减轻个性化带来的事实偏差，同时保留个性化行为。并介绍了PFQABench基准，用于联合评估事实和个性化问答。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决个性化语言模型在面对事实查询时产生的个人偏好替代客观事实的问题，这种现象被称为个性化诱导的幻觉，这会影响事实的可靠性并传播错误信念。

Method: 研究采用了一种轻量级的推理时方法FPPS，通过在推理过程中调整模型的输出来减轻这一问题，同时保持个性化行为。

Result: 实验表明，FPPS方法在多个语言模型和个性化策略下显著提高了事实准确性，同时保持了个性化性能。

Conclusion: 该研究为解决个性化语言模型在面对事实查询时的可靠性问题提供了一种可行的方法，并通过PFQABench基准展示了其有效性。

Abstract: Personalized large language models (LLMs) adapt model behavior to individual users to enhance user satisfaction, yet personalization can inadvertently distort factual reasoning. We show that when personalized LLMs face factual queries, there exists a phenomenon where the model generates answers aligned with a user's prior history rather than the objective truth, resulting in personalization-induced hallucinations that degrade factual reliability and may propagate incorrect beliefs, due to representational entanglement between personalization and factual representations. To address this issue, we propose Factuality-Preserving Personalized Steering (FPPS), a lightweight inference-time approach that mitigates personalization-induced factual distortions while preserving personalized behavior. We further introduce PFQABench, the first benchmark designed to jointly evaluate factual and personalized question answering under personalization. Experiments across multiple LLM backbones and personalization methods show that FPPS substantially improves factual accuracy while maintaining personalized performance.

</details>


### [49] [Redefining Machine Simultaneous Interpretation: From Incremental Translation to Human-Like Strategies](https://arxiv.org/abs/2601.11002)
*Qianen Zhang,Zeyu Yang,Satoshi Nakamura*

Main category: cs.CL

TL;DR: 本文提出了一种扩展的SiMT方法，通过引入四种自适应动作（Sentence_Cut、Drop、Partial_Summarization和Pronominalization），使实时机器翻译能够在保持语义保真的同时进行重构、省略和简化。实验表明该方法在多个基准上提高了语义指标并减少了延迟。


<details>
  <summary>Details</summary>
Motivation: 传统的SiMT方法无法满足实时翻译时对高质量和速度的要求。

Method: 提出了四种自适应动作，通过构建带有动作感知提示的大型语言模型框架进行训练，并开发了延迟感知的TTS流水线来评估实时性。

Result: 实验结果显示，该方法在多个基准上提高了语义指标并减少了延迟，尤其是Drop和Sentence_Cut的结合在流畅性和延迟之间提供了更好的平衡。

Conclusion: 该方法为解决实时机器翻译中语义和实时性之间的冲突提供了新的思路。

Abstract: Simultaneous Machine Translation (SiMT) requires high-quality translations under strict real-time constraints, which traditional policies with only READ/WRITE actions cannot fully address. We extend the action space of SiMT with four adaptive actions: Sentence_Cut, Drop, Partial_Summarization and Pronominalization, which enable real-time restructuring, omission, and simplification while preserving semantic fidelity. We adapt these actions in a large language model (LLM) framework and construct training references through action-aware prompting. To evaluate both quality and word-level monotonicity, we further develop a latency-aware TTS pipeline that maps textual outputs to speech with realistic timing. Experiments on the ACL60/60 English-Chinese, English-German and English-Japanese benchmarks show that our framework consistently improves semantic metrics and achieves lower delay compared to reference translations and salami-based baselines. Notably, combining Drop and Sentence_Cut leads to consistent improvements in the balance between fluency and latency. These results demonstrate that enriching the action space of LLM-based SiMT provides a promising direction for bridging the gap between human and machine interpretation.

</details>


### [50] [NAACL: Noise-AwAre Verbal Confidence Calibration for LLMs in RAG Systems](https://arxiv.org/abs/2601.11004)
*Jiayu Liu,Rui Wang,Qing Zong,Qingcheng Zeng,Tianshi Zheng,Haochen Shi,Dadi Guo,Baixuan Xu,Chunyang Li,Yangqiu Song*

Main category: cs.CL

TL;DR: 该研究系统地研究了四种基准模型的校准性能，发现由于检索到的上下文噪声，LLMs表现为较差的校准能力，容易产生过度自信。为此提出NAACL规则框架，通过监督微调改进模型的内在噪声意识。


<details>
  <summary>Details</summary>
Motivation: 由于LLMs在关键领域的应用需求，需要准确评估模型的置信度。

Method: 通过系统地研究四种基准模型，分析LLMs在RAG设置下的校准问题，识别出由于噪声检索上下文导致的虚假置信问题，并提出NAACL噪声感知信心校准规则框架。

Result: NAACL框架通过合成约2K HotpotQA样例数据，进行监督微调，显著提升了模型的校准性能，特别是在域内提升了10.9%，域外提升了8.0%。

Conclusion: NAACL框架为LLMs提供了对抗检索噪声和提升校准可靠性的机制，促进了模型的准确性和知识可靠性。

Abstract: Accurately assessing model confidence is essential for deploying large language models (LLMs) in mission-critical factual domains. While retrieval-augmented generation (RAG) is widely adopted to improve grounding, confidence calibration in RAG settings remains poorly understood. We conduct a systematic study across four benchmarks, revealing that LLMs exhibit poor calibration performance due to noisy retrieved contexts. Specifically, contradictory or irrelevant evidence tends to inflate the model's false certainty, leading to severe overconfidence. To address this, we propose NAACL Rules (Noise-AwAre Confidence CaLibration Rules) to provide a principled foundation for resolving overconfidence under noise. We further design NAACL, a noise-aware calibration framework that synthesizes supervision from about 2K HotpotQA examples guided by these rules. By performing supervised fine-tuning (SFT) with this data, NAACL equips models with intrinsic noise awareness without relying on stronger teacher models. Empirical results show that NAACL yields substantial gains, improving ECE scores by 10.9% in-domain and 8.0% out-of-domain. By bridging the gap between retrieval noise and verbal calibration, NAACL paves the way for both accurate and epistemically reliable LLMs.

</details>


### [51] [Finding the Translation Switch: Discovering and Exploiting the Task-Initiation Features in LLMs](https://arxiv.org/abs/2601.11019)
*Xinwei Wu,Heng Liu,Xiaohu Zhao,Yuqi Ren,Linlong Xu,Longyue Wang,Deyi Xiong,Weihua Luo,Kaifu Zhang*

Main category: cs.CL

TL;DR: 该研究利用稀疏自编码器和一种新的框架，发现了大规模语言模型在翻译任务中的内在能力，并提出了一种新的数据选择策略，通过优先训练难以激活翻译起始特征的样本，提高了数据效率和抑制幻觉。此外，这些机制在更大规模的语言模型中具有可迁移性。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在翻译任务上表现出色，但其内在机理不透明。为了揭示这一内在能力，研究引入了一种新的框架来识别任务特定特征，进而优化翻译表现。

Method: 研究采用稀疏自编码器（SAE）作为基础，通过分析翻译输入中频繁共激活的特征，结合主成分分析（PCA）一致性度量过滤功能性不一致的特征，以识别翻译初始化特征。然后通过因果干预实验证明这些特征对翻译任务的重要性。

Result: 研究成功识别了一组小的翻译初始化特征，通过增强这些特征可以引导模型做出正确的翻译，而削弱它们会导致幻觉和不相关的输出。此外，引入了一种新的数据选择策略，重点关注难以激活翻译初始化特征的样本，以提高数据效率并减少幻觉。

Conclusion: 该研究不仅解码了大规模语言模型在翻译中的关键机制，还为通过利用内部模型机制创建更稳健和高效的模型提供了蓝图。

Abstract: Large Language Models (LLMs) frequently exhibit strong translation abilities, even without task-specific fine-tuning. However, the internal mechanisms governing this innate capability remain largely opaque. To demystify this process, we leverage Sparse Autoencoders (SAEs) and introduce a novel framework for identifying task-specific features. Our method first recalls features that are frequently co-activated on translation inputs and then filters them for functional coherence using a PCA-based consistency metric. This framework successfully isolates a small set of **translation initiation** features. Causal interventions demonstrate that amplifying these features steers the model towards correct translation, while ablating them induces hallucinations and off-task outputs, confirming they represent a core component of the model's innate translation competency. Moving from analysis to application, we leverage this mechanistic insight to propose a new data selection strategy for efficient fine-tuning. Specifically, we prioritize training on **mechanistically hard** samples-those that fail to naturally activate the translation initiation features. Experiments show this approach significantly improves data efficiency and suppresses hallucinations. Furthermore, we find these mechanisms are transferable to larger models of the same family. Our work not only decodes a core component of the translation mechanism in LLMs but also provides a blueprint for using internal model mechanism to create more robust and efficient models. The codes are available at https://github.com/flamewei123/AAAI26-translation-Initiation-Features.

</details>


### [52] [From Interpretability to Performance: Optimizing Retrieval Heads for Long-Context Language Models](https://arxiv.org/abs/2601.11020)
*Youmi Ma,Naoaki Okazaki*

Main category: cs.CL

TL;DR: 该研究通过设计RetMask方法，利用掩码检索头来增强LLM的长文上下文能力，取得了显著的性能提升。主要改进为在第三代Llama模型上提升了2.28点的HELMET分数，生成带有引用提升了70%，段落重新排名提升了32%。实验表明，检索头的组织模式影响了效果。


<details>
  <summary>Details</summary>
Motivation: 当前研究的主要动机是为了探讨检索头在提升模型长文本上下文能力方面的作用。以往的研究虽然识别了检索头的存在，但尚未明确其在改进模型性能方面的贡献。因此，研究设计了一种掩码检索头的方法（RetMask）来进一步探索检索头在LLM中的效用。

Method: 该研究采用了一种机制驱动的方法，通过将正常模型输出与删除检索头版本的对比生成训练信号。该方法主要用于评估不同组织模式的检索头在提升LLM性能方面的效果。

Result: 研究结果显示，RetMask方法显著提高了第三代Llama模型在特定任务上的表现，包括在128K的HELMET分数上提升了2.28点，在生成带有引用上有70%的增益，段落重新排名上有32%的提升。此外，实验还表明了检索头组织模式对模型效果的影响。

Conclusion: 该研究证实了检索头在提升LLM的长文本上下文能力方面的功能，并展示了通过机制驱动的方法可以将这些见解转化为实际性能的提高。此外，研究还探讨了检索头组织模式对模型性能的影响，这为未来的长文本处理和模型优化提供了新的视角。

Abstract: Advances in mechanistic interpretability have identified special attention heads, known as retrieval heads, that are responsible for retrieving information from the context. However, the role of these retrieval heads in improving model performance remains unexplored. This work investigates whether retrieval heads can be leveraged to enhance the long-context capabilities of LLMs. Specifically, we propose RetMask, a method that generates training signals by contrasting normal model outputs with those from an ablated variant in which the retrieval heads are masked. This mechanism-based approach achieves substantial improvements: +2.28 points on HELMET at 128K for Llama-3.1, with +70% gains on generation with citation and +32% on passage re-ranking, while preserving performance on general tasks. Experiments across three model families reveal that the effectiveness depends on retrieval head organization: models with concentrated patterns of retrieval heads respond strongly, while those with distributed patterns show limited gains. This mechanistic relationship validates the function of retrieval heads and demonstrates that mechanistic insights can be transformed into performance enhancements.

</details>


### [53] [Budget-Aware Anytime Reasoning with LLM-Synthesized Preference Data](https://arxiv.org/abs/2601.11038)
*Xuanming Zhang,Shwan Ashrafi,Aziza Mirsaidova,Amir Rezaeian,Miguel Ballesteros,Lydia B. Chilton,Zhou Yu,Dan Roth*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We study the reasoning behavior of large language models (LLMs) under limited computation budgets. In such settings, producing useful partial solutions quickly is often more practical than exhaustive reasoning, which incurs high inference costs. Many real-world tasks, such as trip planning, require models to deliver the best possible output within a fixed reasoning budget. We introduce an anytime reasoning framework and the Anytime Index, a metric that quantifies how effectively solution quality improves as reasoning tokens increase. To further enhance efficiency, we propose an inference-time self-improvement method using LLM-synthesized preference data, where models learn from their own reasoning comparisons to produce better intermediate solutions. Experiments on NaturalPlan (Trip), AIME, and GPQA datasets show consistent gains across Grok-3, GPT-oss, GPT-4.1/4o, and LLaMA models, improving both reasoning quality and efficiency under budget constraints.

</details>


### [54] [Spectral Characterization and Mitigation of Sequential Knowledge Editing Collapse](https://arxiv.org/abs/2601.11042)
*Chi Zhang,Mengqi Zhang,Xiaotian Ye,Runxi Cheng,Zisheng Zhou,Ying Zhou,Pengjie Ren,Zhumin Chen*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Sequential knowledge editing in large language models often causes catastrophic collapse of the model's general abilities, especially for parameter-modifying methods. Existing approaches mitigate this issue through heuristic constraints on parameter updates, yet the mechanisms underlying such degradation remain insufficiently understood. In this work, we present a spectral analysis of sequential knowledge editing and show that a model's general abilities are closely associated with dominant singular directions of pretrained weight matrices. These directions are highly sensitive to perturbations and are progressively disrupted by repeated edits, closely tracking the collapse in both editing efficacy and general performance. Building on this insight, we propose REVIVE, a plug-and-play framework that stabilizes sequential editing by explicitly preserving the dominant singular subspace. REVIVE represents parameter updates in the spectral basis of the original weights and filters components that would interfere with the protected region. Extensive experiments across multiple models and benchmarks show that REVIVE consistently improves editing efficacy while substantially preserving general abilities under long-horizon sequential editing, including extreme settings with up to 20,000 edits.

</details>


### [55] [CoG: Controllable Graph Reasoning via Relational Blueprints and Failure-Aware Refinement over Knowledge Graphs](https://arxiv.org/abs/2601.11047)
*Yuanxiang Liu,Songze Li,Xiaoke Guo,Zhaoyan Gong,Qifei Zhang,Huajun Chen,Wen Zhang*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large Language Models (LLMs) have demonstrated remarkable reasoning capabilities but often grapple with reliability challenges like hallucinations. While Knowledge Graphs (KGs) offer explicit grounding, existing paradigms of KG-augmented LLMs typically exhibit cognitive rigidity--applying homogeneous search strategies that render them vulnerable to instability under neighborhood noise and structural misalignment leading to reasoning stagnation. To address these challenges, we propose CoG, a training-free framework inspired by Dual-Process Theory that mimics the interplay between intuition and deliberation. First, functioning as the fast, intuitive process, the Relational Blueprint Guidance module leverages relational blueprints as interpretable soft structural constraints to rapidly stabilize the search direction against noise. Second, functioning as the prudent, analytical process, the Failure-Aware Refinement module intervenes upon encountering reasoning impasses. It triggers evidence-conditioned reflection and executes controlled backtracking to overcome reasoning stagnation. Experimental results on three benchmarks demonstrate that CoG significantly outperforms state-of-the-art approaches in both accuracy and efficiency.

</details>


### [56] [Efficient Multilingual Name Type Classification Using Convolutional Networks](https://arxiv.org/abs/2601.11090)
*Davor Lauc*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We present a convolutional neural network approach for classifying proper names by language and entity type. Our model, Onomas-CNN X, combines parallel convolution branches with depthwise-separable operations and hierarchical classification to process names efficiently on CPU hardware. We evaluate the architecture on a large multilingual dataset covering 104 languages and four entity types (person, organization, location, other). Onomas-CNN X achieves 92.1% accuracy while processing 2,813 names per second on a single CPU core - 46 times faster than fine-tuned XLM-RoBERTa with comparable accuracy. The model reduces energy consumption by a factor of 46 compared to transformer baselines. Our experiments demonstrate that specialized CNN architectures remain competitive with large pre-trained models for focused NLP tasks when sufficient training data exists.

</details>


### [57] [Integrity Shield A System for Ethical AI Use & Authorship Transparency in Assessments](https://arxiv.org/abs/2601.11093)
*Ashish Raj Shekhar,Shiven Agarwal,Priyanuj Bordoloi,Yash Shah,Tejas Anvekar,Vivek Gupta*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large Language Models (LLMs) can now solve entire exams directly from uploaded PDF assessments, raising urgent concerns about academic integrity and the reliability of grades and credentials. Existing watermarking techniques either operate at the token level or assume control over the model's decoding process, making them ineffective when students query proprietary black-box systems with instructor-provided documents. We present Integrity Shield, a document-layer watermarking system that embeds schema-aware, item-level watermarks into assessment PDFs while keeping their human-visible appearance unchanged. These watermarks consistently prevent MLLMs from answering shielded exam PDFs and encode stable, item-level signatures that can be reliably recovered from model or student responses. Across 30 exams spanning STEM, humanities, and medical reasoning, Integrity Shield achieves exceptionally high prevention (91-94% exam-level blocking) and strong detection reliability (89-93% signature retrieval) across four commercial MLLMs. Our demo showcases an interactive interface where instructors upload an exam, preview watermark behavior, and inspect pre/post AI performance & authorship evidence.

</details>


### [58] [The Growing Gains and Pains of Iterative Web Corpora Crawling: Insights from South Slavic CLASSLA-web 2.0 Corpora](https://arxiv.org/abs/2601.11170)
*Taja Kuzman Pungeršek,Peter Rupnik,Vít Suchomel,Nikola Ljubešić*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Crawling national top-level domains has proven to be highly effective for collecting texts in less-resourced languages. This approach has been recently used for South Slavic languages and resulted in the largest general corpora for this language group: the CLASSLA-web 1.0 corpora. Building on this success, we established a continuous crawling infrastructure for iterative national top-level domain crawling across South Slavic and related webs. We present the first outcome of this crawling infrastructure - the CLASSLA-web 2.0 corpus collection, with substantially larger web corpora containing 17.0 billion words in 38.1 million texts in seven languages: Bosnian, Bulgarian, Croatian, Macedonian, Montenegrin, Serbian, and Slovenian. In addition to genre categories, the new version is also automatically annotated with topic labels. Comparing CLASSLA-web 2.0 with its predecessor reveals that only one-fifth of the texts overlap, showing that re-crawling after just two years yields largely new content. However, while the new web crawls bring growing gains, we also notice growing pains - a manual inspection of top domains reveals a visible degradation of web content, as machine-generated sites now contribute a significant portion of texts.

</details>


### [59] [DOREMI: Optimizing Long Tail Predictions in Document-Level Relation Extraction](https://arxiv.org/abs/2601.11190)
*Laura Menotti,Stefano Marchesin,Gianmaria Silvello*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Document-Level Relation Extraction (DocRE) presents significant challenges due to its reliance on cross-sentence context and the long-tail distribution of relation types, where many relations have scarce training examples. In this work, we introduce DOcument-level Relation Extraction optiMizing the long taIl (DOREMI), an iterative framework that enhances underrepresented relations through minimal yet targeted manual annotations. Unlike previous approaches that rely on large-scale noisy data or heuristic denoising, DOREMI actively selects the most informative examples to improve training efficiency and robustness. DOREMI can be applied to any existing DocRE model and is effective at mitigating long-tail biases, offering a scalable solution to improve generalization on rare relations.

</details>


### [60] [T$^\star$: Progressive Block Scaling for MDM Through Trajectory Aware RL](https://arxiv.org/abs/2601.11214)
*Hanchen Xia,Baoyou Chen,Yutang Ge,Guojiang Zhao,Siyu Zhu*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We present T$^\star$, a simple \textsc{TraceRL}-based training curriculum for progressive block-size scaling in masked diffusion language models (MDMs). Starting from an AR-initialized small-block MDM, T$^\star$~transitions smoothly to larger blocks, enabling higher-parallelism decoding with minimal performance degradation on math reasoning benchmarks. Moreover, further analysis suggests that T$^\star$~can converge to an alternative decoding schedule $\hat{\rm S}$ that achieves comparable performance.

</details>


### [61] [MultiCaption: Detecting disinformation using multilingual visual claims](https://arxiv.org/abs/2601.11220)
*Rafael Martins Frade,Rrubaa Panchendrarajan,Arkaitz Zubiaga*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Online disinformation poses an escalating threat to society, driven increasingly by the rapid spread of misleading content across both multimedia and multilingual platforms. While automated fact-checking methods have advanced in recent years, their effectiveness remains constrained by the scarcity of datasets that reflect these real-world complexities. To address this gap, we first present MultiCaption, a new dataset specifically designed for detecting contradictions in visual claims. Pairs of claims referring to the same image or video were labeled through multiple strategies to determine whether they contradict each other. The resulting dataset comprises 11,088 visual claims in 64 languages, offering a unique resource for building and evaluating misinformation-detection systems in truly multimodal and multilingual environments. We then provide comprehensive experiments using transformer-based architectures, natural language inference models, and large language models, establishing strong baselines for future research. The results show that MultiCaption is more challenging than standard NLI tasks, requiring task-specific finetuning for strong performance. Moreover, the gains from multilingual training and testing highlight the dataset's potential for building effective multilingual fact-checking pipelines without relying on machine translation.

</details>


### [62] [Language of Thought Shapes Output Diversity in Large Language Models](https://arxiv.org/abs/2601.11227)
*Shaoyang Xu,Wenxuan Zhang*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Output diversity is crucial for Large Language Models as it underpins pluralism and creativity. In this work, we reveal that controlling the language used during model thinking-the language of thought-provides a novel and structural source of output diversity. Our preliminary study shows that different thinking languages occupy distinct regions in a model's thinking space. Based on this observation, we study two repeated sampling strategies under multilingual thinking-Single-Language Sampling and Mixed-Language Sampling-and conduct diversity evaluation on outputs that are controlled to be in English, regardless of the thinking language used. Across extensive experiments, we demonstrate that switching the thinking language from English to non-English languages consistently increases output diversity, with a clear and consistent positive correlation such that languages farther from English in the thinking space yield larger gains. We further show that aggregating samples across multiple thinking languages yields additional improvements through compositional effects, and that scaling sampling with linguistic heterogeneity expands the model's diversity ceiling. Finally, we show that these findings translate into practical benefits in pluralistic alignment scenarios, leading to broader coverage of cultural knowledge and value orientations in LLM outputs. Our code is publicly available at https://github.com/iNLP-Lab/Multilingual-LoT-Diversity.

</details>


### [63] [FactCorrector: A Graph-Inspired Approach to Long-Form Factuality Correction of Large Language Models](https://arxiv.org/abs/2601.11232)
*Javier Carnerero-Cano,Massimiliano Pronesti,Radu Marinescu,Tigran Tchrakian,James Barry,Jasmina Gajcin,Yufang Hou,Alessandra Pascale,Elizabeth Daly*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large language models (LLMs) are widely used in knowledge-intensive applications but often generate factually incorrect responses. A promising approach to rectify these flaws is correcting LLMs using feedback. Therefore, in this paper, we introduce FactCorrector, a new post-hoc correction method that adapts across domains without retraining and leverages structured feedback about the factuality of the original response to generate a correction. To support rigorous evaluations of factuality correction methods, we also develop the VELI5 benchmark, a novel dataset containing systematically injected factual errors and ground-truth corrections. Experiments on VELI5 and several popular long-form factuality datasets show that the FactCorrector approach significantly improves factual precision while preserving relevance, outperforming strong baselines. We release our code at https://ibm.biz/factcorrector.

</details>


### [64] [How DDAIR you? Disambiguated Data Augmentation for Intent Recognition](https://arxiv.org/abs/2601.11234)
*Galo Castillo-López,Alexis Lombard,Nasredine Semmar,Gaël de Chalendar*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large Language Models (LLMs) are effective for data augmentation in classification tasks like intent detection. In some cases, they inadvertently produce examples that are ambiguous with regard to untargeted classes. We present DDAIR (Disambiguated Data Augmentation for Intent Recognition) to mitigate this problem. We use Sentence Transformers to detect ambiguous class-guided augmented examples generated by LLMs for intent recognition in low-resource scenarios. We identify synthetic examples that are semantically more similar to another intent than to their target one. We also provide an iterative re-generation method to mitigate such ambiguities. Our findings show that sentence embeddings effectively help to (re)generate less ambiguous examples, and suggest promising potential to improve classification performance in scenarios where intents are loosely or broadly defined.

</details>


### [65] [Reasoning in Trees: Improving Retrieval-Augmented Generation for Multi-Hop Question Answering](https://arxiv.org/abs/2601.11255)
*Yuling Shi,Maolin Sun,Zijun Liu,Mo Yang,Yixiong Fang,Tianran Sun,Xiaodong Gu*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Retrieval-Augmented Generation (RAG) has demonstrated significant effectiveness in enhancing large language models (LLMs) for complex multi-hop question answering (QA). For multi-hop QA tasks, current iterative approaches predominantly rely on LLMs to self-guide and plan multi-step exploration paths during retrieval, leading to substantial challenges in maintaining reasoning coherence across steps from inaccurate query decomposition and error propagation. To address these issues, we introduce Reasoning Tree Guided RAG (RT-RAG), a novel hierarchical framework for complex multi-hop QA. RT-RAG systematically decomposes multi-hop questions into explicit reasoning trees, minimizing inaccurate decomposition through structured entity analysis and consensus-based tree selection that clearly separates core queries, known entities, and unknown entities. Subsequently, a bottom-up traversal strategy employs iterative query rewriting and refinement to collect high-quality evidence, thereby mitigating error propagation. Comprehensive experiments show that RT-RAG substantially outperforms state-of-the-art methods by 7.0% F1 and 6.0% EM, demonstrating the effectiveness of RT-RAG in complex multi-hop QA.

</details>


### [66] [One LLM to Train Them All: Multi-Task Learning Framework for Fact-Checking](https://arxiv.org/abs/2601.11293)
*Malin Astrid Larsson,Harald Fosen Grunnaleite,Vinay Setty*

Main category: cs.CL

TL;DR: 该论文提出了一种使用多任务学习（MTL）方法，通过细调单一模型来进行声明检测、证据重排序和立场检测等多任务联合任务的方法。


<details>
  <summary>Details</summary>
Motivation: 现有的自动化事实核查（AFC）方法依赖于复杂的大型封闭模型，存在可持续性问题，而多任务学习（MTL）提供了一个更高效、成本较低的替代方案。

Method: 论文采用几种多任务学习策略，如分类头、因果语言建模头和指令微调，应用于小型解码器只读语言模型（例如，Qwen3-4b），并评估了不同模型大小、任务顺序和标准非LLM基线。

Result: 研究表明，多任务模型在声明检测、证据重排序和立场检测方面相比零/少样本设置分别获得了高达44%、54%和31%的相对增益。

Conclusion: 最终，论文为使用多任务学习和语言模型进行自动化事实核查提供了实用的、经验为基础的指南。

Abstract: Large language models (LLMs) are reshaping automated fact-checking (AFC) by enabling unified, end-to-end verification pipelines rather than isolated components. While large proprietary models achieve strong performance, their closed weights, complexity, and high costs limit sustainability. Fine-tuning smaller open weight models for individual AFC tasks can help but requires multiple specialized models resulting in high costs. We propose \textbf{multi-task learning (MTL)} as a more efficient alternative that fine-tunes a single model to perform claim detection, evidence ranking, and stance detection jointly. Using small decoder-only LLMs (e.g., Qwen3-4b), we explore three MTL strategies: classification heads, causal language modeling heads, and instruction-tuning, and evaluate them across model sizes, task orders, and standard non-LLM baselines. While multitask models do not universally surpass single-task baselines, they yield substantial improvements, achieving up to \textbf{44\%}, \textbf{54\%}, and \textbf{31\%} relative gains for claim detection, evidence re-ranking, and stance detection, respectively, over zero-/few-shot settings. Finally, we also provide practical, empirically grounded guidelines to help practitioners apply MTL with LLMs for automated fact-checking.

</details>


### [67] [Membership Inference on LLMs in the Wild](https://arxiv.org/abs/2601.11314)
*Jiatong Yi,Yanyang Li*

Main category: cs.CL

TL;DR: 本文提出了一种名为SimMIA的稳健会员推理攻击框架，该框架在仅依赖生成文本的前提下，通过先进的采样策略和评分机制有效执行会员推理攻击。


<details>
  <summary>Details</summary>
Motivation: 现有的会员推理攻击技术要么依赖不可访问的模型内部信息，要么在严格的黑盒环境中表现不佳。因此，需要一种适用于仅依赖生成文本的现代私有大型语言模型的稳健攻击框架。

Method: SimMIA框架采用了先进且谨慎的采样和评分机制，这种方法适用于纯粹基于文本的模型。

Result: 实验结果显示，SimMIA在黑盒设置下达到了最先进的性能，与利用模型内部信息的基线方法相竞争。

Conclusion: 研究还建立了一个新的基准 WikiMIA-25，用于评估会员推理攻击在现代私有大型语言模型上的表现。

Abstract: Membership Inference Attacks (MIAs) act as a crucial auditing tool for the opaque training data of Large Language Models (LLMs). However, existing techniques predominantly rely on inaccessible model internals (e.g., logits) or suffer from poor generalization across domains in strict black-box settings where only generated text is available. In this work, we propose SimMIA, a robust MIA framework tailored for this text-only regime by leveraging an advanced sampling strategy and scoring mechanism. Furthermore, we present WikiMIA-25, a new benchmark curated to evaluate MIA performance on modern proprietary LLMs. Experiments demonstrate that SimMIA achieves state-of-the-art results in the black-box setting, rivaling baselines that exploit internal model information.

</details>


### [68] [F-Actor: Controllable Conversational Behaviour in Full-Duplex Models](https://arxiv.org/abs/2601.11329)
*Maike Züfle,Ondrej Klejch,Nicholas Sanders,Jan Niehues,Alexandra Birch,Tsz Kin Lam*

Main category: cs.CL

TL;DR: 本文介绍了一种无需大规模预训练和多阶段优化的可控制整通信对话语音模型，该模型仅需2000小时的数据即可训练，并可遵循具体指令控制语音特性、话题、对话行为及对话发起。


<details>
  <summary>Details</summary>
Motivation: 当前的语音对话系统缺乏动态适应上下文的能力，限制了其自然度和实用性。本文旨在开发一种可以在资源有限条件下训练的有效模型，以提升语音对话系统的自然度和个性化能力。

Method: 该研究提出了一个单一训练阶段协议，通过冻结音频编码器并仅微调语言模型来训练可控制整通信对话模型。该方法限制了模型对数据的依赖，并确保了模型能执行具体的指令来调整多个对话控制维度。

Result: 训练所得模型需要2000小时的数据，且无需大规模预训练或多阶段优化。模型可以指令控制声音特征、对话主题、对话行为（如回话应对和打断）以及对话发起。

Conclusion: 本文展示了一种在资源受限条件下训练并能按需控制的整通信对话语音模型，旨在推动可控制对话系统的进一步研究与应用。

Abstract: Spoken conversational systems require more than accurate speech generation to have human-like conversations: to feel natural and engaging, they must produce conversational behaviour that adapts dynamically to the context. Current spoken conversational systems, however, rarely allow such customization, limiting their naturalness and usability. In this work, we present the first open, instruction-following full-duplex conversational speech model that can be trained efficiently under typical academic resource constraints. By keeping the audio encoder frozen and finetuning only the language model, our model requires just 2,000 hours of data, without relying on large-scale pretraining or multi-stage optimization. The model can follow explicit instructions to control speaker voice, conversation topic, conversational behaviour (e.g., backchanneling and interruptions), and dialogue initiation. We propose a single-stage training protocol and systematically analyze design choices. Both the model and training code will be released to enable reproducible research on controllable full-duplex speech systems.

</details>


### [69] [Idea First, Code Later: Disentangling Problem Solving from Code Generation in Evaluating LLMs for Competitive Programming](https://arxiv.org/abs/2601.11332)
*Sama Hadhoud,Alaa Elsetohy,Frederikus Hudi,Jan Christian Blaise Cruz,Steven Halim,Alham Fikri Aji*

Main category: cs.CL

TL;DR: 该研究探讨了大规模语言模型（LLMs）在解决编程竞赛问题时的表现，并提出将自然语言编辑评论作为评估和生成解决方案的核心。研究发现，虽然LLMs在生成编辑评论上有一定改进，但在代码实现上仍面临挑战，研究还提出了一种LLM作为评判员的评估协议。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法将算法推理与代码实现混淆在一起，而编程竞赛本质上是解决问题的过程。自然语言编辑可以提供清晰的解决方案，有助于改善LLMs的理解和应用。

Method: 通过一个包含83个ICPC风格问题的数据集（附带黄金编辑评论和完全测试套件），使用自然语言编辑评论作为模型生成解决方案的基础，将模型生成的评论与专家编写的黄金标准进行比较，以诊断推理错误并验证LLM作为评判员的评估协议。

Result: 在使用专家撰写的黄金编辑评论时，一些LLMs的解决率得到提高，尤其是在实现上取得了显著进步。然而，模型仍难以实现黄金级，且生成的编辑评论与黄金标准之间仍存在理解上的差距。

Conclusion: 研究建议未来基准测试应明确区分问题解决和实现，以促进对此类问题的更深入研究和改进。

Abstract: Large Language Models (LLMs) increasingly succeed on competitive programming problems, yet existing evaluations conflate algorithmic reasoning with code-level implementation. We argue that competitive programming is fundamentally a problem-solving task and propose centering natural-language editorials in both solution generation and evaluation. Generating an editorial prior to code improves solve rates for some LLMs, with substantially larger gains when using expertly written gold editorials. However, even with gold editorials, models continue to struggle with implementation, while the gap between generated and gold editorials reveals a persistent problem-solving bottleneck in specifying correct and complete algorithms. Beyond pass/fail metrics, we diagnose reasoning errors by comparing model-generated editorials to gold standards using expert annotations and validate an LLM-as-a-judge protocol for scalable evaluation. We introduce a dataset of 83 ICPC-style problems with gold editorials and full test suites, and evaluate 19 LLMs, arguing that future benchmarks should explicitly separate problem solving from implementation.

</details>


### [70] [Neural Chain-of-Thought Search: Searching the Optimal Reasoning Path to Enhance Large Language Models](https://arxiv.org/abs/2601.11340)
*Guoming Ling,Zhongzhan Huang,Yupei Lin,Junxin Li,Shanshan Zhong,Hefeng Wu,Liang Lin*

Main category: cs.CL

TL;DR: NCoTS是一种通过动态搜索优化推理策略，减少冗余并提升准确性的新框架，能够显著提高生成推理路径的质量。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型在解决问题时缺乏前瞻性的推理步骤生成，NCoTS旨在通过动态搜索来找到最优的推理策略，从而克服这一限制。

Method: NCoTS框架通过量化表征解空间，采用双因素启发式方法评价候选推理算子，优化推理路径的正确性和计算成本。

Result: NCoTS在多种推理基准测试中实现了帕累托改进，能够提高超过3.5%的准确率，并减少生成长度超过22%。

Conclusion: NCoTS为大语言模型提供了一种有效提升其推理能力的新方法，有望在AI领域引发新的研究和应用突破。

Abstract: Chain-of-Thought reasoning has significantly enhanced the problem-solving capabilities of Large Language Models. Unfortunately, current models generate reasoning steps sequentially without foresight, often becoming trapped in suboptimal reasoning paths with redundant steps. In contrast, we introduce Neural Chain-of-Thought Search (NCoTS), a framework that reformulates reasoning as a dynamic search for the optimal thinking strategy. By quantitatively characterizing the solution space, we reveal the existence of sparse superior reasoning paths that are simultaneously more accurate and concise than standard outputs. Our method actively navigates towards these paths by evaluating candidate reasoning operators using a dual-factor heuristic that optimizes for both correctness and computational cost. Consequently, NCoTS achieves a Pareto improvement across diverse reasoning benchmarks, boosting accuracy by over 3.5% while reducing generation length by over 22%. Our code and data are available at https://github.com/MilkThink-Lab/Neural-CoT-Search.

</details>


### [71] [How Much Would a Clinician Edit This Draft? Evaluating LLM Alignment for Patient Message Response Drafting](https://arxiv.org/abs/2601.11344)
*Parker Seegmiller,Joseph Gatto,Sarah E. Greer,Ganza Belise Isingizwe,Rohan Ray,Timothy E. Burdick,Sarah Masud Preum*

Main category: cs.CL

TL;DR: 该研究通过开发新的主题元素分类和评估框架，对大型语言模型在患者门户消息回应中的适应性进行了大规模评估，揭示了LLM在特定主题上的生成能力有限，强调了要根据个别医生的偏好进行调整的重要性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决将大型语言模型（LLMs）集成到临床工作流程中可能带来的问题，特别是验证这些模型是否能够减少医生在门户工作中的时间和精力。

Method: 研究开发了一个新的主题元素分类，并提出了一种新的评估框架来评估LLM生成的回应中医生编辑负担的内容和主题水平。此外，研究通过专家标注数据集和不同的适应技术（如主题提示、检索增强生成、监督微调和直接偏好优化）进行了大规模评估。

Result: 研究结果表明，LLMs在某些主题上的生成能力有限，尤其是在生成旨在从患者处获得更多信息的问题部分。通过以主题为导向的适应策略，大多数主题都得到了改进。

Conclusion: 研究结果强调了针对个别医生的偏好调整LLMs的必要性，以实现患者-医生通信工作流程中的可靠和负责任的使用。

Abstract: Large language models (LLMs) show promise in drafting responses to patient portal messages, yet their integration into clinical workflows raises various concerns, including whether they would actually save clinicians time and effort in their portal workload. We investigate LLM alignment with individual clinicians through a comprehensive evaluation of the patient message response drafting task. We develop a novel taxonomy of thematic elements in clinician responses and propose a novel evaluation framework for assessing clinician editing load of LLM-drafted responses at both content and theme levels. We release an expert-annotated dataset and conduct large-scale evaluations of local and commercial LLMs using various adaptation techniques including thematic prompting, retrieval-augmented generation, supervised fine-tuning, and direct preference optimization. Our results reveal substantial epistemic uncertainty in aligning LLM drafts with clinician responses. While LLMs demonstrate capability in drafting certain thematic elements, they struggle with clinician-aligned generation in other themes, particularly question asking to elicit further information from patients. Theme-driven adaptation strategies yield improvements across most themes. Our findings underscore the necessity of adapting LLMs to individual clinician preferences to enable reliable and responsible use in patient-clinician communication workflows.

</details>


### [72] [Reward Modeling for Scientific Writing Evaluation](https://arxiv.org/abs/2601.11374)
*Furkan Şahinuç,Subhabrata Dutta,Iryna Gurevych*

Main category: cs.CL

TL;DR: 本文提出了一种面向科学写作评估的成本效益高的开源奖励模型，通过两阶段训练框架优化科学评估偏好并增强推理能力，从而实现在不同任务和评估标准下的有效泛化。


<details>
  <summary>Details</summary>
Motivation: 当前的LLM基评估模型和奖励模型主要针对固定基准和评估标准进行优化，难以处理科学领域的稀疏知识和任务依赖的多方面标准。

Method: 本文提出了一种两阶段训练框架，首先优化科学评估偏好，然后增强推理能力。同时，采用多方面评估设计和跨任务联合训练，以实现细粒度评估和对动态标准和评估标准的鲁棒性。

Result: 实验证明，本文的训练框架显著提高了LLM基科学写作评估的效果，模型能够在不同任务和未见过的科学写作评估设置中有效泛化。

Conclusion: 本文研究成果有助于开发适用于不同科学写作任务的可靠评估模型。

Abstract: Scientific writing is an expert-domain task that demands deep domain knowledge, task-specific requirements and reasoning capabilities that leverage the domain knowledge to satisfy the task specifications. While scientific text generation has been widely studied, its evaluation remains a challenging and open problem. It is critical to develop models that can be reliably deployed for evaluating diverse open-ended scientific writing tasks while adhering to their distinct requirements. However, existing LLM-based judges and reward models are primarily optimized for general-purpose benchmarks with fixed scoring rubrics and evaluation criteria. Consequently, they often fail to reason over sparse knowledge of scientific domains when interpreting task-dependent and multi-faceted criteria. Moreover, fine-tuning for each individual task is costly and impractical for low-resource settings. To bridge these gaps, we propose cost-efficient, open-source reward models tailored for scientific writing evaluation. We introduce a two-stage training framework that initially optimizes scientific evaluation preferences and then refines reasoning capabilities. Our multi-aspect evaluation design and joint training across diverse tasks enable fine-grained assessment and robustness to dynamic criteria and scoring rubrics. Experimental analysis shows that our training regime strongly improves LLM-based scientific writing evaluation. Our models generalize effectively across tasks and to previously unseen scientific writing evaluation settings, allowing a single trained evaluator to be reused without task-specific retraining.

</details>


### [73] [Relational Linearity is a Predictor of Hallucinations](https://arxiv.org/abs/2601.11429)
*Yuetian Lu,Yihong Liu,Hinrich Schütze*

Main category: cs.CL

TL;DR: 该研究专注于大型语言模型（LLMs）生成与未知实体相关的虚假答案的常见问题，通过SyntHal数据集验证了线性关系导致的虚假信息发生率较高，从而指出模型知识评估能力在数据存储结构中的依赖性。


<details>
  <summary>Details</summary>
Motivation: 研究揭示了大型语言模型产生虚假答案的根本原因，强调了数据线性关系对模型知识评估能力的影响。

Method: 研究团队通过创建6000个合成实体的数据集SyntHal，针对六种不同类型的线性关系，对四款不同的模型进行了测试，分析了模型在不同关系下的虚假信息发生率以及相关线性度。

Result: 研究发现，模型在处理线性关系时的虚假信息发生率较高，并且线性关系的度量$Δ	ext{cos}$与虚假信息发生率之间存在显著相关性（$r ∈ [.78, .82]$），从而验证了线性关系对模型知识评估能力影响的假设。

Conclusion: 研究结果表明，大型语言模型在处理线性关系时的知识存储方式影响其自我评估能力，这对于管理和改进模型的虚假行为以及提升事实知识表示具有重要意义。

Abstract: Hallucination is a central failure mode in large language models (LLMs). We focus on hallucinations of answers to questions like: "Which instrument did Glenn Gould play?", but we ask these questions for synthetic entities that are unknown to the model. Surprisingly, we find that medium-size models like Gemma-7B-IT frequently hallucinate, i.e., they have difficulty recognizing that the hallucinated fact is not part of their knowledge. We hypothesize that an important factor in causing these hallucinations is the linearity of the relation: linear relations tend to be stored more abstractly, making it difficult for the LLM to assess its knowledge; the facts of nonlinear relations tend to be stored more directly, making knowledge assessment easier. To investigate this hypothesis, we create SyntHal, a dataset of 6000 synthetic entities for six relations. In our experiments with four models, we determine, for each relation, the hallucination rate on SyntHal and also measure its linearity, using $Δ\cos$. We find a strong correlation ($r \in [.78,.82]$) between relational linearity and hallucination rate, providing evidence for our hypothesis that the underlying storage of triples of a relation is a factor in how well a model can self-assess its knowledge. This finding has implications for how to manage hallucination behavior and suggests new research directions for improving the representation of factual knowledge in LLMs.

</details>


### [74] [The unreasonable effectiveness of pattern matching](https://arxiv.org/abs/2601.11432)
*Gary Lupyan,Blaise Agüera y Arcas*

Main category: cs.CL

TL;DR: 大型语言模型能够理解由随机替换内容词的毫无意义字符串构成的“Jabberwocky”语言，表明它们依靠模式匹配来恢复潜在意义，这支持了模式匹配在语言处理中的有效性。


<details>
  <summary>Details</summary>
Motivation: 为了探讨大型语言模型（LLMs）的工作原理，作者通过引入一种所有或大部分内容词被随机替换成无意义字符串的“Jabberwocky”语言，展示LLMs如何表现出理解能力，以此回应关于LLMs是语言模仿者、数据库还是模糊版互联网的争议。

Method: 使用随机替换内容词的“Jabberwocky”语言进行实验，验证LLMs是否能够恢复部分或完全失去实际意义的句子的意义。

Result: 大型语言模型展示了理解“Jabberwocky”语言的能力，翻译出具有连贯意义的句子。这表明，LLMs对结构性模式的依赖是其实现语言处理有效性的关键因素。

Conclusion: 该研究通过实验证明了大型语言模型可以通过模式匹配恢复结构中的潜在意义，提出模式匹配是真实智能的一部分，不是替代方案。

Abstract: We report on an astonishing ability of large language models (LLMs) to make sense of "Jabberwocky" language in which most or all content words have been randomly replaced by nonsense strings, e.g., translating "He dwushed a ghanc zawk" to "He dragged a spare chair". This result addresses ongoing controversies regarding how to best think of what LLMs are doing: are they a language mimic, a database, a blurry version of the Web? The ability of LLMs to recover meaning from structural patterns speaks to the unreasonable effectiveness of pattern-matching. Pattern-matching is not an alternative to "real" intelligence, but rather a key ingredient.

</details>


### [75] [Hierarchical Orthogonal Residual Spread for Precise Massive Editing in Large Language Models](https://arxiv.org/abs/2601.11441)
*Xiaojie Gu,Guangxu Chen,Yuheng Yang,Jingxin Han,Andi Zhang*

Main category: cs.CL

TL;DR: 论文提出了一种名为HORSE的新方法，通过层次正交残差扩散信息矩阵来减少噪声梯度并支持更稳定的模型编辑。该方法在理论上与多种流行方法进行了比较，并通过广泛的实验验证了其在多个大型语言模型上的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的模型编辑方法通常集中在优化融合新旧知识的信息矩阵，但这些方法可能面临计算成本高和产生冲突的问题。因此，为了降低噪声梯度并提供更稳定的编辑，该研究提出了HORSE方法。

Method: HORSE方法旨在通过利用层次正交残差扩散信息矩阵来减少噪声梯度。具体而言，它从不同角度进行模型编辑，避免了直接优化信息矩阵原有的方法可能产生的计算成本高和冲突问题。

Result: 实验结果表明，HORSE可以在多个大型语言模型上实现精准的大规模模型编辑，并通过对比实验展示了与其他流行方法的有效性。此外，相关代码已发布。

Conclusion: 该研究通过理论分析和实验验证，证明了HORSE作为一种新的模型编辑方法，为解决大型语言模型的安全问题提供了新的视角和方法。

Abstract: Large language models (LLMs) exhibit exceptional performance across various domains, yet they face critical safety concerns. Model editing has emerged as an effective approach to mitigate these issues. Existing model editing methods often focus on optimizing an information matrix that blends new and old knowledge. While effective, these approaches can be computationally expensive and may cause conflicts. In contrast, we shift our attention to Hierarchical Orthogonal Residual SprEad of the information matrix, which reduces noisy gradients and enables more stable edits from a different perspective. We demonstrate the effectiveness of our method HORSE through a clear theoretical comparison with several popular methods and extensive experiments conducted on two datasets across multiple LLMs. The results show that HORSE maintains precise massive editing across diverse scenarios. The code is available at https://github.com/XiaojieGu/HORSE

</details>


### [76] [Predict the Retrieval! Test time adaptation for Retrieval Augmented Generation](https://arxiv.org/abs/2601.11443)
*Xin Sun,Zhongqi Chen,Qiang Liu,Shu Wu,Bowen Song,Weiqiang Wang,Zilei Wang,Liang Wang*

Main category: cs.CL

TL;DR: TTARAG 提出了一种测试时适应方法，通过在推理过程中动态更新语言模型参数来提高 RAG 系统在专门领域中的性能。


<details>
  <summary>Details</summary>
Motivation: 当前 RAG 系统在转换到专用领域时由于分布偏移而导致性能不佳，TTARAG 方法旨在通过使模型学习预测检索到的内容来自动适应目标领域，从而提高 RAG 系统的性能。

Method: TTARAG 提出了一种测试时适应方法。当模型进行推理时，它学习预测检索到的内容，并根据这个预测自动调整模型参数以适应目标领域。

Result: 通过在六个不同领域的全面实验，TTARAG 方法在所有测试场景中均表现出显著的性能提升。

Conclusion: TTARAG 能够有效地提升 RAG 在专用领域中的性能，显示出在实际应用中的潜力。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a powerful approach for enhancing large language models' question-answering capabilities through the integration of external knowledge. However, when adapting RAG systems to specialized domains, challenges arise from distribution shifts, resulting in suboptimal generalization performance. In this work, we propose TTARAG, a test-time adaptation method that dynamically updates the language model's parameters during inference to improve RAG system performance in specialized domains. Our method introduces a simple yet effective approach where the model learns to predict retrieved content, enabling automatic parameter adjustment to the target domain. Through extensive experiments across six specialized domains, we demonstrate that TTARAG achieves substantial performance improvements over baseline RAG systems. Code available at https://github.com/sunxin000/TTARAG.

</details>


### [77] [CTest-Metric: A Unified Framework to Assess Clinical Validity of Metrics for CT Report Generation](https://arxiv.org/abs/2601.11488)
*Vanshali Sharma,Andrea Mia Bejar,Gorkem Durak,Ulas Bagci*

Main category: cs.CL

TL;DR: 本文提出了一种统一的度量评估框架CTest-Metric，用于评估CT影像报告生成中领域特定度量的临床适用性和稳健性。


<details>
  <summary>Details</summary>
Motivation: 在生成式AI时代，医疗任务如影像报告生成愈发依赖自动化，但现有度量标准往往不尽完善。这要求开发专门领域的度量标准，然而缺乏评测它们在临床环境中的可靠性和适用性的统一框架。因此，该研究旨在通过CTest-Metric框架提升CT影像报告生成度量标准的评估水平。

Method: CTest-Metric框架包括三个模块来评估CT报告生成中度量的临床适用性：1) 通过文本生成模型重新措辞来测试写作风格通用性；2) 以不同严重程度注入合成错误；3) 使用临床专家对175个争议案例进行评分，以测试度量与专家评估的相关性。

Result: 八个广泛使用的度量标准（BLEU、ROUGE、METEOR、BERTScore-F1、F1-RadGraph、RaTEScore、GREEN Score、CRG）在CT-CLIP模型构建的七种文本生成模型上进行测试。结果显示词汇度量标准对样式变化极为敏感；GREEN Score最符合专家判断（Spearman相关系数~0.70）；CRG则与专家判断呈负相关；而BERTScore-F1对事实性错误注入最为稳健。

Conclusion: 本研究发布CTest-Metric框架、代码及匿名评估数据，旨在促进未来可重复的基准测试和度量标准的发展。

Abstract: In the generative AI era, where even critical medical tasks are increasingly automated, radiology report generation (RRG) continues to rely on suboptimal metrics for quality assessment. Developing domain-specific metrics has therefore been an active area of research, yet it remains challenging due to the lack of a unified, well-defined framework to assess their robustness and applicability in clinical contexts. To address this, we present CTest-Metric, a first unified metric assessment framework with three modules determining the clinical feasibility of metrics for CT RRG. The modules test: (i) Writing Style Generalizability (WSG) via LLM-based rephrasing; (ii) Synthetic Error Injection (SEI) at graded severities; and (iii) Metrics-vs-Expert correlation (MvE) using clinician ratings on 175 "disagreement" cases. Eight widely used metrics (BLEU, ROUGE, METEOR, BERTScore-F1, F1-RadGraph, RaTEScore, GREEN Score, CRG) are studied across seven LLMs built on a CT-CLIP encoder. Using our novel framework, we found that lexical NLG metrics are highly sensitive to stylistic variations; GREEN Score aligns best with expert judgments (Spearman~0.70), while CRG shows negative correlation; and BERTScore-F1 is least sensitive to factual error injection. We will release the framework, code, and allowable portion of the anonymized evaluation data (rephrased/error-injected CT reports), to facilitate reproducible benchmarking and future metric development.

</details>


### [78] [Do explanations generalize across large reasoning models?](https://arxiv.org/abs/2601.11517)
*Koyena Pal,David Bau,Chandan Singh*

Main category: cs.CL

TL;DR: 该研究探讨了大型推理模型（LRMs）生成的推理链（CoT）解释的一般性问题，发现这些解释在这种形式上表现出一般性，并且可以通过人工偏好排名和强化学习后训练进行验证，同时提出了一种简单的句子级聚类策略以提高一致性。


<details>
  <summary>Details</summary>
Motivation: 探讨大型推理模型生成的推理链解释是否具有普遍性，即能否被其他模型理解和运用，以更好地指导AI科学的理解和发展。

Method: 通过评估特定的一般性概念，即一个LRM生成的解释能否使其他LRM产生相同的行为，研究这一问题。

Result: 研究发现，推理链解释确实能够使不同模型产生一致的行为，且这种一致性与人工偏好排名和强化学习后的表现相关。

Conclusion: 研究结果指示我们在使用LRM解释来获得新见解时应谨慎，并提出了一种简单的句子级策略以提升解释的一致性，为评估LRM解释的一般性提供了框架。

Abstract: Large reasoning models (LRMs) produce a textual chain of thought (CoT) in the process of solving a problem, which serves as a potentially powerful tool to understand the problem by surfacing a human-readable, natural-language explanation. However, it is unclear whether these explanations generalize, i.e. whether they capture general patterns about the underlying problem rather than patterns which are esoteric to the LRM. This is a crucial question in understanding or discovering new concepts, e.g. in AI for science. We study this generalization question by evaluating a specific notion of generalizability: whether explanations produced by one LRM induce the same behavior when given to other LRMs. We find that CoT explanations often exhibit this form of generalization (i.e. they increase consistency between LRMs) and that this increased generalization is correlated with human preference rankings and post-training with reinforcement learning. We further analyze the conditions under which explanations yield consistent answers and propose a straightforward, sentence-level ensembling strategy that improves consistency. Taken together, these results prescribe caution when using LRM explanations to yield new insights and outline a framework for characterizing LRM explanation generalization.

</details>


### [79] [How Long Is a Piece of String? A Brief Empirical Analysis of Tokenizers](https://arxiv.org/abs/2601.11518)
*Jonathan Roberts,Kai Han,Samuel Albanie*

Main category: cs.CL

TL;DR: 该研究通过对文本数据不同分布下的序列压缩成token进行全面的实证分析，揭示了关于token长度的常用启发式方法过于简单，并期望研究的洞察为当前LLM中的token化提供清晰的理解。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决现有使用token作为模型、输入和输出的比较标准以及推理定价估计的基础，遇到的实际问题：不同模型和文本领域的token化存在巨大差异，导致naive的token计数解读困难。

Method: 采用全面的实证分析方法，探索不同文本数据分布下序列压缩成token的情况，挑战并量化了关于token长度的常见启发式方法。

Result: 研究结果显示，关于token长度的常用启发式方法过于简化，实际token化存在显著差异。

Conclusion: 研究强调了解决token化差异的重要性，为当前的LLM中的token化提供了新的见解，增强了理解与清晰度。

Abstract: Frontier LLMs are increasingly utilised across academia, society and industry. A commonly used unit for comparing models, their inputs and outputs, and estimating inference pricing is the token. In general, tokens are used as a stable currency, assumed to be broadly consistent across tokenizers and contexts, enabling direct comparisons. However, tokenization varies significantly across models and domains of text, making naive interpretation of token counts problematic. We quantify this variation by providing a comprehensive empirical analysis of tokenization, exploring the compression of sequences to tokens across different distributions of textual data. Our analysis challenges commonly held heuristics about token lengths, finding them to be overly simplistic. We hope the insights of our study add clarity and intuition toward tokenization in contemporary LLMs.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [80] [SwiftKV: An Edge-Oriented Attention Algorithm and Multi-Head Accelerator for Fast, Efficient LLM Decoding](https://arxiv.org/abs/2601.10953)
*Junming Zhang,Qinyan Zhang,Huajun Sun,Feiyang Gao,Sheng Hu,Rui Nie,Xiangshui Miao*

Main category: cs.AR

TL;DR: SwiftKV Attention 提出了一种单通道、低延迟的注意力推理算法，适用于边缘加速器，同时设计了 SwiftKV-MHA 加速器，支持高精度注意力计算和低精度 GEMV 操作，以实现高效解码。


<details>
  <summary>Details</summary>
Motivation: 针对大规模语言模型在边缘设备上的应用挑战，特别是快速注意力推理和高效解码的需求。

Method: SwiftKV Attention 设计了每个 token 管道化的注意力推理算法，无需关注分数材料化、分块 softmax 或第二次迭代。SwiftKV-MHA 则在同一个处理器阵列上实现高精度注意力计算和低精度 GEMV 操作。

Result: SwiftKV Attention 在边缘加速器上实现了 7.16 倍的加速比，相比其他注意力算法表现更优。SwiftKV-MHA 进一步降低了注意力延迟 13.48 倍，在相同设置下提高了生成速度 17.4% 和提高了标记效率 1.98 倍。

Conclusion: 该研究在边缘设备上实现了高效的大规模语言模型注意力推理和解码，显著提高了性能，并证明了其在实际应用中的有效性。

Abstract: Edge acceleration for large language models is crucial for their widespread application; however, achieving fast attention inference and efficient decoding on resource-constrained edge accelerators remains challenging. This paper presents SwiftKV Attention, a per-token pipelined, low-latency single-pass attention inference algorithm, where every (kt, vt) in the KV cache is processed exactly once in a uniform per-token pipeline without score materialization, blockwise softmax, or a second pass, thereby enabling fast execution on edge accelerators with a single hardware set and no resource-intensive parallelism. Furthermore, to address the limited support for multi-head LLM decoding in existing accelerators, we design the SwiftKV-MHA accelerator, which enables high precision attention and low precision GEMV on the same processor array, achieving fast and efficient multi-head parallel decoding. Experimental results show that, on the edge accelerator, the SwiftKV Attention algorithm achieves a 7.16* speedup over native attention and significantly outperforms other attention algorithms. SwiftKV-MHA further reduces attention latency by 13.48*; under the same settings, it improves generation speed by 17.4% and increases token efficiency by 1.98* compared with state-of-the-art works.

</details>


### [81] [RidgeWalker: Perfectly Pipelined Graph Random Walks on FPGAs](https://arxiv.org/abs/2601.11057)
*Hongshi Tan,Yao Chen,Xinyu Chen,Qizhen Zhang,Cheng Chen,Weng-Fai Wong,Bingsheng He*

Main category: cs.AR

TL;DR: RidgeWalker是一种针对数据中心FPGA的高性能Graph Random Walk加速器，通过分解GRW任务并采用异步流水线及反馈调度器，实现了高效的执行和负载均衡，相比现有FPGA和GPU方案大幅提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有GRW方案由于效率低下、静态调度等原因无法充分利用硬件潜力。

Method: RidgeWalker通过Markov特性将GRW任务分解为不需要状态的细粒度任务，引入异步流水线架构和基于排队理论的反馈调度器。

Result: 实验结果显示，RidgeWalker对比现有FPGA方案平均加速7.0x，GPU方案加速8.1x，最高加速高达71.0x和22.9x。

Conclusion: RidgeWalker在数据中心FPGA上展现了高性能，为GRW提供了一种有效的加速解决方案。

Abstract: Graph Random Walks (GRWs) offer efficient approximations of key graph properties and have been widely adopted in many applications. However, GRW workloads are notoriously difficult to accelerate due to their strong data dependencies, irregular memory access patterns, and imbalanced execution behavior. While recent work explores FPGA-based accelerators for GRWs, existing solutions fall far short of hardware potential due to inefficient pipelining and static scheduling. This paper presents RidgeWalker, a high-performance GRW accelerator designed for datacenter FPGAs. The key insight behind RidgeWalker is that the Markov property of GRWs allows decomposition into stateless, fine-grained tasks that can be executed out-of-order without compromising correctness. Building on this, RidgeWalker introduces an asynchronous pipeline architecture with a feedback-driven scheduler grounded in queuing theory, enabling perfect pipelining and adaptive load balancing. We prototype RidgeWalker on datacenter FPGAs and evaluated it across a range of GRW algorithms and real-world graph datasets. Experimental results demonstrate that RidgeWalker achieves an average speedup of 7.0x over state-of-the-art FPGA solutions and 8.1x over GPU solutions, with peak speedups of up to 71.0x and 22.9x, respectively. The source code is publicly available at https://github.com/Xtra-Computing/RidgeWalker.

</details>


<div id='cs.PF'></div>

# cs.PF [[Back]](#toc)

### [82] [Balanced allocation: considerations from large scale service environments](https://arxiv.org/abs/2601.10874)
*Amer Diwan,Prabhakar Raghavan,Eli Upfal*

Main category: cs.PF

TL;DR: 该研究扩展了一种多路平衡分配策略，以应对大规模系统中的突发流量、不同优先级任务和不稳定的信息。通过模拟和分析论证显示，该策略能够迅速从突发流量中恢复，并能平滑处理不同优先级和噪声信息。


<details>
  <summary>Details</summary>
Motivation: 先前的工作虽然研究了基本的多路平衡分配方案，但在应对大规模系统中的突发流量、不同优先级任务和不稳定信息等方面却缺乏深入研究。因此，本文作者基于在构建和运行全球规模云应用的实践经验，扩展了对此类分配策略的理解。

Method: 通过广泛的模拟和分析论证，作者探索了多路平衡分配在不同情况下的表现。

Result: 研究结果表明，多路平衡分配在应对突发流量和不同优先级任务时表现良好，同时对不稳定信息也有较好的容忍能力。

Conclusion: 该研究通过结合模拟和分析方法，加深了对多路平衡分配策略的认识，提出了适用于大规模系统的技术方案。

Abstract: We study d-way balanced allocation, which assigns each incoming job to the lightest loaded among d randomly chosen servers. While prior work has extensively studied the performance of the basic scheme, there has been less published work on adapting this technique to many aspects of large-scale systems. Based on our experience in building and running planet-scale cloud applications, we extend the understanding of d-way balanced allocation along the following dimensions:
  (i) Bursts: Events such as breaking news can produce bursts of requests that may temporarily exceed the servicing capacity of the system. Thus, we explore what happens during a burst and how long it takes for the system to recover from such bursts. (ii) Priorities: Production systems need to handle jobs with a mix of priorities (e.g., user facing requests may be high priority while other requests may be low priority). We extend d-way balanced allocation to handle multiple priorities. (iii) Noise: Production systems are often typically distributed and thus d-way balanced allocation must work with stale or incorrect information. Thus we explore the impact of noisy information and their interactions with bursts and priorities.
  We explore the above using both extensive simulations and analytical arguments. Specifically we show, (i) using simulations, that d-way balanced allocation quickly recovers from bursts and can gracefully handle priorities and noise; and (ii) that analysis of the underlying generative models complements our simulations and provides insight into our simulation results.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [83] [Do You Trust Me? Cognitive-Affective Signatures of Trustworthiness in Large Language Models](https://arxiv.org/abs/2601.10719)
*Gerard Yeo,Svetlana Churina,Kokil Jaidka*

Main category: cs.AI

TL;DR: 本研究分析了指令调制的大语言模型（LLM）在Web样本文本中对感知可信度的编码方式，发现这些模型在预训练期间隐式地编码了可信度提示，并且精细化调整作用较小，主要关联于公平性、确定性和问责性，这些维度是在线建立信任的关键。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索大语言模型在心理上如何表征感知可信度这一概念，以及这些模型是否在预训练期间隐式地捕捉了人类在线建立信任的关键维度。

Method: 研究使用了PEACE-Reviews数据集，该数据集根据认知评估、情感和行为意图进行了标注。研究分析了LLM在不同层和头级别的激活差异，对高可信度和低可信度文本进行了区分。

Result: 研究结果显示，尽管各大语言模型在不同层和头级别的激活存在显著差异，但它们在预训练期间隐式地捕捉到了可信度提示。进一步的探针分析显示，信度信号可以线性可解，并且微调效应主要是改进而不是重构成分。

Conclusion: 现代大语言模型在没有显式监督的情况下内化了心理接地的信度信号，这为在Web生态系统中设计可信赖、透明且值得信任的AI系统提供了基础。

Abstract: Perceived trustworthiness underpins how users navigate online information, yet it remains unclear whether large language models (LLMs),increasingly embedded in search, recommendation, and conversational systems, represent this construct in psychologically coherent ways. We analyze how instruction-tuned LLMs (Llama 3.1 8B, Qwen 2.5 7B, Mistral 7B) encode perceived trustworthiness in web-like narratives using the PEACE-Reviews dataset annotated for cognitive appraisals, emotions, and behavioral intentions. Across models, systematic layer- and head-level activation differences distinguish high- from low-trust texts, revealing that trust cues are implicitly encoded during pretraining. Probing analyses show linearly de-codable trust signals and fine-tuning effects that refine rather than restructure these representations. Strongest associations emerge with appraisals of fairness, certainty, and accountability-self -- dimensions central to human trust formation online. These findings demonstrate that modern LLMs internalize psychologically grounded trust signals without explicit supervision, offering a representational foundation for designing credible, transparent, and trust-worthy AI systems in the web ecosystem. Code and appendix are available at: https://github.com/GerardYeo/TrustworthinessLLM.

</details>


### [84] [CTHA: Constrained Temporal Hierarchical Architecture for Stable Multi-Agent LLM Systems](https://arxiv.org/abs/2601.10738)
*Percy Jardine*

Main category: cs.AI

TL;DR: CTHA是一种解决多时标智能体架构中协调稳定性问题的框架，通过消息契约约束、授权流形约束和仲裁解决约束来确保多层决策的协调性，实验表明其在复杂任务执行中表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多时标智能体架构虽然提高了性能，但牺牲了协调稳定性，导致层间冲突加剧、错误传播无界和扩展能力受限。CTHA旨在解决这些问题。

Method: CTHA通过定义消息契约约束、授权流形约束和仲裁解决约束来处理层间通信。具体来说，它使用类型化的摘要、计划和策略包来正式化信息流；根据每个层的时间范围限制其决策空间；并通过仲裁机制确保多层决策的冲突自由组合。

Result: 在实验中，CTHA减少了47%的失败级联，提高了2.3倍的样本效率，并且相比未受约束的层级基准表现出更优秀的可扩展性。

Conclusion: CTHA作为时间层次结构的有原则扩展，将有助于更深入地理解多智能体协调，并为具备鲁棒性的自主系统的演进提供有希望的方向。

Abstract: Recently, multi-time-scale agent architectures have extended the ubiquitous single-loop paradigm by introducing temporal hierarchies with distinct cognitive layers. While yielding substantial performance gains, this diversification fundamentally compromises the coordination stability intrinsic to unified agent systems, which causes severe inter-layer conflicts, unbounded error propagation, and restricted scalability. To address these challenges, we propose Constrained Temporal Hierarchical Architecture (CTHA), a general framework that projects the inter-layer communication space onto structured manifolds to restore coordination stability, while incorporating principled arbitration mechanisms to ensure coherent decision-making. Specifically, CTHA enforces three key constraints: (1) Message Contract Constraints that formalize information flow between layers via typed summary, plan, and policy packets; (2) Authority Manifold Constraints that bound each layer's decision space according to its temporal scope; and (3) Arbiter Resolution Constraints that guarantee conflict-free composition of multi-layer decisions. Empirical experiments demonstrate that CTHA is effective for complex task execution at scale, offering 47% reduction in failure cascades, 2.3x improvement in sample efficiency, and superior scalability compared to unconstrained hierarchical baselines. We anticipate that CTHA, as a principled extension of temporal hierarchies, will contribute to a deeper understanding of multi-agent coordination and suggest promising directions for the evolution of robust autonomous systems.

</details>


### [85] [Optimisation of complex product innovation processes based on trend models with three-valued logic](https://arxiv.org/abs/2601.10768)
*Nina Bočková,Barbora Volná,Mirko Dohnal*

Main category: cs.AI

TL;DR: 该研究利用基于一组启发式的模型探讨复杂的产品创新过程，通过简单的趋势（增加、减少或不变）表示启发式，避免依赖数值或粗糙集，定义趋势模型的解决方案为系统可能场景及它们之间的转换集，并通过转换图展示系统可能的未来或过去行为。


<details>
  <summary>Details</summary>
Motivation: 为在复杂多变的产品创新过程中提供一种更加简单的建模方法，以避免传统的数值或粗糙集方法可能带来的信息过载问题。

Method: 采用一组启发式，通过简单趋势（增加、减少或不变）作为量化指标，定义趋势模型的解决方案，并使用转换图来表示这些解决方案之间的转换。

Result: 该方法可以有效地描述和预测复杂产品创新过程中的潜在行为变化，提供了一种较为直观和简洁的建模方式。

Conclusion: 该研究为理解和分析复杂产品创新过程提供了一种新的探索途径，为进一步研究产品生命周期管理和创新策略提供了理论基础。

Abstract: This paper investigates complex product-innovation processes using models grounded in a set of heuristics. Each heuristic is expressed through simple trends -- increasing, decreasing, or constant -- which serve as minimally information-intensive quantifiers, avoiding reliance on numerical values or rough sets. A solution to a trend model is defined as a set of scenarios with possible transitions between them, represented by a transition graph. Any possible future or past behaviour of the system under study can thus be depicted by a path within this graph.

</details>


### [86] [ARC Prize 2025: Technical Report](https://arxiv.org/abs/2601.10904)
*François Chollet,Mike Knoop,Gregory Kamradt,Bryan Landers*

Main category: cs.AI

TL;DR: ARC-AGI基准系列作为衡量新型任务上少样本泛化的关键指标，吸引1455支团队和15,154项提交，最高得分为24%。新基准ARC-AGI-2相较于前代更具复杂性，强调迭代程序优化的反馈循环，同时也是知识覆盖依赖过拟合的新问题。论文讨论了领先方法，迭代优化环在AGI进步中的角色，知识依赖过拟合问题，并预览了即将发布的ARC-AGI-3。


<details>
  <summary>Details</summary>
Motivation: 为了评估人工智能在抽象推理和新型任务上的能力，以及推动AI在这些领域的进步。

Method: 通过分析ARC-AGI相关竞赛活动、提交情况和具体结果来评估当前AI技术在抽象问题解决上的表现。

Result: ARC-AGI-2竞赛中，最高得分为24%，参赛团队和提交数量显著增长。反馈环优化方法成为主流，但知识覆盖依赖过拟合问题显现。

Conclusion: 当前最先进的AI系统仍受制于知识覆盖的限制，AGI的进步需要探索创新的反馈优化机制，并且未来将引入互动推理挑战。

Abstract: The ARC-AGI benchmark series serves as a critical measure of few-shot generalization on novel tasks, a core aspect of intelligence. The ARC Prize 2025 global competition targeted the newly released ARC-AGI-2 dataset, which features greater task complexity compared to its predecessor. The Kaggle competition attracted 1,455 teams and 15,154 entries, with the top score reaching 24% on the ARC-AGI-2 private evaluation set. Paper submissions nearly doubled year-over-year to 90 entries, reflecting the growing research interest in fluid intelligence and abstract reasoning. The defining theme of 2025 is the emergence of the refinement loop -- a per-task iterative program optimization loop guided by a feedback signal. Refinement loops come in a variety of forms, in particular evolutionary program synthesis approaches and application-layer refinements to commercial AI systems. Such refinement loops are also possible in weight space, as evidenced by zero-pretraining deep learning methods which are now achieving competitive performance with remarkably small networks (7M parameters). In parallel, four frontier AI labs (Anthropic, Google DeepMind, OpenAI, and xAI) reported ARC-AGI performance in public model cards in 2025, establishing ARC-AGI as an industry standard benchmark for AI reasoning. However, our analysis indicates that current frontier AI reasoning performance remains fundamentally constrained to knowledge coverage, giving rise to new forms of benchmark contamination. In this paper, we survey the top-performing methods, examine the role of refinement loops in AGI progress, discuss knowledge-dependent overfitting, and preview ARC-AGI-3, which introduces interactive reasoning challenges that require exploration, planning, memory, goal acquisition, and alignment capabilities.

</details>


### [87] [What Matters in Data Curation for Multimodal Reasoning? Insights from the DCVLR Challenge](https://arxiv.org/abs/2601.10922)
*Yosub Shin,Michael Buriek,Boris Sobolev,Pavel Bushuyeu,Vikas Kumar,Haoyang Xu,Samuel Watson,Igor Molybog*

Main category: cs.AI

TL;DR: 该研究通过NeurIPS 2025 DCVLR挑战探讨了多模态推理的数据整理，发现难度基线下的样本选择是主要的性能增益驱动因素，增加数据集大小对平均准确率没有可靠提升，而常用的多样性及合成增强技术无额外增益甚至可能降低性能。


<details>
  <summary>Details</summary>
Motivation: 研究提出了一个挑战，旨在研究多模式数据整理，通过固定模型和训练协议来分离数据集的选择。研究者希望探索哪些数据选择策略对提升多模态推理性能最为有效。

Method: 研究使用了一个紧凑的、从Walton Multimodal Cold Start衍生的精心筛选的数据集，并在固定的训练方案下对比了不同的数据选择方法，包括难度基线选择、增加数据集大小、应用多样性及合成增强技术。

Result: 研究发现，基于难度的样本选择是主要的性能增益驱动因素。增加数据量主要减少了运行之间的方差，并没有提高平均准确性。通常使用的多样性及合成增强技术没有提供额外的收益，有时甚至会降低性能。

Conclusion: 研究揭示了DCVLR是一个饱和期评估，并指出了对多模态推理来说，对齐和难度的角色至关重要。

Abstract: We study data curation for multimodal reasoning through the NeurIPS 2025 Data Curation for Vision-Language Reasoning (DCVLR) challenge, which isolates dataset selection by fixing the model and training protocol. Using a compact curated dataset derived primarily from Walton Multimodal Cold Start, our submission placed first in the challenge. Through post-competition ablations, we show that difficulty-based example selection on an aligned base dataset is the dominant driver of performance gains. Increasing dataset size does not reliably improve mean accuracy under the fixed training recipe, but mainly reduces run-to-run variance, while commonly used diversity and synthetic augmentation heuristics provide no additional benefit and often degrade performance. These results characterize DCVLR as a saturation-regime evaluation and highlight the central role of alignment and difficulty in data-efficient multimodal reasoning.

</details>


### [88] [Efficient Protein Optimization via Structure-aware Hamiltonian Dynamics](https://arxiv.org/abs/2601.11012)
*Jiahao Wang,Shuangjia Zheng*

Main category: cs.AI

TL;DR: HADES是一种利用贝叶斯优化和哈密顿动力学的蛋白质序列优化方法，能有效减少高维度复杂性和结构约束影响，实验表明其在多种指标上优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 现有的基于序列的优化方法难以处理蛋白质工程中的高维度复杂性和结构约束问题。HADES旨在通过结合贝叶斯优化和哈密顿动力学来克服这些挑战。

Method: HADES通过引入动力学采样机制和一个两阶段编码解码框架来生成连续状态系统中的蛋白质序列。此方法利用贝叶斯优化来快速探索有利区域，并通过学习结构和功能关系来构建平滑的采样景观。

Result: HADES在多项指标上优于现有的最先进的基线方法，在模拟实验中表现出色。

Conclusion: HADES为蛋白质工程提供了一种有效的方法，能够更好地考虑蛋白质结构和序列之间的相互约束，有助于设计具有优化特性的蛋白质。

Abstract: The ability to engineer optimized protein variants has transformative potential for biotechnology and medicine. Prior sequence-based optimization methods struggle with the high-dimensional complexities due to the epistasis effect and the disregard for structural constraints. To address this, we propose HADES, a Bayesian optimization method utilizing Hamiltonian dynamics to efficiently sample from a structure-aware approximated posterior. Leveraging momentum and uncertainty in the simulated physical movements, HADES enables rapid transition of proposals toward promising areas. A position discretization procedure is introduced to propose discrete protein sequences from such a continuous state system. The posterior surrogate is powered by a two-stage encoder-decoder framework to determine the structure and function relationships between mutant neighbors, consequently learning a smoothed landscape to sample from. Extensive experiments demonstrate that our method outperforms state-of-the-art baselines in in-silico evaluations across most metrics. Remarkably, our approach offers a unique advantage by leveraging the mutual constraints between protein structure and sequence, facilitating the design of protein sequences with similar structures and optimized properties. The code and data are publicly available at https://github.com/GENTEL-lab/HADES.

</details>


### [89] [MiCA: A Mobility-Informed Causal Adapter for Lightweight Epidemic Forecasting](https://arxiv.org/abs/2601.11089)
*Suhan Guo,Jiahong Deng,Furao Shen*

Main category: cs.AI

TL;DR: MiCA 是一种适用于传染病预测的轻量级模块，通过因果发现推断移动关系并在时间预测模型中通过门控残差混合进行集成，从而在嘈杂和数据有限的情况下轻量化模型仍能有效利用移动导来的空间结构。


<details>
  <summary>Details</summary>
Motivation: 现有的参数密集型移动感知预报器依赖于清洁和丰富的数据，但在真实的疫情数据中，人类移动数据通常噪音大且难以与疾病记录可靠整合，疫情案例时间序列通常较短且报告的分辨率较低，这些限制了参数密集型方法的有效性。

Method: MiCA 通过因果发现推断移动关系，并通过门控残差混合将这些关系整合到时间序列预测模型中，形成一种轻量级且架构无关的模块。

Result: 在四个实际世界的疫情数据集上进行了广泛的实验，包括 COVID-19 住院人数、COVID-19 死亡人数、流感和登革热，MiCA 一致提高了轻量级时间序列骨干模型的表现，平均相对误差减少了 7.5%，同时保持了与当前最先进的空间-时间模型相当的性能。

Conclusion: MiCA 在保持模型轻量级的同时，通过使用移动旅行数据来预测疫情，展示了其在有限可用数据和嘈杂数据域内预报传染病的有效性和稳健性。

Abstract: Accurate forecasting of infectious disease dynamics is critical for public health planning and intervention. Human mobility plays a central role in shaping the spatial spread of epidemics, but mobility data are noisy, indirect, and difficult to integrate reliably with disease records. Meanwhile, epidemic case time series are typically short and reported at coarse temporal resolution. These conditions limit the effectiveness of parameter-heavy mobility-aware forecasters that rely on clean and abundant data. In this work, we propose the Mobility-Informed Causal Adapter (MiCA), a lightweight and architecture-agnostic module for epidemic forecasting. MiCA infers mobility relations through causal discovery and integrates them into temporal forecasting models via gated residual mixing. This design allows lightweight forecasters to selectively exploit mobility-derived spatial structure while remaining robust under noisy and data-limited conditions, without introducing heavy relational components such as graph neural networks or full attention. Extensive experiments on four real-world epidemic datasets, including COVID-19 incidence, COVID-19 mortality, influenza, and dengue, show that MiCA consistently improves lightweight temporal backbones, achieving an average relative error reduction of 7.5\% across forecasting horizons. Moreover, MiCA attains performance competitive with SOTA spatio-temporal models while remaining lightweight.

</details>


### [90] [Do We Always Need Query-Level Workflows? Rethinking Agentic Workflow Generation for Multi-Agent Systems](https://arxiv.org/abs/2601.11147)
*Zixu Wang,Bingbing Xu,Yige Yuan,Huawei Shen,Xueqi Cheng*

Main category: cs.AI

TL;DR: 本文介绍了一个新的基于少样本校准生成评估框架SCALE，该框架在保持与现有方法相当性能的同时大幅降低了令牌使用量。


<details>
  <summary>Details</summary>
Motivation: 现有方法生成工作流的成本和收益存在不确定性，且全面执行任务级别的评估代价高昂且不可靠。因此，需要探索一种成本更低、更高效的任务级别生成方法。

Method: 提出了一个名为SCALE的少样本校准生成评估框架，利用自我进化和生成奖励建模的思路，减少了全面执行验证评估的需要。

Result: 与现有方法相比，SCALE在多个数据集上保持了竞争力，性能下降仅为0.61%，同时减少了83%的令牌使用量。

Conclusion: 本文展示了SCALE框架的有效性，并推广了利用少样本校准进行任务级别生成评估的新方法。

Abstract: Multi-Agent Systems (MAS) built on large language models typically solve complex tasks by coordinating multiple agents through workflows. Existing approaches generates workflows either at task level or query level, but their relative costs and benefits remain unclear. After rethinking and empirical analyses, we show that query-level workflow generation is not always necessary, since a small set of top-K best task-level workflows together already covers equivalent or even more queries. We further find that exhaustive execution-based task-level evaluation is both extremely token-costly and frequently unreliable. Inspired by the idea of self-evolution and generative reward modeling, we propose a low-cost task-level generation framework \textbf{SCALE}, which means \underline{\textbf{S}}elf prediction of the optimizer with few shot \underline{\textbf{CAL}}ibration for \underline{\textbf{E}}valuation instead of full validation execution. Extensive experiments demonstrate that \textbf{SCALE} maintains competitive performance, with an average degradation of just 0.61\% compared to existing approach across multiple datasets, while cutting overall token usage by up to 83\%.

</details>


### [91] [TANDEM: Temporal-Aware Neural Detection for Multimodal Hate Speech](https://arxiv.org/abs/2601.11178)
*Girish A. Koushik,Helen Treharne,Diptesh Kanojia*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Social media platforms are increasingly dominated by long-form multimodal content, where harmful narratives are constructed through a complex interplay of audio, visual, and textual cues. While automated systems can flag hate speech with high accuracy, they often function as "black boxes" that fail to provide the granular, interpretable evidence, such as precise timestamps and target identities, required for effective human-in-the-loop moderation. In this work, we introduce TANDEM, a unified framework that transforms audio-visual hate detection from a binary classification task into a structured reasoning problem. Our approach employs a novel tandem reinforcement learning strategy where vision-language and audio-language models optimize each other through self-constrained cross-modal context, stabilizing reasoning over extended temporal sequences without requiring dense frame-level supervision. Experiments across three benchmark datasets demonstrate that TANDEM significantly outperforms zero-shot and context-augmented baselines, achieving 0.73 F1 in target identification on HateMM (a 30% improvement over state-of-the-art) while maintaining precise temporal grounding. We further observe that while binary detection is robust, differentiating between offensive and hateful content remains challenging in multi-class settings due to inherent label ambiguity and dataset imbalance. More broadly, our findings suggest that structured, interpretable alignment is achievable even in complex multimodal settings, offering a blueprint for the next generation of transparent and actionable online safety moderation tools.

</details>


### [92] [Beyond Model Scaling: Test-Time Intervention for Efficient Deep Reasoning](https://arxiv.org/abs/2601.11252)
*Qianyue Wang,Jinwu Hu,Yufeng Wang,Huanxiang Lin,Bolin Chen,Zhiquan Wen,Yaofo Chen,Mingkui Tan*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large Reasoning Models (LRMs) excel at multi-step reasoning but often suffer from inefficient reasoning processes like overthinking and overshoot, where excessive or misdirected reasoning increases computational cost and degrades performance. Existing efficient reasoning methods operate in a closed-loop manner, lacking mechanisms for external intervention to guide the reasoning process. To address this, we propose Think-with-Me, a novel test-time interactive reasoning paradigm that introduces external feedback intervention into the reasoning process. Our key insights are that transitional conjunctions serve as natural points for intervention, signaling phases of self-validation or exploration and using transitional words appropriately to prolong the reasoning enhances performance, while excessive use affects performance. Building on these insights, Think-with-Me pauses reasoning at these points for external feedback, adaptively extending or terminating reasoning to reduce redundancy while preserving accuracy. The feedback is generated via a multi-criteria evaluation (rationality and completeness) and comes from either human or LLM proxies. We train the target model using Group Relative Policy Optimization (GRPO) to adapt to this interactive mode. Experiments show that Think-with-Me achieves a superior balance between accuracy and reasoning length under limited context windows. On AIME24, Think-with-Me outperforms QwQ-32B by 7.19% in accuracy while reducing average reasoning length by 81% under an 8K window. The paradigm also benefits security and creative tasks.

</details>


### [93] [XChoice: Explainable Evaluation of AI-Human Alignment in LLM-based Constrained Choice Decision Making](https://arxiv.org/abs/2601.11286)
*Weihong Qi,Fan Huang,Rasika Muralidharan,Jisun An,Haewoon Kwak*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We present XChoice, an explainable framework for evaluating AI-human alignment in constrained decision making. Moving beyond outcome agreement such as accuracy and F1 score, XChoice fits a mechanism-based decision model to human data and LLM-generated decisions, recovering interpretable parameters that capture the relative importance of decision factors, constraint sensitivity, and implied trade-offs. Alignment is assessed by comparing these parameter vectors across models, options, and subgroups. We demonstrate XChoice on Americans' daily time allocation using the American Time Use Survey (ATUS) as human ground truth, revealing heterogeneous alignment across models and activities and salient misalignment concentrated in Black and married groups. We further validate robustness of XChoice via an invariance analysis and evaluate targeted mitigation with a retrieval augmented generation (RAG) intervention. Overall, XChoice provides mechanism-based metrics that diagnose misalignment and support informed improvements beyond surface outcome matching.

</details>


### [94] [AstroReason-Bench: Evaluating Unified Agentic Planning across Heterogeneous Space Planning Problems](https://arxiv.org/abs/2601.11354)
*Weiyi Wang,Xinchi Chen,Jingjing Gong,Xuanjing Huang,Xipeng Qiu*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Recent advances in agentic Large Language Models (LLMs) have positioned them as generalist planners capable of reasoning and acting across diverse tasks. However, existing agent benchmarks largely focus on symbolic or weakly grounded environments, leaving their performance in physics-constrained real-world domains underexplored. We introduce AstroReason-Bench, a comprehensive benchmark for evaluating agentic planning in Space Planning Problems (SPP), a family of high-stakes problems with heterogeneous objectives, strict physical constraints, and long-horizon decision-making. AstroReason-Bench integrates multiple scheduling regimes, including ground station communication and agile Earth observation, and provides a unified agent-oriented interaction protocol. Evaluating on a range of state-of-the-art open- and closed-source agentic LLM systems, we find that current agents substantially underperform specialized solvers, highlighting key limitations of generalist planning under realistic constraints. AstroReason-Bench offers a challenging and diagnostic testbed for future agentic research.

</details>


### [95] [Hyperparameter Optimization of Constraint Programming Solvers](https://arxiv.org/abs/2601.11389)
*Hedieh Haddad,Thibault Falque,Pierre Talbot,Pascal Bouvry*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The performance of constraint programming solvers is highly sensitive to the choice of their hyperparameters. Manually finding the best solver configuration is a difficult, time-consuming task that typically requires expert knowledge. In this paper, we introduce probe and solve algorithm, a novel two-phase framework for automated hyperparameter optimization integrated into the CPMpy library. This approach partitions the available time budget into two phases: a probing phase that explores different sets of hyperparameters using configurable hyperparameter optimization methods, followed by a solving phase where the best configuration found is used to tackle the problem within the remaining time.
  We implement and compare two hyperparameter optimization methods within the probe and solve algorithm: Bayesian optimization and Hamming distance search. We evaluate the algorithm on two different constraint programming solvers, ACE and Choco, across 114 combinatorial problem instances, comparing their performance against the solver's default configurations.
  Results show that using Bayesian optimization, the algorithm outperforms the solver's default configurations, improving solution quality for ACE in 25.4% of instances and matching the default performance in 57.9%, and for Choco, achieving superior results in 38.6% of instances. It also consistently surpasses Hamming distance search within the same framework, confirming the advantage of model-based exploration over simple local search. Overall, the probe and solve algorithm offers a practical, resource-aware approach for tuning constraint solvers that yields robust improvements across diverse problem types.

</details>


### [96] [Exploring LLM Features in Predictive Process Monitoring for Small-Scale Event-Logs](https://arxiv.org/abs/2601.11468)
*Alessandro Padella,Massimiliano de Leoni,Marlon Dumas*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Predictive Process Monitoring is a branch of process mining that aims to predict the outcome of an ongoing process. Recently, it leveraged machine-and-deep learning architectures. In this paper, we extend our prior LLM-based Predictive Process Monitoring framework, which was initially focused on total time prediction via prompting. The extension consists of comprehensively evaluating its generality, semantic leverage, and reasoning mechanisms, also across multiple Key Performance Indicators. Empirical evaluations conducted on three distinct event logs and across the Key Performance Indicators of Total Time and Activity Occurrence prediction indicate that, in data-scarce settings with only 100 traces, the LLM surpasses the benchmark methods. Furthermore, the experiments also show that the LLM exploits both its embodied prior knowledge and the internal correlations among training traces. Finally, we examine the reasoning strategies employed by the model, demonstrating that the LLM does not merely replicate existing predictive methods but performs higher-order reasoning to generate the predictions.

</details>


### [97] [Health Facility Location in Ethiopia: Leveraging LLMs to Integrate Expert Knowledge into Algorithmic Planning](https://arxiv.org/abs/2601.11479)
*Yohai Trabelsi,Guojun Xiong,Fentabil Getnet,Stéphane Verguet,Milind Tambe*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Ethiopia's Ministry of Health is upgrading health posts to improve access to essential services, particularly in rural areas. Limited resources, however, require careful prioritization of which facilities to upgrade to maximize population coverage while accounting for diverse expert and stakeholder preferences. In collaboration with the Ethiopian Public Health Institute and Ministry of Health, we propose a hybrid framework that systematically integrates expert knowledge with optimization techniques. Classical optimization methods provide theoretical guarantees but require explicit, quantitative objectives, whereas stakeholder criteria are often articulated in natural language and difficult to formalize. To bridge these domains, we develop the Large language model and Extended Greedy (LEG) framework. Our framework combines a provable approximation algorithm for population coverage optimization with LLM-driven iterative refinement that incorporates human-AI alignment to ensure solutions reflect expert qualitative guidance while preserving coverage guarantees. Experiments on real-world data from three Ethiopian regions demonstrate the framework's effectiveness and its potential to inform equitable, data-driven health system planning.

</details>


### [98] [BoxMind: Closed-loop AI strategy optimization for elite boxing validated in the 2024 Olympics](https://arxiv.org/abs/2601.11492)
*Kaiwen Wang,Kaili Zheng,Rongrong Deng,Qingmin Fan,Milin Zhang,Zongrui Li,Xuesi Zhou,Bo Han,Liren Chen,Chenyi Guo,Ji Wu*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Competitive sports require sophisticated tactical analysis, yet combat disciplines like boxing remain underdeveloped in AI-driven analytics due to the complexity of action dynamics and the lack of structured tactical representations. To address this, we present BoxMind, a closed-loop AI expert system validated in elite boxing competition. By defining atomic punch events with precise temporal boundaries and spatial and technical attributes, we parse match footage into 18 hierarchical technical-tactical indicators. We then propose a graph-based predictive model that fuses these explicit technical-tactical profiles with learnable, time-variant latent embeddings to capture the dynamics of boxer matchups. Modeling match outcome as a differentiable function of technical-tactical indicators, we turn winning probability gradients into executable tactical adjustments. Experiments show that the outcome prediction model achieves state-of-the-art performance, with 69.8% accuracy on BoxerGraph test set and 87.5% on Olympic matches. Using this predictive model as a foundation, the system generates strategic recommendations that demonstrate proficiency comparable to human experts. BoxMind is validated through a closed-loop deployment during the 2024 Paris Olympics, directly contributing to the Chinese National Team's historic achievement of three gold and two silver medals. BoxMind establishes a replicable paradigm for transforming unstructured video data into strategic intelligence, bridging the gap between computer vision and decision support in competitive sports.

</details>
