<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 197]
- [cs.CL](#cs.CL) [Total: 58]
- [cs.AI](#cs.AI) [Total: 49]
- [cs.AR](#cs.AR) [Total: 17]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Doppler-Enhanced Deep Learning: Improving Thyroid Nodule Segmentation with YOLOv5 Instance Segmentation](https://arxiv.org/abs/2512.00639)
*Mahmoud El Hussieni*

Main category: cs.CV

TL;DR: 研究利用YOLOv5算法对甲状腺结节进行实例分割，评估了不同变种在含或不含频谱成像的数据集上的性能，发现包含频谱成像能显著提高分割精度。


<details>
  <summary>Details</summary>
Motivation: 甲状腺癌的全球发病率上升推动了计算机辅助检测方法的发展，精确的甲状腺结节分割是AI辅助临床决策支持系统的关键。该项研究旨在使用YOLOv5算法通过超声图像实现甲状腺结节的实例分割。

Method: 研究对比了YOLOv5的多个变种（Nano、Small、Medium、Large、XLarge）在包含或不包含频谱成像的两个数据集上的性能。

Result: YOLOv5-Large 在包含频谱成像的数据集上表现最佳，Dice得分为91%，mAP为0.87。移除频谱成像后，YOLOv5-Small 的Dice得分为79%，但包含频谱成像则可显著提升所有型号的性能。

Conclusion: 该研究指出，使用YOLOv5进行甲状腺结节实例分割提供了一种有效的实时检测方法，可能适用于自动化诊断系统。

Abstract: The increasing prevalence of thyroid cancer globally has led to the development of various computer-aided detection methods. Accurate segmentation of thyroid nodules is a critical first step in the development of AI-assisted clinical decision support systems. This study focuses on instance segmentation of thyroid nodules using YOLOv5 algorithms on ultrasound images. We evaluated multiple YOLOv5 variants (Nano, Small, Medium, Large, and XLarge) across two dataset versions, with and without doppler images. The YOLOv5-Large algorithm achieved the highest performance with a dice score of 91\% and mAP of 0.87 on the dataset including doppler images. Notably, our results demonstrate that doppler images, typically excluded by physicians, can significantly improve segmentation performance. The YOLOv5-Small model achieved 79\% dice score when doppler images were excluded, while including them improved performance across all model variants. These findings suggest that instance segmentation with YOLOv5 provides an effective real-time approach for thyroid nodule detection, with potential clinical applications in automated diagnostic systems.

</details>


### [2] [Closing the Gap: Data-Centric Fine-Tuning of Vision Language Models for the Standardized Exam Questions](https://arxiv.org/abs/2512.00042)
*Egemen Sert,Şeyda Ertekin*

Main category: cs.CV

TL;DR: 本文展示了使用高质量标注数据集和优化的推理语法进行监督微调可以达到与专有方法相近的性能。通过创建一个包含课本题目解答对、课程对齐插图和上下文材料的161.4M多模态数据集，并使用优化的推理语法微调Qwen-2.5VL-32B模型，该模型在新基准测试YKSUniform上取得了78.6%的准确率，接近于Gemini 2.0 Flash。


<details>
  <summary>Details</summary>
Motivation: 本文探讨了标准化考试题目作为多模态推理测试的严格性，并展示了训练数据和表示语法在多模态推理中的重要性。

Method: 本研究编制了一个包含161.4M多模态数据的大型数据集，其中包括课本题目和解答对、课程对齐插图和上下文材料，并使用了优化的推理语法进行大规模监督微调。

Result: 通过这种方法，该研究的模型在新基准测试YKSUniform上取得了78.6%的准确率，接近于Gemini 2.0 Flash。

Conclusion: 本研究展示了数据驱动的方法在提升多模态推理性能方面的潜力，证明了精心编排的多模态数据和课程接地可以推动监督微调接近最佳性能。

Abstract: Multimodal reasoning has become a cornerstone of modern AI research. Standardized exam questions offer a uniquely rigorous testbed for such reasoning, providing structured visual contexts and verifiable answers. While recent progress has largely focused on algorithmic advances such as reinforcement learning (e.g., GRPO, DPO), the data centric foundations of vision language reasoning remain less explored.
  We show that supervised fine-tuning (SFT) with high-quality data can rival proprietary approaches. To this end, we compile a 161.4 million token multimodal dataset combining textbook question-solution pairs, curriculum aligned diagrams, and contextual materials, and fine-tune Qwen-2.5VL-32B using an optimized reasoning syntax (QMSA). The resulting model achieves 78.6% accuracy, only 1.0% below Gemini 2.0 Flash, on our newly released benchmark YKSUniform, which standardizes 1,854 multimodal exam questions across 309 curriculum topics.
  Our results reveal that data composition and representational syntax play a decisive role in multimodal reasoning. This work establishes a data centric framework for advancing open weight vision language models, demonstrating that carefully curated and curriculum-grounded multimodal data can elevate supervised fine-tuning to near state-of-the-art performance.

</details>


### [3] [PEFT-DML: Parameter-Efficient Fine-Tuning Deep Metric Learning for Robust Multi-Modal 3D Object Detection in Autonomous Driving](https://arxiv.org/abs/2512.00060)
*Abdolazim Rezaei,Mehdi Sookhak*

Main category: cs.CV

TL;DR: PEFT-DML 提出了一种参数高效的方法，用于自驾车中的鲁棒多模态 3D 物体检测，通过将不同类型传感器数据整合到一个共享的潜在空间来应对传感器数据丢失或未知组合的情况。


<details>
  <summary>Details</summary>
Motivation: 为了解决自动驾驶中多模态 3D 物体检测在传感器数据缺失或不常见组合条件下的鲁棒性问题，需要一种参数高效的框架来处理不同类型的传感器数据。

Method: PEFT-DML 通过使用 LoRA 和适配器层来整合不同模态的数据，并将其映射到共同的潜在空间，提高了训练效率并增强了对快动、天气变化和域转移的鲁棒性。

Result: 在 nuScenes 基准测试中，PEFT-DML 展现出卓越的准确性。

Conclusion: PEFT-DML 框架为鲁棒多模态 3D 物体检测提供了一种有效的解决方案，适用于自动驾驶场景中不同传感器数据的应用。

Abstract: This study introduces PEFT-DML, a parameter-efficient deep metric learning framework for robust multi-modal 3D object detection in autonomous driving. Unlike conventional models that assume fixed sensor availability, PEFT-DML maps diverse modalities (LiDAR, radar, camera, IMU, GNSS) into a shared latent space, enabling reliable detection even under sensor dropout or unseen modality class combinations. By integrating Low-Rank Adaptation (LoRA) and adapter layers, PEFT-DML achieves significant training efficiency while enhancing robustness to fast motion, weather variability, and domain shifts. Experiments on benchmarks nuScenes demonstrate superior accuracy.

</details>


### [4] [Satellite to Street : Disaster Impact Estimator](https://arxiv.org/abs/2512.00065)
*Sreesritha Sai,Sai Venkata Suma Sreeja,Deepthi,Nikhil*

Main category: cs.CV

TL;DR: 提出了一个结合灾前和灾后卫星图像的深度学习框架，用于生成细粒度的像素级损伤图，以支持快速，一致的灾害响应。


<details>
  <summary>Details</summary>
Motivation: 灾后评估工作需要高效，客观，能够扩展的方法，手动解析卫星图像速度慢，主观且难以扩展。

Method: 该模型采用了修改后的双输入U-Net架构，具有增强的特征融合，能够捕捉局部结构变化和广泛上下文线索，并通过分类意识加权损失函数处理真实灾后数据集中的未受损害像素主导问题。

Result: 在公开可用的灾害数据集上的实验表明，与传统的分割和基线变化检测模型相比，该模型在结构性损伤的定位和分类方面有所改进。

Conclusion: 生成的损伤图提供了快速，一致的评估机制，支持基于数据的灾害管理，但不是替代专家决策。

Abstract: Accurate post-disaster damage assessment is of high importance for prioritizing emergency response; however, manual interpretation of satellite imagery is slow, subjective, and hard to scale. While deep-learning models for image segmentation, such as U-Net-based baselines and change-detection models, are useful baselines, they often struggle with subtle structural variations and severe class imbalance, yielding poor detection of highly damaged regions. The present work proposes a deep-learning framework that jointly processes pre- and post-disaster satellite images to obtain fine-grained pixel-level damage maps: Satellite-to-Street: Disaster Impact Estimator. The model uses a modified dual-input U-Net architecture with enhanced feature fusion to capture both the local structural changes as well as the broader contextual cues. Class-aware weighted loss functions are integrated in order to handle the dominance of undamaged pixels in real disaster datasets, thus enhancing sensitivity toward major and destroyed categories. Experimentation on publicly available disaster datasets shows improved localization and classification of structural damage when compared to traditional segmentation and baseline change-detection models. The resulting damage maps provide a rapid and consistent assessment mechanism to support and not replace expert decision-making, thus allowing more efficient, data-driven disaster management.

</details>


### [5] [ProvRain: Rain-Adaptive Denoising and Vehicle Detection via MobileNet-UNet and Faster R-CNN](https://arxiv.org/abs/2512.00073)
*Aswinkumar Varathakumaran,Nirmala Paramanandham*

Main category: cs.CV

TL;DR: 该研究提出了一种称为ProvRain的轻量级检测管道，通过使用合成和实际数据集结合强化学习方法来提高夜间雨天下的车辆检测准确性。


<details>
  <summary>Details</summary>
Motivation: 夜间行车环境复杂，车灯识别技术难以应对恶劣天气条件如雨、雪等引起的各种噪声干扰，影响车辆检测的准确性和召回率。

Method: 该研究所采用的ProvRain管道利用了MobileNet-U-Net架构，并通过层次化的训练方法适应各种天气条件，并采用了综合合成和实际数据集的混合数据源增强模型的鲁棒性。

Result: 与基于PVDN数据集训练的标准Faster RCNN架构相比，该研究提出的ProvRain管道在雨天的车辆检测中显著提高了准确率（提升了8.94%）和召回率（提高了10.25%）。定制的MobileNet-U-Net架构在峰值信噪比（PSNR）、结构相似性（SSIM）等指标上也取得了10-15%的改进，并减少了67%的感知误差。

Conclusion: 该研究通过提出一种新的轻量级检测管道，有效地提升了车辆在游戏中雨天的检测性能，具有广阔的应用前景。

Abstract: Provident vehicle detection has a lot of scope in the detection of vehicle during night time. The extraction of features other than the headlamps of vehicles allows us to detect oncoming vehicles before they appear directly on the camera. However, it faces multiple issues especially in the field of night vision, where a lot of noise caused due to weather conditions such as rain or snow as well as camera conditions. This paper focuses on creating a pipeline aimed at dealing with such noise while at the same time maintaining the accuracy of provident vehicular detection. The pipeline in this paper, ProvRain, uses a lightweight MobileNet-U-Net architecture tuned to generalize to robust weather conditions by using the concept of curricula training. A mix of synthetic as well as available data from the PVDN dataset is used for this. This pipeline is compared to the base Faster RCNN architecture trained on the PVDN dataset to see how much the addition of a denoising architecture helps increase the detection model's performance in rainy conditions. The system boasts an 8.94\% increase in accuracy and a 10.25\% increase in recall in the detection of vehicles in rainy night time frames. Similarly, the custom MobileNet-U-Net architecture that was trained also shows a 10-15\% improvement in PSNR, a 5-6\% increase in SSIM, and upto a 67\% reduction in perceptual error (LPIPS) compared to other transformer approaches.

</details>


### [6] [Adapter Shield: A Unified Framework with Built-in Authentication for Preventing Unauthorized Zero-Shot Image-to-Image Generation](https://arxiv.org/abs/2512.00075)
*Jun Jia,Hongyi Miao,Yingjie Zhou,Wangqiu Zhou,Jianbo Zhang,Linhan Cao,Dandan Zhu,Hua Yang,Xiongkuo Min,Wei Sun,Guangtao Zhai*

Main category: cs.CV

TL;DR: 本文提出了一种名为Adapter Shield的解决方案，通过在零样本生成场景中保护个人图像免受滥用，实现了加密嵌入并设计了多重目标对抗扰动方法，使未经授权用户只能生成扭曲或加密的输出。


<details>
  <summary>Details</summary>
Motivation: 随着扩散模型的发展，零样本图像生成技术已经能够实现高保真度的身份复制或艺术风格再现，但这也带来了未经授权的身份克隆和风格模仿等知识产权问题的风险。

Method: 适应器屏蔽系统首先分析了当前零样本方法如何利用图像编码器从输入图像中提取嵌入，然后通过交叉注意力层将这些嵌入送入扩散模型的UNet。该系统随后构建了一个可逆加密系统，通过不同密钥将原始嵌入映射到不同的加密表示。此外，还设计了一种多重目标对抗扰动方法，引导原始嵌入向预定的加密模式偏移。

Result: 该方法在阻止未经授权的零样本图像合成方面优于现有的最先进的防御措施，同时支持验证用户的安全和灵活的访问控制。

Conclusion: 这项工作展示了在零样本生成场景中保护个人图像免受滥用的方法，并提供了防御工具来确保只有授权用户能够正常生成图像，同时限制了未经授权用户的生成能力。

Abstract: With the rapid progress in diffusion models, image synthesis has advanced to the stage of zero-shot image-to-image generation, where high-fidelity replication of facial identities or artistic styles can be achieved using just one portrait or artwork, without modifying any model weights. Although these techniques significantly enhance creative possibilities, they also pose substantial risks related to intellectual property violations, including unauthorized identity cloning and stylistic imitation. To counter such threats, this work presents Adapter Shield, the first universal and authentication-integrated solution aimed at defending personal images from misuse in zero-shot generation scenarios. We first investigate how current zero-shot methods employ image encoders to extract embeddings from input images, which are subsequently fed into the UNet of diffusion models through cross-attention layers. Inspired by this mechanism, we construct a reversible encryption system that maps original embeddings into distinct encrypted representations according to different secret keys. The authorized users can restore the authentic embeddings via a decryption module and the correct key, enabling normal usage for authorized generation tasks. For protection purposes, we design a multi-target adversarial perturbation method that actively shifts the original embeddings toward designated encrypted patterns. Consequently, protected images are embedded with a defensive layer that ensures unauthorized users can only produce distorted or encrypted outputs. Extensive evaluations demonstrate that our method surpasses existing state-of-the-art defenses in blocking unauthorized zero-shot image synthesis, while supporting flexible and secure access control for verified users.

</details>


### [7] [Diffusion-Based Synthetic Brightfield Microscopy Images for Enhanced Single Cell Detection](https://arxiv.org/abs/2512.00078)
*Mario de Jesus da Graca,Jörg Dahlkemper,Peer Stelldinger*

Main category: cs.CV

TL;DR: 该研究利用基于U-Net的扩散模型生成合成明场显微镜图像，旨在提高单细胞检测准确性，同时减少对昂贵手动注释的依赖。


<details>
  <summary>Details</summary>
Motivation: 当前生物学研究中单细胞检测存在数据稀缺和注释瓶颈问题，深度学习方法进展受限。因此，研究通过生成合成数据来提升单细胞检测模型的性能，减轻人工标注负担。

Method: 使用基于U-Net的无条件模型生成合成图像，并训练预测模型。实验使用YOLOv8, YOLOv9和RT-DETR进行，探索合成数据对目标检测性能的影响。

Result: 合成数据训练可以显著提高检测精度，并且生成的图像质量很高，人的专家难以区分合成和真实图像。

Conclusion: 基于扩散的合成数据生成方法在显微图像分析中是个有前景的途径，能够增强真实数据集，减少对人工标注的依赖，提高细胞检测模型的鲁棒性。

Abstract: Accurate single cell detection in brightfield microscopy is crucial for biological research, yet data scarcity and annotation bottlenecks limit the progress of deep learning methods. We investigate the use of unconditional models to generate synthetic brightfield microscopy images and evaluate their impact on object detection performance. A U-Net based diffusion model was trained and used to create datasets with varying ratios of synthetic and real images. Experiments with YOLOv8, YOLOv9 and RT-DETR reveal that training with synthetic data can achieve improved detection accuracies (at minimal costs). A human expert survey demonstrates the high realism of generated images, with experts not capable to distinguish them from real microscopy images (accuracy 50%). Our findings suggest that diffusion-based synthetic data generation is a promising avenue for augmenting real datasets in microscopy image analysis, reducing the reliance on extensive manual annotation and potentially improving the robustness of cell detection models.

</details>


### [8] [Conceptual Evaluation of Deep Visual Stereo Odometry for the MARWIN Radiation Monitoring Robot in Accelerator Tunnels](https://arxiv.org/abs/2512.00080)
*André Dehne,Juri Zach,Peer Stelldinger*

Main category: cs.CV

TL;DR: MAR Winn机器人在欧洲XFEL中采用纯视觉的深度视差区间里程计(DVSO)以解决传统导航方法在未知几何结构中的不足，尽管在低纹理表面、光照变化、计算负载以及辐射下的鲁棒性方面存在问题。


<details>
  <summary>Details</summary>
Motivation: 在欧洲XFEL这样复杂且要求高度自动化的应用场景中，开发一种能够应对未知环境的新型导航技术以提升MAR Winn机器人的自主导航能力。

Method: 提出了深度视差区间里程计(DVSO)，结合视差、光学流以及自我监督学习，实现无需标签数据的情况下同时估计深度和 ego-运动。

Result: DVSO在概念评估中表现出了减少比例漂移的优点，并且具有低成本传感器和可扩展数据收集等优势。

Conclusion: 未来的工作将致力于解决DVSO在低纹理表面、环境光照变化、计算负载以及辐射影响下的鲁棒性等问题，朝着使MAR Winn能在受限的安全关键基础设施中更加自主导航的目标前进。

Abstract: The MARWIN robot operates at the European XFEL to perform autonomous radiation monitoring in long, monotonous accelerator tunnels where conventional localization approaches struggle. Its current navigation concept combines lidar-based edge detection, wheel/lidar odometry with periodic QR-code referencing, and fuzzy control of wall distance, rotation, and longitudinal position. While robust in predefined sections, this design lacks flexibility for unknown geometries and obstacles. This paper explores deep visual stereo odometry (DVSO) with 3D-geometric constraints as a focused alternative. DVSO is purely vision-based, leveraging stereo disparity, optical flow, and self-supervised learning to jointly estimate depth and ego-motion without labeled data. For global consistency, DVSO can subsequently be fused with absolute references (e.g., landmarks) or other sensors. We provide a conceptual evaluation for accelerator tunnel environments, using the European XFEL as a case study. Expected benefits include reduced scale drift via stereo, low-cost sensing, and scalable data collection, while challenges remain in low-texture surfaces, lighting variability, computational load, and robustness under radiation. The paper defines a research agenda toward enabling MARWIN to navigate more autonomously in constrained, safety-critical infrastructures.

</details>


### [9] [Exploring Diagnostic Prompting Approach for Multimodal LLM-based Visual Complexity Assessment: A Case Study of Amazon Search Result Pages](https://arxiv.org/abs/2512.00082)
*Divendar Murtadak,Yoon Kim,Trilokya Akula*

Main category: cs.CV

TL;DR: 本研究通过诊断提示提高了MLLM评估亚马逊搜索结果页面视觉复杂度的可靠性，F1分数显著提升，但仍需更多研究及数据提升准确度。


<details>
  <summary>Details</summary>
Motivation: 鉴于当前MLLM在视觉复杂度评估上的局限性，尤其是对产品相似性和色彩强度评估的不足，研究旨在探索诊断提示如何改善MLLM评估性能。

Method: 研究者使用了200个亚马逊搜索结果页面，并结合人类专家的注释，对比了基于诊断提示和基于经典格式原则提示的方法。

Result: 研究结果发现，使用诊断提示可以显著提高MLLM对未来人类复杂度判断的预测能力，F1分数从0.031提高到了0.297，但绝对性能仍较低，Kappa值为0.071。

Conclusion: 研究结论认为，诊断提示是迈向与人类一致的MLLM评估的一个初步步骤，但需要进一步研究和改进，特别是在更大的现实数据集上进行验证。

Abstract: This study investigates whether diagnostic prompting can improve Multimodal Large Language Model (MLLM) reliability for visual complexity assessment of Amazon Search Results Pages (SRP). We compare diagnostic prompting with standard gestalt principles-based prompting using 200 Amazon SRP pages and human expert annotations. Diagnostic prompting showed notable improvements in predicting human complexity judgments, with F1-score increasing from 0.031 to 0.297 (+858\% relative improvement), though absolute performance remains modest (Cohen's $κ$ = 0.071). The decision tree revealed that models prioritize visual design elements (badge clutter: 38.6\% importance) while humans emphasize content similarity, suggesting partial alignment in reasoning patterns. Failure case analysis reveals persistent challenges in MLLM visual perception, particularly for product similarity and color intensity assessment. Our findings indicate that diagnostic prompting represents a promising initial step toward human-aligned MLLM-based evaluation, though failure cases with consistent human-MLLM disagreement require continued research and refinement in prompting approaches with larger ground truth datasets for reliable practical deployment.

</details>


### [10] [A Fast and Efficient Modern BERT based Text-Conditioned Diffusion Model for Medical Image Segmentation](https://arxiv.org/abs/2512.00084)
*Venkata Siddharth Dhara,Pawan Kumar*

Main category: cs.CV

TL;DR: FastTextDiff是一种利用医学文本注释提高医学图像分割模型性能的新方法，通过集成ModernBERT进行跨模态注意，提升分割准确性并缩短训练时间。


<details>
  <summary>Details</summary>
Motivation: 当前DPMs在医学影像生成和去噪中表现良好，但在分割性能上受到像素级密集标签的限制，这些标签成本高昂且需要专家知识。FastTextDiff旨在通过整合医学文本注释来优化分割模型，减少对昂贵标签的需求。

Method: FastTextDiff方法主要包括：1) 使用现代BERT处理长临床笔记，2) 训练ModernBERT从MIMIC-III和MIMIC-IV中编码临床知识，3) 利用FlashAttention 2的交替注意力机制提升性能，4) 在扩散模型分割管道中替代Clinical BioBERT。

Result: 实验验证了ModernBERT在扩散模型分割管道中的有效性和效率，FastTextDiff在分割准确性上优于传统模型，同时具有更快的训练速度。

Conclusion: FastTextDiff通过结合文本和视觉模态信息，为医学图像分割提供了改进的途径，展示了多模态技术在医学成像分析中的潜力。

Abstract: In recent times, denoising diffusion probabilistic models (DPMs) have proven effective for medical image generation and denoising, and as representation learners for downstream segmentation. However, segmentation performance is limited by the need for dense pixel-wise labels, which are expensive, time-consuming, and require expert knowledge. We propose FastTextDiff, a label-efficient diffusion-based segmentation model that integrates medical text annotations to enhance semantic representations. Our approach uses ModernBERT, a transformer capable of processing long clinical notes, to tightly link textual annotations with semantic content in medical images. Trained on MIMIC-III and MIMIC-IV, ModernBERT encodes clinical knowledge that guides cross-modal attention between visual and textual features. This study validates ModernBERT as a fast, scalable alternative to Clinical BioBERT in diffusion-based segmentation pipelines and highlights the promise of multi-modal techniques for medical image analysis. By replacing Clinical BioBERT with ModernBERT, FastTextDiff benefits from FlashAttention 2, an alternating attention mechanism, and a 2-trillion-token corpus, improving both segmentation accuracy and training efficiency over traditional diffusion-based models.

</details>


### [11] [Multi-modal On-Device Learning for Monocular Depth Estimation on Ultra-low-power MCUs](https://arxiv.org/abs/2512.00086)
*Davide Nadalini,Manuele Rusci,Elia Cereda,Luca Benini,Francesco Conti,Daniele Palossi*

Main category: cs.CV

TL;DR: 本文提出了一种针对物联网设备的多模态在设备学习技术，通过在新环境中激活深度传感器收集伪标签并进行微调，实现了在Greenwaves GAP9 MCU上进行深度估计，相比全量更新减少了84%的内存使用，同时保持了较高精度。


<details>
  <summary>Details</summary>
Motivation: 物联网设备受限于硬件参数，深度学习模型在实际应用中的准确性会下降。为解决这一问题，本文提出了一种多模态在设备学习技术，减轻了对传感器数据不匹配的敏感度。

Method: 提出了一种内存驱动稀疏更新方案，减少训练所需的内存，同时使用深度传感器收集伪标签用于模型微调。

Result: 实验证实在Greenwaves GAP9 MCU上进行深度估计，仅需17.8分钟，相比全量更新减少了84%的内存使用，最终将KITTI和NYUv2数据集上的根均方误差分别降低至0.6m。

Conclusion: 本文基于在设备学习的多模态技术成功应用于物联网设备深度估计，显著提高了模型的适应性和准确性。

Abstract: Monocular depth estimation (MDE) plays a crucial role in enabling spatially-aware applications in Ultra-low-power (ULP) Internet-of-Things (IoT) platforms. However, the limited number of parameters of Deep Neural Networks for the MDE task, designed for IoT nodes, results in severe accuracy drops when the sensor data observed in the field shifts significantly from the training dataset. To address this domain shift problem, we present a multi-modal On-Device Learning (ODL) technique, deployed on an IoT device integrating a Greenwaves GAP9 MicroController Unit (MCU), a 80 mW monocular camera and a 8 x 8 pixel depth sensor, consuming $\approx$300mW. In its normal operation, this setup feeds a tiny 107 k-parameter $μ$PyD-Net model with monocular images for inference. The depth sensor, usually deactivated to minimize energy consumption, is only activated alongside the camera to collect pseudo-labels when the system is placed in a new environment. Then, the fine-tuning task is performed entirely on the MCU, using the new data. To optimize our backpropagation-based on-device training, we introduce a novel memory-driven sparse update scheme, which minimizes the fine-tuning memory to 1.2 MB, 2.2x less than a full update, while preserving accuracy (i.e., only 2% and 1.5% drops on the KITTI and NYUv2 datasets). Our in-field tests demonstrate, for the first time, that ODL for MDE can be performed in 17.8 minutes on the IoT node, reducing the root mean squared error from 4.9 to 0.6m with only 3 k self-labeled samples, collected in a real-life deployment scenario.

</details>


### [12] [Exploring Automated Recognition of Instructional Activity and Discourse from Multimodal Classroom Data](https://arxiv.org/abs/2512.00087)
*Ivo Bueno,Ruikun Hou,Babette Bühler,Tim Fütterer,James Drimalla,Jonathan Kyle Foster,Peter Youngs,Peter Gerjets,Ulrich Trautwein,Enkelejda Kasneci*

Main category: cs.CV

TL;DR: 该研究利用大规模标注的课堂教学录像和转录数据，设计了多模态分析管道，评估了零样本多模态语言模型、微调视觉-语言模型和自监督视频变压器等方法，并采用标签特异性阈值、上下文窗口和类不平衡损失函数处理标签不平衡和多标签复杂性问题，结果显示微调模型在视频和转录数据上的表现优于提示基模型。


<details>
  <summary>Details</summary>
Motivation: 当前的课堂教学记录分析依赖于手工标注，耗时且难以扩展。为了提供基于实际反馈的教师支持，研究旨在开发一种基于AI的自动化分析方法。

Method: 研究团队使用包含164小时视频和68份课堂转录的大规模标注数据集，设计了视频和转录数据的多模态分析管道。它们评估了零样本多模态语言模型、微调视觉-语言模型和自监督视频变压器，并通过上下文窗口和不平衡损失函数处理了标签不平衡和多标签问题。

Result: 结果显示，微调模型在视频数据上的宏-F1得分为0.577，在转录数据上的得分为0.460，均优于基于提示的方法。

Conclusion: 这些结果证明了自动教室分析的可行性，并为此提供了实现大规模教师反馈系统的基础。

Abstract: Observation of classroom interactions can provide concrete feedback to teachers, but current methods rely on manual annotation, which is resource-intensive and hard to scale. This work explores AI-driven analysis of classroom recordings, focusing on multimodal instructional activity and discourse recognition as a foundation for actionable feedback. Using a densely annotated dataset of 164 hours of video and 68 lesson transcripts, we design parallel, modality-specific pipelines. For video, we evaluate zero-shot multimodal LLMs, fine-tuned vision-language models, and self-supervised video transformers on 24 activity labels. For transcripts, we fine-tune a transformer-based classifier with contextualized inputs and compare it against prompting-based LLMs on 19 discourse labels. To handle class imbalance and multi-label complexity, we apply per-label thresholding, context windows, and imbalance-aware loss functions. The results show that fine-tuned models consistently outperform prompting-based approaches, achieving macro-F1 scores of 0.577 for video and 0.460 for transcripts. These results demonstrate the feasibility of automated classroom analysis and establish a foundation for scalable teacher feedback systems.

</details>


### [13] [TeleViT1.0: Teleconnection-aware Vision Transformers for Subseasonal to Seasonal Wildfire Pattern Forecasts](https://arxiv.org/abs/2512.00089)
*Ioannis Prapas,Nikolaos Papadopoulos,Nikolaos-Ioannis Bountos,Dimitrios Michail,Gustau Camps-Valls,Ioannis Papoutsis*

Main category: cs.CV

TL;DR: TeleViT通过结合精细尺度的本地火因、粗化的全球数据以及遥连接指数，实现了对未来森林火灾长达四个月的预测，显著提升了AUPRC性能。


<details>
  <summary>Details</summary>
Motivation: 目前难以预见未来的森林火灾，而长时间预测对于制定燃料管理和资源分配计划至关重要。由于森林火灾受全球气候变化和遥连接的影响，传统的短时预测模型在长时预测中效果不佳。因此，研究提出了一种TeleViT模型来改善这一问题。

Method: TeleViT模型采用了一种非对称的分词策略，生成异构分词并由变换器编码器联合处理，再由解码器保持空间结构。该模型旨在融合精细尺度的本地因素、粗化的全球数据以及遥连接指数，以实现多尺度融合。

Result: 实验结果表明，TeleViT模型在使用全球海事火灾数据库（2001-2021，8天分辨率）时，整体性能优于U-Net++、ViT和气候学方法。无论预测时间如何，TeleViT使用全球输入的版本都能保持较高性能，甚至在四个月的预测时甚至超过气候学方法。在不同的区域，TeleViT在季节性一致的火灾区域显示出最高的技能。

Conclusion: 研究证明，可通过设计能够明确编码地球系统背景的架构来延长森林火灾在跨季节到次季节时间尺度的可预见性。

Abstract: Forecasting wildfires weeks to months in advance is difficult, yet crucial for planning fuel treatments and allocating resources. While short-term predictions typically rely on local weather conditions, long-term forecasting requires accounting for the Earth's interconnectedness, including global patterns and teleconnections. We introduce TeleViT, a Teleconnection-aware Vision Transformer that integrates (i) fine-scale local fire drivers, (ii) coarsened global fields, and (iii) teleconnection indices. This multi-scale fusion is achieved through an asymmetric tokenization strategy that produces heterogeneous tokens processed jointly by a transformer encoder, followed by a decoder that preserves spatial structure by mapping local tokens to their corresponding prediction patches.
  Using the global SeasFire dataset (2001-2021, 8-day resolution), TeleViT improves AUPRC performance over U-Net++, ViT, and climatology across all lead times, including horizons up to four months. At zero lead, TeleViT with indices and global inputs reaches AUPRC 0.630 (ViT 0.617, U-Net 0.620), at 16x8day lead (around 4 months), TeleViT variants using global input maintain 0.601-0.603 (ViT 0.582, U-Net 0.578), while surpassing the climatology (0.572) at all lead times. Regional results show the highest skill in seasonally consistent fire regimes, such as African savannas, and lower skill in boreal and arid regions. Attention and attribution analyses indicate that predictions rely mainly on local tokens, with global fields and indices contributing coarse contextual information. These findings suggest that architectures explicitly encoding large-scale Earth-system context can extend wildfire predictability on subseasonal-to-seasonal timescales.

</details>


### [14] [Deep Filament Extraction for 3D Concrete Printing](https://arxiv.org/abs/2512.00091)
*Karam Mawas,Mehdi Maboudi,Pedro Achanccaray,Markus Gerke*

Main category: cs.CV

TL;DR: 本文介绍了针对基于挤出和喷射混凝土3D打印方法中的纤维进行自动质量控制的过程。该方法不依赖于用于数据获取的传感器类型，并适用于生料和固化材料，可用于在线和后打印质量控制。


<details>
  <summary>Details</summary>
Motivation: 由于3D混凝土打印技术在建筑行业的广泛应用，对于打印结构的质量控制变得尤为重要。现有的研究和实践往往依赖于人工检查或者单一的传感器类型，这限制了其效率和准确性。因此，本文提出了一个独立于传感器类型的自动化纤维质量控制流程，旨在提高3D混凝土打印的质量控制水平。

Method: 本文提出的方法包括一个独立于传感器类型的自动化纤维质量控制流程，该流程可以采集来自相机、结构光系统（SLS）或地面激光扫描仪（TLS）的数据。该方法能够处理生料和固化的材料，从而支持在线和后打印的质量控制。

Result: 本研究开发的自动化纤维质量控制方法能够在不受传感器限制的情况下，实现对挤出和喷射混凝土3D打印类型中的纤维的定量分析，提高了质量控制的效率和准确性。该方法的成功应用可以显著提升3DCP技术的实际应用水平。

Conclusion: 本文提出了一种针对基于挤出和喷射混凝土3D打印的纤维进行了自动化质量控制的流程，这种方法具有灵活性高和适用范围广的特点，能够满足当前和未来建筑行业的需求。未来的研究可以进一步优化质量控制标准，或者研究与其他3D打印技术的结合应用。

Abstract: The architecture, engineering and construction (AEC) industry is constantly evolving to meet the demand for sustainable and effective design and construction of the built environment. In the literature, two primary deposition techniques for large-scale 3D concrete printing (3DCP) have been described, namely extrusion-based (Contour Crafting-CC) and shotcrete 3D printing (SC3DP) methods. The deposition methods use a digitally controlled nozzle to print material layer by layer. The continuous flow of concrete material used to create the printed structure is called a filament or layer. As these filaments are the essential structure defining the printed object, the filaments' geometry quality control is crucial. This paper presents an automated procedure for quality control (QC) of filaments in extrusion-based and SC3DP printing methods. The paper also describes a workflow that is independent of the sensor used for data acquisition, such as a camera, a structured light system (SLS) or a terrestrial laser scanner (TLS). This method can be used with materials in either the fresh or cured state. Thus, it can be used for online and post-printing QC.

</details>


### [15] [Comparative Analysis of Vision Transformer, Convolutional, and Hybrid Architectures for Mental Health Classification Using Actigraphy-Derived Images](https://arxiv.org/abs/2512.00103)
*Ifeanyi Okala*

Main category: cs.CV

TL;DR: 本研究探究了三种基于图像的模型（VGG16、ViT-B/16 和 CoAtNet-Tiny）在识别抑郁症、精神分裂症和健康对照组时的表现，尽管所有模型在训练数据上表现良好，但在未见数据上的表现各异。CoAtNet-Tiny 显示出最为一致的表现，VGG16 有所提升但常常停留在较低准确度，而 ViT-B/16 的表现则在不同折叠间变化显著。总体而言，CoAtNet-Tiny 在精神健康工作中的表现最为稳定。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索不同机器学习模型在心理健康领域中处理来自活动记录（actigraphy）的数据的有效性。

Method: 研究使用了三个图像模型：VGG16、ViT-B/16 和 CoAtNet-Tiny。通过将腕戴式活动信号转换为 30x48 的图像，并使用三分对折的主体内分割方法进行评估。

Result: 尽管所有模型都能很好地拟合训练数据，但在未见过的数据上的行为各异。CoAtNet-Tiny 显示出最稳定的表现，拥有最高的平均准确率和最稳定的学习曲线。而 VGG16 的表现呈现稳定提升的趋势，但往往停留在较低的准确率水平。ViT-B/16 在某些运行中表现强劲，但在不同折间的性能变化明显。

Conclusion: 研究结果表明，在基于活动记录图像的数据上，CoAtNet-Tiny 在心理健康类应用中表现出更为一致和稳健的性能。这表明某些混合设计可能特别适合依赖于活动记录图像的神经精神科任务。

Abstract: This work examines how three different image-based methods, VGG16, ViT-B/16, and CoAtNet-Tiny, perform in identifying depression, schizophrenia, and healthy controls using daily actigraphy records. Wrist-worn activity signals from the Psykose and Depresjon datasets were converted into 30 by 48 images and evaluated through a three-fold subject-wise split. Although all methods fitted the training data well, their behaviour on unseen data differed. VGG16 improved steadily but often settled at lower accuracy. ViT-B/16 reached strong results in some runs, but its performance shifted noticeably from fold to fold. CoAtNet-Tiny stood out as the most reliable, recording the highest average accuracy and the most stable curves across folds. It also produced the strongest precision, recall, and F1-scores, particularly for the underrepresented depression and schizophrenia classes. Overall, the findings indicate that CoAtNet-Tiny performed most consistently on the actigraphy images, while VGG16 and ViT-B/16 yielded mixed results. These observations suggest that certain hybrid designs may be especially suited for mental-health work that relies on actigraphy-derived images.

</details>


### [16] [TinyViT: Field Deployable Transformer Pipeline for Solar Panel Surface Fault and Severity Screening](https://arxiv.org/abs/2512.00117)
*Ishwaryah Pandiarajan,Mohamed Mansoor Roomi Sindha,Uma Maheswari Pandyan,Sharafia N*

Main category: cs.CV

TL;DR: 本文提出了一种名为TinyViT的紧凑型管道，结合Transformer基段、光谱-空间特征工程和集合回归，仅通过平面可见光图像实现了表面异常分类和严重性估计，从而实现低成本、大规模的光伏板维护，并推动了太阳能健康监测的普遍适用。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态成像策略因引入了日程农场级别的部署中的物流和经济障碍而面临挑战。本文旨在利用深度学习和经典机器学习相结合的方法，通过平面可见光图像单点获取光伏板表面异常分类和严重性估计，以克服这些障碍，实现经济高效的光伏系统维护。

Method: 本文介绍了TinyViT，一种结合了Transformer基段进行分割、光谱-空间特征工程和集合回归的紧凑性管道。该系统从常用的消费级彩色相机拼接光伏板图像中进行处理，实现了表面异常分类和生成可操作的严重性等级。

Result: 实验结果表明，该方法在分类和回归子模块上都达到了与专业方法相当的准确性和可解释性。

Conclusion: 本文提出的方法通过消除对电致发光或红外传感器的依赖，为资源有限的安装提供了经济高效的维护方案，并促进了太阳能健康监测的普遍适用。

Abstract: Sustained operation of solar photovoltaic assets hinges on accurate detection and prioritization of surface faults across vast, geographically distributed modules. While multi modal imaging strategies are popular, they introduce logistical and economic barriers for routine farm level deployment. This work demonstrates that deep learning and classical machine learning may be judiciously combined to achieve robust surface anomaly categorization and severity estimation from planar visible band imagery alone. We introduce TinyViT which is a compact pipeline integrating Transformer based segmentation, spectral-spatial feature engineering, and ensemble regression. The system ingests consumer grade color camera mosaics of PV panels, classifies seven nuanced surface faults, and generates actionable severity grades for maintenance triage. By eliminating reliance on electroluminescence or IR sensors, our method enables affordable, scalable upkeep for resource limited installations, and advances the state of solar health monitoring toward universal field accessibility. Experiments on real public world datasets validate both classification and regression sub modules, achieving accuracy and interpretability competitive with specialized approaches.

</details>


### [17] [Hybrid Synthetic Data Generation with Domain Randomization Enables Zero-Shot Vision-Based Part Inspection Under Extreme Class Imbalance](https://arxiv.org/abs/2512.00125)
*Ruo-Syuan Mei,Sixian Jia,Guangze Li,Soo Yeon Lee,Brian Musser,William Keller,Sreten Zakula,Jorge Arinez,Chenhui Shao*

Main category: cs.CV

TL;DR: 本文提出了一种通过合成数据生成（SDG）框架来解决工业品质检测中高成本标注数据和类别不平衡问题的方法。该方法利用了基于模拟渲染、领域随机化和真实背景合成的技术，实现了无标注学习的零样本学习，能够在一小时内生成12,960张标注图像进行模型训练，并在实际工业部件上达到了高的检测和分类准确性。


<details>
  <summary>Details</summary>
Motivation: 在工业品检中，传统方法依赖于人工标注的数据集，既费时又昂贵。同时，缺陷样本稀缺，导致类别不平衡，影响机器学习模型的性能。因此，需要一种有效的解决方案来生成大量高质量、平衡且自动标注的数据集。

Method: 本文提出了一种新的SDG管道，通过结合基于模拟渲染、领域随机化和实际背景合成的技术，生成大规模、标注完整的数据集。接着，采用YOLOv8n和MobileNetV3-small模型训练，专门针对合成数据进行优化。

Result: 实验表明，基于合成数据的方法在检测精度（mAP@0.5为0.995）和分类准确率（96%和90.1%的平衡准确率）方面表现优异，尤其是在类别极度不平衡的情况下达到了90-91%的平衡准确率。相比基于少量真实数据的基准方法，该方法显著提高了准确率。

Conclusion: 本文通过合成数据生成框架，有效地解决了工业品检中数据稀缺和平衡性问题，展示了无标注学习的潜力，并为生产线上的无人工干预下的自动品质检测提供了有效解决方案。

Abstract: Machine learning, particularly deep learning, is transforming industrial quality inspection. Yet, training robust machine learning models typically requires large volumes of high-quality labeled data, which are expensive, time-consuming, and labor-intensive to obtain in manufacturing. Moreover, defective samples are intrinsically rare, leading to severe class imbalance that degrades model performance. These data constraints hinder the widespread adoption of machine learning-based quality inspection methods in real production environments. Synthetic data generation (SDG) offers a promising solution by enabling the creation of large, balanced, and fully annotated datasets in an efficient, cost-effective, and scalable manner. This paper presents a hybrid SDG framework that integrates simulation-based rendering, domain randomization, and real background compositing to enable zero-shot learning for computer vision-based industrial part inspection without manual annotation. The SDG pipeline generates 12,960 labeled images in one hour by varying part geometry, lighting, and surface properties, and then compositing synthetic parts onto real image backgrounds. A two-stage architecture utilizing a YOLOv8n backbone for object detection and MobileNetV3-small for quality classification is trained exclusively on synthetic data and evaluated on 300 real industrial parts. The proposed approach achieves an mAP@0.5 of 0.995 for detection, 96% classification accuracy, and 90.1% balanced accuracy. Comparative evaluation against few-shot real-data baseline approaches demonstrates significant improvement. The proposed SDG-based approach achieves 90-91% balanced accuracy under severe class imbalance, while the baselines reach only 50% accuracy. These results demonstrate that the proposed method enables annotation-free, scalable, and robust quality inspection for real-world manufacturing applications.

</details>


### [18] [Mammo-FM: Breast-specific foundational model for Integrated Mammographic Diagnosis, Prognosis, and Reporting](https://arxiv.org/abs/2512.00198)
*Shantanu Ghosh,Vedant Parthesh Joshi,Rayan Syed,Aya Kassem,Abhishek Varshney,Payel Basak,Weicheng Dai,Judy Wawira Gichoya,Hari M. Trivedi,Imon Banerjee,Shyam Visweswaran,Clare B. Poynton,Kayhan Batmanghelich*

Main category: cs.CV

TL;DR: Mammo-FM 是一种用于乳腺X光摄影的眼球模型，基于最大的多样化数据集进行预训练，并且在各种任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 乳腺癌是全球女性的主要死因之一，迫切需要开发专门用于乳腺影像学的模型以提高诊断和治疗效率并确保医疗活动的透明度。

Method: Mammo-FM 采用预训练方法，在四个美国医疗机构的 140,677 位患者的 821,326 张乳腺X光片上进行训练。

Result: Mammo-FM 在诊断、预后和报告生成任务中表现优异，虽然参数量仅为最先进通用模型的三分之一。

Conclusion: Mammo-FM 证明了针对特定临床领域的模型在综合执行多种任务时的高效性和价值，并强调了严格的、与领域相匹配的评估的重要性。

Abstract: Breast cancer is one of the leading causes of death among women worldwide. We introduce Mammo-FM, the first foundation model specifically for mammography, pretrained on the largest and most diverse dataset to date - 140,677 patients (821,326 mammograms) across four U.S. institutions. Mammo-FM provides a unified foundation for core clinical tasks in breast imaging, including cancer diagnosis, pathology localization, structured report generation, and cancer risk prognosis within a single framework. Its alignment between images and text enables both visual and textual interpretability, improving transparency and clinical auditability, which are essential for real-world adoption. We rigorously evaluate Mammo-FM across diagnosis, prognosis, and report-generation tasks in in- and out-of-distribution datasets. Despite operating on native-resolution mammograms and using only one-third of the parameters of state-of-the-art generalist FMs, Mammo-FM consistently outperforms them across multiple public and private benchmarks. These results highlight the efficiency and value of domain-specific foundation models designed around the full spectrum of tasks within a clinical domain and emphasize the importance of rigorous, domain-aligned evaluation.

</details>


### [19] [ReactionMamba: Generating Short &Long Human Reaction Sequences](https://arxiv.org/abs/2512.00208)
*Hajra Anwar Beg,Baptiste Chopin,Hao Tang,Mohamed Daoudi*

Main category: cs.CV

TL;DR:  ReactionMamba 是一种新颖的框架，用于生成长时间的3D人体反应动作，它结合了运动VAE进行高效编码和Mamba基于状态空间模型进行解码，实现了复杂的动律生成。


<details>
  <summary>Details</summary>
Motivation: 现有的方法在生成复杂动作序列（如舞蹈和武术）方面存在限制，特别是在生成长时间序列时。因此，论文提出了 ReactionMamba 框架，旨在填补这些空白。

Method:  ReactionMamba 采用了一种结合了运动VAE的高效编码和 Mamba 基于状态空间模型的解码的新设计，这使得模型能够自然地生成复杂的反应序列。

Result: 通过在 NTU120-AS、Lindy Hop 和 InterX 等三种数据集上的评测，ReactionMamba 在真实性和多样性方面表现出色，尤其在生成长序列方面取得了显著的效果。

Conclusion: 与现有的 InterFormer、ReMoS 和 Ready-to-React 方法相比，ReactionMamba 在性能上取得了实质性的改进，特别是提高了推断速度。

Abstract: We present ReactionMamba, a novel framework for generating long 3D human reaction motions. Reaction-Mamba integrates a motion VAE for efficient motion encoding with Mamba-based state-space models to decode temporally consistent reactions. This design enables ReactionMamba to generate both short sequences of simple motions and long sequences of complex motions, such as dance and martial arts. We evaluate ReactionMamba on three datasets--NTU120-AS, Lindy Hop, and InterX--and demonstrate competitive performance in terms of realism, diversity, and long-sequence generation compared to previous methods, including InterFormer, ReMoS, and Ready-to-React, while achieving substantial improvements in inference speed.

</details>


### [20] [DenseScan: Advancing 3D Scene Understanding with 2D Dense Annotation](https://arxiv.org/abs/2512.00226)
*Zirui Wang,Tao Zhang*

Main category: cs.CV

TL;DR: DenseScan 提供了一个新数据集，通过自动化流程将多视角 2D 图像与多模态大型语言模型结合，生成详细的多层次描述。它增强了物体级理解和问答性能，适用于细节化的视觉语言导航和交互式问答任务。


<details>
  <summary>Details</summary>
Motivation: 目前的 3D 场景理解数据集虽然提供了几何和实例级信息，但缺少用于细微视觉语言任务的丰富语义注释。DenseScan 的目的是解决这一问题，以提升场景理解性能，特别适用于真实世界的 AI 辅助。

Method: DenseScan 使用自动化软件流水线处理多视角 2D 图像与大型语言模型，实现场景元素的详细描述，并通过基于场景的问题生成增强注释。

Result: 实验结果显示，与传统注释流水线相比，DenseScan 在物体级理解和问答任务上的表现显著提高。

Conclusion: DenseScan 为未来的机器人和增强现实研究提供了丰富的注释数据和工具，促进了 3D 场景理解技术的发展。

Abstract: 3D understanding is a key capability for real-world AI assistance. High-quality data plays an important role in driving the development of the 3D understanding community. Current 3D scene understanding datasets often provide geometric and instance-level information, yet they lack the rich semantic annotations necessary for nuanced visual-language tasks.In this work, we introduce DenseScan, a novel dataset with detailed multi-level descriptions generated by an automated pipeline leveraging multi-view 2D images and multimodal large language models (MLLMs). Our approach enables dense captioning of scene elements, ensuring comprehensive object-level descriptions that capture context-sensitive details. Furthermore, we extend these annotations through scenario-based question generation, producing high-level queries that integrate object properties, spatial relationships, and scene context. By coupling geometric detail with semantic richness, DenseScan broadens the range of downstream tasks, from detailed visual-language navigation to interactive question answering. Experimental results demonstrate that our method significantly enhances object-level understanding and question-answering performance in 3D environments compared to traditional annotation pipelines. We release both the annotated dataset and our annotation pipeline to facilitate future research and applications in robotics, augmented reality, and beyond. Through DenseScan, we aim to catalyze new avenues in 3D scene understanding, allowing researchers and practitioners to tackle the complexities of real-world environments with richer, more contextually aware annotations.

</details>


### [21] [UniDiff: Parameter-Efficient Adaptation of Diffusion Models for Land Cover Classification with Multi-Modal Remotely Sensed Imagery and Sparse Annotations](https://arxiv.org/abs/2512.00261)
*Yuzhen Hu,Saurabh Prasad*

Main category: cs.CV

TL;DR: UniDiff提出了一种参数高效的方法，仅使用目标域数据即可将预训练的扩散模型适应于多种传感模态，从而有效缓解稀疏标注约束，实现多模态遥感数据的有效融合。


<details>
  <summary>Details</summary>
Motivation: 现有方法受限于标签数据的稀缺，阻碍了其在多模态遥感中的实际应用，尽管存在先进的架构进步。

Method: UniDiff通过FiLM时间模态条件化、少于5%参数的高效适应以及伪RGB锚定，实现预训练的扩散模型在目标域的无监督适应。

Result: 实验结果表明，在两个多模态基准数据集上，预训练的扩散模型的无监督适应有效缓解了标注约束，实现了多模态遥感数据的有效融合。

Conclusion: UniDiff展示了在仅有限标注数据下，如何高效地适应多模态遥感任务的潜力。

Abstract: Sparse annotations fundamentally constrain multimodal remote sensing: even recent state-of-the-art supervised methods such as MSFMamba are limited by the availability of labeled data, restricting their practical deployment despite architectural advances. ImageNet-pretrained models provide rich visual representations, but adapting them to heterogeneous modalities such as hyperspectral imaging (HSI) and synthetic aperture radar (SAR) without large labeled datasets remains challenging. We propose UniDiff, a parameter-efficient framework that adapts a single ImageNet-pretrained diffusion model to multiple sensing modalities using only target-domain data. UniDiff combines FiLM-based timestep-modality conditioning, parameter-efficient adaptation of approximately 5% of parameters, and pseudo-RGB anchoring to preserve pre-trained representations and prevent catastrophic forgetting. This design enables effective feature extraction from remote sensing data under sparse annotations. Our results with two established multi-modal benchmarking datasets demonstrate that unsupervised adaptation of a pre-trained diffusion model effectively mitigates annotation constraints and achieves effective fusion of multi-modal remotely sensed data.

</details>


### [22] [USB: Unified Synthetic Brain Framework for Bidirectional Pathology-Healthy Generation and Editing](https://arxiv.org/abs/2512.00269)
*Jun Wang,Peirong Liu*

Main category: cs.CV

TL;DR: USB框架提供了病理性和健康脑图像的一致双向生成和编辑，通过联合病变和脑解剖模型以及保持解剖一致性来生成多样且真实的图像结果。


<details>
  <summary>Details</summary>
Motivation: 当前大多数脑影像生成和编辑方法仅专注于视觉质量，并且分别处理病理性图像和健康图像，而缺乏整体性的病理-健康双向编辑能力，难以满足临床需求。

Method: USB框架采用配对扩散机制建模病变和脑解剖的联合分布，并通过一致性指导算法确保双向病理-健康编辑过程中保持解剖一致性。

Result: 在六个公开的脑MRI数据集上，包括健康对照、中风和阿尔茨海默病患者，USB展示了多样性和现实性的生成能力。

Conclusion: USB框架不仅为脑图像生成和编辑提供了统一基准，还为扩展数据集创建和稳健的神经影像分析提供了新机会。

Abstract: Understanding the relationship between pathological and healthy brain structures is fundamental to neuroimaging, connecting disease diagnosis and detection with modeling, prediction, and treatment planning. However, paired pathological-healthy data are extremely difficult to obtain, as they rely on pre- and post-treatment imaging, constrained by clinical outcomes and longitudinal data availability. Consequently, most existing brain image generation and editing methods focus on visual quality yet remain domain-specific, treating pathological and healthy image modeling independently. We introduce USB (Unified Synthetic Brain), the first end-to-end framework that unifies bidirectional generation and editing of pathological and healthy brain images. USB models the joint distribution of lesions and brain anatomy through a paired diffusion mechanism and achieves both pathological and healthy image generation. A consistency guidance algorithm further preserves anatomical consistency and lesion correspondence during bidirectional pathology-healthy editing. Extensive experiments on six public brain MRI datasets including healthy controls, stroke, and Alzheimer's patients, demonstrate USB's ability to produce diverse and realistic results. By establishing the first unified benchmark for brain image generation and editing, USB opens opportunities for scalable dataset creation and robust neuroimaging analysis. Code is available at https://github.com/jhuldr/USB.

</details>


### [23] [HIMOSA: Efficient Remote Sensing Image Super-Resolution with Hierarchical Mixture of Sparse Attention](https://arxiv.org/abs/2512.00275)
*Yi Liu,Yi Wan,Xinyi Liu,Qiong Wu,Panwang Xia,Xuejun Huang,Yongjun Zhang*

Main category: cs.CV

TL;DR: HIMOSA提出了一个轻量级的遥感影像超分辨率框架，通过引入内容感知稀疏注意力机制和层次窗口扩展，提高了推理速度并保持了重建性能。


<details>
  <summary>Details</summary>
Motivation: 现有遥感图像超分辨率方法在模型性能和计算效率之间存在权衡，HIMOSA旨在解决这一问题，以满足远程 sensing 应用中实时性和模型轻量化的关键需求。

Method: HIMOSA通过利用遥感图像中的固有冗余性，引入内容感知稀疏注意力机制，并采用层次窗口扩展来处理多尺度重复模式，从而实现高效推理。

Result: 实验结果表明，HIMOSA在多个遥感数据集上超越了其他方法，同时保持了计算效率。

Conclusion: HIMOSA框架为遥感图像超分辨率提供了新的解决方案，能够在保证重建性能的同时显著提升计算效率。

Abstract: In remote sensing applications, such as disaster detection and response, real-time efficiency and model lightweighting are of critical importance. Consequently, existing remote sensing image super-resolution methods often face a trade-off between model performance and computational efficiency. In this paper, we propose a lightweight super-resolution framework for remote sensing imagery, named HIMOSA. Specifically, HIMOSA leverages the inherent redundancy in remote sensing imagery and introduces a content-aware sparse attention mechanism, enabling the model to achieve fast inference while maintaining strong reconstruction performance. Furthermore, to effectively leverage the multi-scale repetitive patterns found in remote sensing imagery, we introduce a hierarchical window expansion and reduce the computational complexity by adjusting the sparsity of the attention. Extensive experiments on multiple remote sensing datasets demonstrate that our method achieves state-of-the-art performance while maintaining computational efficiency.

</details>


### [24] [Rethinking Lung Cancer Screening: AI Nodule Detection and Diagnosis Outperforms Radiologists, Leading Models, and Standards Beyond Size and Growth](https://arxiv.org/abs/2512.00281)
*Sylvain Bodard,Pierre Baudot,Benjamin Renoust,Charles Voyton,Gwendoline De Bie,Ezequiel Geremia,Van-Khoa Le,Danny Francis,Pierre-Henri Siot,Yousra Haddou,Vincent Bobin,Jean-Christophe Brisset,Carey C. Thomson,Valerie Bourdes,Benoit Huet*

Main category: cs.CV

TL;DR: 该研究提出了一种基于低剂量CT扫描的AI系统，能够直接在结节水平上进行肺癌筛查和恶性诊断，克服了传统筛查方法对结节大小和生长的依赖性。系统性能超过了放射科医生、Lung-RADS分级和现有的AI模型，在小结节和早期癌症诊断中特别出色。


<details>
  <summary>Details</summary>
Motivation: 早期检测恶性肺结节至关重要，但传统的基于结节大小和生长的速度的筛查方法导致了诊断延迟。本研究旨在通过开发一套结合浅层深度学习和特征特化模型的集成系统，直接在结节水平上进行肺癌筛查和恶性诊断，以提高诊断精度和效率。

Method: 研究团队设计了一个包含浅层深度学习和基于特征的专业模型的集成系统。该系统在25,709个扫描图像和69,449个标注结节上进行训练和评估。实验证明，该系统在内部分组测试中AUC达到了0.98，在独立组测试中AUC为0.945。该系统在假阳性率为0.5次/扫描时的敏感性达到了99.3%，并显著优于放射科医生和现有AI模型。

Result: 该AI系统在结节大小和生长速度所有的度量标准上都超过了放射科医生和Lung-RADS分级系统，尤其是在小结节和早期癌症的诊断上。该系统还超越了许多生长指标，包括最不准确的体积翻倍时间（Volume-Doubling Time）。此外，在诊断不确定和缓慢生长的结节方面，它也取得了放射科医生一年前的诊断结果。

Conclusion: 该研究表明，基于低剂量CT扫描的AI系统具有精准检测和诊断恶性肺结节的能力，能够直接在结节水平上进行早期肺癌筛查。这一新的筛查方式有望克服传统方法的局限性，提高肺癌筛查的准确性和效率。

Abstract: Early detection of malignant lung nodules is critical, but its dependence on size and growth in screening inherently delays diagnosis. We present an AI system that redefines lung cancer screening by performing both detection and malignancy diagnosis directly at the nodule level on low-dose CT scans. To address limitations in dataset scale and explainability, we designed an ensemble of shallow deep learning and feature-based specialized models. Trained and evaluated on 25,709 scans with 69,449 annotated nodules, the system outperforms radiologists, Lung-RADS, and leading AI models (Sybil, Brock, Google, Kaggle). It achieves an area under the receiver operating characteristic curve (AUC) of 0.98 internally and 0.945 on an independent cohort. With 0.5 false positives per scan at 99.3\% sensitivity, it addresses key barriers to AI adoption. Critically, it outperforms radiologists across all nodule sizes and stages, excelling in stage 1 cancers, and all growth-based metrics, including the least accurate: Volume-Doubling Time. It also surpasses radiologists by up to one year in diagnosing indeterminate and slow-growing nodules.

</details>


### [25] [TGSFormer: Scalable Temporal Gaussian Splatting for Embodied Semantic Scene Completion](https://arxiv.org/abs/2512.00300)
*Rui Qian,Haozhi Cao,Tianchen Deng,Tianxin Hu,Weixiang Guo,Shenghai Yuan,Lihua Xie*

Main category: cs.CV

TL;DR: TGSFormer 是一种用于体态3D语义场景完成的可扩展框架，它通过时空预测维护持久化的高斯记忆，利用双重时间编码器和置信度感知的体素融合模块，实现高效的场景重建。


<details>
  <summary>Details</summary>
Motivation: 现有的高斯基线方法依赖于在预定义的空间范围内随机初始化许多原语，这导致了冗余并导致了大规模下的不良可扩展性。深度引导的方法减轻了这一点，但在处理更大规模时仍会遇到延迟和内存开销问题。TGSFormer的目的是提供一种新的框架来解决这些挑战。

Method: TGSFormer 使用时空预测维护持久化的高斯记忆，而不是依赖于图像一致性和帧缓存。通过双重时间编码器处理当前和历史高斯特征，并通过置信度感知的交叉注意机制。之后，置信度感知的体素融合模块将重叠的原语合并成体素对齐的表示，以调节密度并保持紧凑性。

Result: TGSFormer在本地和体态3D语义场景完成基准上取得了最先进的结果，实现了更高的准确性和可扩展性，同时使用显著减少的原语数量并保持长期场景的一致性。

Conclusion: TGSFormer 通过维护时空预测的持久高斯记忆和置信度感知的体素融合机制，展现了在3D场景完成任务上的优越性能，并在代码被接受后公开分享。

Abstract: Embodied 3D Semantic Scene Completion (SSC) infers dense geometry and semantics from continuous egocentric observations. Most existing Gaussian-based methods rely on random initialization of many primitives within predefined spatial bounds, resulting in redundancy and poor scalability to unbounded scenes. Recent depth-guided approach alleviates this issue but remains local, suffering from latency and memory overhead as scale increases. To overcome these challenges, we propose TGSFormer, a scalable Temporal Gaussian Splatting framework for embodied SSC. It maintains a persistent Gaussian memory for temporal prediction, without relying on image coherence or frame caches. For temporal fusion, a Dual Temporal Encoder jointly processes current and historical Gaussian features through confidence-aware cross-attention. Subsequently, a Confidence-aware Voxel Fusion module merges overlapping primitives into voxel-aligned representations, regulating density and maintaining compactness. Extensive experiments demonstrate that TGSFormer achieves state-of-the-art results on both local and embodied SSC benchmarks, offering superior accuracy and scalability with significantly fewer primitives while maintaining consistent long-term scene integrity. The code will be released upon acceptance.

</details>


### [26] [Optimizing Distributional Geometry Alignment with Optimal Transport for Generative Dataset Distillation](https://arxiv.org/abs/2512.00308)
*Xiao Cui,Yulei Qin,Wengang Zhou,Hongsheng Li,Houqiang Li*

Main category: cs.CV

TL;DR: 该研究将数据集蒸馏问题重新表述为最优传输距离最小化问题，通过OT指导的扩散采样、标签-图像对齐软标签重标记以及OT基于的逻辑匹配三个步骤实现全局和实例级别的细粒度对齐。


<details>
  <summary>Details</summary>
Motivation: 当前方法主要关注全局分布统计（如均值和方差），而忽视了关键的实例级特征和内部类别差异，导致泛化能力欠佳。因此，本研究旨在通过引入最优传输方法改进数据集蒸馏。

Method: 研究提出了一个由三个部分组成的方案：1）OT引导的扩散采样，用于对齐实际和蒸馏图像的潜在分布；2）标签-图像对齐的软标签重标记，基于蒸馏图像分布的复杂性来调整标签分布；3）基于OT的逻辑匹配，对齐学生模型的输出与软标签分布。

Result: 在不同架构和大规模数据集上进行的大量实验表明，本方法在高效性方面优于现有最先进的方法。在ImageNet-1K数据集的IPC=10设置下，每一架构都至少实现了4%的准确率提升。

Conclusion: 本研究通过对数据集蒸馏问题的创新解决方式，成功提升了模型在复杂高维分布上的泛化性能。

Abstract: Dataset distillation seeks to synthesize a compact distilled dataset, enabling models trained on it to achieve performance comparable to models trained on the full dataset. Recent methods for large-scale datasets focus on matching global distributional statistics (e.g., mean and variance), but overlook critical instance-level characteristics and intraclass variations, leading to suboptimal generalization. We address this limitation by reformulating dataset distillation as an Optimal Transport (OT) distance minimization problem, enabling fine-grained alignment at both global and instance levels throughout the pipeline. OT offers a geometrically faithful framework for distribution matching. It effectively preserves local modes, intra-class patterns, and fine-grained variations that characterize the geometry of complex, high-dimensional distributions. Our method comprises three components tailored for preserving distributional geometry: (1) OT-guided diffusion sampling, which aligns latent distributions of real and distilled images; (2) label-image-aligned soft relabeling, which adapts label distributions based on the complexity of distilled image distributions; and (3) OT-based logit matching, which aligns the output of student models with soft-label distributions. Extensive experiments across diverse architectures and large-scale datasets demonstrate that our method consistently outperforms state-of-the-art approaches in an efficient manner, achieving at least 4% accuracy improvement under IPC=10 settings for each architecture on ImageNet-1K.

</details>


### [27] [Odometry Without Correspondence from Inertially Constrained Ruled Surfaces](https://arxiv.org/abs/2512.00327)
*Chenqi Zhu,Levi Burner,Yiannis Aloimonos*

Main category: cs.CV

TL;DR: 该研究提出了一种基于规则曲面的3D场景重建和视觉里程计的新算法，通过结合车载IMU的惯性测量来限制解空间的维度。


<details>
  <summary>Details</summary>
Motivation: 现有视觉里程计方法依赖于特征提取和光流计算，容易受对应问题困扰，导致难以保证精度，这一研究旨在通过引入事件摄像机的边缘检测能力和利用IMU惯性测量，提供一种新的控制维数的方法以解决这一问题。

Method: 该方法基于摄像机移动过程中观察到的直线在图像空间时间中的表现，即被扫描的光滑表面（规则曲面）。通过分析这些规则曲面的形状以获取关于里程计的相关信息，并利用IMU传感器提供的惯性测量来限制解空间的维度。进而，通过点到直线的关联进行微分计算更新。

Result: 经过实验验证，该方法能够有效进行3D场景重建，并显著提高了视觉里程计的性能和稳定性。

Conclusion: 该研究为解决视觉里程计中的对应问题提供了一种新的路径，对于提高视觉里程计在复杂环境下的鲁棒性和精确性具有重要意义。

Abstract: Visual odometry techniques typically rely on feature extraction from a sequence of images and subsequent computation of optical flow. This point-to-point correspondence between two consecutive frames can be costly to compute and suffers from varying accuracy, which affects the odometry estimate's quality. Attempts have been made to bypass the difficulties originating from the correspondence problem by adopting line features and fusing other sensors (event camera, IMU) to improve performance, many of which still heavily rely on correspondence. If the camera observes a straight line as it moves, the image of the line sweeps a smooth surface in image-space time. It is a ruled surface and analyzing its shape gives information about odometry. Further, its estimation requires only differentially computed updates from point-to-line associations. Inspired by event cameras' propensity for edge detection, this research presents a novel algorithm to reconstruct 3D scenes and visual odometry from these ruled surfaces. By constraining the surfaces with the inertia measurements from an onboard IMU sensor, the dimensionality of the solution space is greatly reduced.

</details>


### [28] [MVAD : A Comprehensive Multimodal Video-Audio Dataset for AIGC Detection](https://arxiv.org/abs/2512.00336)
*Mengxue Hu,Yunfeng Diao,Changtao Miao,Jianshu Li,Zhe Li,Joey Tianyi Zhou*

Main category: cs.CV

TL;DR: 本文介绍了Multimodal Video-Audio Dataset (MVAD)，这是一个专为检测AI生成的多模态视频-音频内容而设计的首个综合数据集，包含真实的多模态样本，具有高质量和多样性。


<details>
  <summary>Details</summary>
Motivation: 现有的合成视频数据集主要集中在视觉模态上，而包含音频的数据集大多局限于面部换脸技术，这无法涵盖更广泛的多模态AI生成内容，因此阻碍了可信赖检测系统的开发。MVAD旨在填补这一关键空白。

Method: MVAD基于三种现实的视频-音频伪造模式生成真实多模态样本，通过多种最先进的生成模型实现高质量，涵盖现实和动漫视觉风格、四种内容类别（人类、动物、物体和场景）以及四种视频-音频多模态数据类型。

Result: 目前尚未明确提及结果。

Conclusion: 本文提出了一种全新的数据集MVAD，以促进多模态视频-音频内容的检测研究和开发。

Abstract: The rapid advancement of AI-generated multimodal video-audio content has raised significant concerns regarding information security and content authenticity. Existing synthetic video datasets predominantly focus on the visual modality alone, while the few incorporating audio are largely confined to facial deepfakes--a limitation that fails to address the expanding landscape of general multimodal AI-generated content and substantially impedes the development of trustworthy detection systems. To bridge this critical gap, we introduce the Multimodal Video-Audio Dataset (MVAD), the first comprehensive dataset specifically designed for detecting AI-generated multimodal video-audio content. Our dataset exhibits three key characteristics: (1) genuine multimodality with samples generated according to three realistic video-audio forgery patterns; (2) high perceptual quality achieved through diverse state-of-the-art generative models; and (3) comprehensive diversity spanning realistic and anime visual styles, four content categories (humans, animals, objects, and scenes), and four video-audio multimodal data types. Our dataset will be available at https://github.com/HuMengXue0104/MVAD.

</details>


### [29] [Assimilation Matters: Model-level Backdoor Detection in Vision-Language Pretrained Models](https://arxiv.org/abs/2512.00343)
*Zhongqi Wang,Jie Zhang,Shiguang Shan,Xilin Chen*

Main category: cs.CV

TL;DR: AMDET 是一种无需任何先验知识的新型模型级后门检测框架，通过揭示 backdoored 文本编码器中特征吸积特性及注意力权重的集中现象来检测后门，最终在多种攻击模式和 VLP 模型结构下实现了高精度和高效性。


<details>
  <summary>Details</summary>
Motivation: 当前的后门检测方法通常依赖于训练数据集、后门触发和目标以及下游分类器的先验知识，但在实际应用中获取这些信息可能不可行。因此，提出了 AMDET 框架，旨在无需此类先验知识的情况下检测后门攻击。

Method: AMDET 通过揭示 backdoored 文本编码器中所有 token 的表示特征高度相似性的现象，进一步分析出这种现象的原因是注意力权重集中于触发词。利用这一洞察，AMDET 通过在 token 向量嵌入上进行梯度基反转，来恢复能够激活后门行为的隐式特征。此外，AMDET 通过分析 CLIP 模型的后门自然特征来筛选出实际被注入的后门。

Result: AMDET 在 3,600 个 backdoored 和 benign-finetuned 模型上，使用两种攻击模式，针对三种 VLP 模型结构的大量实验中，检测后门攻击的 F1 分数达到 89.90%。此外，AMDET 在 RTX 4090 GPU 上实现一次完整检测所需时间约为 5 分钟，并对适应性攻击表现出较强的鲁棒性。

Conclusion: AMDET 框架有效地解决了在实际应用中后门检测的挑战，通过新的特征吸积特性和梯度基反转方法，提高了后门检测的精度、效率和鲁棒性。

Abstract: Vision-language pretrained models (VLPs) such as CLIP have achieved remarkable success, but are also highly vulnerable to backdoor attacks. Given a model fine-tuned by an untrusted third party, determining whether the model has been injected with a backdoor is a critical and challenging problem. Existing detection methods usually rely on prior knowledge of training dataset, backdoor triggers and targets, or downstream classifiers, which may be impractical for real-world applications. To address this, To address this challenge, we introduce Assimilation Matters in DETection (AMDET), a novel model-level detection framework that operates without any such prior knowledge. Specifically, we first reveal the feature assimilation property in backdoored text encoders: the representations of all tokens within a backdoor sample exhibit a high similarity. Further analysis attributes this effect to the concentration of attention weights on the trigger token. Leveraging this insight, AMDET scans a model by performing gradient-based inversion on token embeddings to recover implicit features that capable of activating backdoor behaviors. Furthermore, we identify the natural backdoor feature in the OpenAI's official CLIP model, which are not intentionally injected but still exhibit backdoor-like behaviors. We then filter them out from real injected backdoor by analyzing their loss landscapes. Extensive experiments on 3,600 backdoored and benign-finetuned models with two attack paradigms and three VLP model structures show that AMDET detects backdoors with an F1 score of 89.90%. Besides, it achieves one complete detection in approximately 5 minutes on a RTX 4090 GPU and exhibits strong robustness against adaptive attacks. Code is available at: https://github.com/Robin-WZQ/AMDET

</details>


### [30] [mmPred: Radar-based Human Motion Prediction in the Dark](https://arxiv.org/abs/2512.00345)
*Junqiao Fan,Haocong Rao,Jiarui Zhang,Jianfei Yang,Lihua Xie*

Main category: cs.CV

TL;DR: mmPred 是一种基于雷达的新框架，用于姿态预测，通过双域的历史动作表示和全局骨架关系变换器提高预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于 RGB-D 相机的人体动作预测方法对光照条件敏感并存在隐私问题，而毫米波雷达具有鲁棒性和隐私保护性，因此引入雷达作为新的传感模态。

Method: mmPred 引入了双域的历史动作表示，结合时间域姿态细化 (TPR) 分支和频域主导动作 (FDM) 分支来指导生成过程，同时设计了全局骨架关系变换器 (GST) 作为扩散骨干来建模全局关节间的合作关系。

Result: 实验结果表明，mmPred 达到了最新的技术水平，比现有方法在 mmBody 上性能高出 8.6%，在 mm-Fi 上性能高出 22%。

Conclusion: mmPred 框架展示了毫米波雷达在人体动作预测中的潜力，并提出了处理雷达特定噪声的有效策略。

Abstract: Existing Human Motion Prediction (HMP) methods based on RGB-D cameras are sensitive to lighting conditions and raise privacy concerns, limiting their real-world applications such as firefighting and healthcare. Motivated by the robustness and privacy-preserving nature of millimeter-wave (mmWave) radar, this work introduces radar as a novel sensing modality for HMP, for the first time. Nevertheless, radar signals often suffer from specular reflections and multipath effects, resulting in noisy and temporally inconsistent measurements, such as body-part miss-detection. To address these radar-specific artifacts, we propose mmPred, the first diffusion-based framework tailored for radar-based HMP. mmPred introduces a dual-domain historical motion representation to guide the generation process, combining a Time-domain Pose Refinement (TPR) branch for learning fine-grained details and a Frequency-domain Dominant Motion (FDM) branch for capturing global motion trends and suppressing frame-level inconsistency. Furthermore, we design a Global Skeleton-relational Transformer (GST) as the diffusion backbone to model global inter-joint cooperation, enabling corrupted joints to dynamically aggregate information from others. Extensive experiments show that mmPred achieves state-of-the-art performance, outperforming existing methods by 8.6% on mmBody and 22% on mm-Fi.

</details>


### [31] [THCRL: Trusted Hierarchical Contrastive Representation Learning for Multi-View Clustering](https://arxiv.org/abs/2512.00368)
*Jian Zhu*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的方法THCRL，旨在解决多视图聚类中的不可信融合问题，通过引入DSHF和AKCL模块，分别实现了多视图数据的可信融合和融合表示与视图特定表示的对齐。


<details>
  <summary>Details</summary>
Motivation: 当前的多视图聚类方法通常忽略视图内的固有噪声，且在使用对比学习的传统方法中，相似性计算忽视了同一簇内最近邻的结构信息，导致不可信融合。

Method: THCRL方法包含两个关键模块：DSHF（深度对称层次融合）模块利用UNet架构结合多种去噪机制实现多视图数据的可信融合；AKCL（平均最近邻对比学习）模块使融合表示与视图特定表示对齐。

Result:  extensive experiments demonstrated that THCRL achieved state-of-the-art performance in deep multi-view clustering tasks.

Conclusion: THCRL方法通过引入DSHF和AKCL模块，在解决多视图聚类中的不可信融合问题上取得了较好的效果，是深多视图聚类任务中的先进方法。

Abstract: Multi-View Clustering (MVC) has garnered increasing attention in recent years. It is capable of partitioning data samples into distinct groups by learning a consensus representation. However, a significant challenge remains: the problem of untrustworthy fusion. This problem primarily arises from two key factors: 1) Existing methods often ignore the presence of inherent noise within individual views; 2) In traditional MVC methods using Contrastive Learning (CL), similarity computations typically rely on different views of the same instance, while neglecting the structural information from nearest neighbors within the same cluster. Consequently, this leads to the wrong direction for multi-view fusion. To address this problem, we present a novel Trusted Hierarchical Contrastive Representation Learning (THCRL). It consists of two key modules. Specifically, we propose the Deep Symmetry Hierarchical Fusion (DSHF) module, which leverages the UNet architecture integrated with multiple denoising mechanisms to achieve trustworthy fusion of multi-view data. Furthermore, we present the Average K-Nearest Neighbors Contrastive Learning (AKCL) module to align the fused representation with the view-specific representation. Unlike conventional strategies, AKCL enhances representation similarity among samples belonging to the same cluster, rather than merely focusing on the same sample across views, thereby reinforcing the confidence of the fused representation. Extensive experiments demonstrate that THCRL achieves the state-of-the-art performance in deep MVC tasks.

</details>


### [32] [POLARIS: Projection-Orthogonal Least Squares for Robust and Adaptive Inversion in Diffusion Models](https://arxiv.org/abs/2512.00369)
*Wenshuo Chen,Haosen Li,Shaofeng Liang,Lei Wang,Haozhe Jia,Kaishen Yuan,Jieming Wu,Bowen Tian,Yutao Yue*

Main category: cs.CV

TL;DR: POLARIS通过重新定义反演过程为误差源而非误差补偿，并引入数学上合理的公式，每步最小化反演误差，以解决重建退化中的近似噪声误差问题。


<details>
  <summary>Details</summary>
Motivation: 当前的反演去噪方法未能充分考虑到近似噪声误差对重建质量的影响，尤其是在反演过程中误差累积导致的问题。

Method: POLARIS提出了一种新方法，通过引入投影-正交最小二乘误差源模型，以每步优化的方式解决反演过程中产生的误差。

Result: POLARIS仅需一行代码即可显著提高反演潜变量质量，并且几乎不增加性能开销，有效减少了近似噪声误差，提升了下游任务的准确性。

Conclusion: POLARIS展示了在基于扩散模型的反演去噪中的一种新颖且有效的解决方案，为相关研究和应用提供了改进方向。

Abstract: The Inversion-Denoising Paradigm, which is based on diffusion models, excels in diverse image editing and restoration tasks. We revisit its mechanism and reveal a critical, overlooked factor in reconstruction degradation: the approximate noise error. This error stems from approximating the noise at step t with the prediction at step t-1, resulting in severe error accumulation throughout the inversion process. We introduce Projection-Orthogonal Least Squares for Robust and Adaptive Inversion (POLARIS), which reformulates inversion from an error-compensation problem into an error-origin problem. Rather than optimizing embeddings or latent codes to offset accumulated drift, POLARIS treats the guidance scale ω as a step-wise variable and derives a mathematically grounded formula to minimize inversion error at each step. Remarkably, POLARIS improves inversion latent quality with just one line of code. With negligible performance overhead, it substantially mitigates noise approximation errors and consistently improves the accuracy of downstream tasks.

</details>


### [33] [Pore-scale Image Patch Dataset and A Comparative Evaluation of Pore-scale Facial Features](https://arxiv.org/abs/2512.00381)
*Dong Li,HuaLiang Lin,JiaYu Li*

Main category: cs.CV

TL;DR: 本文提出了一种针对面部细微结构数据稀缺问题的PorePatch数据集，并采用数据-模型协同进化框架生成高质量的数据，使深度学习模型在面部匹配任务中获得了优于传统手工程设计描述子的表现。


<details>
  <summary>Details</summary>
Motivation: 面部皮肤区域的微纹理特性给局部描述子匹配带来了挑战，特别是在面部动态分析和3D人脸重建的应用中。深学习基于的描述子在许多应用中表现得比传统手工构建的描述子更好，但由于缺乏毛孔级图像块的数据集，限制了它们在面部领域的进一步发展。

Method: 本文提出了一种PorePatch数据集，通过数据-模型协同进化框架生成高质量的数据，从而实现对该数据集进行深度学习模型训练及实验。

Result: 通过在提出的PorePatch数据集上训练现有最佳模型，我们发现模型在面部匹配任务中取得了FPR95为1.91%的结果，相比传统的PSIFT描述子（22.41%）有显著的性能提升。

Conclusion: 尽管在面部匹配任务中，深度学习描述子模型取得了较好的效果，但在3D重建任务中的表现并不明显优于传统描述子，表明在处理面部弱纹理区域问题上，深度学习描述子仍存在局限性，还需要更多工作来改进。

Abstract: The weak-texture nature of facial skin regions presents significant challenges for local descriptor matching in applications such as facial motion analysis and 3D face reconstruction. Although deep learning-based descriptors have demonstrated superior performance to traditional hand-crafted descriptors in many applications, the scarcity of pore-scale image patch datasets has hindered their further development in the facial domain. In this paper, we propose the PorePatch dataset, a high-quality pore-scale image patch dataset, and establish a rational evaluation benchmark. We introduce a Data-Model Co-Evolution (DMCE) framework to generate a progressively refined, high-quality dataset from high-resolution facial images. We then train existing SOTA models on our dataset and conduct extensive experiments. Our results show that the SOTA model achieves a FPR95 value of 1.91% on the matching task, outperforming PSIFT (22.41%) by a margin of 20.5%. However, its advantage is diminished in the 3D reconstruction task, where its overall performance is not significantly better than that of traditional descriptors. This indicates that deep learning descriptors still have limitations in addressing the challenges of facial weak-texture regions, and much work remains to be done in this field.

</details>


### [34] [EZ-SP: Fast and Lightweight Superpoint-Based 3D Segmentation](https://arxiv.org/abs/2512.00385)
*Louis Geist,Loic Landrieu,Damien Robert*

Main category: cs.CV

TL;DR: 本文提出了一种高效且轻量级的基于超点的3D语义分割方法，通过学习且完全在GPU上运行的分割算法，实现了比现有方法快13倍的超点生成，并且参数量少，适用于大规模点云场景。


<details>
  <summary>Details</summary>
Motivation: 现有的基于点或体素的3D语义分割方法在计算效率上受到限制，特别是CPU瓶颈问题。文章旨在设计一种更高效的方法，以提高3D语义分割的速度和效率。

Method: 由一个在GPU上学习的、完全无监督的分割算法组成，该算法能够生成几何上和语义上一致的超点，速度快13倍。该模块具有不到6万个参数，可以在不到20分钟内训练，并且无需手工设计特征。通过组合一个轻量级的超点分类器，整个管道可以适应小于2MB的VRAM，支持实时推理。

Result: 与现有基于点的方法相比，此方法在72倍更快的推理速度和120倍更少的参数下，仍能达到最先进的性能，适用于三种不同的场景：室内扫描S3DIS、自动驾驶KITT-360和航空激光雷达DALES。

Conclusion: 该技术能够快速生成几何和语义一致的超点，适用于大规模点云场景，支持实时推理，为3D语义分割提供了新的高效方法。

Abstract: Superpoint-based pipelines provide an efficient alternative to point- or voxel-based 3D semantic segmentation, but are often bottlenecked by their CPU-bound partition step. We propose a learnable, fully GPU partitioning algorithm that generates geometrically and semantically coherent superpoints 13$\times$ faster than prior methods. Our module is compact (under 60k parameters), trains in under 20 minutes with a differentiable surrogate loss, and requires no handcrafted features. Combine with a lightweight superpoint classifier, the full pipeline fits in $<$2 MB of VRAM, scales to multi-million-point scenes, and supports real-time inference. With 72$\times$ faster inference and 120$\times$ fewer parameters, EZ-SP matches the accuracy of point-based SOTA models across three domains: indoor scans (S3DIS), autonomous driving (KITTI-360), and aerial LiDAR (DALES). Code and pretrained models are accessible at github.com/drprojects/superpoint_transformer.

</details>


### [35] [WiseEdit: Benchmarking Cognition- and Creativity-Informed Image Editing](https://arxiv.org/abs/2512.00387)
*Kaihang Pan,Weile Chen,Haiyi Qiu,Qifan Yu,Wendong Bu,Zehan Wang,Yun Zhu,Juncheng Li,Siliang Tang*

Main category: cs.CV

TL;DR: WiseEdit 是一个知识密集型基准测试，旨在全面评估基于认知和创意思维的图像编辑能力，包括深入的任务深度、广泛的知识广度以及难以单独完成的复杂任务。它涵盖三大类型的知识：陈述性、程序性及元认知知识，并包含1,220个测试案例，旨在客观揭示最先进的图像编辑模型在基于知识的认知推理和创造性的Composition能力上的局限。


<details>
  <summary>Details</summary>
Motivation: 现有的图像编辑模型虽然具备高级智能能力，但现有的基准测试无法全面评估这些能力。为了弥补这一缺陷，作者提出了WiseEdit，该测试旨在提供更广泛、更深入的评估，以便更好地理解模型在基于知识的认知推理和创意生成方面的能力。

Method: WiseEdit 通过三个递进步骤（警觉、解释和想象）来分解图像编辑任务，每个步骤都是对模型在特定步骤上完成挑战性的任务。同时，它还包含了复杂的任务，这些任务需要三个步骤的共同作用。此外，WiseEdit 还整合了三大类知识：陈述性知识、程序性知识和元认知知识。

Result: WiseEdit 包含1,220个测试案例，以客观地揭示当前最先进的图像编辑模型在基于知识的认知推理和创造性组成能力上的局限性。

Conclusion: WiseEdit 为评估高级认知和创意图像编辑能力提供了一个新的框架，有助于促进该领域的进一步研究和发展。

Abstract: Recent image editing models boast next-level intelligent capabilities, facilitating cognition- and creativity-informed image editing. Yet, existing benchmarks provide too narrow a scope for evaluation, failing to holistically assess these advanced abilities. To address this, we introduce WiseEdit, a knowledge-intensive benchmark for comprehensive evaluation of cognition- and creativity-informed image editing, featuring deep task depth and broad knowledge breadth. Drawing an analogy to human cognitive creation, WiseEdit decomposes image editing into three cascaded steps, i.e., Awareness, Interpretation, and Imagination, each corresponding to a task that poses a challenge for models to complete at the specific step. It also encompasses complex tasks, where none of the three steps can be finished easily. Furthermore, WiseEdit incorporates three fundamental types of knowledge: Declarative, Procedural, and Metacognitive knowledge. Ultimately, WiseEdit comprises 1,220 test cases, objectively revealing the limitations of SoTA image editing models in knowledge-based cognitive reasoning and creative composition capabilities. The benchmark, evaluation code, and the generated images of each model will be made publicly available soon. Project Page: https://qnancy.github.io/wiseedit_project_page/.

</details>


### [36] [Better, Stronger, Faster: Tackling the Trilemma in MLLM-based Segmentation with Simultaneous Textual Mask Prediction](https://arxiv.org/abs/2512.00395)
*Jiazhen Liu,Mingkuan Feng,Long Chen*

Main category: cs.CV

TL;DR: STAMP 提出了一种新颖的多模态大语言模型架构，通过将分段预测与非自回归掩码预测分离，避免了对话能力和分段性能之间的冲突，实现了高效的分段任务和对话生成。


<details>
  <summary>Details</summary>
Motivation: 解决多模态大语言模型在保持对话能力、高分段性能和快速推理速度之间的核心难题。

Method: STAMP利用all-mask预测方法，将文本对话生成和非自回归分段掩码预测任务分离，通过一个前向传递过程同时生成文本回应和分段掩码。

Result: STAMP在多个分段基准上显著优于现有方法，在对话、分段性能和速度方面表现出优异的综合性能。

Conclusion: 该研究提出了一种新的解决方案，能够在保持多模态大语言模型对话能力的同时，实现高效的分段任务。

Abstract: Integrating segmentation into Multimodal Large Language Models (MLLMs) presents a core trilemma: simultaneously preserving dialogue ability, achieving high segmentation performance, and ensuring fast inference. Prevailing paradigms are forced into a compromise. Embedding prediction methods introduce a conflicting pixel-level objective that degrades the MLLM's general dialogue abilities. The alternative, next-token prediction, reframes segmentation as an autoregressive task, which preserves dialogue but forces a trade-off between poor segmentation performance with sparse outputs or prohibitive inference speeds with rich ones. We resolve this trilemma with all-mask prediction, a novel paradigm that decouples autoregressive dialogue generation from non-autoregressive mask prediction. We present STAMP: Simultaneous Textual All-Mask Prediction, an MLLM that embodies this paradigm. After generating a textual response, STAMP predicts an entire segmentation mask in a single forward pass by treating it as a parallel "fill-in-the-blank" task over image patches. This design maintains the MLLM's dialogue ability by avoiding conflicting objectives, enables high segmentation performance by leveraging rich, bidirectional spatial context for all mask tokens, and achieves exceptional speed. Extensive experiments show that STAMP significantly outperforms state-of-the-art methods across multiple segmentation benchmarks, providing a solution that excels in dialogue, segmentation, and speed without compromise.

</details>


### [37] [Low-Bitrate Video Compression through Semantic-Conditioned Diffusion](https://arxiv.org/abs/2512.00408)
*Lingdong Wang,Guan-Ming Su,Divya Kothandaraman,Tsung-Wei Huang,Mohammad Hajiesmaili,Ramesh K. Sitaraman*

Main category: cs.CV

TL;DR: DiSCo 提出了一种新的语义视频压缩框架，通过传递最相关的语义信息并利用生成先验进行细节合成，实现了在极低码率下 superior 的视频质量。


<details>
  <summary>Details</summary>
Motivation: 传统视频编解码器在极低码率下表现不佳，DiSCo 致力于解决这个问题并通过重新定义视频压缩方法，使其更符合人类感知特性。

Method: DiSCo 将原始视频分解为三个紧凑的模态：文本描述、时空降级视频和可选的草图或姿态，然后使用条件视频扩散模型从这些紧凑表示生成高质量的、时序一致的视频。此外，引入了定时前向填充、令牌交织和模态特定编码技术以提高多模态生成和模态的紧凑性。

Result: 实验表明，在感知指标方面，DiSCo 在极低码率下相比基线语义和传统编解码器表现出 2-10 倍的优势。

Conclusion: DiSCo 框架展示了在极低码率下实现高质量视频编码的潜力，并为未来的语义视频编码技术提供了新的思路。

Abstract: Traditional video codecs optimized for pixel fidelity collapse at ultra-low bitrates and produce severe artifacts. This failure arises from a fundamental misalignment between pixel accuracy and human perception. We propose a semantic video compression framework named DiSCo that transmits only the most meaningful information while relying on generative priors for detail synthesis. The source video is decomposed into three compact modalities: a textual description, a spatiotemporally degraded video, and optional sketches or poses that respectively capture semantic, appearance, and motion cues. A conditional video diffusion model then reconstructs high-quality, temporally coherent videos from these compact representations. Temporal forward filling, token interleaving, and modality-specific codecs are proposed to improve multimodal generation and modality compactness. Experiments show that our method outperforms baseline semantic and traditional codecs by 2-10X on perceptual metrics at low bitrates.

</details>


### [38] [SplatFont3D: Structure-Aware Text-to-3D Artistic Font Generation with Part-Level Style Control](https://arxiv.org/abs/2512.00413)
*Ji Gan,Lingxu Chen,Jiaxu Leng,Xinbo Gao*

Main category: cs.CV

TL;DR: SplatFont3D 是一个新颖的基于3D高斯点的结构感知的文本转3D艺术字体框架，能够根据多样的风格文本提示生成精准的部分级风格控制的3D艺术字体。


<details>
  <summary>Details</summary>
Motivation: 3D艺术字体能够应用于沉浸式3D环境如视频游戏和动画，同时提高2D艺术字体的创新性和视觉质量。但现有的3D艺术字体生成模型在部分级风格控制、结构约束等方面存在不足。

Method: SplatFont3D提出了两个关键模块：Glyph2Cloud用于逐级增强2D字符形状和风格并生成3D点云来初始化3D高斯分布；动态组件分配策略利用3D高斯分布的几何先验进行部件划分，减轻三维高斯优化过程中漂移引起的纠缠。

Result: SplatFont3D在风格文本一致性、视觉质量和渲染效率方面优于现有3D艺术字体生成模型。

Conclusion: SplatFont3D框架通过捕捉文本内容的语义和语法，结合精细的3D高斯点生成和优化，实现了更加精确和有效的部分级风格控制，为3D艺术字体的设计提供了高效和高质量的解决方案。

Abstract: Artistic font generation (AFG) can assist human designers in creating innovative artistic fonts. However, most previous studies primarily focus on 2D artistic fonts in flat design, leaving personalized 3D-AFG largely underexplored. 3D-AFG not only enables applications in immersive 3D environments such as video games and animations, but also may enhance 2D-AFG by rendering 2D fonts of novel views. Moreover, unlike general 3D objects, 3D fonts exhibit precise semantics with strong structural constraints and also demand fine-grained part-level style control. To address these challenges, we propose SplatFont3D, a novel structure-aware text-to-3D AFG framework with 3D Gaussian splatting, which enables the creation of 3D artistic fonts from diverse style text prompts with precise part-level style control. Specifically, we first introduce a Glyph2Cloud module, which progressively enhances both the shapes and styles of 2D glyphs (or components) and produces their corresponding 3D point clouds for Gaussian initialization. The initialized 3D Gaussians are further optimized through interaction with a pretrained 2D diffusion model using score distillation sampling. To enable part-level control, we present a dynamic component assignment strategy that exploits the geometric priors of 3D Gaussians to partition components, while alleviating drift-induced entanglement during 3D Gaussian optimization. Our SplatFont3D provides more explicit and effective part-level style control than NeRF, attaining faster rendering efficiency. Experiments show that our SplatFont3D outperforms existing 3D models for 3D-AFG in style-text consistency, visual quality, and rendering efficiency.

</details>


### [39] [PhysGen: Physically Grounded 3D Shape Generation for Industrial Design](https://arxiv.org/abs/2512.00422)
*Yingxuan You,Chen Zhao,Hantao Zhang,Mingda Xu,Pascal Fua*

Main category: cs.CV

TL;DR: 本文提出了一种结合物理的3D形状生成管线，通过引入流匹配模型和物理感知正则化项，使生成的形状在物理属性上更加真实。


<details>
  <summary>Details</summary>
Motivation: 现有的生成模型无法利用物理知识来生成具有特定物理属性的真实感3D形状，本研究旨在解决这个问题。

Method: 提出了一个基于物理的3D形状生成管线，其中包含一个交替更新过程，迭代地进行速度更新和基于物理的细化，同时引入了物理感知的正则化项。系统地利用了'}形状与物理'变分自编码器（SP-VAE），将形状和物理信息联合编码到统一的潜在空间中。

Result: 在三个基准上的实验表明，这种协同建模方法在形状的真实感上超越了纯粹的视觉可信度。生成的形状不仅看起来更真实，而且具有所期望的物理属性。

Conclusion: 这种方法为工业设计应用中生成具有特定物理属性的3D形状提供了一种新的管道。

Abstract: Existing generative models for 3D shapes can synthesize high-fidelity and visually plausible shapes. For certain classes of shapes that have undergone an engineering design process, the realism of the shape is tightly coupled with the underlying physical properties, e.g., aerodynamic efficiency for automobiles. Since existing methods lack knowledge of such physics, they are unable to use this knowledge to enhance the realism of shape generation. Motivated by this, we propose a unified physics-based 3D shape generation pipeline, with a focus on industrial design applications. Specifically, we introduce a new flow matching model with explicit physical guidance, consisting of an alternating update process. We iteratively perform a velocity-based update and a physics-based refinement, progressively adjusting the latent code to align with the desired 3D shapes and physical properties. We further strengthen physical validity by incorporating a physics-aware regularization term into the velocity-based update step. To support such physics-guided updates, we build a shape-and-physics variational autoencoder (SP-VAE) that jointly encodes shape and physics information into a unified latent space. The experiments on three benchmarks show that this synergistic formulation improves shape realism beyond mere visual plausibility.

</details>


### [40] [Recovering Origin Destination Flows from Bus CCTV: Early Results from Nairobi and Kigali](https://arxiv.org/abs/2512.00424)
*Nthenya Kyatha,Jay Taneja*

Main category: cs.CV

TL;DR: 本研究提出了一种结合目标检测、跟踪、特征提取、OCR时间戳和车况识别的系统，用于在亚非地区公共汽车中恢复乘车OD流动，但在高密度等现实压力下性能显著下降。


<details>
  <summary>Details</summary>
Motivation: 现有的自动系统在亚非地区的过度拥挤的公共交通环境下无法捕获可靠的乘客流量数据，因此需要一种创新的系统来解决这个问题。

Method: 研究基于已安装的车载CCTV监控系统，集成YOLOv12目标检测、BotSORT跟踪、OSNet嵌入、OCR文本识别以获取时间戳，并结合车况识别来恢复公共汽车的OD流动。

Result: 在标注Nairobi和Kigali公交车的CCTV录像片段上，该系统在低密度、光照良好的环境中获得了较高的计数准确性（召回率≈95%，精确率≈91%，F1值≈93%），生成的OD矩阵与手动计数结果接近。但在高密度等现实压力下，性能显著下降，例如在高峰时段上下车人数计数减少约40%，在单色段中的召回率下降约17%

Conclusion: 研究揭示了在亚非地区公交系统部署特定的失败模式，强调了需要开发更稳健的Re-ID方法来应对现实中的各种挑战。

Abstract: Public transport in sub-Saharan Africa (SSA) often operates in overcrowded conditions where existing automated systems fail to capture reliable passenger flow data. Leveraging onboard CCTV already deployed for security, we present a baseline pipeline that combines YOLOv12 detection, BotSORT tracking, OSNet embeddings, OCR-based timestamping, and telematics-based stop classification to recover bus origin--destination (OD) flows. On annotated CCTV segments from Nairobi and Kigali buses, the system attains high counting accuracy under low-density, well-lit conditions (recall $\approx$95\%, precision $\approx$91\%, F1 $\approx$93\%). It produces OD matrices that closely match manual tallies. Under realistic stressors such as overcrowding, color-to-monochrome shifts, posture variation, and non-standard door use, performance degrades sharply (e.g., $\sim$40\% undercount in peak-hour boarding and a $\sim$17 percentage-point drop in recall for monochrome segments), revealing deployment-specific failure modes and motivating more robust, deployment-focused Re-ID methods for SSA transit.

</details>


### [41] [Recognizing Pneumonia in Real-World Chest X-rays with a Classifier Trained with Images Synthetically Generated by Nano Banana](https://arxiv.org/abs/2512.00428)
*Jiachuan Peng,Kyle Lam,Jianing Qiu*

Main category: cs.CV

TL;DR: 该研究使用Nano Banana生成的合成胸部X光图像训练分类器，结果显示在真实数据集上的性能良好，但还存在一些挑战和局限性，如潜在的偏差和需要进一步的验证。


<details>
  <summary>Details</summary>
Motivation: 研究者旨在探索利用最新的AI生成的合成数据来训练医疗AI模型的可能性，特别是在肺炎检测领域。

Method: 研究者使用Nano Banana生成了合成的胸部X光图像，并用这些图像训练了一个分类器。然后，该分类器被应用于两个真实世界的数据集以进行外部验证。研究者报告了AUROC和AUPR等指标来评估分类器的性能。

Result: 在2018 RSNA肺炎检测数据集中，模型的AUROC和AUPR分别为0.923和0.900。在胸部X光数据集中的相应指标为0.824和0.913。模型在真实数据集上的表现证明了其可行性，并暗示了合成数据在医疗AI开发中的一种潜在用途。

Conclusion: 尽管取得了初步成果，研究者指出仍然存在一些挑战，比如生成的合成图像在多样性上的控制需要改进，并需要对结果进行后处理以确保与真实数据的一致性。未来还需更多验证、监管审查和伦理监督。

Abstract: We trained a classifier with synthetic chest X-ray (CXR) images generated by Nano Banana, the latest AI model for image generation and editing, released by Google. When directly applied to real-world CXRs having only been trained with synthetic data, the classifier achieved an AUROC of 0.923 (95% CI: 0.919 - 0.927), and an AUPR of 0.900 (95% CI: 0.894 - 0.907) in recognizing pneumonia in the 2018 RSNA Pneumonia Detection dataset (14,863 CXRs), and an AUROC of 0.824 (95% CI: 0.810 - 0.836), and an AUPR of 0.913 (95% CI: 0.904 - 0.922) in the Chest X-Ray dataset (5,856 CXRs). These external validation results on real-world data demonstrate the feasibility of this approach and suggest potential for synthetic data in medical AI development. Nonetheless, several limitations remain at present, including challenges in prompt design for controlling the diversity of synthetic CXR data and the requirement for post-processing to ensure alignment with real-world data. However, the growing sophistication and accessibility of medical intelligence will necessitate substantial validation, regulatory approval, and ethical oversight prior to clinical translation.

</details>


### [42] [FR-TTS: Test-Time Scaling for NTP-based Image Generation with Effective Filling-based Reward Signal](https://arxiv.org/abs/2512.00438)
*Hang Xu,Linjiang Huang,Feng Zhao*

Main category: cs.CV

TL;DR: 该研究提出了基于填充的奖励(Filling-Based Reward, FR)方法，通过估计中间样本的未来路径来改善TTS在NTP中的应用。FR-TTS策略利用FR估计中间样本的未来表现，并结合多样性奖励和动态权重调度来全面评价中间样本。


<details>
  <summary>Details</summary>
Motivation: 现有的TTS方法在NTP中面临挑战，因为中间样本与完整样本之间的奖励相关性较低。因此，这项研究旨在提出一种新方法，以提高中间样本的预测质量。

Method: 首先，该研究引入了基于填充的奖励方法，通过寻找合理的填充方案来估计中间样本的未来路径。接下来，基于FR，提出了一种新的TTS策略（FR-TTS），该策略不仅寻找最佳填充方案，还结合了多样性奖励和动态权重调度，从而对中间样本进行全面评估。

Result: 实验结果表明，FR-TTS在多个基准和多种奖励模型上均优于现有的TTS方法。

Conclusion: 该研究提出的方法和策略，成功改善了TTS在NTP任务中的应用效果，并通过实验验证了其优越性。

Abstract: Test-time scaling (TTS) has become a prevalent technique in image generation, significantly boosting output quality by expanding the number of parallel samples and filtering them using pre-trained reward models. However, applying this powerful methodology to the next-token prediction (NTP) paradigm remains challenging. The primary obstacle is the low correlation between the reward of an image decoded from an intermediate token sequence and the reward of the fully generated image. Consequently, these incomplete intermediate representations prove to be poor indicators for guiding the pruning direction, a limitation that stems from their inherent incompleteness in scale or semantic content. To effectively address this critical issue, we introduce the Filling-Based Reward (FR). This novel design estimates the approximate future trajectory of an intermediate sample by finding and applying a reasonable filling scheme to complete the sequence. Both the correlation coefficient between rewards of intermediate samples and final samples, as well as multiple intrinsic signals like token confidence, indicate that the FR provides an excellent and reliable metric for accurately evaluating the quality of intermediate samples. Building upon this foundation, we propose FR-TTS, a sophisticated scaling strategy. FR-TTS efficiently searches for good filling schemes and incorporates a diversity reward with a dynamic weighting schedule to achieve a balanced and comprehensive evaluation of intermediate samples. We experimentally validate the superiority of FR-TTS over multiple established benchmarks and various reward models. Code is available at \href{https://github.com/xuhang07/FR-TTS}{https://github.com/xuhang07/FR-TTS}.

</details>


### [43] [CausalAffect: Causal Discovery for Facial Affective Understanding](https://arxiv.org/abs/2512.00456)
*Guanyu Hu,Tangzheng Lian,Dimitrios Kollias,Oya Celiktutan,Xinyu Yang*

Main category: cs.CV

TL;DR: 该研究提出了一种名为CausalAffect的框架，用于面部情感分析中的因果图发现，无需联合注释数据集或手工构建的因果先验，即可恢复与已建立的心理学理论一致的因果结构，揭示新型的抑制关系和未表征的依赖关系。


<details>
  <summary>Details</summary>
Motivation: 现有的面部情感分析方法很少关注从数据中直接推断行动单元(AUs)和表情之间具有心理合理性因果关系的问题。

Method: CausalAffect框架通过两级极性和方向感知的因果层次结构来建模AUs之间的依赖关系和AUs到表情的依赖关系，该层次结构结合了基于人口的规律性和以样本自适应的结构。引入了特征级反事实干预机制来强化真实的因果效应并抑制虚假相关。

Result: 在六个基准数据集上的广泛实验表明，CausalAffect在AU检测和表情识别方面均取得了最先进的成果，建立了因果发现与可解释面部行为之间的原则性联系。

Conclusion: CausalAffect提供了对面部表情中的因果关系进行研究的全新视角，为未来的情感计算领域提供了更深入的理解和更有效的手段。

Abstract: Understanding human affect from facial behavior requires not only accurate recognition but also structured reasoning over the latent dependencies that drive muscle activations and their expressive outcomes. Although Action Units (AUs) have long served as the foundation of affective computing, existing approaches rarely address how to infer psychologically plausible causal relations between AUs and expressions directly from data. We propose CausalAffect, the first framework for causal graph discovery in facial affect analysis. CausalAffect models AU-AU and AU-Expression dependencies through a two-level polarity and direction aware causal hierarchy that integrates population-level regularities with sample-adaptive structures. A feature-level counterfactual intervention mechanism further enforces true causal effects while suppressing spurious correlations. Crucially, our approach requires neither jointly annotated datasets nor handcrafted causal priors, yet it recovers causal structures consistent with established psychological theories while revealing novel inhibitory and previously uncharacterized dependencies. Extensive experiments across six benchmarks demonstrate that CausalAffect advances the state of the art in both AU detection and expression recognition, establishing a principled connection between causal discovery and interpretable facial behavior. All trained models and source code will be released upon acceptance.

</details>


### [44] [RealGen: Photorealistic Text-to-Image Generation via Detector-Guided Rewards](https://arxiv.org/abs/2512.00473)
*Junyan Ye,Leiqi Zhu,Yuncheng Guo,Dongzhi Jiang,Zilong Huang,Yifan Zhang,Zhiyuan Yan,Haohuan Fu,Conghui He,Weijia Li*

Main category: cs.CV

TL;DR: RealGen 提出了一种结合 LLM 和扩散模型以生成高保真度图像的框架，并通过 Detector Reward 机制优化生成过程，同时引入 RealBench 评估基准以实现无监督的真伪评估。


<details>
  <summary>Details</summary>
Motivation: 现有图像生成技术在逼真度上存在不足，RealGen 旨在通过引入改进机制，达到图像‘难以区分真实’的生成目标。

Method: RealGen 框架融合 LLM 和扩散模型，利用 Detector Reward 机制和 GRPO 算法优化生成流程。

Result: RealGen 在逼真度、细节和美学上显著优于通用模型 GPT-Image-1 和 Qwen-Image 及专门的 Mod-T2I 模型 FLUX-Krea。

Conclusion: 通过设计合理的机制，RealGen 有效提升了图像生成的真实性和质量，为未来图像生成技术的发展提供了新的参考。

Abstract: With the continuous advancement of image generation technology, advanced models such as GPT-Image-1 and Qwen-Image have achieved remarkable text-to-image consistency and world knowledge However, these models still fall short in photorealistic image generation. Even on simple T2I tasks, they tend to produce " fake" images with distinct AI artifacts, often characterized by "overly smooth skin" and "oily facial sheens". To recapture the original goal of "indistinguishable-from-reality" generation, we propose RealGen, a photorealistic text-to-image framework. RealGen integrates an LLM component for prompt optimization and a diffusion model for realistic image generation. Inspired by adversarial generation, RealGen introduces a "Detector Reward" mechanism, which quantifies artifacts and assesses realism using both semantic-level and feature-level synthetic image detectors. We leverage this reward signal with the GRPO algorithm to optimize the entire generation pipeline, significantly enhancing image realism and detail. Furthermore, we propose RealBench, an automated evaluation benchmark employing Detector-Scoring and Arena-Scoring. It enables human-free photorealism assessment, yielding results that are more accurate and aligned with real user experience. Experiments demonstrate that RealGen significantly outperforms general models like GPT-Image-1 and Qwen-Image, as well as specialized photorealistic models like FLUX-Krea, in terms of realism, detail, and aesthetics. The code is available at https://github.com/yejy53/RealGen.

</details>


### [45] [CC-FMO: Camera-Conditioned Zero-Shot Single Image to 3D Scene Generation with Foundation Model Orchestration](https://arxiv.org/abs/2512.00493)
*Boshi Tang,Henry Zheng,Rui Huang,Gao Huang*

Main category: cs.CV

TL;DR: CC-FMO 是一种能够生成高质量3D场景的零样本、相机条件化管道，通过结合语义感知的向量集表示和细节丰富的结构化隐含表示，来实现场景生成。


<details>
  <summary>Details</summary>
Motivation: 高精度的单张图片生成高质量3D场景对于增强现实/虚拟现实和实体AI应用至关重要。虽然大规模三维基础模型在实例级别生成方面取得了显著进步，但在场景生成中仍然存在一致性问题。

Method: CC-FMO引入了一种结合语义感知的向量集表示与细节丰富的结构化隐含表示的混合实例生成器，同时设计了一个简单有效的相机条件化比例求解算法来增强场景一致性。

Result: CC-FMO能够生成与输入图像对齐的高质量、高保真度的成分场景，并且在与主要先进的方法进行比较实验中表现出色。

Conclusion: CC-FMO提供了在单张图像生成高质量3D场景方面的可能性，并且展示了一种有效的解决方案来克服以往方法的局限性。

Abstract: High-quality 3D scene generation from a single image is crucial for AR/VR and embodied AI applications. Early approaches struggle to generalize due to reliance on specialized models trained on curated small datasets. While recent advancements in large-scale 3D foundation models have significantly enhanced instance-level generation, coherent scene generation remains a challenge, where performance is limited by inaccurate per-object pose estimations and spatial inconsistency. To this end, this paper introduces CC-FMO, a zero-shot, camera-conditioned pipeline for single-image to 3D scene generation that jointly conforms to the object layout in input image and preserves instance fidelity. CC-FMO employs a hybrid instance generator that combines semantics-aware vector-set representation with detail-rich structured latent representation, yielding object geometries that are both semantically plausible and high-quality. Furthermore, CC-FMO enables the application of foundational pose estimation models in the scene generation task via a simple yet effective camera-conditioned scale-solving algorithm, to enforce scene-level coherence. Extensive experiments demonstrate that CC-FMO consistently generates high-fidelity camera-aligned compositional scenes, outperforming all state-of-the-art methods.

</details>


### [46] [Terrain Sensing with Smartphone Structured Light: 2D Dynamic Time Warping for Grid Pattern Matching](https://arxiv.org/abs/2512.00514)
*Tanaka Nobuaki*

Main category: cs.CV

TL;DR: 本文提出了一种基于智能手机的结构光系统，用于地势感知，通过改进的2D-DTW算法来匹配变形的网格图案。


<details>
  <summary>Details</summary>
Motivation: 在不平坦地形上运行的低成本移动机器人难以通过视觉感知细小的凸起或倾斜，但这些因素会影响其运动稳定性。因此，提出了基于智能手机的结构光系统，能够通过投影网格图案并从单手设备中重构局部地形不平度来解决这一问题。

Method: 该方法包括使用结构光系统投影网格图案，并通过一种新的基于网格拓扑约束的2D-DTW算法来匹配变形的网格观察结果，从而实现地形感知。

Result: 结果表明，该系统不仅能用于地形感知，还可以作为一种通用工具，在图像处理中匹配结构化的网格图案。

Conclusion: 该论文描述了一个整体系统的设计，以及由此应用中提出的2D-DTW扩展。

Abstract: Low-cost mobile rovers often operate on uneven terrain where small bumps or tilts are difficult to perceive visually but can significantly affect locomotion stability. To address this problem, we explore a smartphone-based structured-light system that projects a grid pattern onto the ground and reconstructs local terrain unevenness from a single handheld device. The system is inspired by face-recognition projectors, but adapted for ground sensing. A key technical challenge is robustly matching the projected grid with its deformed observation under perspective distortion and partial occlusion. Conventional one-dimensional dynamic time warping (1D-DTW) is not directly applicable to such two-dimensional grid patterns. We therefore propose a topology-constrained two-dimensional dynamic time warping (2D-DTW) algorithm that performs column-wise alignment under a global grid consistency constraint. The proposed method is designed to be simple enough to run on resource limited platforms while preserving the grid structure required for accurate triangulation. We demonstrate that our 2D-DTW formulation can be used not only for terrain sensing but also as a general tool for matching structured grid patterns in image processing scenarios. This paper describes the overall system design as well as the 2D-DTW extension that emerged from this application.

</details>


### [47] [Image Generation as a Visual Planner for Robotic Manipulation](https://arxiv.org/abs/2512.00532)
*Ye Pang*

Main category: cs.CV

TL;DR: 该研究探索了通过轻量级LoRA微调，使现有的语言图像生成模型为类视频机器人规划器，并在Jaco Play数据集、Bridge V2和RT1数据集上进行验证，结果表明编码了可迁移的时间先验知识的预训练图像生成器，在轻度监督下能生成连贯的机器人操作视频。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖大规模领域特定数据集且泛化能力不足，而近期的语言图像生成模型表明了强大的组成性，即使没有显式的时序建模也能生成时间连贯的网格图像。因此，研究探索是否可以利用此类模型来作为机器人的视觉规划工具。

Method: 研究提出了一个两部分框架，包括基于文本条件生成和轨迹条件生成。通过LoRA微调适应这些语言图像生成模型。

Result: 实验结果显示，在Jaco Play数据集、Bridge V2和RT1数据集上，两种生成模式均能生成连贯的机器人操作视频，且与各自的条件相匹配。

Conclusion: 研究的发现表明，预训练的图像生成器内含可转移的时间先验知识，可以在轻微监督下执行类似于视频的机器人规划任务。

Abstract: Generating realistic robotic manipulation videos is an important step toward unifying perception, planning, and action in embodied agents. While existing video diffusion models require large domain-specific datasets and struggle to generalize, recent image generation models trained on language-image corpora exhibit strong compositionality, including the ability to synthesize temporally coherent grid images. This suggests a latent capacity for video-like generation even without explicit temporal modeling.
  We explore whether such models can serve as visual planners for robots when lightly adapted using LoRA finetuning. We propose a two-part framework that includes: (1) text-conditioned generation, which uses a language instruction and the first frame, and (2) trajectory-conditioned generation, which uses a 2D trajectory overlay and the same initial frame. Experiments on the Jaco Play dataset, Bridge V2, and the RT1 dataset show that both modes produce smooth, coherent robot videos aligned with their respective conditions.
  Our findings indicate that pretrained image generators encode transferable temporal priors and can function as video-like robotic planners under minimal supervision. Code is released at \href{https://github.com/pangye202264690373/Image-Generation-as-a-Visual-Planner-for-Robotic-Manipulation}{https://github.com/pangye202264690373/Image-Generation-as-a-Visual-Planner-for-Robotic-Manipulation}.

</details>


### [48] [Cross-Temporal 3D Gaussian Splatting for Sparse-View Guided Scene Update](https://arxiv.org/abs/2512.00534)
*Zeyuan An,Yanghang Xiao,Zhiying Leng,Frederick W. B. Li,Xiaohui Liang*

Main category: cs.CV

TL;DR: 本文介绍了跨时间3D高斯散点图（Cross-Temporal 3DGS），这是一种新的框架，用于从稀疏视图更新3D场景，通过跨时间镜头对齐、基于干扰的置信度初始化和渐进式跨时间优化三个阶段，实现不同时间点的3D场景重建和更新。


<details>
  <summary>Details</summary>
Motivation: 提出了Cross-Temporal 3DGS框架，旨在解决使用稀疏视图更新3D场景在城市规划、灾害评估和历史遗址保护等实际应用中的挑战。

Method: 该方法包括三个阶段：首先，跨时间镜头对齐以估计和对齐不同时间戳的相机姿态；其次，基于干扰的置信度初始化以识别时间戳之间的不变区域，从而指导更新；最后，渐进式跨时间优化，该过程通过迭代整合历史先验信息来逐步提高3D场景的重建质量。此外，该方法支持非连续捕获。

Result: 实验结果显示，该方法在重建质量和数据效率方面显著优于基线方法，提升了场景版本控制、跨时间数字双胞胎和长期空间记录的潜力。

Conclusion: Cross-Temporal 3DGS是一种强有力的工具，适用于需要长时间监控和更新的3D场景应用，尤其在没有密集扫描数据的情况下。

Abstract: Maintaining consistent 3D scene representations over time is a significant challenge in computer vision. Updating 3D scenes from sparse-view observations is crucial for various real-world applications, including urban planning, disaster assessment, and historical site preservation, where dense scans are often unavailable or impractical. In this paper, we propose Cross-Temporal 3D Gaussian Splatting (Cross-Temporal 3DGS), a novel framework for efficiently reconstructing and updating 3D scenes across different time periods, using sparse images and previously captured scene priors. Our approach comprises three stages: 1) Cross-temporal camera alignment for estimating and aligning camera poses across different timestamps; 2) Interference-based confidence initialization to identify unchanged regions between timestamps, thereby guiding updates; and 3) Progressive cross-temporal optimization, which iteratively integrates historical prior information into the 3D scene to enhance reconstruction quality. Our method supports non-continuous capture, enabling not only updates using new sparse views to refine existing scenes, but also recovering past scenes from limited data with the help of current captures. Furthermore, we demonstrate the potential of this approach to achieve temporal changes using only sparse images, which can later be reconstructed into detailed 3D representations as needed. Experimental results show significant improvements over baseline methods in reconstruction quality and data efficiency, making this approach a promising solution for scene versioning, cross-temporal digital twins, and long-term spatial documentation.

</details>


### [49] [SAIDO: Generalizable Detection of AI-Generated Images via Scene-Aware and Importance-Guided Dynamic Optimization in Continual Learning](https://arxiv.org/abs/2512.00539)
*Yongkang Hu,Yu Cheng,Yushuo Zhang,Yuan Xie,Zhaoxia Yin*

Main category: cs.CV

TL;DR: 本文提出一种场景感知和重要性指导的动态优化检测框架(SAIDO)，通过连续学习调整以应对不断变化的生成方法和内容类型，在稳定性与可塑性上均优于当前SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 随着图像生成技术的广泛应用，AI生成图像的检测成为了一个关键问题。现有方法难以应对不断变化的生成方法和内容类型，因此需要一种新的方法来解决该问题。

Method: 为了应对这个挑战，作者提出了SAIDO框架，包括一个基于场景的专家模块(SAEM)和一个重要性指导动态优化机制(IDOM)。

Result: 在连续学习任务上的实验表明，该方法在稳定性与可塑性上均优于当前最优方法，平均检测错误率和遗忘率分别减少了44.22%和40.57%，在开放世界的数据集上，与最优方法相比，平均检测准确性提高了9.47%。

Conclusion: 本文提出的方法为解决图像生成方法不断变化带来的挑战提供了一个有效的解决方案。

Abstract: The widespread misuse of image generation technologies has raised security concerns, driving the development of AI-generated image detection methods. However, generalization has become a key challenge and open problem: existing approaches struggle to adapt to emerging generative methods and content types in real-world scenarios. To address this issue, we propose a Scene-Aware and Importance-Guided Dynamic Optimization detection framework with continual learning (SAIDO). Specifically, we design Scene-Awareness-Based Expert Module (SAEM) that dynamically identifies and incorporates new scenes using VLLMs. For each scene, independent expert modules are dynamically allocated, enabling the framework to capture scene-specific forgery features better and enhance cross-scene generalization. To mitigate catastrophic forgetting when learning from multiple image generative methods, we introduce Importance-Guided Dynamic Optimization Mechanism (IDOM), which optimizes each neuron through an importance-guided gradient projection strategy, thereby achieving an effective balance between model plasticity and stability. Extensive experiments on continual learning tasks demonstrate that our method outperforms the current SOTA method in both stability and plasticity, achieving 44.22\% and 40.57\% relative reductions in average detection error rate and forgetting rate, respectively. On open-world datasets, it improves the average detection accuracy by 9.47\% compared to the current SOTA method.

</details>


### [50] [Asset-Driven Sematic Reconstruction of Dynamic Scene with Multi-Human-Object Interactions](https://arxiv.org/abs/2512.00547)
*Sandika Biswas,Qianyi Wu,Biplab Banerjee,Hamid Rezatofighi*

Main category: cs.CV

TL;DR: 本文提出了一种结合3D生成模型、语义感知变形以及基于高斯局部体化的方法来处理多个人和物体的动态场景，从而在严重遮挡下保持物体结构的一致性。


<details>
  <summary>Details</summary>
Motivation: 由于多个人和物体的动态场景建模面临众多挑战，如复杂的遮挡和多样化的运动模式，现有的方法难以实现高质量的重建。本文旨在改善多个人与物体在阴影下的重建效果。

Method: 本文提出了一种混合方法，结合了3D生成模型、语义感知变形（包括刚体对象的刚体变换和基于蒙皮的变形人类）以及基于高斯局部体化的方法，以实现动态场景中物体在遮挡下的精细重构。

Result: 实验结果表明，本文提出的方法在多个人与物体的动态场景中，能产生更好的表面重建效果。

Conclusion: 通过结合多种技术，本文成功地解决了多个人与物体的动态场景建模难题，特别是在严重遮挡条件下，显示了良好的物体结构重构能力。

Abstract: Real-world human-built environments are highly dynamic, involving multiple humans and their complex interactions with surrounding objects. While 3D geometry modeling of such scenes is crucial for applications like AR/VR, gaming, and embodied AI, it remains underexplored due to challenges like diverse motion patterns and frequent occlusions. Beyond novel view rendering, 3D Gaussian Splatting (GS) has demonstrated remarkable progress in producing detailed, high-quality surface geometry with fast optimization of the underlying structure. However, very few GS-based methods address multihuman, multiobject scenarios, primarily due to the above-mentioned inherent challenges. In a monocular setup, these challenges are further amplified, as maintaining structural consistency under severe occlusion becomes difficult when the scene is optimized solely based on GS-based rendering loss. To tackle the challenges of such a multihuman, multiobject dynamic scene, we propose a hybrid approach that effectively combines the advantages of 1) 3D generative models for generating high-fidelity meshes of the scene elements, 2) Semantic-aware deformation, \ie rigid transformation of the rigid objects and LBS-based deformation of the humans, and mapping of the deformed high-fidelity meshes in the dynamic scene, and 3) GS-based optimization of the individual elements for further refining their alignments in the scene. Such a hybrid approach helps maintain the object structures even under severe occlusion and can produce multiview and temporally consistent geometry. We choose HOI-M3 for evaluation, as, to the best of our knowledge, this is the only dataset featuring multihuman, multiobject interactions in a dynamic scene. Our method outperforms the state-of-the-art method in producing better surface reconstruction of such scenes.

</details>


### [51] [NeuroVolve: Evolving Visual Stimuli toward Programmable Neural Objectives](https://arxiv.org/abs/2512.00557)
*Haomiao Chen,Keith W Jamison,Mert R. Sabuncu,Amy Kuceyeski*

Main category: cs.CV

TL;DR: NeuroVolve是一种新的生成框架，通过优化预训练的视觉-语言模型嵌入空间中的神经目标函数来生成脑引导的图像。它不仅能够再现独立脑区的选择性，还能合成满足跨多个区域复杂约束的连贯场景。该框架揭示了嵌入空间中的语义轨迹，揭示了脑区之间的协同和反协同关系，并支持个性化的大脑驱动合成。


<details>
  <summary>Details</summary>
Motivation: 当前的生成模型方法在重现孤立区域的选择性方面表现良好，但在复杂、自然主义的视觉下，这些方法对脑区之间的相互作用提供有限的洞察。NeuroVolve旨在填补这一空白，提供一种新的生成框架，能够更好地理解大脑如何整合分布式模式来创造其神经表示。

Method: NeuroVolve使用预训练的视觉-语言模型，并通过优化嵌入空间中的神经目标函数来生成图像。该框架通过激活或抑制单一区域或多个区域的组合，实现了可编程的神经目标。研究人员通过追踪优化步骤，揭示了嵌入空间中的语义轨迹，并展示了脑区之间的协同和反协同效应。

Result: NeuroVolve展示了在单个ROIs生成低级和语义特征特定刺激的能力，同时也实现了多区域目标下的刺激对齐。此框架能够揭示脑区间的相互作用关系，如共激活和去相关，并支持个性化的脑驱动合成。

Conclusion: 研究证明，NeuroVolve是一个有效的框架，它可以提供脑区级别的图像生成并揭示神经表示中的语义路径。它还表明此框架可以支持个性化的大脑驱动合成，并为未来的大脑信号与视觉表示的研究提供了新的方法和见解。

Abstract: What visual information is encoded in individual brain regions, and how do distributed patterns combine to create their neural representations? Prior work has used generative models to replicate known category selectivity in isolated regions (e.g., faces in FFA), but these approaches offer limited insight into how regions interact during complex, naturalistic vision. We introduce NeuroVolve, a generative framework that provides brain-guided image synthesis via optimization of a neural objective function in the embedding space of a pretrained vision-language model. Images are generated under the guidance of a programmable neural objective, i.e., activating or deactivating single regions or multiple regions together. NeuroVolve is validated by recovering known selectivity for individual brain regions, while expanding to synthesize coherent scenes that satisfy complex, multi-region constraints. By tracking optimization steps, it reveals semantic trajectories through embedding space, unifying brain-guided image editing and preferred stimulus generation in a single process. We show that NeuroVolve can generate both low-level and semantic feature-specific stimuli for single ROIs, as well as stimuli aligned to curated neural objectives. These include co-activation and decorrelation between regions, exposing cooperative and antagonistic tuning relationships. Notably, the framework captures subject-specific preferences, supporting personalized brain-driven synthesis and offering interpretable constraints for mapping, analyzing, and probing neural representations of visual information.

</details>


### [52] [Describe Anything Anywhere At Any Moment](https://arxiv.org/abs/2512.00565)
*Nicolas Gorlo,Lukas Schmid,Luca Carlone*

Main category: cs.CV

TL;DR: DAAAM 提出了一种新颖的时空记忆框架，用于大型和实时的 4D 场景理解，能够在保持实时性能的同时构建具有详细几何语义描述的 4D 场景图，并在时空问题回答基准测试中取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成丰富的开放词汇描述时会牺牲实时性能，特别是在需要将这些描述与 3D 对齐的情况下。DAAAM 试图解决这种情况下的场景理解挑战，提供了实时性能和详细描述之间的平衡。

Method: DAAAM 引入了一种基于优化的前处理方法，通过批量处理优化语义描述的推断速度，使用批处理来提高在线处理速度，同时构建一个分层的 4D 场景图作为时空内一致的记忆表示。

Result: 在复杂的时空问题回答任务中，DAAAM 在 NaVQA 基准测试中达到了最先进的性能，显著提高了问题准确性、位置误差和时间误差。在 SG3D 基准测试中，它也展示了对序贯任务定位的一般化能力。

Conclusion: DAAAM 提供了一个强大的时空框架，能够实时构建详细的场景图，并已在多个基准测试中展现出优越性能。

Abstract: Computer vision and robotics applications ranging from augmented reality to robot autonomy in large-scale environments require spatio-temporal memory frameworks that capture both geometric structure for accurate language-grounding as well as semantic detail. Existing methods face a tradeoff, where producing rich open-vocabulary descriptions comes at the expense of real-time performance when these descriptions have to be grounded in 3D. To address these challenges, we propose Describe Anything, Anywhere, at Any Moment (DAAAM), a novel spatio-temporal memory framework for large-scale and real-time 4D scene understanding. DAAAM introduces a novel optimization-based frontend to infer detailed semantic descriptions from localized captioning models, such as the Describe Anything Model (DAM), leveraging batch processing to speed up inference by an order of magnitude for online processing. It leverages such semantic understanding to build a hierarchical 4D scene graph (SG), which acts as an effective globally spatially and temporally consistent memory representation. DAAAM constructs 4D SGs with detailed, geometrically grounded descriptions while maintaining real-time performance. We show that DAAAM's 4D SG interfaces well with a tool-calling agent for inference and reasoning.
  We thoroughly evaluate DAAAM in the complex task of spatio-temporal question answering on the NaVQA benchmark and show its generalization capabilities for sequential task grounding on the SG3D benchmark. We further curate an extended OC-NaVQA benchmark for large-scale and long-time evaluations. DAAAM achieves state-of-the-art results in both tasks, improving OC-NaVQA question accuracy by 53.6%, position errors by 21.9%, temporal errors by 21.6%, and SG3D task grounding accuracy by 27.8% over the most competitive baselines, respectively. We release our data and code open-source.

</details>


### [53] [Integrating Skeleton Based Representations for Robust Yoga Pose Classification Using Deep Learning Models](https://arxiv.org/abs/2512.00572)
*Mohammed Mohiuddin,Syed Mohammod Minhaz Hossain,Sumaiya Khanam,Prionkar Barua,Aparup Barua,MD Tamim Hossain*

Main category: cs.CV

TL;DR: 该研究引入了一个名为'Yoga-16'的数据集，并系统评估了三种深度学习架构在瑜伽姿势识别中的表现，结果显示基于骨架的表示优于原始图像输入。


<details>
  <summary>Details</summary>
Motivation: 由于瑜伽在全球受欢迎，尽管具有精神和身体健康的益处，但错误的姿态可能导致受伤，故需减少依赖专家来对瑜伽姿势进行分类。

Method: 研究中提出了一个名为'Yoga-16'的数据集，并使用三种深度学习架构（VGG16、ResNet50和Xception）基于三种输入模式（直接图像、MediaPipe Pose骨架图像和YOLOv8 Pose骨架图像）进行系统评估。

Result: 实验表明，基于骨架的表示优于原始图像输入，VGG16与MediaPipe Pose骨架输入的准确率达到最高，为96.09%。还使用Grad-CAM提供了可解释性分析，旨在瑜伽姿势分类中的模型决策。

Conclusion: 研究通过提出改进的数据集和系统评估不同架构，展示了基于骨架的表示在瑜伽姿势识别上的优越性，并提供了模型决策的见解。

Abstract: Yoga is a popular form of exercise worldwide due to its spiritual and physical health benefits, but incorrect postures can lead to injuries. Automated yoga pose classification has therefore gained importance to reduce reliance on expert practitioners. While human pose keypoint extraction models have shown high potential in action recognition, systematic benchmarking for yoga pose recognition remains limited, as prior works often focus solely on raw images or a single pose extraction model. In this study, we introduce a curated dataset, 'Yoga-16', which addresses limitations of existing datasets, and systematically evaluate three deep learning architectures (VGG16, ResNet50, and Xception) using three input modalities (direct images, MediaPipe Pose skeleton images, and YOLOv8 Pose skeleton images). Our experiments demonstrate that skeleton-based representations outperform raw image inputs, with the highest accuracy of 96.09% achieved by VGG16 with MediaPipe Pose skeleton input. Additionally, we provide interpretability analysis using Grad-CAM, offering insights into model decision-making for yoga pose classification with cross validation analysis.

</details>


### [54] [SatireDecoder: Visual Cascaded Decoupling for Enhancing Satirical Image Comprehension](https://arxiv.org/abs/2512.00582)
*Yue Jiang,Haiwei Xue,Minghao Han,Mingcheng Li,Xiaolu Hou,Dingkang Yang,Lihua Zhang,Xu Zheng*

Main category: cs.CV

TL;DR: SatireDecoder 通过引入多智能体系统和链式推理策略，有效解析视觉讽刺，显著提高了误解准确性并减少了幻觉。


<details>
  <summary>Details</summary>
Motivation: 当前的视觉语言模型在理解纯视觉讽刺时面临挑战，尤其是难以整合局部实体关系和全局语境，导致误解、认知偏差和幻觉。

Method: SatireDecoder 采用多智能体系统实现视觉级联解耦，分解图像为精细的局部和全局语义表示，并使用基于不确定性的链式推理策略将复杂的讽刺理解过程分解为具有最小不确定性的子任务。

Result: 实验结果表明，SatireDecoder 在理解视觉讽刺方面优于现有基线，显著提高了解释准确性并减少了幻觉。

Conclusion: SatireDecoder 提供了一种新的方向，为视觉语言推理中的复杂语义任务提供了有希望的解决方案。

Abstract: Satire, a form of artistic expression combining humor with implicit critique, holds significant social value by illuminating societal issues. Despite its cultural and societal significance, satire comprehension, particularly in purely visual forms, remains a challenging task for current vision-language models. This task requires not only detecting satire but also deciphering its nuanced meaning and identifying the implicated entities. Existing models often fail to effectively integrate local entity relationships with global context, leading to misinterpretation, comprehension biases, and hallucinations. To address these limitations, we propose SatireDecoder, a training-free framework designed to enhance satirical image comprehension. Our approach proposes a multi-agent system performing visual cascaded decoupling to decompose images into fine-grained local and global semantic representations. In addition, we introduce a chain-of-thought reasoning strategy guided by uncertainty analysis, which breaks down the complex satire comprehension process into sequential subtasks with minimized uncertainty. Our method significantly improves interpretive accuracy while reducing hallucinations. Experimental results validate that SatireDecoder outperforms existing baselines in comprehending visual satire, offering a promising direction for vision-language reasoning in nuanced, high-level semantic tasks.

</details>


### [55] [Scaling Down to Scale Up: Towards Operationally-Efficient and Deployable Clinical Models via Cross-Modal Low-Rank Adaptation for Medical Vision-Language Models](https://arxiv.org/abs/2512.00597)
*Thuraya Alzubaidi,Farhad R. Nezami,Muzammil Behzad*

Main category: cs.CV

TL;DR: MedCT-VLM 是一个参数高效的视觉语言框架，通过低秩适配（LoRA）方法将大型 CT 基础模型适应于下游临床任务。研究在 18 种胸部病理分类中展示了显著效果提升。


<details>
  <summary>Details</summary>
Motivation: 目前基础模型在医学成像领域的应用受限，特别是体积医学影像，如CT成像。MedCT-VLM 旨在解决这一问题，通过参数高效的适配方法，将大规模预训练模型应用于医学成像任务。

Method: MedCT-VLM 使用参数高效的低秩适配（LoRA）方法，仅对少部分参数进行微调。具体来说，它在不直接重新训练大模型参数的情况下，插入低秩分解矩阵到视觉和文本编码器的注意力层。

Result: 在零样本分类任务上对 18 种胸部病理进行评估时，MedCT-VLM 的平均 AUROC、准确率和宏观 F1 分数均有所改善：AUROC 从 61.3% 提高到 68.9%、准确率从 67.2% 提高到 73.6%、宏观 F1 分数从 32.1% 提高到 36.9%。

Conclusion: 参数高效的适配方法能够有效将大规模预训练模型转移到医学成像任务，尤其是在标签数据稀缺的零样本场景中。

Abstract: Foundation models trained via vision-language pretraining have demonstrated strong zero-shot capabilities across diverse image domains, yet their application to volumetric medical imaging remains limited. We introduce MedCT-VLM: Medical CT Vision-Language Model, a parameter-efficient vision-language framework designed to adapt large-scale CT foundation models for downstream clinical tasks. MedCT-VLM uses a parameter-efficient approach to adapt CT-CLIP, a contrastive vision-language model trained on 25,692 chest CT volumes, for multi-label pathology classification using Low-Rank Adaptation (LoRA). Rather than fine-tuning the model's 440 M parameters directly, we insert low-rank decomposition matrices into attention layers of both vision and text encoders, training only 1.67M parameters (0.38\% of total). We evaluate on zero-shot classification across 18 thoracic pathologies, where the model must align CT embeddings with unseen text prompts at inference without task-specific training. LoRA fine-tuning improves mean AUROC from 61.3\% to 68.9\% (+7.6 pp), accuracy from 67.2\% to 73.6\% (+6.4 pp), and macro-F1 from 32.1\% to 36.9\% (+4.8 pp). These results demonstrate that parameter-efficient methods can effectively transfer large-scale pretraining to downstream medical imaging tasks, particularly for zero-shot scenarios where labeled data is scarce.

</details>


### [56] [Automatic Pith Detection in Tree Cross-Section Images Using Deep Learning](https://arxiv.org/abs/2512.00625)
*Tzu-I Liao,Mahmoud Fakhry,Jibin Yesudas Varghese*

Main category: cs.CV

TL;DR: 本文研究了YOLOv9、U-Net、Swin Transformer、DeepLabV3和Mask R-CNN在树横截面皮质检测方面的应用，通过动态扩增数据集提高泛化能力。Swin Transformer表现最佳，而Mask R-CNN在应用非最大抑制后性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 传统的树皮质检测方法是手动的且容易出错，本文探讨了深度学习模型在自动化皮质检测方面的应用潜力，以提高检测的准确性和效率。

Method: 研究人员构建了一个包含582张标注图像的数据集，并使用数据扩增技术提高模型的泛化能力。对不同的深度学习模型（YOLOv9、U-Net、Swin Transformer、DeepLabV3和Mask R-CNN）进行了评估，并通过非最大抑制等方法优化模型性能。

Result: Swin Transformer在细粒度分割任务中表现最佳，准确率达到0.94。YOLOv9在边界精度上表现不佳，但检测框检测效果良好。U-Net适用于具有结构化的模式，而DeepLabV3捕捉多尺度特征，尽管边界精度略有偏差。将Mask R-CNN与非最大抑制结合使用后，其IoU从0.45提高到0.80。

Conclusion: 研究结果表明，深度学习模型在树皮质检测中具有潜力，但模型的选择依赖于数据集特征和应用需求。通过优化参数和使用非最大抑制，性能得到了显著提升。

Abstract: Pith detection in tree cross-sections is essential for forestry and wood quality analysis but remains a manual, error-prone task. This study evaluates deep learning models -- YOLOv9, U-Net, Swin Transformer, DeepLabV3, and Mask R-CNN -- to automate the process efficiently. A dataset of 582 labeled images was dynamically augmented to improve generalization. Swin Transformer achieved the highest accuracy (0.94), excelling in fine segmentation. YOLOv9 performed well for bounding box detection but struggled with boundary precision. U-Net was effective for structured patterns, while DeepLabV3 captured multi-scale features with slight boundary imprecision. Mask R-CNN initially underperformed due to overlapping detections, but applying Non-Maximum Suppression (NMS) improved its IoU from 0.45 to 0.80. Generalizability was next tested using an oak dataset of 11 images from Oregon State University's Tree Ring Lab. Additionally, for exploratory analysis purposes, an additional dataset of 64 labeled tree cross-sections was used to train the worst-performing model to see if this would improve its performance generalizing to the unseen oak dataset. Key challenges included tensor mismatches and boundary inconsistencies, addressed through hyperparameter tuning and augmentation. Our results highlight deep learning's potential for tree cross-section pith detection, with model choice depending on dataset characteristics and application needs.

</details>


### [57] [XAI-Driven Skin Disease Classification: Leveraging GANs to Augment ResNet-50 Performance](https://arxiv.org/abs/2512.00626)
*Kim Gerard A. Villanueva,Priyanka Kumar*

Main category: cs.CV

TL;DR: 本研究提出了一种基于DCGAN的数据增广和ResNet-50分类器的CAD系统，结合了LIME和SHAP可解释AI提高了诊断准确性和临床可解释性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决多类皮肤病变诊断中的主观性问题、数据集中的类别不平衡以及深度学习模型的“黑箱”性质。

Method: 使用DCGAN进行数据增广以解决数据不平衡问题，然后使用调整后的ResNet-50分类器进行训练，并结合LIME和SHAP可解释AI提供透明度。

Result: 系统实现了92.50%的整体准确率和98.82%的宏AUC，显著优于其他基准架构。

Conclusion: 这项工作证明了一种结合高性能和必需的临床解释性的验证框架，为安全的诊断部署奠定了基础。未来的研究应优先提高关键类别的区分能力。

Abstract: Accurate and timely diagnosis of multi-class skin lesions is hampered by subjective methods, inherent data imbalance in datasets like HAM10000, and the "black box" nature of Deep Learning (DL) models. This study proposes a trustworthy and highly accurate Computer-Aided Diagnosis (CAD) system to overcome these limitations. The approach utilizes Deep Convolutional Generative Adversarial Networks (DCGANs) for per class data augmentation to resolve the critical class imbalance problem. A fine-tuned ResNet-50 classifier is then trained on the augmented dataset to classify seven skin disease categories. Crucially, LIME and SHAP Explainable AI (XAI) techniques are integrated to provide transparency by confirming that predictions are based on clinically relevant features like irregular morphology. The system achieved a high overall Accuracy of 92.50 % and a Macro-AUC of 98.82 %, successfully outperforming various prior benchmarked architectures. This work successfully validates a verifiable framework that combines high performance with the essential clinical interpretability required for safe diagnostic deployment. Future research should prioritize enhancing discrimination for critical categories, such as Melanoma NOS (F1-Score is 0.8602).

</details>


### [58] [MambaScope: Coarse-to-Fine Scoping for Efficient Vision Mamba](https://arxiv.org/abs/2512.00647)
*Shanhui Liu,Rui Xu,Yunke Wang*

Main category: cs.CV

TL;DR: CF-ViM 提出了一种名为 Coarse-to-Fine Vision Mamba 的自适应框架，通过首先进行粗粒度推理以显著减少输入图像的标记长度和计算量，然后在预测置信度低时对选定区域进行细粒度处理，以最小化的附加成本恢复关键视觉细节。这种方法使得 CF-ViM 能够根据图像复杂性动态分配计算资源，从而在不影响重要视觉信息的情况下实现高效处理。


<details>
  <summary>Details</summary>
Motivation: 现有的 Vision Mamba 方法由于输入标记数量的限制而在效率上受到根本性的限制，而纯粹的标记减少方法（如标记修剪或合并）会不可避免地引入信息损失。CF-ViM 的提出旨在提供一种更高效且适应性强的方法，通过区分不同图像的复杂性来动态调整分辨率和计算资源分配。

Method: CF-ViM 引入了一种粗粒度到细粒度的处理策略，首先将图像划分为大块进行粗粒度推理，显著减少了标记长度和计算量。如果模型的预测置信度较低，则对选定区域进行更精细的处理，以恢复关键视觉细节，同时保持较低的计算代价。这种策略允许 CF-ViM 根据图像复杂性动态调整计算资源分配。

Result: CF-ViM 在 ImageNet 数据集上展示了其超越基线 Vision Mamba 和现有的标记减少技术的优越性能，在准确性和效率方面均有所提升。

Conclusion: CF-ViM 通过一种新颖的方法解决了 Vision Mamba 在处理效率上的问题，提出了一种自适应框架，可以根据图像的具体复杂程度进行精细调整，展示了其在效率和准确性提升方面的能力。

Abstract: Vision Mamba has emerged as a promising and efficient alternative to Vision Transformers, yet its efficiency remains fundamentally constrained by the number of input tokens. Existing token reduction approaches typically adopt token pruning or merging to reduce computation. However, they inherently lead to information loss, as they discard or compress token representations. This problem is exacerbated when applied uniformly to fine-grained token representations across all images, regardless of visual complexity. We observe that not all inputs require fine-grained processing. Simple images can be effectively handled at coarse resolution, while only complex ones may warrant refinement. Based on this insight, we propose \textit{Coarse-to-Fine Vision Mamba (CF-ViM)}, an adaptive framework for efficient inference. CF-ViM first performs coarse-grained inference by dividing the input image into large patches, significantly reducing the token length and computation. When the model's prediction confidence is low, selected regions are re-processed at a finer resolution to recover critical visual details with minimal additional cost. This dynamic resolution assignment strategy allows CF-ViM to allocate computation adaptively according to image complexity, ensuring efficient processing without compromising essential visual information. Experiments on ImageNet demonstrate that CF-ViM outperforms both the baseline Vision Mamba and state-of-the-art token reduction techniques in terms of accuracy and efficiency.

</details>


### [59] [Realistic Handwritten Multi-Digit Writer (MDW) Number Recognition Challenges](https://arxiv.org/abs/2512.00676)
*Kiri L. Wagstaff*

Main category: cs.CV

TL;DR: 本文通过利用NIST手写数字图像的书写者知识，创建了更现实的多数字书写者（MDW）基准数据集，发现孤立数字分类器在多数字识别上表现不佳，提出更为任务特定的性能指标和方法，以提高实际数字识别任务的表现。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决实际数字识别问题，孤立数字分类器在处理由同一书写者记录的多数字时表现不佳，提出了更接近实际应用的评估指标和研究方法。

Method: 利用NIST数据集构建多数字书写者（MDW）基准数据集，基于书写者的知识来训练和评估多数字识别算法。

Result: 发现孤立数字分类器在多数字场景下表现不佳，且提出了任务特定的性能评估指标，使得未来研究能够更好地针对实际应用场景进行优化。

Conclusion: 提出的MDW基准数据集和评估标准有助于推动多数字识别领域的研究朝着解决实际应用场景中的问题方向发展。

Abstract: Isolated digit classification has served as a motivating problem for decades of machine learning research. In real settings, numbers often occur as multiple digits, all written by the same person. Examples include ZIP Codes, handwritten check amounts, and appointment times. In this work, we leverage knowledge about the writers of NIST digit images to create more realistic benchmark multi-digit writer (MDW) data sets. As expected, we find that classifiers may perform well on isolated digits yet do poorly on multi-digit number recognition. If we want to solve real number recognition problems, additional advances are needed. The MDW benchmarks come with task-specific performance metrics that go beyond typical error calculations to more closely align with real-world impact. They also create opportunities to develop methods that can leverage task-specific knowledge to improve performance well beyond that of individual digit classification methods.

</details>


### [60] [Dynamic-eDiTor: Training-Free Text-Driven 4D Scene Editing with Multimodal Diffusion Transformer](https://arxiv.org/abs/2512.00677)
*Dong In Lee,Hyungjun Doh,Seunggeun Chi,Runlin Duan,Sangpil Kim,Karthik Ramani*

Main category: cs.CV

TL;DR: Dynamic-eDiTor 是一个无需训练的文本驱动 4D 编辑框架，利用 MultiModal Diffusion Transformer (MM-DiT) 和 4D Gaussian Splatting (4DGS)，实现了在不增加训练负担的情况下进行无缝多视角视频编辑，具有更高的编辑保真度和多视角及时间一致性。


<details>
  <summary>Details</summary>
Motivation: 现有方法利用 2D 扩散模型独立编辑每一帧，导致运动失真、几何漂移和编辑不完整的问题。Dynamic-eDiTor 通过利用 MultiModal Diffusion Transformer (MM-DiT) 和 4D Gaussian Splatting (4DGS)，旨在解决当前在 4D 场景编辑中多视角和时间一致性难以保证的问题。

Method: Dynamic-eDiTor 依赖于 MultiModal Diffusion Transformer (MM-DiT) 和 4D Gaussian Splatting (4DGS)。主要机制包括时空子网格注意力 (STGA) 用于局部一致的多视角和时间融合，以及上下文标记传播 (CTP) 用于全局传播，通过标记继承和光学流引导的标记替换实现。

Result: 实验结果表明，Dynamic-eDiTor 在多视角视频 DNeRF 数据集上的编辑精度和时空一致性均优于现有方法。

Conclusion: Dynamic-eDiTor 为 4D 场景编辑提供了一种高效而强大的工具，无需额外训练，能够实现高质量的多视角视频编辑。

Abstract: Recent progress in 4D representations, such as Dynamic NeRF and 4D Gaussian Splatting (4DGS), has enabled dynamic 4D scene reconstruction. However, text-driven 4D scene editing remains under-explored due to the challenge of ensuring both multi-view and temporal consistency across space and time during editing. Existing studies rely on 2D diffusion models that edit frames independently, often causing motion distortion, geometric drift, and incomplete editing. We introduce Dynamic-eDiTor, a training-free text-driven 4D editing framework leveraging Multimodal Diffusion Transformer (MM-DiT) and 4DGS. This mechanism consists of Spatio-Temporal Sub-Grid Attention (STGA) for locally consistent cross-view and temporal fusion, and Context Token Propagation (CTP) for global propagation via token inheritance and optical-flow-guided token replacement. Together, these components allow Dynamic-eDiTor to perform seamless, globally consistent multi-view video without additional training and directly optimize pre-trained source 4DGS. Extensive experiments on multi-view video dataset DyNeRF demonstrate that our method achieves superior editing fidelity and both multi-view and temporal consistency prior approaches. Project page for results and code: https://di-lee.github.io/dynamic-eDiTor/

</details>


### [61] [Silhouette-based Gait Foundation Model](https://arxiv.org/abs/2512.00691)
*Dingqiang Ye,Chao Fan,Kartik Narayan,Bingzhe Wu,Chengwen Luo,Jianqiang Li,Vishal M. Patel*

Main category: cs.CV

TL;DR: FoundationGait 是一种可扩展的自监督预训练框架，可广泛适用于多种步态任务，具有出色的跨数据集和条件的鲁棒性能，显著提高了步态识别的准确性。


<details>
  <summary>Details</summary>
Motivation: 当前步态识别模型存在的问题在于规模较小、泛化能力有限，难以适应多种步态任务。因此，需要设计一个统一的基础模型，解决这个问题。

Method: FoundationGait 采用自监督预训练框架，利用多种步态数据集进行大规模学习，提升了模型的泛化能力和鲁棒性。

Result: FoundationGait 在多个领域（如步态识别、脊柱侧弯筛查、抑郁症预测和属性估计）上展现出良好的性能，在 Gait3D 和 OU-MVLP 数据集上分别达到了 48.0% 和 64.5% 的零样本识别准确率。

Conclusion: FoundationGait 是一种重要的步态识别技术进步，为后续研究提供了新的方向。

Abstract: Gait patterns play a critical role in human identification and healthcare analytics, yet current progress remains constrained by small, narrowly designed models that fail to scale or generalize. Building a unified gait foundation model requires addressing two longstanding barriers: (a) Scalability. Why have gait models historically failed to follow scaling laws? (b) Generalization. Can one model serve the diverse gait tasks that have traditionally been studied in isolation? We introduce FoundationGait, the first scalable, self-supervised pretraining framework for gait understanding. Its largest version has nearly 0.13 billion parameters and is pretrained on 12 public gait datasets comprising over 2 million walking sequences. Extensive experiments demonstrate that FoundationGait, with or without fine-tuning, performs robustly across a wide spectrum of gait datasets, conditions, tasks (e.g., human identification, scoliosis screening, depression prediction, and attribute estimation), and even input modality. Notably, it achieves 48.0% zero-shot rank-1 accuracy on the challenging in-the-wild Gait3D dataset (1,000 test subjects) and 64.5% on the largest in-the-lab OU-MVLP dataset (5,000+ test subjects), setting a new milestone in robust gait recognition. Coming code and model: https://github.com/ShiqiYu/OpenGait.

</details>


### [62] [Affordance-First Decomposition for Continual Learning in Video-Language Understanding](https://arxiv.org/abs/2512.00694)
*Mengzhu Xu,Hanzhi Liu,Ningkang Peng,Qianyu Chen,Canran Xiao*

Main category: cs.CV

TL;DR: AFD通过将视频映射到缓慢变化的能力标记，形成共享的时间对齐底层，并通过弱对齐和教师一致性进行稳定化，实现针对领域增量和时间增量的大规模多模态理解任务的卓越性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在面对不断变化的数据和查询风格时的局限性，如模糊了稳定性与适应性间的界限，并依赖于静态路由和容量或需要回放过去的数据。

Method: 提出了一种名为AFD的方法，通过将视频映射到缓慢变化的能力标记，并形成共享的时间对齐底层，以及通过一个轻量级、查询导向、冲突感知调度器集中适应和按需扩展容量。此外，使用弱对齐和教师一致性进行底层的稳定化，同时在训练中仅使用问题回放。

Result: AFD在多种大规模多模态理解任务中均表现出色，例如，在领域增量视频问答（ViLCo）中实现了29.6%和20.7%的精确率，同时在时间增量iVQA中的准确率达到39.5%，并且在所有任务中都保持了极低的遗忘度。

Conclusion: AFD为大规模多模态理解提供了明确的稳定性与适应性间划分，能够有效地应对非稳态数据挑战，并且在多个任务上实现了最佳性能。

Abstract: Continual learning for video--language understanding is increasingly important as models face non-stationary data, domains, and query styles, yet prevailing solutions blur what should stay stable versus what should adapt, rely on static routing/capacity, or require replaying past videos. We aim to explicitly specify where stability lives and where plasticity should be focused under realistic memory and privacy constraints. We introduce Affordance-First Decomposition (AFD): videos are mapped to slowly varying affordance tokens that form a shared, time-aligned substrate, while a lightweight, query-routed, conflict-aware scheduler concentrates adaptation and grows capacity only when needed. The substrate is stabilized via weak alignment and teacher consistency, and training uses question-only replay. AFD achieves state-of-the-art across protocols: 51.6% average accuracy with -1.8% forgetting on domain-incremental VideoQA, ViLCo R@1@0.5 of 29.6% (MQ) and 20.7% (NLQ) with 18.4% stAP@0.25 (VQ), and 39.5% accuracy with -1.6% forgetting on time-incremental iVQA. Overall, AFD offers an explicit, interpretable split between a stable interaction-centered substrate and targeted adaptation.

</details>


### [63] [Generalized Medical Phrase Grounding](https://arxiv.org/abs/2512.01085)
*Wenjun Zhang,Shekhar S. Chandra,Aaron Nicolson*

Main category: cs.CV

TL;DR: 该研究提出了一个用于医学图像报告的新型模型MedGrounder，它能够更好地处理多区域和非可接地的描述，并且减少了对人工标注框的依赖。


<details>
  <summary>Details</summary>
Motivation: 现有的医学影像报告（MPG）系统普遍存在假设每个短语对应一个确切的边界框的问题，但实际报告中存在跨多个区域的病症描述、非诊断性文本及不可较为的标毕业语言，MedGrounder模型旨在解决这些问题。

Method: 研究人员首先提出了一种新的任务表述，即“通用医学短语配准”（GMPG），目标是将整个句子映射到多个得分区域，并用这种方法设计了一个叫做MedGrounder的新模型。模型采取了双阶段的训练方法：预训练阶段使用报告-解剖框对齐的数据集进行预训练，之后再用人工标注的数据集进行微调。

Result: MedGrounder在PadChest-GR和MS-CXR数据集上的实验结果表明，在处理多地区和非可配准语句时，它表现出了强大的无监督迁移学习能力，并且优于基于参考表达理解的模型和生成报告的基线模型，同时使用的人工标注框数量显著较少。

Conclusion: MedGrounder模型展示了在医学短语配准领域的一个新解决方案，并且达到了实际应用的要求。

Abstract: Medical phrase grounding (MPG) maps textual descriptions of radiological findings to corresponding image regions. These grounded reports are easier to interpret, especially for non-experts. Existing MPG systems mostly follow the referring expression comprehension (REC) paradigm and return exactly one bounding box per phrase. Real reports often violate this assumption. They contain multi-region findings, non-diagnostic text, and non-groundable phrases, such as negations or descriptions of normal anatomy. Motivated by this, we reformulate the task as generalised medical phrase grounding (GMPG), where each sentence is mapped to zero, one, or multiple scored regions. To realise this formulation, we introduce the first GMPG model: MedGrounder. We adopted a two-stage training regime: pre-training on report sentence--anatomy box alignment datasets and fine-tuning on report sentence--human annotated box datasets. Experiments on PadChest-GR and MS-CXR show that MedGrounder achieves strong zero-shot transfer and outperforms REC-style and grounded report generation baselines on multi-region and non-groundable phrases, while using far fewer human box annotations. Finally, we show that MedGrounder can be composed with existing report generators to produce grounded reports without retraining the generator.

</details>


### [64] [Optimizing LVLMs with On-Policy Data for Effective Hallucination Mitigation](https://arxiv.org/abs/2512.00706)
*Chengzhi Yu,Yifan Xu,Yifan Chen,Wenyi Zhang*

Main category: cs.CV

TL;DR: 本文分析了大型视觉语言模型在减轻幻觉方面的数据生成过程，提出了使用判别分类器进行二分类标注以减少幻觉的方法，并设计了一种基于动态样本重加权的鲁棒迭代直接偏好优化算法。实验表明，该方法显著降低了LLaVA-1.5-7B和LLaVA-1.5-13B在MMHalBench和Object HalBench上的幻觉率，甚至使开源模型LLaVA-1.5-13B超过了GPT-4V。


<details>
  <summary>Details</summary>
Motivation: 由于大规模视觉语言模型（LVLMs）在多模态任务中的潜力，研究如何减少LVLMs中的幻觉现象变得尤为重要。

Method: 本文首先分析了LVLM幻觉减轻过程中的数据生成过程，指出现场策略数据显著优于离场策略数据，进而提出了使用判别分类器进行二分类标注的方法。为了进一步提高现场策略数据的利用效率，本文设计了一种鲁棒的迭代直接偏好优化算法，采用了动态样本重加权策略。

Result: 实验在三个基准测试集上进行了全面的评估，证明了该方法的有效性，特别是在LLaVA-1.5-7B和LLaVA-1.5-13B在MMHalBench和Object HalBench上的幻觉率分别降低了50.8%和79.5%。此外，本文的方法使得开源模型LLaVA-1.5-13B的性能超过了GPT-4V。

Conclusion: 本文提出的方法在幻觉减轻方面取得了显著效果，并为后续研究提供了有效的策略和技术。

Abstract: Recently, large vision-language models (LVLMs) have risen to be a promising approach for multimodal tasks. However, principled hallucination mitigation remains a critical challenge.In this work, we first analyze the data generation process in LVLM hallucination mitigation and affirm that on-policy data significantly outperforms off-policy data, which thus calls for efficient and reliable preference annotation of on-policy data. We then point out that, existing annotation methods introduce additional hallucination in training samples, which may enhance the model's hallucination patterns, to address this problem, we propose training a hallucination classifier giving binary annotations, which guarantee clean chosen samples for the subsequent alignment. To further harness of the power of on-policy data, we design a robust iterative direct preference optimization (DPO) algorithm adopting a dynamic sample reweighting scheme. We conduct comprehensive experiments on three benchmarks with comparison to 8 state-of-the-art baselines. In particular, our approach reduces the hallucination rate of LLaVA-1.5-7B on MMHalBench by 50.8% and the average hallucination rate on Object HalBench by 79.5%; more significantly, our method fully taps into the potential of open-source models, enabling LLaVA-1.5-13B to even surpass the performance of GPT-4V.

</details>


### [65] [Generative Adversarial Gumbel MCTS for Abstract Visual Composition Generation](https://arxiv.org/abs/2512.01242)
*Zirui Zhao,Boye Niu,David Hsu,Wee Sun Lee*

Main category: cs.CV

TL;DR: 本文提出了一种结合显式几何推理与神经语义的约束引导框架，通过AlphaGo风格搜索确保可行性，并利用微调的视觉语言模型作为奖励信号进行评分。该方法在拼图组装任务中表现出更高的有效性和语义准确度。


<details>
  <summary>Details</summary>
Motivation: 本文研究抽象视觉组合问题，重点在于空间配置和几何基础的组合。解决这一问题面临的挑战包括组合性排列选择、数据有限性和离散可行性等，这些都使得基于像素的空间生成方法不适用。

Method: 提出的约束引导框架结合了显式几何推理与神经语义。通过AlphaGo风格的搜索确保可行性，使用微调后的视觉语言模型作为奖励信号进行评分。通过生成模型与奖励模型的迭代，提升生成实例的准确度。

Result: 在拼图组装任务中，本文提出的方法在有效性与语义准确性方面优于扩散生成和自回归的基本模型，尤其是在约束条件变严格时效果更为明显。

Conclusion: 本文通过结合几何推理和神经语义的方法，有效地解决了抽象视觉组合的问题，提出的方法具有较高的准确性和实用性。

Abstract: We study abstract visual composition, in which identity is primarily determined by the spatial configuration and relations among a small set of geometric primitives (e.g., parts, symmetry, topology). They are invariant primarily to texture and photorealistic detail. Composing such structures from fixed components under geometric constraints and vague goal specification (such as text) is non-trivial due to combinatorial placement choices, limited data, and discrete feasibility (overlap-free, allowable orientations), which create a sparse solution manifold ill-suited to purely statistical pixel-space generators. We propose a constraint-guided framework that combines explicit geometric reasoning with neural semantics. An AlphaGo-style search enforces feasibility, while a fine-tuned vision-language model scores semantic alignment as reward signals. Our algorithm uses a policy network as a heuristic in Monte-Carlo Tree Search and fine-tunes the network via search-generated plans. Inspired by the Generative Adversarial Network, we use the generated instances for adversarial reward refinement. Over time, the generation should approach the actual data more closely when the reward model cannot distinguish between generated instances and ground-truth. In the Tangram Assembly task, our approach yields higher validity and semantic fidelity than diffusion and auto-regressive baselines, especially as constraints tighten.

</details>


### [66] [RS-ISRefiner: Towards Better Adapting Vision Foundation Models for Interactive Segmentation of Remote Sensing Images](https://arxiv.org/abs/2512.00718)
*Deliang Wang,Peng Liu*

Main category: cs.CV

TL;DR: RS-ISRefiner是一种针对遥感图像的创新交互分割框架，通过适配器调优策略、混合注意力机制和改进的概率图调制方案，实现了更高的分割精度、效率和交互成本。


<details>
  <summary>Details</summary>
Motivation: 现有交互分割方法难以应用于遥感图像，因为缺乏标注数据和高计算成本。RS-ISRefiner通过专门设计，旨在解决这些问题，以提高分割准确性并降低交互成本。

Method: RS-ISRefiner采用适配器调优策略，保留视觉基础模型的通用表示，同时学习遥感特有的空间和边界特征。集成卷积局部建模与基于Transformer的全局推理的混合注意力机制增强了对尺度多样性及场景复杂性的鲁棒性。改进的概率图调制方案有效地结合了历史用户交互，提高了迭代精化过程的稳定性和边界精度。

Result: 在六个遥感数据集（iSAID、ISPRS Potsdam、SandBar、NWPU、LoveDA Urban和WHUBuilding）上进行的全面实验表明，RS-ISRefiner在分割精度、效率和交互成本方面优于最先进的交互分割方法。

Conclusion: RS-ISRefiner在遥感实例分割方面表现出色，展现出其有效性和通用性，适用于实际的遥感应用场景。

Abstract: Interactive image segmentation(IIS) plays a critical role in generating precise annotations for remote sensing imagery, where objects often exhibit scale variations, irregular boundaries and complex backgrounds. However, existing IIS methods, primarily designed for natural images, struggle to generalize to remote sensing domains due to limited annotated data and computational overhead. To address these challenges, we proposed RS-ISRefiner, a novel click-based IIS framework tailored for remote sensing images. The framework employs an adapter-based tuning strategy that preserves the general representations of Vision Foundation Models while enabling efficient learning of remote sensing-specific spatial and boundary characteristics. A hybrid attention mechanism integrating convolutional local modeling with Transformer-based global reasoning enhances robustness against scale diversity and scene complexity. Furthermore, an improved probability map modulation scheme effectively incorporates historical user interactions, yielding more stable iterative refinement and higher boundary fidelity. Comprehensive experiments on six remote sensing datasets, including iSAID, ISPRS Potsdam, SandBar, NWPU, LoveDA Urban and WHUBuilding, demonstrate that RS-ISRefiner consistently outperforms state-of-the-art IIS methods in terms of segmentation accuracy, efficiency and interaction cost. These results confirm the effectiveness and generalizability of our framework, making it highly suitable for high-quality instance segmentation in practical remote sensing scenarios.

</details>


### [67] [TrajDiff: End-to-end Autonomous Driving without Perception Annotation](https://arxiv.org/abs/2512.00723)
*Xingtai Gui,Jianbo Zhao,Wencheng Han,Jikai Wang,Jiahao Gong,Feiyang Tan,Cheng-zhong Xu,Jianbing Shen*

Main category: cs.CV

TL;DR: 本研究提出了一种名为 TrajDiff 的轨迹导向的 BEV 条件扩散框架，该方法从仅包含原始传感器数据和未来轨迹的目标中生成多元且合理的轨迹，无需手工感知标注，从而为端到端自动驾驶提供了无需感知标注的生成方法。


<details>
  <summary>Details</summary>
Motivation: 由于手动感知标注的成本高昂，故开发无需感知标注的轨迹生成方法对于端到端自动驾驶变得日益重要。

Method: 该方法通过设计一个简单的轨迹导向的 BEV 编码器将原始传感器数据转化为 TrajBEV 特征，并利用 Egocentric 信息及预测的 TrajBEV 特征通过 Trajectory-oriented BEV Diffusion Transformer (TB-DiT) 直接生成多元且合理的轨迹。

Result: TrajDiff 在 NAVSIM 基准测试中取得了 87.5 PDMS 的成绩，达到了无标注方法的最新水平。通过数据规模扩展，性能进一步提升至 88.5 PDMS，接近基于感知的高级方法的水平。

Conclusion: TrajDiff 为端到端自动驾驶提供了一种无需感知标注的轨迹生成方法，并通过大规模数据的训练展示了其应用前景。

Abstract: End-to-end autonomous driving systems directly generate driving policies from raw sensor inputs. While these systems can extract effective environmental features for planning, relying on auxiliary perception tasks, developing perception annotation-free planning paradigms has become increasingly critical due to the high cost of manual perception annotation. In this work, we propose TrajDiff, a Trajectory-oriented BEV Conditioned Diffusion framework that establishes a fully perception annotation-free generative method for end-to-end autonomous driving. TrajDiff requires only raw sensor inputs and future trajectory, constructing Gaussian BEV heatmap targets that inherently capture driving modalities. We design a simple yet effective trajectory-oriented BEV encoder to extract the TrajBEV feature without perceptual supervision. Furthermore, we introduce Trajectory-oriented BEV Diffusion Transformer (TB-DiT), which leverages ego-state information and the predicted TrajBEV features to directly generate diverse yet plausible trajectories, eliminating the need for handcrafted motion priors. Beyond architectural innovations, TrajDiff enables exploration of data scaling benefits in the annotation-free setting. Evaluated on the NAVSIM benchmark, TrajDiff achieves 87.5 PDMS, establishing state-of-the-art performance among all annotation-free methods. With data scaling, it further improves to 88.5 PDMS, which is comparable to advanced perception-based approaches. Our code and model will be made publicly available.

</details>


### [68] [StreamGaze: Gaze-Guided Temporal Reasoning and Proactive Understanding in Streaming Videos](https://arxiv.org/abs/2512.01707)
*Daeun Lee,Subhojyoti Mukherjee,Branislav Kveton,Ryan A. Rossi,Viet Dac Lai,Seunghyun Yoon,Trung Bui,Franck Dernoncourt,Mohit Bansal*

Main category: cs.CV

TL;DR: StreamGaze是一个新的基准测试，旨在评估模型在处理实时视点和预测用户意图方面的表现。它包括基于视线的过去、现在和前瞻性任务，使用眼球追踪数据，展示了最先进的模型与人类在视角引导方面的差距。


<details>
  <summary>Details</summary>
Motivation: 当前的流媒体基准测试主要评估时间推理能力，但忽略了模型是否能够解释或利用人类注视信号。这个基准测试填补了这一空白，旨在评估大规模语言模型是否能够有效利用注视来进行流媒体视频的时间和前瞻性推理。

Method: 该基准测试通过开发一个将第一人称视频与原始的眼球追踪轨迹对齐的生成管道来构建，包括注视点提取、区域特定的视觉提示和扫描路径构建，生成了空间和时间上与人类感知动态紧密相关的问答对。

Result: 所有StreamGaze任务都显示出最先进的大规模语言模型与人类表现之间存在显著的性能差距，揭示了基于目光的时间推理、意图建模和前瞻性预测的基本局限性。

Conclusion: 该研究不仅提供了对当前模型困境的详细分析，还为未来模型需要发展的关键能力提供了见解，并宣布公开数据和代码，以支持该领域的进一步研究。

Abstract: Streaming video understanding requires models not only to process temporally incoming frames, but also to anticipate user intention for realistic applications like AR glasses. While prior streaming benchmarks evaluate temporal reasoning, none measure whether MLLMs can interpret or leverage human gaze signals within a streaming setting. To fill this gap, we introduce StreamGaze, the first benchmark designed to evaluate how effectively MLLMs use gaze for temporal and proactive reasoning in streaming videos. StreamGaze introduces gaze-guided past, present, and proactive tasks that comprehensively evaluate streaming video understanding. These tasks assess whether models can use real-time gaze to follow shifting attention and infer user intentions from only past and currently observed frames. To build StreamGaze, we develop a gaze-video QA generation pipeline that aligns egocentric videos with raw gaze trajectories via fixation extraction, region-specific visual prompting, and scanpath construction. This pipeline produces spatio-temporally grounded QA pairs that closely reflect human perceptual dynamics. Across all StreamGaze tasks, we observe substantial performance gaps between state-of-the-art MLLMs and human performance, revealing fundamental limitations in gaze-based temporal reasoning, intention modeling, and proactive prediction. We further provide detailed analyses of gaze-prompting strategies, reasoning behaviors, and task-specific failure modes, offering deeper insight into why current MLLMs struggle and what capabilities future models must develop. All data and code will be publicly released to support continued research in gaze-guided streaming video understanding.

</details>


### [69] [Multi-GRPO: Multi-Group Advantage Estimation for Text-to-Image Generation with Tree-Based Trajectories and Multiple Rewards](https://arxiv.org/abs/2512.00743)
*Qiang Lyu,Zicong Chen,Chongxiao Wang,Haolin Shi,Shibo Gao,Ran Piao,Youwei Zeng,Jianlou Si,Fei Ding,Jing Li,Chun Pong Lau,Weiqiang Wang*

Main category: cs.CV

TL;DR: 该研究针对Group Relative Policy Optimization (GRPO)方法中的两个主要问题提出了Multi-GRPO方法：1) 共享的功劳归属，导致早期去噪步骤的准确性估计不准确；2) 奖励混合，导致目标之间的梯度不稳定。通过树状轨迹和基于奖励的分组机制来解决这些问题。


<details>
  <summary>Details</summary>
Motivation: 为了提高Group Relative Policy Optimization (GRPO)方法在文本到图像生成任务中的性能，尤其是解决共享功劳归属问题和奖励混合问题，提出了Multi-GRPO算法。

Method: Multi-GRPO算法包括两种分组机制：基于树的轨迹和基于奖励的分组。基于树的轨迹通过在早期去噪步骤的分支形成时间分组，以便于准确估计早期内部的性能增量。基于奖励的分组机制独立计算每个奖励函数的优势，避免相互矛盾的信息。

Result: 在单目标PickScore-25k和多目标OCR-Color-10基准测试中，Multi-GRPO显示出更高的稳定性和对齐性能，成功平衡了多个目标的冲突。

Conclusion: Multi-GRPO通过改进的分组机制有效解决了现有GRPO方法中的主要问题，为文本到图像生成任务中的多目标优化提供了新的解决方案。

Abstract: Recently, Group Relative Policy Optimization (GRPO) has shown promising potential for aligning text-to-image (T2I) models, yet existing GRPO-based methods suffer from two critical limitations. (1) \textit{Shared credit assignment}: trajectory-level advantages derived from group-normalized sparse terminal rewards are uniformly applied across timesteps, failing to accurately estimate the potential of early denoising steps with vast exploration spaces. (2) \textit{Reward-mixing}: predefined weights for combining multi-objective rewards (e.g., text accuracy, visual quality, text color)--which have mismatched scales and variances--lead to unstable gradients and conflicting updates. To address these issues, we propose \textbf{Multi-GRPO}, a multi-group advantage estimation framework with two orthogonal grouping mechanisms. For better credit assignment, we introduce tree-based trajectories inspired by Monte Carlo Tree Search: branching trajectories at selected early denoising steps naturally forms \emph{temporal groups}, enabling accurate advantage estimation for early steps via descendant leaves while amortizing computation through shared prefixes. For multi-objective optimization, we introduce \emph{reward-based grouping} to compute advantages for each reward function \textit{independently} before aggregation, disentangling conflicting signals. To facilitate evaluation of multiple objective alignment, we curate \textit{OCR-Color-10}, a visual text rendering dataset with explicit color constraints. Across the single-reward \textit{PickScore-25k} and multi-objective \textit{OCR-Color-10} benchmarks, Multi-GRPO achieves superior stability and alignment performance, effectively balancing conflicting objectives. Code will be publicly available at \href{https://github.com/fikry102/Multi-GRPO}{https://github.com/fikry102/Multi-GRPO}.

</details>


### [70] [Probabilistic Modeling of Multi-rater Medical Image Segmentation for Diversity and Personalization](https://arxiv.org/abs/2512.00748)
*Ke Liu,Shangde Gao,Yichao Fu,Shangqi Gao,Chunhua Shen*

Main category: cs.CV

TL;DR: 文章提出了一种新的概率模型，名为ProSeg，用于解决多评审人医学图像分割中的多样性和个性化问题。通过引入两个潜在变量来建模专家注释偏好和图像边界模糊度，并使用变分推断获得它们的条件概率分布，从而生成多样化且专家个人化的分割结果。


<details>
  <summary>Details</summary>
Motivation: 现有的医学图像分割模型难以同时实现多样化和个性化，ProSeg旨在解决这一问题，通过引入新的潜在变量和概率模型，提供了更全面的分割结果。

Method: ProSeg通过引入两个潜在变量，一个用于建模专家注释偏好，另一个用于表示图像边界模糊度。这两个潜在变量的条件概率分布通过变分推断获得，允许通过从这些分布中采样生成分割输出。

Result: ProSeg在鼻咽癌数据集(Nasopharyngeal Carcinoma, NPC)和肺结节数据集(Lung Nodule, LIDC-IDRI)上的实验表明，它实现了新的性能指标，提供了一种具有多样性和专家个性化特点的分割结果。

Conclusion: ProSeg通过有效的概率建模，成功地实现了医学图像分割的多样性与个性化，为该领域提供了新的解决方案。

Abstract: Medical image segmentation is inherently influenced by data uncertainty, arising from ambiguous boundaries in medical scans and inter-observer variability in diagnosis. To address this challenge, previous works formulated the multi-rater medical image segmentation task, where multiple experts provide separate annotations for each image. However, existing models are typically constrained to either generate diverse segmentation that lacks expert specificity or to produce personalized outputs that merely replicate individual annotators. We propose Probabilistic modeling of multi-rater medical image Segmentation (ProSeg) that simultaneously enables both diversification and personalization. Specifically, we introduce two latent variables to model expert annotation preferences and image boundary ambiguity. Their conditional probabilistic distributions are then obtained through variational inference, allowing segmentation outputs to be generated by sampling from these distributions. Extensive experiments on both the nasopharyngeal carcinoma dataset (NPC) and the lung nodule dataset (LIDC-IDRI) demonstrate that our ProSeg achieves a new state-of-the-art performance, providing segmentation results that are both diverse and expert-personalized. Code can be found in https://github.com/AI4MOL/ProSeg.

</details>


### [71] [Charts Are Not Images: On the Challenges of Scientific Chart Editing](https://arxiv.org/abs/2512.00752)
*Shawn Li,Ryan Rossi,Sungchul Kim,Sunav Choudhary,Franck Dernoncourt,Puneet Mathur,Zhengzhong Tu,Yue Zhao*

Main category: cs.CV

TL;DR: 本文介绍了FigEdit，一个大规模的科学图表编辑基准，包含超过30,000个样本，并涵盖多种编辑任务。评估结果表明，现有模型在处理结构化变换方面表现不佳，现有评价指标也无法准确捕捉图表编辑的语义正确性。


<details>
  <summary>Details</summary>
Motivation: 现有的图像生成模型在编辑自然图像方面表现出色，但在处理科学图表时存在不足。科学图表不仅仅是像素的排列，更是结构化的数据视觉表示，因此编辑需求不仅仅是像素操作，而是结构化的转换问题。因此需要引入一个新的基准来评估模型在科学图表编辑方面的表现。

Method: 作者构建了一个大规模的科学图表编辑基准，名为FigEdit，包含超过30,000个样本。该基准涵盖了10种不同的图表类型和丰富的复杂编辑指令，分为五类任务：单次编辑、多次编辑、对话式编辑、基于视觉指导的编辑和风格迁移。

Result: 通过在FigEdit上评估一系列当前最先进的模型，作者发现这些模型在处理科学图表时表现较差，无法应对所需的结构化变换。传统的评价指标（如SSIM和PSNR）在捕捉图表编辑的语义正确性方面有限制。

Conclusion: FigEdit揭示了像素级操作的局限性，并为开发和评估结构感知模型提供了坚实的基础。作者通过发布FigEdit，旨在促进结构感知图表编辑的系统性进展，并鼓励未来对科学图表的视觉和语义层有更好理解的模型研究。

Abstract: Generative models, such as diffusion and autoregressive approaches, have demonstrated impressive capabilities in editing natural images. However, applying these tools to scientific charts rests on a flawed assumption: a chart is not merely an arrangement of pixels but a visual representation of structured data governed by a graphical grammar. Consequently, chart editing is not a pixel-manipulation task but a structured transformation problem. To address this fundamental mismatch, we introduce \textit{FigEdit}, a large-scale benchmark for scientific figure editing comprising over 30,000 samples. Grounded in real-world data, our benchmark is distinguished by its diversity, covering 10 distinct chart types and a rich vocabulary of complex editing instructions. The benchmark is organized into five distinct and progressively challenging tasks: single edits, multi edits, conversational edits, visual-guidance-based edits, and style transfer. Our evaluation of a range of state-of-the-art models on this benchmark reveals their poor performance on scientific figures, as they consistently fail to handle the underlying structured transformations required for valid edits. Furthermore, our analysis indicates that traditional evaluation metrics (e.g., SSIM, PSNR) have limitations in capturing the semantic correctness of chart edits. Our benchmark demonstrates the profound limitations of pixel-level manipulation and provides a robust foundation for developing and evaluating future structure-aware models. By releasing \textit{FigEdit} (https://github.com/adobe-research/figure-editing), we aim to enable systematic progress in structure-aware figure editing, provide a common ground for fair comparison, and encourage future research on models that understand both the visual and semantic layers of scientific charts.

</details>


### [72] [Seeing the Wind from a Falling Leaf](https://arxiv.org/abs/2512.00762)
*Zhiyuan Gao,Jiageng Mao,Hong-Xing Yu,Haozhe Lou,Emily Yue-Ting Jia,Jernej Barbic,Jiajun Wu,Yue Wang*

Main category: cs.CV

TL;DR: 本文提出了一种端到端可微逆渲染框架，能够从视频中恢复出物体背后的隐形力场，尤其适用于估计由物体运动引起的风场。该框架能够直接从视频数据中建模物体的几何结构、物理属性及其相互作用，并通过反向传播直接从物体运动中恢复出力的表示。


<details>
  <summary>Details</summary>
Motivation: 以往的计算机视觉研究主要集中在通过视频建模物体的运动，但很少关注背后隐形的物理互动。本文旨在通过开发一种端到端可微逆渲染框架，从视觉观察中恢复隐形力场，从而更好地理解和建模视觉下的物理过程。

Method: 该方法采用了端到端的可微逆渲染框架，能够同时拟合视频中的物体几何、物理属性及其相互作用。通过反向传播，该方法可以直接从物体的运动中恢复力的表示。

Result: 该方法在合成数据和真实场景中得到了验证，表明其在从视频中推理出可接受的力场方面的潜力。此外，该框架还展示了其在基于物理的视频生成和编辑中的应用潜力。

Conclusion: 本文提出的方法旨在理解并建模像素背后的物理过程，可能在计算机视觉和物理学之间架起桥梁，通过更多视频结果，可以访问作者项目页。

Abstract: A longstanding goal in computer vision is to model motions from videos, while the representations behind motions, i.e. the invisible physical interactions that cause objects to deform and move, remain largely unexplored. In this paper, we study how to recover the invisible forces from visual observations, e.g., estimating the wind field by observing a leaf falling to the ground. Our key innovation is an end-to-end differentiable inverse graphics framework, which jointly models object geometry, physical properties, and interactions directly from videos. Through backpropagation, our approach enables the recovery of force representations from object motions. We validate our method on both synthetic and real-world scenarios, and the results demonstrate its ability to infer plausible force fields from videos. Furthermore, we show the potential applications of our approach, including physics-based video generation and editing. We hope our approach sheds light on understanding and modeling the physical process behind pixels, bridging the gap between vision and physics. Please check more video results in our \href{https://chaoren2357.github.io/seeingthewind/}{project page}.

</details>


### [73] [The Outline of Deception: Physical Adversarial Attacks on Traffic Signs Using Edge Patches](https://arxiv.org/abs/2512.00765)
*Haojie Jia,Te Hu,Haowen Li,Long Jin,Chongshi Xin,Yuchi Yao,Jiarui Xiao*

Main category: cs.CV

TL;DR: 本研究提出了一种名为TESP-Attack的新颖攻击方法，旨在通过生成形状符合交通标志特征且能无缝融入背景环境的边缘对齐掩膜，实现视觉隐身，从而提升物理对抗攻击在交通标志分类中的成功率。


<details>
  <summary>Details</summary>
Motivation: 当前的物理攻击方法缺乏隐蔽性，容易被人类观察者察觉，因此本研究旨在开发一种新的对抗性攻击方法以提高其隐蔽性和攻击成功率。

Method: 研究基于人类视觉注意力主要集中在交通标志的中央区域这一观察，采用了实例分割生成边缘对齐的掩膜，并利用U-Net生成对抗性贴片。通过颜色、纹理限制以及频率域分析优化贴片，使得其能与背景环境无缝融合。

Result: 该方法在多种交通标志分类模型中表现出优秀的攻击成功率，即使在有限的查询预算下也能达到超过90%的成功率。同时，该方法具有良好的跨模型可转移性和在不同角度和距离下的鲁棒性。

Conclusion: 总体来说，TESP-Attack展示了其在提高驾驶安全性和交通系统稳定性方面的重要潜力，但同时也提出了对抗性智能驾驶系统安全性的新挑战。

Abstract: Intelligent driving systems are vulnerable to physical adversarial attacks on traffic signs. These attacks can cause misclassification, leading to erroneous driving decisions that compromise road safety. Moreover, within V2X networks, such misinterpretations can propagate, inducing cascading failures that disrupt overall traffic flow and system stability. However, a key limitation of current physical attacks is their lack of stealth. Most methods apply perturbations to central regions of the sign, resulting in visually salient patterns that are easily detectable by human observers, thereby limiting their real-world practicality. This study proposes TESP-Attack, a novel stealth-aware adversarial patch method for traffic sign classification. Based on the observation that human visual attention primarily focuses on the central regions of traffic signs, we employ instance segmentation to generate edge-aligned masks that conform to the shape characteristics of the signs. A U-Net generator is utilized to craft adversarial patches, which are then optimized through color and texture constraints along with frequency domain analysis to achieve seamless integration with the background environment, resulting in highly effective visual concealment. The proposed method demonstrates outstanding attack success rates across traffic sign classification models with varied architectures, achieving over 90% under limited query budgets. It also exhibits strong cross-model transferability and maintains robust real-world performance that remains stable under varying angles and distances.

</details>


### [74] [EAG3R: Event-Augmented 3D Geometry Estimation for Dynamic and Extreme-Lighting Scenes](https://arxiv.org/abs/2512.00771)
*Xiaoshan Wu,Yifei Yu,Xiaoyang Lyu,Yihua Huang,Bo Wang,Baoheng Zhang,Zhongrui Wang,Xiaojuan Qi*

Main category: cs.CV

TL;DR: EAG3R通过结合点云重建和异步事件流，引入了基于Retinex的图像增强模块和SNR感知融合机制，及基于事件的光度一致性损失，实现了在动态低光照场景下的鲁棒几何估计。


<details>
  <summary>Details</summary>
Motivation: 现有的RGB-only方法在真实世界条件下，尤其是面对动态物体和极端照明时表现不佳。EAG3R通过引入异步事件流解决这些问题，提高在动态低光照场景下的几何估计精度。

Method: EAG3R基于MonST3R骨架，提出了一个Retinex启发的图像增强模块和SNR感知融合机制，以及一个基于事件的光度一致性损失。该方法能在无需夜间数据重新训练的情况下，实现对动态低光场景的几何估计。

Result: 在多种单目深度估计、相机姿态跟踪和动态重建任务中，EAG3R显著优于现有的RGB-only基准方法。

Conclusion: EAG3R在动态低光照环境下的几何估计性能优越，为自主导航、SLAM及3D场景重建等应用提供了新的解决方案。

Abstract: Robust 3D geometry estimation from videos is critical for applications such as autonomous navigation, SLAM, and 3D scene reconstruction. Recent methods like DUSt3R demonstrate that regressing dense pointmaps from image pairs enables accurate and efficient pose-free reconstruction. However, existing RGB-only approaches struggle under real-world conditions involving dynamic objects and extreme illumination, due to the inherent limitations of conventional cameras. In this paper, we propose EAG3R, a novel geometry estimation framework that augments pointmap-based reconstruction with asynchronous event streams. Built upon the MonST3R backbone, EAG3R introduces two key innovations: (1) a retinex-inspired image enhancement module and a lightweight event adapter with SNR-aware fusion mechanism that adaptively combines RGB and event features based on local reliability; and (2) a novel event-based photometric consistency loss that reinforces spatiotemporal coherence during global optimization. Our method enables robust geometry estimation in challenging dynamic low-light scenes without requiring retraining on night-time data. Extensive experiments demonstrate that EAG3R significantly outperforms state-of-the-art RGB-only baselines across monocular depth estimation, camera pose tracking, and dynamic reconstruction tasks.

</details>


### [75] [PolarGS: Polarimetric Cues for Ambiguity-Free Gaussian Splatting with Accurate Geometry Recovery](https://arxiv.org/abs/2512.00794)
*Bo Guo,Sijia Wen,Yifan Zhao,Jia Li,Zhiming Zheng*

Main category: cs.CV

TL;DR: PolarGS 是一种结合了偏振光信息的 3D Gaussian Splatting 方法，通过偏振光特性提高光度学模糊区域的几何重建精度。


<details>
  <summary>Details</summary>
Motivation: 现有 3D Gaussian Splatting 方法在反射和无纹理表面的光度学模糊区域表现不佳，提出 PolarGS 以利用偏振光特性改善这些区域的重建精度。

Method: PolarGS 通过引入光谱导向的光度学修正策略和偏振增强的高斯密集优化机制，实现了对反射区域的识别和高斯球的优化，并通过修正后的模型生成新的高斯球，增强了无纹理区域的几何重建。

Result: PolarGS 相较于现有最先进的方法实现了更优的几何精度。

Conclusion: PolarGS 是一种光学感知的 3DGS 扩展方法，通过利用偏振光特性解决了光度学模糊区域的重建问题。

Abstract: Recent advances in surface reconstruction for 3D Gaussian Splatting (3DGS) have enabled remarkable geometric accuracy. However, their performance degrades in photometrically ambiguous regions such as reflective and textureless surfaces, where unreliable cues disrupt photometric consistency and hinder accurate geometry estimation. Reflected light is often partially polarized in a manner that reveals surface orientation, making polarization an optic complement to photometric cues in resolving such ambiguities. Therefore, we propose PolarGS, an optics-aware extension of RGB-based 3DGS that leverages polarization as an optical prior to resolve photometric ambiguities and enhance reconstruction accuracy. Specifically, we introduce two complementary modules: a polarization-guided photometric correction strategy, which ensures photometric consistency by identifying reflective regions via the Degree of Linear Polarization (DoLP) and refining reflective Gaussians with Color Refinement Maps; and a polarization-enhanced Gaussian densification mechanism for textureless area geometry recovery, which integrates both Angle and Degree of Linear Polarization (A/DoLP) into a PatchMatch-based depth completion process. This enables the back-projection and fusion of new Gaussians, leading to more complete reconstruction. PolarGS is framework-agnostic and achieves superior geometric accuracy compared to state-of-the-art methods.

</details>


### [76] [CircleFlow: Flow-Guided Camera Blur Estimation using a Circle Grid Target](https://arxiv.org/abs/2512.00796)
*Jiajian He,Enjie Hu,Shiqi Chen,Tianchen Qiu,Huajun Feng,Zhihai Xu,Yueting Chen*

Main category: cs.CV

TL;DR: CircleFlow是一种高保真点扩展函数（PSF）估计框架，通过流动引导的边缘定位精确表征模糊，实现了状态-of-the-art的PSF估计精度和可靠性。


<details>
  <summary>Details</summary>
Motivation: 准确的PSF估计对于光学表征和计算视觉非常重要，但由于基于强度的反卷积的固有模糊和不良提出的问题，这仍然具有挑战性。

Method: CircleFlow框架采用流动引导的边缘定位，通过成像圆形网格目标并利用目标的二进制亮度先验，分别估计图像和内核，通过亚像素对齐和光学流指导初始化的二进制结构重建锐化图像，并将PSF建模为能量受限的隐式神经表示。

Result: 在模拟和真实世界数据上的广泛实验表明，CircleFlow达到了最先进的PSF估计精度和可靠性。

Conclusion: 这验证了CircleFlow在实际PSF校准方面的有效性。

Abstract: The point spread function (PSF) serves as a fundamental descriptor linking the real-world scene to the captured signal, manifesting as camera blur. Accurate PSF estimation is crucial for both optical characterization and computational vision, yet remains challenging due to the inherent ambiguity and the ill-posed nature of intensity-based deconvolution. We introduce CircleFlow, a high-fidelity PSF estimation framework that employs flow-guided edge localization for precise blur characterization. CircleFlow begins with a structured capture that encodes locally anisotropic and spatially varying PSFs by imaging a circle grid target, while leveraging the target's binary luminance prior to decouple image and kernel estimation. The latent sharp image is then reconstructed through subpixel alignment of an initialized binary structure guided by optical flow, whereas the PSF is modeled as an energy-constrained implicit neural representation. Both components are jointly optimized within a demosaicing-aware differentiable framework, ensuring physically consistent and robust PSF estimation enabled by accurate edge localization. Extensive experiments on simulated and real-world data demonstrate that CircleFlow achieves state-of-the-art accuracy and reliability, validating its effectiveness for practical PSF calibration.

</details>


### [77] [Thinking with Drafts: Speculative Temporal Reasoning for Efficient Long Video Understanding](https://arxiv.org/abs/2512.00805)
*Pengfei Hu,Meng Cao,Yingyao Wang,Yi Wang,Jiahua Dong,Jun Song,Yu Cheng,Bo Zheng,Xiaodan Liang*

Main category: cs.CV

TL;DR: 本文提出了一种名为SpecTemp的启发式推理框架，通过解耦时间和推理，使用协作的双模型设计实现了长时间视频理解，提高了效率并保持了准确性。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有框架中多模态上下文逐步增长和冗余导致的效率瓶颈，本文旨在提高长视频理解的能力和效率。

Method: 该方法采用了强化学习为基础的Speculative Temporal推理框架。它包含一个轻量级的草图多模态大型语言模型（MLLM），快速探索并建议关键帧，以及一个强大的目标MLLM，专注于时间推理和验证草图的建议，此过程迭代直到收敛。同时，作者构建了SpecTemp-80K数据集，提供同步的双层次注解以支持训练。

Result: 实验表明，SpecTemp不仅在多个视频理解基准上保持了竞争力，还在推理速度方面大幅超越了现有的以帧为中心的推理方法。

Conclusion: 本文提出的方法SpecTemp能够有效提高长视频理解的效率和精度，为未来的视频理解研究提供了新的视角。

Abstract: Long video understanding is essential for human-like intelligence, enabling coherent perception and reasoning over extended temporal contexts. While the emerging thinking-with-frames paradigm, which alternates between global temporal reasoning and local frame examination, has advanced the reasoning capabilities of video multi-modal large language models (MLLMs), it suffers from a significant efficiency bottleneck due to the progressively growing and redundant multi-modal context. To address this, we propose SpecTemp, a reinforcement learning-based Speculative Temporal reasoning framework that decouples temporal perception from reasoning via a cooperative dual-model design. In SpecTemp, a lightweight draft MLLM rapidly explores and proposes salient frames from densely sampled temporal regions, while a powerful target MLLM focuses on temporal reasoning and verifies the draft's proposals, iteratively refining its attention until convergence. This design mirrors the collaborative pathways of the human brain, balancing efficiency with accuracy. To support training, we construct the SpecTemp-80K dataset, featuring synchronized dual-level annotations for coarse evidence spans and fine-grained frame-level evidence. Experiments across multiple video understanding benchmarks demonstrate that SpecTemp not only maintains competitive accuracy but also significantly accelerates inference compared with existing thinking-with-frames methods.

</details>


### [78] [IRPO: Boosting Image Restoration via Post-training GRPO](https://arxiv.org/abs/2512.00814)
*Haoxuan Xu. Yi Liu,Boyuan Jiang,Jinlong Peng,Donghao Luo,Xiaobin Hu,Shuicheng Yan,Haoang Li*

Main category: cs.CV

TL;DR: 本文提出了一种名为IRPO的方法，它基于低级GRPO后训练范式，系统地探索了数据公式化和奖励建模。IRPO通过选择预训练阶段的低表现样本来优化性能，并引入了结构一致性、感知对齐和任务特定的恢复奖励来平衡目标准确性和人类感知偏好。实验结果表明，IRPO在多种退化类型上超越了AdaIR基线。


<details>
  <summary>Details</summary>
Motivation: 现有的图像修复方法依赖于像素级的精确匹配，这导致了过度平滑和泛化能力差的问题。本文旨在探索低级图像修复的方法，以解决这些问题。

Method: IRPO方法首先通过预训练阶段选择低表现样本来优化数据公式化，并且引入了三种互补的奖励组件：通用奖励（结构一致性）、专家奖励（基于Qwen-VL的感知对齐）和恢复奖励（任务特定的低级质量）来建模奖励条件。

Result: 通过全面的实验，IRPO在六个在域和五个跨域的低级基准上实现了最先进的结果，尤其是在跨域设置上比AdaIR基线高出3.43 dB。

Conclusion: 本文提出的方法IRPO展示了在低级图像修复任务上的优越性能，并为该领域的进一步研究提供了新的视角。

Abstract: Recent advances in post-training paradigms have achieved remarkable success in high-level generation tasks, yet their potential for low-level vision remains rarely explored. Existing image restoration (IR) methods rely on pixel-level hard-fitting to ground-truth images, struggling with over-smoothing and poor generalization. To address these limitations, we propose IRPO, a low-level GRPO-based post-training paradigm that systematically explores both data formulation and reward modeling. We first explore a data formulation principle for low-level post-training paradigm, in which selecting underperforming samples from the pre-training stage yields optimal performance and improved efficiency. Furthermore, we model a reward-level criteria system that balances objective accuracy and human perceptual preference through three complementary components: a General Reward for structural fidelity, an Expert Reward leveraging Qwen-VL for perceptual alignment, and a Restoration Reward for task-specific low-level quality. Comprehensive experiments on six in-domain and five out-of-domain (OOD) low-level benchmarks demonstrate that IRPO achieves state-of-the-art results across diverse degradation types, surpassing the AdaIR baseline by 0.83 dB on in-domain tasks and 3.43 dB on OOD settings. Our code can be shown in https://github.com/HaoxuanXU1024/IRPO.

</details>


### [79] [PanFlow: Decoupled Motion Control for Panoramic Video Generation](https://arxiv.org/abs/2512.00832)
*Cheng Zhang,Hanwen Liang,Donny Y. Chen,Qianyi Wu,Konstantinos N. Plataniotis,Camilo Cruz Gambardella,Jianfei Cai*

Main category: cs.CV

TL;DR: PanFlow 是一种新颖的方法，利用全景图的球形特性解耦了高动态的相机旋转和输入的光学流条件，从而更精确地控制大规模和动态的运动，并通过球形噪声扭曲策略促进全景边界上运动的循环一致性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在全景视频生成中缺乏对运动的明确控制，并难以生成具有大规模和复杂运动的场景。

Method: PanFlow 方法通过利用全景图的球面属性分解相机的高动态旋转和输入的光学流条件，同时引入球面噪声扭曲策略以提高跨全景边界运动的一致性。

Result: PanFlow 在多种应用中展示了其效果，包括运动转移和视频编辑。广泛实验表明，该方法在运动保真度、视觉质量以及时间连贯性方面均优于以往的方法。

Conclusion: PanFlow 通过创建一个大规模且富含动作的全景视频数据集并提供代码和模型，展示了其在全景视频生成方面的显著改进。

Abstract: Panoramic video generation has attracted growing attention due to its applications in virtual reality and immersive media. However, existing methods lack explicit motion control and struggle to generate scenes with large and complex motions. We propose PanFlow, a novel approach that exploits the spherical nature of panoramas to decouple the highly dynamic camera rotation from the input optical flow condition, enabling more precise control over large and dynamic motions. We further introduce a spherical noise warping strategy to promote loop consistency in motion across panorama boundaries. To support effective training, we curate a large-scale, motion-rich panoramic video dataset with frame-level pose and flow annotations. We also showcase the effectiveness of our method in various applications, including motion transfer and video editing. Extensive experiments demonstrate that PanFlow significantly outperforms prior methods in motion fidelity, visual quality, and temporal coherence. Our code, dataset, and models are available at https://github.com/chengzhag/PanFlow.

</details>


### [80] [AFRAgent : An Adaptive Feature Renormalization Based High Resolution Aware GUI agent](https://arxiv.org/abs/2512.00846)
*Neeraj Anand,Rishabh Jain,Sohan Patnaik,Balaji Krishnamurthy,Mausoom Sarkar*

Main category: cs.CV

TL;DR: 本文介绍了一种基于 instruct-BLIP 的多模态架构 AFRAgent，能够在 GUI 自动化方面实现卓越性能，同时体积仅为最接近竞品的四分之一。通过引入一种有效的图像嵌入增强技术，AFRAgent 在 Meta-GUI 和 AITW 基准测试中取得了领先性能，建立了一个新的基准。


<details>
  <summary>Details</summary>
Motivation: 针对现有视觉语言模型在 GUI 自动化中的准确性与模型规模之间的矛盾，提出了一种新的多模态架构 AFRAgent，旨在提高自动化性能同时减小模型规模。

Method: AFRAgent 架构基于 instruct-BLIP，通过引入一种新的图像嵌入增强技术——适应性特征再规范化，从 token 级别执行仿射变换，以提升低分辨率图像嵌入并融合高分辨率细节。

Result: AFRAgent 在 Meta-GUI 和 AITW 基准测试中取得了一流的自动化性能，并且模型体积仅为最接近竞品的四分之一。

Conclusion: 本文提出的方法在 GUI 自动化领域取得突破，不仅提高了自动化流程的准确性和效率，还有效减小了模型规模，有望推动移动用户界面自动化技术的发展。

Abstract: There is a growing demand for mobile user interface (UI) automation, driven by its broad applications across industries. With the advent of visual language models (VLMs), GUI automation has progressed from generating text-based instructions for humans to autonomously executing tasks, thus optimizing automation workflows. Recent approaches leverage VLMs for this problem due to their ability to 1) process on-screen content directly, 2) remain independent of device-specific APIs by utilizing human actions (e.g., clicks, typing), and 3) apply real-world contextual knowledge for task understanding. However, these models often have trouble accurately identifying widgets and determining actions due to limited spatial information in vision encoder features. Additionally, top-performing models are often large, requiring extensive training and resulting in inference delays. In this work, we introduce AFRAgent, an instruct-BLIP-based multimodal architecture that achieves superior performance in GUI automation while being less than one-fourth the size of its nearest competitor. To enhance image embeddings in the large language model (LLM) pipeline, we propose an adaptive feature renormalization-based (a token-level affine transformation) technique that effectively enriches low-resolution image embeddings and fuses high-resolution details. We evaluate AFRAgent on Meta-GUI and AITW benchmarks, establishing a new state-of-the-art baseline for smartphone automation.

</details>


### [81] [Smol-GS: Compact Representations for Abstract 3D Gaussian Splatting](https://arxiv.org/abs/2512.00850)
*Haishan Wang,Mohammad Hassan Vali,Arno Solin*

Main category: cs.CV

TL;DR: Smol-GS 是一个新颖的3D Gaussian Splatting 方法，通过结合空间和语义信息高效压缩3D场景，同时保持高渲染质量，适用于下游任务如导航、规划和更广泛的3D场景理解。


<details>
  <summary>Details</summary>
Motivation: 随着3D数据量的快速增长，高效压缩和表示3D场景成为一个重要的研究方向。Smol-GS通过引入新颖的编码方法，旨在减轻3D数据存储和处理的负担。

Method: Smol-GS 设计了三个关键功能：1) 递归体素层次结构用于捕捉点云坐标；2) 拉普拉斯特征存储抽象化的视觉与形状信息；3) 存储颜色、透明度、变换和材料属性以表示Splat特征。

Result: Smol-GS 能够使3D场景压缩达到数量级的效果，同时在标准基准测试中保持高渲染质量。

Conclusion: Smol-GS 通过集成高效的稀疏表示和语义信息的有效编码，解决了3D数据压缩的问题，并展现了在视觉保真的基础上，离散表示适用于下游任务的巨大潜力。

Abstract: We present Smol-GS, a novel method for learning compact representations for 3D Gaussian Splatting (3DGS). Our approach learns highly efficient encodings in 3D space that integrate both spatial and semantic information. The model captures the coordinates of the splats through a recursive voxel hierarchy, while splat-wise features store abstracted cues, including color, opacity, transformation, and material properties. This design allows the model to compress 3D scenes by orders of magnitude without loss of flexibility. Smol-GS achieves state-of-the-art compression on standard benchmarks while maintaining high rendering quality. Beyond visual fidelity, the discrete representations could potentially serve as a foundation for downstream tasks such as navigation, planning, and broader 3D scene understanding.

</details>


### [82] [TAP-CT: 3D Task-Agnostic Pretraining of Computed Tomography Foundation Models](https://arxiv.org/abs/2512.00872)
*Tim Veenboer,George Yiasemis,Eric Marcus,Vivien Van Veldhuizen,Cees G. M. Snoek,Jonas Teuwen,Kevin B. W. Groot Lipman*

Main category: cs.CV

TL;DR: TAP-CT是一种针对CT数据的自监督预训练方法，采用Vision Transformers和DINOv2进行大规模3D预训练，能够提供稳定、鲁棒的表示，且对于下游任务具有广泛的通用性。


<details>
  <summary>Details</summary>
Motivation: 现有的医学基础模型往往需要大量的微调或依赖于资源密集型的解码器，而许多现有的编码器则是通过偏移特定任务的目标进行预训练的。因此，需要一种在任务上不依赖于具体任务、需要最少微调的基础模型。

Method: TAP-CT方法采用了Vision Transformers（ViTs）和DINOv2为CT数据构建自监督预训练方法。对该模型进行了特定修改，包括对块嵌入、位置编码以及体数据增强做了调整，使得深度感知的同时保持了结构的简洁。

Result: 在大规模3D CT数据集（105,000个体素）上进行预训练后，TAP-CT能够产生稳定的、鲁棒的预冻结表示，这些表示在下游任务上具有良好的通用性。

Conclusion: TAP-CT提供了一种简单的且高效的方法来构建跨模态、通用的基础模型，并为未来医学成像领域的研究提供了低资源强度的基准。

Abstract: Existing foundation models (FMs) in the medical domain often require extensive fine-tuning or rely on training resource-intensive decoders, while many existing encoders are pretrained with objectives biased toward specific tasks. This illustrates a need for a strong, task-agnostic foundation model that requires minimal fine-tuning beyond feature extraction. In this work, we introduce a suite of task-agnostic pretraining of CT foundation models (TAP-CT): a simple yet effective adaptation of Vision Transformers (ViTs) and DINOv2 for volumetric data, enabling scalable self-supervised pretraining directly on 3D CT volumes. Our approach incorporates targeted modifications to patch embeddings, positional encodings, and volumetric augmentations, making the architecture depth-aware while preserving the simplicity of the underlying architectures. We show that large-scale 3D pretraining on an extensive in-house CT dataset (105K volumes) yields stable, robust frozen representations that generalize strongly across downstream tasks. To promote transparency and reproducibility, and to establish a powerful, low-resource baseline for future research in medical imaging, we will release all pretrained models, experimental configurations, and downstream benchmark code at https://huggingface.co/fomofo/tap-ct-b-3d.

</details>


### [83] [Neural Discrete Representation Learning for Sparse-View CBCT Reconstruction: From Algorithm Design to Prospective Multicenter Clinical Evaluation](https://arxiv.org/abs/2512.00873)
*Haoshen Wang,Lei Chen,Wei-Hua Zhang,Linxia Wu,Yong Luo,Zengmao Wang,Yuan Xiong,Chengcheng Zhu,Wenjuan Tang,Xueyi Zhang,Wei Zhou,Xuhua Duan,Lefei Zhang,Gao-Jun Teng,Bo Du,Huangxuan Zhao*

Main category: cs.CV

TL;DR: 本文提出了一种名为 DeepPriorCBCT 的深度学习框架，使用传统的六分之一辐射剂量实现与标准重建算法相当的诊断质量和图像质量，半量的数据采集大大降低了手术过程中辐射风险，同时通过医疗机构的评估证实了其临床应用的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的 CBCT 诊断方法在提高早期或中期胸腔肿瘤诊断和治疗效率的同时，会增加患者因辐射导致二次恶性肿瘤的风险。因此，研究提出了一种低剂量 CBCT 重建方法来减少辐射风险。

Method: 研究采用了深度学习技术开发了一种能够提高图像质量的低剂量 CBCT 框架 DeepPriorCBCT。该方法通过三个阶段训练模型，使用较少的原始数据重构高质量的 CBCT 图像。同时，在多中心、多期临床试验中验证了模型的有效性。

Result: 在包含 4102 名患者 8675 次 CBCT 扫描的分割验证集上，DeepPriorCBCT 的诊断性能和整体图像质量与标准重建算法相当。在回顾性和前瞻性研究中，11 名医学专家和 25 名介入医师均认可重建图像的质量，而辐射暴露量则显著减少。

Conclusion: DeepPriorCBCT 为低剂量 CBCT 重建树立了新标准，有效降低了辐射风险并保证了诊断的准确性，在多中心和前瞻性临床试验中被证明具有良好的临床应用前景。

Abstract: Cone beam computed tomography (CBCT)-guided puncture has become an established approach for diagnosing and treating early- to mid-stage thoracic tumours, yet the associated radiation exposure substantially elevates the risk of secondary malignancies. Although multiple low-dose CBCT strategies have been introduced, none have undergone validation using large-scale multicenter retrospective datasets, and prospective clinical evaluation remains lacking. Here, we propose DeepPriorCBCT - a three-stage deep learning framework that achieves diagnostic-grade reconstruction using only one-sixth of the conventional radiation dose. 4102 patients with 8675 CBCT scans from 12 centers were included to develop and validate DeepPriorCBCT. Additionally, a prospective cross-over trial (Registry number: NCT07035977) which recruited 138 patients scheduled for percutaneous thoracic puncture was conducted to assess the model's clinical applicability. Assessment by 11 physicians confirmed that reconstructed images were indistinguishable from original scans. Moreover, diagnostic performance and overall image quality were comparable to those generated by standard reconstruction algorithms. In the prospective trial, five radiologists reported no significant differences in image quality or lesion assessment between DeepPriorCBCT and the clinical standard (all P>0.05). Likewise, 25 interventionalists expressed no preference between model-based and full-sampling images for surgical guidance (Kappa<0.2). Radiation exposure with DeepPriorCBCT was reduced to approximately one-sixth of that with the conventional approach, and collectively, the findings confirm that it enables high-quality CBCT reconstruction under sparse sampling conditions while markedly decreasing intraoperative radiation risk.

</details>


### [84] [Feed-Forward 3D Gaussian Splatting Compression with Long-Context Modeling](https://arxiv.org/abs/2512.00877)
*Zhening Liu,Rui Song,Yushi Huang,Yingdong Hu,Xinjie Zhang,Jiawei Shao,Zehong Lin,Jun Zhang*

Main category: cs.CV

TL;DR: 提出了一个新颖的端到端3DGS压缩框架，该框架通过大规模包含数千个基于莫兰序列的高斯函数的上下文结构，以及细粒度的空间-通道自回归熵模型和基于注意力的变换编码模型，实现了高效压缩和广泛适用的3D表示。


<details>
  <summary>Details</summary>
Motivation: 现有的3DGS压缩方法在处理大规模数据时表现不佳，因为它们难以建模长距离的空间依赖关系，这限制了3DGS在实际应用中的推广。

Method: 提出了一种全新的端到端3DGS压缩框架，包括大规模上下文结构、细粒度的空间-通道自回归熵模型和基于注意力的变换编码模型。

Result: 该方法实现了20倍的3DGS压缩比，并在所有可推广的编解码器中达到了最先进的性能。

Conclusion: 本文提出的方法为3D数据的有效压缩和广泛应用提供了一种新的解决方案。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a revolutionary 3D representation. However, its substantial data size poses a major barrier to widespread adoption. While feed-forward 3DGS compression offers a practical alternative to costly per-scene per-train compressors, existing methods struggle to model long-range spatial dependencies, due to the limited receptive field of transform coding networks and the inadequate context capacity in entropy models. In this work, we propose a novel feed-forward 3DGS compression framework that effectively models long-range correlations to enable highly compact and generalizable 3D representations. Central to our approach is a large-scale context structure that comprises thousands of Gaussians based on Morton serialization. We then design a fine-grained space-channel auto-regressive entropy model to fully leverage this expansive context. Furthermore, we develop an attention-based transform coding model to extract informative latent priors by aggregating features from a wide range of neighboring Gaussians. Our method yields a $20\times$ compression ratio for 3DGS in a feed-forward inference and achieves state-of-the-art performance among generalizable codecs.

</details>


### [85] [Quantum-Inspired Spectral Geometry for Neural Operator Equivalence and Structured Pruning](https://arxiv.org/abs/2512.00880)
*Haijian Shao,Wei Liu,Xing Deng*

Main category: cs.CV

TL;DR: 该研究提出了一种量子启发的几何框架，用于表示神经运算符，并建立了跨模态与跨架构运算符可替代性的严格基础。


<details>
  <summary>Details</summary>
Motivation: 解决资源受限和异构的家用硬件上快速发展的多模态智能所面临的瓶颈问题，包括多模态特征异质性、动态场景下实时要求以及硬件特定操作冗余。

Method: 研究引入了一种在Bloch超球体上以归一化奇异值谱表示每个运算符的量子启发的几何框架，并证明了谱到功能等价定理，基于该定理提出了量子度量驱动的功能冗余图和一次完成结构剪枝方法。

Result: 研究证明了所提度量在控制模拟中优于幅度和随机基线，并计划在大规模多模态变压器和家用异构硬件上进行广泛实验验证。

Conclusion: 研究为跨模态和跨架构运算符可替代性奠定了严格的理论基础，并展示了其在多模态和异构硬件环境中的潜在应用潜力。

Abstract: The rapid growth of multimodal intelligence on resource-constrained and heterogeneous domestic hardware exposes critical bottlenecks: multimodal feature heterogeneity, real-time requirements in dynamic scenarios, and hardware-specific operator redundancy. This work introduces a quantum-inspired geometric framework for neural operators that represents each operator by its normalized singular value spectrum on the Bloch hypersphere. We prove a tight spectral-to-functional equivalence theorem showing that vanishing Fubini--Study/Wasserstein-2 distance implies provable functional closeness, establishing the first rigorous foundation for cross-modal and cross-architecture operator substitutability. Based on this metric, we propose Quantum Metric-Driven Functional Redundancy Graphs (QM-FRG) and one-shot structured pruning. Controlled simulation validates the superiority of the proposed metric over magnitude and random baselines. An extensive experimental validation on large-scale multimodal transformers and domestic heterogeneous hardware (Huawei Ascend, Cambricon MLU, Kunlunxin) hardware is deferred to an extended journal version currently in preparation.

</details>


### [86] [Look, Recite, Then Answer: Enhancing VLM Performance via Self-Generated Knowledge Hints](https://arxiv.org/abs/2512.00882)
*Xisheng Feng*

Main category: cs.CV

TL;DR: 该研究提出了一种参数高效框架 'Look, Recite, Then Answer'，旨在通过自动生成的知识提示增强视觉-语言模型(VLMs)，特别是在专门领域如精准农业中表现出显著效果，提高了杂草识别的准确性。


<details>
  <summary>Details</summary>
Motivation: 当前VLMs在特定领域如精准农业中表现受限于视觉感知和语言先验之间的'原因驱动式幻觉'问题，本文通过减少视觉嵌入和专家知识之间的差异来克服这一瓶颈。

Method: 该方法将推理过程分为三个阶段：Look，生成客观的视觉描述和候选集；Recite，利用轻量级路由器将视觉提示转化为针对性查询以触发特定候选的知识；Answer，对描述和知识提示进行并行对齐以选择最一致的标识。

Result: 在AgroBench数据集上，该方法超过了GPT-4o和Qwen-VL等模型，特别是在杂草识别任务上提高了23.6%的准确性。

Conclusion: 该研究提出的方法通过模块化设计有效减少了视觉-语言模型中的幻觉现象，提高了模型在准确农业领域的应用性能。

Abstract: Vision-Language Models (VLMs) exhibit significant performance plateaus in specialized domains like precision agriculture, primarily due to "Reasoning-Driven Hallucination" where linguistic priors override visual perception. A key bottleneck is the "Modality Gap": visual embeddings fail to reliably activate the fine-grained expert knowledge already encoded in model parameters. We propose "Look, Recite, Then Answer," a parameter-efficient framework that enhances VLMs via self-generated knowledge hints while keeping backbone models frozen. The framework decouples inference into three stages: (1) Look generates objective visual descriptions and candidate sets; (2) Recite employs a lightweight 1.7B router to transform visual cues into targeted queries that trigger candidate-specific parametric knowledge; (3) Answer performs parallel evidence alignment between descriptions and recited knowledge to select the most consistent label. On AgroBench, our method achieves state-of-the-art results, improving Weed Identification accuracy by 23.6% over Qwen-VL and surpassing GPT-4o without external search overhead. This modular design mitigates hallucinations by transforming passive perception into active, controllable knowledge retrieval

</details>


### [87] [HanDyVQA: A Video QA Benchmark for Fine-Grained Hand-Object Interaction Dynamics](https://arxiv.org/abs/2512.00885)
*Masatoshi Tateno,Gido Kato,Hirokatsu Kataoka,Yoichi Sato,Takuma Yagi*

Main category: cs.CV

TL;DR: HanDyVQA 是一个细粒度的视频问答基准，全面涵盖了 HOI 中的操作和效果方面，包含多种问题类型和大量的问答对，能够在视频对象分割中评估物体/部件级别的推理。


<details>
  <summary>Details</summary>
Motivation: 现有基准在捕捉 HOI 下的操作动态性方面存在缺陷，HanDyVQA 的目的是提供一个更全面、细粒度的平台，来了解和研究 HOI 中的人手操作和其产生的效果。

Method: 通过创建一个包含六种互补问题类型的基准（操作、过程、对象、位置、状态变化、物体部分），以及超过 11.1K 的多项选择问答对，和 10.3K 的分割掩码，HanDyVQA 分别从识别操作风格、手/物体动作以及部件级别状态变化等角度来收集和提供数据。同时，还通过不同视频基础模型的测试，以及特定提示嵌入视觉特征的方法展示了对 HOI 动态更深层次理解的重要性。

Result: 最新的视频基础模型在 HanDyVQA 上的表现仅达到 73% 的平均准确性，远低于人类表现（97%）。此外，研究发现空间关系、运动理解以及部件级别的几何理解是需要改进之处。并且，将与 HOI 相关的明显提示嵌入到视觉特征中提高了模型的性能。

Conclusion: HanDyVQA 是一个强大的基准，能够推动对 HOI 中的动态进行更细粒度和全面的理解，为未来模型开发提供了有价值的线索和指导。

Abstract: Hand-object interaction (HOI) inherently involves dynamics where human manipulations produce distinct spatio-temporal effects on objects. However, existing semantic HOI benchmarks focused either on manipulation or on the resulting effects at a coarse level, lacking fine-grained spatio-temporal reasoning to capture the underlying dynamics in HOI. We introduce HanDyVQA, a fine-grained video question-answering benchmark that comprehensively covers both the manipulation and effect aspects of HOI. HanDyVQA comprises six complementary question types (Action, Process, Objects, Location, State Change, and Object Parts), totalling 11.1K multiple-choice QA pairs. Collected QA pairs recognizing manipulation styles, hand/object motions, and part-level state changes. HanDyVQA also includes 10.3K segmentation masks for Objects and Object Parts questions, enabling the evaluation of object/part-level reasoning in video object segmentation. We evaluated recent video foundation models on our benchmark and found that even the best-performing model, Gemini-2.5-Pro, reached only 73% average accuracy, which is far from human performance (97%). Further analysis shows the remaining challenges in spatial relationship, motion, and part-level geometric understanding. We also found that integrating explicit HOI-related cues into visual features improves performance, offering insights for developing future models with a deeper understanding of HOI dynamics.

</details>


### [88] [Multilingual Training-Free Remote Sensing Image Captioning](https://arxiv.org/abs/2512.00887)
*Carlos Rebelo,Gil Rocha,João Daniel Silva,Bruno Martins*

Main category: cs.CV

TL;DR: 本文提出了一种基于检索增强提示的无训练多语言图像字幕方法，该方法利用领域适配的SigLIP2编码器从数据存储中检索相关字幕和示例，并提供给语言模型。实验表明，该方法在多个基准数据集上的表现与全监督的英语系统具有竞争力，并且随着重新排序策略的应用，性能进一步提升。


<details>
  <summary>Details</summary>
Motivation: 当前的远程 sensing 图像字幕方法依赖于大规模标注数据集，且主要关注英语，限制了其全球适用性。为了克服这些局限，本文提出了一种无训练的多语言图像字幕方法，旨在提高字幕的多样性并增加对其他语言的支持。

Method: 利用领域适配的SigLIP2编码器检索相关字幕和示例，并结合图基于的重新排序策略，使用多模态模型（VLM）或仅基于文本提示的语言模型（LLM）生成字幕。

Result: 在四个基准数据集上的实验表明，该方法在多语言场景下的性能与全监督的英语系统具有竞争力，尤其是在应用图基于的重新排序策略后，性能提升显著。此外，VLM生成的字幕更贴近视觉内容但词汇多样性更高，而LLM则在BLEU和CIDEr指标上表现更好。直接在目标语言中生成字幕策略的性能优于其他翻译策略。

Conclusion: 本文的文化考核了一种无训练的多语言远程 sensing 图像字幕方法，展示了其在不同语言环境下的应用潜力，并探讨了不同模型的生成特点，为未来的远程 sensing 图像字幕系统开发提供了新的思路。

Abstract: Remote sensing image captioning has advanced rapidly through encoder--decoder models, although the reliance on large annotated datasets and the focus on English restricts global applicability. To address these limitations, we propose the first training-free multilingual approach, based on retrieval-augmented prompting. For a given aerial image, we employ a domain-adapted SigLIP2 encoder to retrieve related captions and few-shot examples from a datastore, which are then provided to a language model. We explore two variants: an image-blind setup, where a multilingual Large Language Model (LLM) generates the caption from textual prompts alone, and an image-aware setup, where a Vision--Language Model (VLM) jointly processes the prompt and the input image. To improve the coherence of the retrieved content, we introduce a graph-based re-ranking strategy using PageRank on a graph of images and captions. Experiments on four benchmark datasets across ten languages demonstrate that our approach is competitive with fully supervised English-only systems and generalizes to other languages. Results also highlight the importance of re-ranking with PageRank, yielding up to 35% improvements in performance metrics. Additionally, it was observed that while VLMs tend to generate visually grounded but lexically diverse captions, LLMs can achieve stronger BLEU and CIDEr scores. Lastly, directly generating captions in the target language consistently outperforms other translation-based strategies. Overall, our work delivers one of the first systematic evaluations of multilingual, training-free captioning for remote sensing imagery, advancing toward more inclusive and scalable multimodal Earth observation systems.

</details>


### [89] [Accelerating Streaming Video Large Language Models via Hierarchical Token Compression](https://arxiv.org/abs/2512.00891)
*Yiyu Wang,Xuyang Liu,Xiyan Gui,Xinying Lin,Boxue Yang,Chenfei Liao,Tailai Chen,Linfeng Zhang*

Main category: cs.CV

TL;DR: 本研究提出了STC框架，通过STC-Cacher和STC-Pruner两种加速器减少ViT编码和LLM预填充阶段的冗余计算，显著提高了实时视频处理效率，同时几乎不损失准确率。


<details>
  <summary>Details</summary>
Motivation: 现有视频大语言模型（VideoLLMs）在实时部署中受到高计算成本的影响，尤其是在Vision Transformer（ViT）编码阶段，由于处理连续视频流中的冗余帧，导致效率低下。此外，LLM预填充阶段的视觉标记序列膨胀进一步增加了延迟和内存开销。为此，研究提出了一种名为STC的插件式层级框架，旨在优化ViT编码和LLM预填充阶段。

Method: STC采用两级加速策略：STC-Cacher通过缓存和重复利用相似帧的特征减少ViT编码的计算负担；STC-Pruner在视觉标记进入LLM前进行压缩，并根据空间和时间的相关性保留最显著的标记。

Result: 在四个基线的实时视频LLM模型上进行的广泛实验中，STC表现出色。它不仅显著改善了ViT编码和LLM预填充的延迟，还在ReKV框架上保持了高达99%的准确性。

Conclusion: 研究成果证明，STC是一种高效且灵活的解决方案，能够提高VideoLLM在实时视频处理中的性能，并在广泛的基准测试中展现出优势。

Abstract: Streaming Video Large Language Models (VideoLLMs) have demonstrated impressive performance across various video understanding tasks, but they face significant challenges in real-time deployment due to the high computational cost of processing dense visual tokens from continuous video streams. In streaming video scenarios, the primary bottleneck lies in the Vision Transformer (ViT) encoding stage, where redundant processing of temporally similar frames leads to inefficiency. Additionally, inflated token sequences during LLM pre-filling further exacerbate latency and memory overhead. To address these challenges, we propose \textbf{S}treaming \textbf{T}oken \textbf{C}ompression (\textbf{STC}), a plug-and-play hierarchical framework that seamlessly integrates into existing streaming VideoLLMs, optimizing both ViT encoding and LLM pre-filling stages to accelerate processing. STC introduces two token-level accelerators: \textbf{STC-Cacher}, which reduces ViT encoding overhead by caching and reusing features from temporally similar frames, and \textbf{STC-Pruner}, which compresses the visual token sequence before it enters the LLM, preserving only the most salient tokens based on both spatial and temporal relevance. Extensive experiments on four baseline streaming VideoLLMs across five benchmarks demonstrate that STC outperforms other compression methods. Notably, STC retains up to \textbf{99\%} of accuracy on the ReKV framework while reducing ViT encoding latency and LLM pre-filling latency by \textbf{24.5\%} and \textbf{45.3\%}.

</details>


### [90] [SwiftVLA: Unlocking Spatiotemporal Dynamics for Lightweight VLA Models at Minimal Overhead](https://arxiv.org/abs/2512.00903)
*Chaojun Ni,Cheng Chen,Xiaofeng Wang,Zheng Zhu,Wenzhao Zheng,Boyuan Wang,Tianrun Chen,Guosheng Zhao,Haoyun Li,Zhehao Dong,Qiang Zhang,Yun Ye,Yang Wang,Guan Huang,Wenjun Mei*

Main category: cs.CV

TL;DR: SwiftVLA 提出了一种基于紧凑预训练 4D 视觉几何变换器的设计，结合了 Fusion Tokens 和掩码重建策略，以增强 VLM 的时空推理能力，最终在不损失性能的情况下，实现了模型轻量化和高效运行。


<details>
  <summary>Details</summary>
Motivation: 现有 VLA 模型参数量巨大，SwiftVLA 起源于减少模型大小和提高效率的需求。

Method: 提出了一种包含预训练4D视觉几何变换器、Fusion Tokens及掩码重建策略的 SwiftVLA 架构，提升时空推理能力。

Result: 实验结果显示 SwiftVLA 在保持性能的同时，实现了比基准模型小得多的模型，运行速度快且内存消耗少。

Conclusion: SwiftVLA 通过引入 4D 视觉几何变换器、Fusion Tokens 和掩码重建策略，有效提升了 VLA 模型的时空理解能力，使其在边缘设备上运行更高效。

Abstract: Vision-Language-Action (VLA) models built on pretrained Vision-Language Models (VLMs) show strong potential but are limited in practicality due to their large parameter counts. To mitigate this issue, using a lightweight VLM has been explored, but it compromises spatiotemporal reasoning. Although some methods suggest that incorporating additional 3D inputs can help, they usually rely on large VLMs to fuse 3D and 2D inputs and still lack temporal understanding. Therefore, we propose SwiftVLA, an architecture that enhances a compact model with 4D understanding while preserving design efficiency. Specifically, our approach features a pretrained 4D visual geometry transformer with a temporal cache that extracts 4D features from 2D images. Then, to enhance the VLM's ability to exploit both 2D images and 4D features, we introduce Fusion Tokens, a set of learnable tokens trained with a future prediction objective to generate unified representations for action generation. Finally, we introduce a mask-and-reconstruct strategy that masks 4D inputs to the VLM and trains the VLA to reconstruct them, enabling the VLM to learn effective 4D representations and allowing the 4D branch to be dropped at inference with minimal performance loss. Experiments in real and simulated environments show that SwiftVLA outperforms lightweight baselines and rivals VLAs up to 7 times larger, achieving comparable performance on edge devices while being 18 times faster and reducing memory footprint by 12 times.

</details>


### [91] [Hierarchical Semantic Alignment for Image Clustering](https://arxiv.org/abs/2512.00904)
*Xingyu Zhu,Beier Zhu,Yunfan Li,Junfeng Fang,Shuo Wang,Kesen Zhao,Hanwang Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种名为CAE的层次语义对齐方法，通过语义空间对齐将图像特征与选择的名词和描述通过最佳传输进行对齐，以实现无训练的图像聚类性能提升。


<details>
  <summary>Details</summary>
Motivation: 当前方法忽视了名词的固有歧义性，可能导致语义表示不准确并降低聚类质量。本文旨在通过引入层次语义对齐方法来解决这一问题，改善无训练情况下的聚类性能。

Method: 本文方法首先从WordNet选择相关名词，并从描述数据集中获取描述，构建一个与图像特征对齐的语义空间。然后，通过最优传输使图像特征与选择的名词和描述对齐，以获得更具区分性的语义空间。最后，将增强后的语义和图像特征结合起来进行聚类。

Result: 在8个数据集上的实验表明，本文方法的有效性，特别是在ImageNet-1K数据集上，无训练的准确性提高了4.2%，调整后的兰德指数（ARI）提高了2.9%。

Conclusion: 本文提出的方法能够在无训练的情况下显著改进图像聚类性能，通过引入多层次的语义对齐方法提出了新的视角，证明了其有效性和优势。

Abstract: Image clustering is a classic problem in computer vision, which categorizes images into different groups. Recent studies utilize nouns as external semantic knowledge to improve clus- tering performance. However, these methods often overlook the inherent ambiguity of nouns, which can distort semantic representations and degrade clustering quality. To address this issue, we propose a hierarChical semAntic alignmEnt method for image clustering, dubbed CAE, which improves cluster- ing performance in a training-free manner. In our approach, we incorporate two complementary types of textual seman- tics: caption-level descriptions, which convey fine-grained attributes of image content, and noun-level concepts, which represent high-level object categories. We first select relevant nouns from WordNet and descriptions from caption datasets to construct a semantic space aligned with image features. Then, we align image features with selected nouns and captions via optimal transport to obtain a more discriminative semantic space. Finally, we combine the enhanced semantic and image features to perform clustering. Extensive experiments across 8 datasets demonstrate the effectiveness of our method, notably surpassing the state-of-the-art training-free approach with a 4.2% improvement in accuracy and a 2.9% improvement in adjusted rand index (ARI) on the ImageNet-1K dataset.

</details>


### [92] [TalkingPose: Efficient Face and Gesture Animation with Feedback-guided Diffusion Model](https://arxiv.org/abs/2512.00909)
*Alireza Javanmardi,Pragati Jaiswal,Tewodros Amberbir Habtegebrial,Christen Millerdurai,Shaoxiang Wang,Alain Pagani,Didier Stricker*

Main category: cs.CV

TL;DR: TalkingPose 是一种新型的基于扩散模型的框架，能够生成长时间、时空一致的人类上半身动画，通过利用驱动帧捕捉面部和手部的表达性动作，并通过一个稳定的扩散模型将这些动作无缝地转移到目标演员上。该框架不增加额外的计算成本，无需次级训练阶段，因此可以生成无限长的动画。


<details>
  <summary>Details</summary>
Motivation: 现有的方法在生成长时间、连贯的人体动画方面受到计算和内存限制的制约，因为它们通常仅在较短的视频片段上进行训练，这限制了它们的潜在能力来生成长时间的连贯内容。

Method: TalkingPose框架利用驱动帧来精确捕捉面部和手部的表达性动作，并通过一个稳定的扩散模型将这些动作无缝地转移到目标演员上，借助基于图像的扩散模型实现反馈驱动机制来确保连续运动并增强时间连贯性。

Result: 该研究成功开发了一种能够在不增加额外计算成本的情况下生成长时间、时空一致的人类上半身动画的方法，并通过新的基准数据集展示其实现效果。

Conclusion: TalkingPose提供了长期时间连贯的人体动画生成，为该领域带来了全新的视角，并为未来的研究奠定了基础。

Abstract: Recent advancements in diffusion models have significantly improved the realism and generalizability of character-driven animation, enabling the synthesis of high-quality motion from just a single RGB image and a set of driving poses. Nevertheless, generating temporally coherent long-form content remains challenging. Existing approaches are constrained by computational and memory limitations, as they are typically trained on short video segments, thus performing effectively only over limited frame lengths and hindering their potential for extended coherent generation. To address these constraints, we propose TalkingPose, a novel diffusion-based framework specifically designed for producing long-form, temporally consistent human upper-body animations. TalkingPose leverages driving frames to precisely capture expressive facial and hand movements, transferring these seamlessly to a target actor through a stable diffusion backbone. To ensure continuous motion and enhance temporal coherence, we introduce a feedback-driven mechanism built upon image-based diffusion models. Notably, this mechanism does not incur additional computational costs or require secondary training stages, enabling the generation of animations with unlimited duration. Additionally, we introduce a comprehensive, large-scale dataset to serve as a new benchmark for human upper-body animation.

</details>


### [93] [ForamDeepSlice: A High-Accuracy Deep Learning Framework for Foraminifera Species Classification from 2D Micro-CT Slices](https://arxiv.org/abs/2512.00912)
*Abdelghafour Halimi,Ali Alibrahim,Didier Barradas-Bautista,Ronell Sicat,Abdulkader M. Afifi*

Main category: cs.CV

TL;DR: 该研究提出了一种基于深度学习的自动化分类方法，用于识别12种放射虫物种。通过精心挑选的高质量2D微CT切片数据集，研究团队使用多个先进的2D CNN架构实现了95.64%的测试准确率和99.6%的Top-3准确率，最终模型整合了ConvNeXt-Large和EfficientNetV2-Small。此外，还开发了一个交互式高级仪表板，支持实时切片分类和3D匹配。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在发展一种更加准确且可操作的自动分类放射虫物种的方法，以提升微古生物学领域内的研究效率和准确性。

Method: 研究团队首先构建了一个包含97个2D微CT扫描标本的科学严谨的数据集，使用了109,617个高质量图像进行训练、验证和测试。通过实施七种主流的2D CNN架构进行试验学习，并最终集成ConvNeXt-Large和EfficientNetV2-Small两个模型。此外，开发了交互式高级仪表板，利用SSIM、NCC和Dice系数等高级相似度度量进行实时切片分类以及3D匹配。

Result: 研究的最终集成模型达到了95.64%的测试准确率和99.6%的Top-3准确率。AUC值为0.998，显示出对所有物种的良好泛化能力。

Conclusion: 这项研究表明，深度学习在微古生物学领域中具有巨大的潜力，并为放射虫分类研究提供了一个完全可重复的框架。

Abstract: This study presents a comprehensive deep learning pipeline for the automated classification of 12 foraminifera species using 2D micro-CT slices derived from 3D scans. We curated a scientifically rigorous dataset comprising 97 micro-CT scanned specimens across 27 species, selecting 12 species with sufficient representation for robust machine learning. To ensure methodological integrity and prevent data leakage, we employed specimen-level data splitting, resulting in 109,617 high-quality 2D slices (44,103 for training, 14,046 for validation, and 51,468 for testing). We evaluated seven state-of-the-art 2D convolutional neural network (CNN) architectures using transfer learning. Our final ensemble model, combining ConvNeXt-Large and EfficientNetV2-Small, achieved a test accuracy of 95.64%, with a top-3 accuracy of 99.6% and an area under the ROC curve (AUC) of 0.998 across all species. To facilitate practical deployment, we developed an interactive advanced dashboard that supports real-time slice classification and 3D slice matching using advanced similarity metrics, including SSIM, NCC, and the Dice coefficient. This work establishes new benchmarks for AI-assisted micropaleontological identification and provides a fully reproducible framework for foraminifera classification research, bridging the gap between deep learning and applied geosciences.

</details>


### [94] [SceneProp: Combining Neural Network and Markov Random Field for Scene-Graph Grounding](https://arxiv.org/abs/2512.00936)
*Keita Otani,Tatsuya Harada*

Main category: cs.CV

TL;DR: 本文提出了一种名为SceneProp的新方法，通过将场景图接地问题重新表述为马尔可夫随机场中的最大后验概率推断问题，实现了基于图的整体推断。这种方法能够在更大的查询图尺寸和复杂性下保持甚至提高准确率，从而显著优于先前的工作。


<details>
  <summary>Details</summary>
Motivation: 现有的基于短语的视觉查询定位方法在解析复杂的结构性描述时表现不佳，本文旨在解决这一结构性缺陷，提出场景图接地方案。

Method: SceneProp 通过将场景图接地问题转换为马尔可夫随机场中的 MAP 推断问题，实现全局推理，通过端到端框架中的可微信念传播算法实现。

Result: 在四个基准测试上的实验表明，SceneProp 能够显著优于先前的工作，其准确率随着查询图尺寸和复杂性的增加而保持甚至提升。

Conclusion: 本文提出了一种新的方法SceneProp，它能够随着查询图变得更大和更复杂时提供更优的视觉查询定位结果，证明了更多关系上下文确实可以并且应该带来更好的图像查询解析表现。

Abstract: Grounding complex, compositional visual queries with multiple objects and relationships is a fundamental challenge for vision-language models. While standard phrase grounding methods excel at localizing single objects, they lack the structural inductive bias to parse intricate relational descriptions, often failing as queries become more descriptive. To address this structural deficit, we focus on scene-graph grounding, a powerful but less-explored formulation where the query is an explicit graph of objects and their relationships. However, existing methods for this task also struggle, paradoxically showing decreased performance as the query graph grows -- failing to leverage the very information that should make grounding easier. We introduce SceneProp, a novel method that resolves this issue by reformulating scene-graph grounding as a Maximum a Posteriori (MAP) inference problem in a Markov Random Field (MRF). By performing global inference over the entire query graph, SceneProp finds the optimal assignment of image regions to nodes that jointly satisfies all constraints. This is achieved within an end-to-end framework via a differentiable implementation of the Belief Propagation algorithm. Experiments on four benchmarks show that our dedicated focus on the scene-graph grounding formulation allows SceneProp to significantly outperform prior work. Critically, its accuracy consistently improves with the size and complexity of the query graph, demonstrating for the first time that more relational context can, and should, lead to better grounding. Codes are available at https://github.com/keitaotani/SceneProp.

</details>


### [95] [Binary-Gaussian: Compact and Progressive Representation for 3D Gaussian Segmentation](https://arxiv.org/abs/2512.00944)
*An Yang,Chenyu Liu,Jun Du,Jianqing Gao,Jia Pan,Jinshui Hu,Baocai Yin,Bing Yin,Cong Liu*

Main category: cs.CV

TL;DR: 本文提出了一种新的3D高斯斑点表示方法，通过将特征压缩为单个整数来减少内存使用量，并通过细化训练过程优化不透明度，从而提高了细粒度分割的能力。


<details>
  <summary>Details</summary>
Motivation: 现有的基于3D高斯斑点的分割方法依赖于高维度的类别特征，导致较大的内存开销。此外，精细分割面临着标签空间拥挤和缺乏稳定多层次控制机制的挑战。

Method: 该方法采用从粗到细的二进制编码方案对每个高斯类别进行表示，通过二进制到十进制的映射将每个特征压缩为一个整数，以大幅减少内存使用。还设计了渐进式训练策略将全景分割分解为一系列独立的子任务，并在分割训练过程中微调不透明度，以解决光照渲染与语义分割之间的不兼容问题。

Result: 在多个基准上的广泛实验表明，该方法在显著减少内存使用和加速推理的同时，实现了最先进的分割性能。

Conclusion: 该研究提出了一种有效的3D高斯斑点表示方法和技术，大大提高了3D场景的内存效率和分割精度。

Abstract: 3D Gaussian Splatting (3D-GS) has emerged as an efficient 3D representation and a promising foundation for semantic tasks like segmentation. However, existing 3D-GS-based segmentation methods typically rely on high-dimensional category features, which introduce substantial memory overhead. Moreover, fine-grained segmentation remains challenging due to label space congestion and the lack of stable multi-granularity control mechanisms. To address these limitations, we propose a coarse-to-fine binary encoding scheme for per-Gaussian category representation, which compresses each feature into a single integer via the binary-to-decimal mapping, drastically reducing memory usage. We further design a progressive training strategy that decomposes panoptic segmentation into a series of independent sub-tasks, reducing inter-class conflicts and thereby enhancing fine-grained segmentation capability. Additionally, we fine-tune opacity during segmentation training to address the incompatibility between photometric rendering and semantic segmentation, which often leads to foreground-background confusion. Extensive experiments on multiple benchmarks demonstrate that our method achieves state-of-the-art segmentation performance while significantly reducing memory consumption and accelerating inference.

</details>


### [96] [Adaptive Evidential Learning for Temporal-Semantic Robustness in Moment Retrieval](https://arxiv.org/abs/2512.00953)
*Haojian Huang,Kaijing Ma,Jin Chen,Haodong Chen,Zhou Wu,Xianghao Zang,Han Fang,Chao Ban,Hao Sun,Mulin Chen,Zhongjiang He*

Main category: cs.CV

TL;DR: 该研究提出了一种名为DEMR的新框架，通过引入Reflective Flipped Fusion (RFF)模块和Geom-正则化器来改善模态不平衡问题，并增强文本敏感度，从而提高了复杂视频场景下时刻检索的准确性、稳健性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 当前方法在处理模态不平衡和捕捉复杂或模糊时刻方面的局限性促使研究提出改进方案。

Method: DEMR框架结合了Reflective Flipped Fusion (RFF)模块和Geom-正则化器，来改进模态平衡问题并增强文本敏感度。RFF模块帮助不同模态的数据进行相互映射和对齐，而Geom-正则化器则被设计用来优化不确定性估计。

Result: 在标准数据集及去偏差数据集ActivityNet-CD和Charades-CD上进行的大量测试表明DEMR可以在提高鲁棒性和准确性的同时也改善了可解释性。

Conclusion: DEMR作为一种新的时刻检索方法，为复杂视频场景中的时间语义准确性提供了一种有前景的解决方案。

Abstract: In the domain of moment retrieval, accurately identifying temporal segments within videos based on natural language queries remains challenging. Traditional methods often employ pre-trained models that struggle with fine-grained information and deterministic reasoning, leading to difficulties in aligning with complex or ambiguous moments. To overcome these limitations, we explore Deep Evidential Regression (DER) to construct a vanilla Evidential baseline. However, this approach encounters two major issues: the inability to effectively handle modality imbalance and the structural differences in DER's heuristic uncertainty regularizer, which adversely affect uncertainty estimation. This misalignment results in high uncertainty being incorrectly associated with accurate samples rather than challenging ones. Our observations indicate that existing methods lack the adaptability required for complex video scenarios. In response, we propose Debiased Evidential Learning for Moment Retrieval (DEMR), a novel framework that incorporates a Reflective Flipped Fusion (RFF) block for cross-modal alignment and a query reconstruction task to enhance text sensitivity, thereby reducing bias in uncertainty estimation. Additionally, we introduce a Geom-regularizer to refine uncertainty predictions, enabling adaptive alignment with difficult moments and improving retrieval accuracy. Extensive testing on standard datasets and debiased datasets ActivityNet-CD and Charades-CD demonstrates significant enhancements in effectiveness, robustness, and interpretability, positioning our approach as a promising solution for temporal-semantic robustness in moment retrieval. The code is publicly available at https://github.com/KaijingOfficial/DEMR.

</details>


### [97] [MM-ACT: Learn from Multimodal Parallel Generation to Act](https://arxiv.org/abs/2512.00975)
*Haotian Liang,Xinyi Chen,Bin Wang,Mingkang Chen,Yitian Liu,Yuhao Zhang,Zanxin Chen,Tianshuo Yang,Yilun Chen,Jiangmiao Pang,Dong Liu,Xiaokang Yang,Yao Mu,Wenqi Shao,Ping Luo*

Main category: cs.CV

TL;DR: 提出了一个名为MM-ACT的统一Vision-Language-Action（VLA）模型，该模型在共享的语义空间中融合了文本、图像和动作，并在所有三个模态中执行生成，同时通过上下文共享多模态学习机制增强了动作生成，验证了其在模拟和真实环境中的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决通用机器人策略需要同时理解语义进行任务规划以及通过预测能力与环境交互的问题，设计MM-ACT模型，使其能够在图像、文本和动作之间共享信息以提高任务执行效率。

Method: MM-ACT采用了一种重新掩码并行解码策略进行文本和图像生成，并使用了一步并行解码策略进行动作生成，同时引入了上下文共享多模态学习作为统一的训练框架，监督所有三个模态的生成。

Result: MM-ACT在LIBERO模拟环境中实现了96.3%的成功率，在真实Franka机器人上完成了三项任务取得了72.0%的成功率，并在RoboTwin2.0上完成了八个双臂任务取得了52.38%的成功率。跨模态学习进一步提高了2.5%的成功率。

Conclusion: MM-ACT通过整合图像、文本和动作生成为通用机器人提供了一个有效的解决方案，通过改进的生成策略和多模态学习增强了其在不同环境下的性能。

Abstract: A generalist robotic policy needs both semantic understanding for task planning and the ability to interact with the environment through predictive capabilities. To tackle this, we present MM-ACT, a unified Vision-Language-Action (VLA) model that integrates text, image, and action in shared token space and performs generation across all three modalities. MM-ACT adopts a re-mask parallel decoding strategy for text and image generation, and employs a one-step parallel decoding strategy for action generation to improve efficiency. We introduce Context-Shared Multimodal Learning, a unified training paradigm that supervises generation in all three modalities from a shared context, enhancing action generation through cross-modal learning. Experiments were conducted on the LIBERO simulation and Franka real-robot setups as well as RoboTwin2.0 to assess in-domain and out-of-domain performances respectively. Our approach achieves a success rate of 96.3% on LIBERO, 72.0% across three tasks of real Franka, and 52.38% across eight bimanual tasks of RoboTwin2.0 with an additional gain of 9.25% from cross-modal learning. We release our codes, models and data at https://github.com/HHYHRHY/MM-ACT.

</details>


### [98] [PhotoFramer: Multi-modal Image Composition Instruction](https://arxiv.org/abs/2512.00993)
*Zhiyuan You,Ke Wang,He Zhang,Xin Cai,Jinjin Gu,Tianfan Xue,Chao Dong,Zhoutong Zhang*

Main category: cs.CV

TL;DR: PhotoFramer 提供了一种多模态的构图指导框架，通过自然语言的描述和生成良好的构图示例来帮助用户改进构图。


<details>
  <summary>Details</summary>
Motivation: 许多普通用户在拍照时难以进行良好的构图，PhotoFramer 旨在通过提供直观的指导来改善这一问题。

Method: PhotoFramer 通过一个大规模的数据集进行训练，这个数据集包含了转换从良好构图到不良构图的数据，并通过两阶段合成不良图像。模型通过处理和生成图文并茂的内容，来提供具体可行的文本指导。

Result: 实验证明，这种结合文本和样例的指导方式比单纯使用样例更为有效，有效地改善了图像构图。

Conclusion: PhotoFramer 为摄影师的专业构图知识提供了实践性的途径，使之成为普通用户的可访问资源。

Abstract: Composition matters during the photo-taking process, yet many casual users struggle to frame well-composed images. To provide composition guidance, we introduce PhotoFramer, a multi-modal composition instruction framework. Given a poorly composed image, PhotoFramer first describes how to improve the composition in natural language and then generates a well-composed example image. To train such a model, we curate a large-scale dataset. Inspired by how humans take photos, we organize composition guidance into a hierarchy of sub-tasks: shift, zoom-in, and view-change tasks. Shift and zoom-in data are sampled from existing cropping datasets, while view-change data are obtained via a two-stage pipeline. First, we sample pairs with varying viewpoints from multi-view datasets, and train a degradation model to transform well-composed photos into poorly composed ones. Second, we apply this degradation model to expert-taken photos to synthesize poor images to form training pairs. Using this dataset, we finetune a model that jointly processes and generates both text and images, enabling actionable textual guidance with illustrative examples. Extensive experiments demonstrate that textual instructions effectively steer image composition, and coupling them with exemplars yields consistent improvements over exemplar-only baselines. PhotoFramer offers a practical step toward composition assistants that make expert photographic priors accessible to everyday users. Codes, model weights, and datasets have been released in https://zhiyuanyou.github.io/photoframer.

</details>


### [99] [S2AM3D: Scale-controllable Part Segmentation of 3D Point Cloud](https://arxiv.org/abs/2512.00995)
*Han Su,Tianyu Huang,Zichen Wan,Xiaohe Wu,Wangmeng Zuo*

Main category: cs.CV

TL;DR: 本文提出了一种称为S2AM3D的方法，它结合了2D分割先验和3D一致监督，旨在解决部分级点云分割中的数据稀少和视角不一致问题。


<details>
  <summary>Details</summary>
Motivation: 现有的部分级点云分割方法受到了数据稀少导致的泛化能力不足和通过2D预训练知识引入导致的跨视角不一致分割结果的困扰。为此，作者提出了S2AM3D方法以提高模型的泛化能力和分割结果的一致性。

Method: S2AM3D采用点一致部分编码器，通过自然3D对比学习聚合多视角2D特征，生成全局一致的点特征。同时，引入了尺度感知提示解码器，通过连续的尺度信号实现实时的分割粒度调整。方法还包括了一个大规模、高质量的部分级点云数据集，用于模型训练。

Result: 实验结果表明，S2AM3D在多种评估设置中取得了领先的性能，展示了在处理复杂结构和大小显著变化的部分时的出色鲁棒性和可控性。

Conclusion: 作者总结了S2AM3D在部分级点云分割成绩上的优势，并指出该方法能够为未来的研究提供参考和借鉴。

Abstract: Part-level point cloud segmentation has recently attracted significant attention in 3D computer vision. Nevertheless, existing research is constrained by two major challenges: native 3D models lack generalization due to data scarcity, while introducing 2D pre-trained knowledge often leads to inconsistent segmentation results across different views. To address these challenges, we propose S2AM3D, which incorporates 2D segmentation priors with 3D consistent supervision. We design a point-consistent part encoder that aggregates multi-view 2D features through native 3D contrastive learning, producing globally consistent point features. A scale-aware prompt decoder is then proposed to enable real-time adjustment of segmentation granularity via continuous scale signals. Simultaneously, we introduce a large-scale, high-quality part-level point cloud dataset with more than 100k samples, providing ample supervision signals for model training. Extensive experiments demonstrate that S2AM3D achieves leading performance across multiple evaluation settings, exhibiting exceptional robustness and controllability when handling complex structures and parts with significant size variations.

</details>


### [100] [Provenance-Driven Reliable Semantic Medical Image Vector Reconstruction via Lightweight Blockchain-Verified Latent Fingerprints](https://arxiv.org/abs/2512.00999)
*Mohsin Rasheed,Abdullah Al-Mamun*

Main category: cs.CV

TL;DR: 该研究提出了一种新的医学影像重构框架，结合了高阶语义嵌入和混合U-Net结构，以保留临床相关结构。同时，通过引入基于无标度图设计的轻量级区块链溯源层，保证了重构事件的可验证记录，从而提高了结构一致性和溯源完整性。


<details>
  <summary>Details</summary>
Motivation: 当前临床医学影像数据存在污染、噪声和潜在篡改等问题，传统的图像重建技术优先考虑像素级别的恢复，可能导致解剖结构失真，影响临床诊断结果。因此，研究提出了一个结合语义和混合U-Net的图像重构框架，以增强临床相关结构的保留，同时通过区块链技术确保重构过程的透明性和可追溯性。

Method: 该方法基于混合U-Net架构，引入高阶语义嵌入，用于临床相关结构的保留。同时，采用规模无用图设计的轻量级区块链技术，构建一套可验证的重构溯源系统。

Result: 实验结果显示，该框架在多个数据集和污染类型上提高了结构一致性、恢复精度和溯源完整性的表现。与现有方法相比，提出的方法具有明显优势。

Conclusion: 该研究通过语义引导的图像重构与安全可追溯性的结合，推动了基于人工智能的医学成像系统的可信性，提高了医疗诊断的信心和法规合规性。

Abstract: Medical imaging is essential for clinical diagnosis, yet real-world data frequently suffers from corruption, noise, and potential tampering, challenging the reliability of AI-assisted interpretation. Conventional reconstruction techniques prioritize pixel-level recovery and may produce visually plausible outputs while compromising anatomical fidelity, an issue that can directly impact clinical outcomes. We propose a semantic-aware medical image reconstruction framework that integrates high-level latent embeddings with a hybrid U-Net architecture to preserve clinically relevant structures during restoration. To ensure trust and accountability, we incorporate a lightweight blockchain-based provenance layer using scale-free graph design, enabling verifiable recording of each reconstruction event without imposing significant overhead. Extensive evaluation across multiple datasets and corruption types demonstrates improved structural consistency, restoration accuracy, and provenance integrity compared with existing approaches. By uniting semantic-guided reconstruction with secure traceability, our solution advances dependable AI for medical imaging, enhancing both diagnostic confidence and regulatory compliance in healthcare environments.

</details>


### [101] [LISA-3D: Lifting Language-Image Segmentation to 3D via Multi-View Consistency](https://arxiv.org/abs/2512.01008)
*Zhongbin Guo,Jiahe Liu,Wenyu Gao,Yushan Li,Chengzhi Li,Ping Jian*

Main category: cs.CV

TL;DR: LISA-3D是一个两阶段框架，通过使用几何感知的低秩适应（LoRA）层来增强LISA模型，利用离线的RGB-D序列和相机位姿构建可微的重投影损失，并直接为SAM-3D模型生成RGBA提示，无需重新训练，实现了从语言到三维重建的提升。


<details>
  <summary>Details</summary>
Motivation: 当前3D重建面临挑战，如依赖开放词汇指令的理解和多视角一致性。LISA-3D旨在通过结合LISA的指令遵循模型和几何感知LoRA层，解决这些挑战，同时减少额外的3D-文本监督需求。

Method: LISA-3D框架采用了两个阶段的方法，第一阶段是通过LoRA层改进LISA模型，第二阶段是利用离线的RGB-D序列和相机位姿构建精确的重投影损失机制，然后将生成的掩码与RGB图像结合为RGBA提示输入SAM-3D模型，输出高精度的3D重建结果，而无需额外训练。

Result: 在ScanRefer和Nr3D数据集上，LISA-3D相对于单视角基线模型提高了15.6%的语言到3D准确率，并且仅适配了11.6M参数。此外，系统是模块化和数据高效的，适应于零样本部署于未见过的类别，提供了语言指导的3D内容创建的实用指南。

Conclusion: LISA-3D提出了一种高效且灵活的方法，通过优化指令遵循模型和集成几何约束，显著提高了3D重建性能，同时保持了模型的模块化和适应性。

Abstract: Text-driven 3D reconstruction demands a mask generator that simultaneously understands open-vocabulary instructions and remains consistent across viewpoints. We present LISA-3D, a two-stage framework that lifts language-image segmentation into 3D by retrofitting the instruction-following model LISA with geometry-aware Low-Rank Adaptation (LoRA) layers and reusing a frozen SAM-3D reconstructor. During training we exploit off-the-shelf RGB-D sequences and their camera poses to build a differentiable reprojection loss that enforces cross-view agreement without requiring any additional 3D-text supervision. The resulting masks are concatenated with RGB images to form RGBA prompts for SAM-3D, which outputs Gaussian splats or textured meshes without retraining. Across ScanRefer and Nr3D, LISA-3D improves language-to-3D accuracy by up to +15.6 points over single-view baselines while adapting only 11.6M parameters. The system is modular, data-efficient, and supports zero-shot deployment on unseen categories, providing a practical recipe for language-guided 3D content creation. Our code will be available at https://github.com/binisalegend/LISA-3D.

</details>


### [102] [Lotus-2: Advancing Geometric Dense Prediction with Powerful Image Generative Model](https://arxiv.org/abs/2512.01030)
*Jing He,Haodong Li,Mingzhi Sheng,Ying-Cong Chen*

Main category: cs.CV

TL;DR: Lotus-2 是一种两阶段确定性框架，适用于从单张图像中进行稳定、准确和精细的空间密集预测，利用预训练生成先验，实现了一种优化的适配协议。


<details>
  <summary>Details</summary>
Motivation: Address the limitations of discriminative regression models in recovering pixel-wise geometric properties and the suboptimality of directly using diffusion model frameworks for deterministic geometric inference.

Method: Lotus-2采用两阶段方式：第一阶段使用单步确定性公式和一个清洁数据目标与轻量局部连续模块生成全局一致结构；第二阶段通过在核心预测器定义的流形上进行约束多步矫正流细化，增强精细几何。

Result: 在仅使用59K训练样本的情况下（不到现有大规模数据集的1%），Lotus-2 在单眼深度估计和表面法线预测方面建立了新的最先进结果。

Conclusion: Lotus-2展示了扩散模型可以作为确定性世界的先验，超越了传统的判别性和生成性范式，提供高质量的几何推理。

Abstract: Recovering pixel-wise geometric properties from a single image is fundamentally ill-posed due to appearance ambiguity and non-injective mappings between 2D observations and 3D structures. While discriminative regression models achieve strong performance through large-scale supervision, their success is bounded by the scale, quality and diversity of available data and limited physical reasoning. Recent diffusion models exhibit powerful world priors that encode geometry and semantics learned from massive image-text data, yet directly reusing their stochastic generative formulation is suboptimal for deterministic geometric inference: the former is optimized for diverse and high-fidelity image generation, whereas the latter requires stable and accurate predictions. In this work, we propose Lotus-2, a two-stage deterministic framework for stable, accurate and fine-grained geometric dense prediction, aiming to provide an optimal adaption protocol to fully exploit the pre-trained generative priors. Specifically, in the first stage, the core predictor employs a single-step deterministic formulation with a clean-data objective and a lightweight local continuity module (LCM) to generate globally coherent structures without grid artifacts. In the second stage, the detail sharpener performs a constrained multi-step rectified-flow refinement within the manifold defined by the core predictor, enhancing fine-grained geometry through noise-free deterministic flow matching. Using only 59K training samples, less than 1% of existing large-scale datasets, Lotus-2 establishes new state-of-the-art results in monocular depth estimation and highly competitive surface normal prediction. These results demonstrate that diffusion models can serve as deterministic world priors, enabling high-quality geometric reasoning beyond traditional discriminative and generative paradigms.

</details>


### [103] [TRoVe: Discovering Error-Inducing Static Feature Biases in Temporal Vision-Language Models](https://arxiv.org/abs/2512.01048)
*Maya Varma,Jean-Benoit Delbrouck,Sophie Ostmeier,Akshay Chaudhari,Curtis Langlotz*

Main category: cs.CV

TL;DR: 该研究提出了一种名为TRoVe的自动化方法，用于发现由时间视觉语言模型学习的引发错误的静态特征偏差。研究通过一个包含101个训练好的时间视觉语言模型的评估框架，展示了TRoVe的有效性，并进一步应用于七种现成的视觉语言模型上，发现了未知的静态特征偏差，证明了这些偏差的知识有助于提高模型的测试性能。


<details>
  <summary>Details</summary>
Motivation: 鉴于视觉语言模型（VLMs）在处理涉及跨图像序列视觉变化的预测任务时可能依赖静态特征偏见，这可能导致下游任务中的预测错误，因此研究旨在自动化发现这些特征偏见以减少系统性预测误差。

Method: TRoVe方法包括评估框架的小规模原始模型与真实标注的学习静态特征偏差，并针对给定的训练好的VLM和下游任务的标注数据集提取候选静态特征，然后根据特征对分类错误的影响及其用于预测的依赖程度来打分。此外，还引入了IR和SP两方面的评估指标。

Result: 研究通过包含101个训练好的时间视觉语言模型的评估框架来评估TRoVe，结果显示TRoVe能够准确识别视觉语言模型中的引发错误的静态特征偏差，相比最接近的基线方法提高了28.6%的准确性，并进一步发现了先前未知的静态特征偏差。

Conclusion: 研究通过自动化的TRoVe方法识别出了视觉语言模型中的静态特征偏差，证明了这有助于减少模型部署前的系统性预测错误。

Abstract: Vision-language models (VLMs) have made great strides in addressing temporal understanding tasks, which involve characterizing visual changes across a sequence of images. However, recent works have suggested that when making predictions, VLMs may rely on static feature biases, such as background or object features, rather than dynamic visual changes. Static feature biases are a type of shortcut and can contribute to systematic prediction errors on downstream tasks; as a result, identifying and characterizing error-inducing static feature biases is critical prior to real-world model deployment. In this work, we introduce TRoVe, an automated approach for discovering error-inducing static feature biases learned by temporal VLMs. Given a trained VLM and an annotated validation dataset associated with a downstream classification task, TRoVe extracts candidate static features from the dataset and scores each feature by (i) the effect of the feature on classification errors as well as (ii) the extent to which the VLM relies on the feature when making predictions. In order to quantitatively evaluate TRoVe, we introduce an evaluation framework consisting of 101 trained temporal VLMs paired with ground-truth annotations for learned static feature biases. We use this framework to demonstrate that TRoVe can accurately identify error-inducing static feature biases in VLMs, achieving a 28.6% improvement over the closest baseline. Finally, we apply TRoVe to 7 off-the-shelf VLMs and 2 temporal understanding tasks, surfacing previously-unknown static feature biases and demonstrating that knowledge of learned biases can aid in improving model performance at test time. Our code is available at https://github.com/Stanford-AIMI/TRoVe.

</details>


### [104] [Parameter Reduction Improves Vision Transformers: A Comparative Study of Sharing and Width Reduction](https://arxiv.org/abs/2512.01059)
*Anantha Padmanaban Krishna Kumar*

Main category: cs.CV

TL;DR: 研究针对Vision Transformers的MLP块的两种简化策略，即GroupedMLP和ShallowMLP，以减少参数数量而不牺牲性能，并提高了训练稳定性。


<details>
  <summary>Details</summary>
Motivation: 尽管扩展规律和许多经验结果表明增加Vision Transformers的规模通常会提高性能，但模型的准确度和训练行为并不总是随着规模的增加而单调增加。研究简化策略以减少参数数量，了解如何在不影响性能的情况下减少参数，并寻找参数分配的有用先验。

Method: 通过对比GroupedMLP和ShallowMLP两种方法，将MLP块的参数数量减少32.7%，并且保持了与基础模型相同的计算成本和在Inference时提高了吞吐量。

Result: GroupedMLP方法保留了基础计算成本的同时达到了81.47%的top-1准确率；ShallowMLP方法虽然在Inference时吞吐量提高了38%，但只达到了81.25%的top-1准确率；这两种方法的top-1准确率都超过了数据集上的86.6M参数基线模型81.05%的准确率，同时提高了训练的稳定性。

Conclusion: 研究表明，在使用标准训练食谱的情况下，对于ViT-B/16在ImageNet-1K数据集上，模型处于一个过参数化区间，在这个区间内MLP容量的减少不会损害性能，甚至可以略微提升性能。这些发现还表明，如参数共享和宽度减少等架构约束可以作为有用的归纳偏置，并强调了在设计Vision Transformers时对参数分配的重要关注点。

Abstract: Although scaling laws and many empirical results suggest that increasing the size of Vision Transformers often improves performance, model accuracy and training behavior are not always monotonically increasing with scale. Focusing on ViT-B/16 trained on ImageNet-1K, we study two simple parameter-reduction strategies applied to the MLP blocks, each removing 32.7\% of the baseline parameters. Our \emph{GroupedMLP} variant shares MLP weights between adjacent transformer blocks and achieves 81.47\% top-1 accuracy while maintaining the baseline computational cost. Our \emph{ShallowMLP} variant halves the MLP hidden dimension and reaches 81.25\% top-1 accuracy with a 38\% increase in inference throughput. Both models outperform the 86.6M-parameter baseline (81.05\%) and exhibit substantially improved training stability, reducing peak-to-final accuracy degradation from 0.47\% to the range 0.03\% to 0.06\%. These results suggest that, for ViT-B/16 on ImageNet-1K with a standard training recipe, the model operates in an overparameterized regime in which MLP capacity can be reduced without harming performance and can even slightly improve it. More broadly, our findings suggest that architectural constraints such as parameter sharing and reduced width may act as useful inductive biases, and highlight the importance of how parameters are allocated when designing Vision Transformers. All code is available at: https://github.com/AnanthaPadmanaban-KrishnaKumar/parameter-efficient-vit-mlps.

</details>


### [105] [Accelerating Inference of Masked Image Generators via Reinforcement Learning](https://arxiv.org/abs/2512.01094)
*Pranav Subbaraman,Shufan Li,Siyan Zhao,Aditya Grover*

Main category: cs.CV

TL;DR: 提出了一种名为Speed-RL的新范式，通过强化学习加速预训练的生成式模型以产生高质量图像，显著提高了图像生成速度，同时保持了可比的图像质量。


<details>
  <summary>Details</summary>
Motivation: 解决 Masked Generative Models (MGM) 生成高质量图像所需计算资源消耗大的问题，考虑加速问题作为强化学习问题，以减少生成高质量图像所需步骤数为目标。

Method: 引入了一个质量奖励和速度奖励相结合的目标函数，使用强化学习微调基础模型。

Result: 实验表明，所提出的方法能使基础模型的速度提高3倍，同时保持可比的图像质量。

Conclusion: 提出的方法为加速预训练的生成式模型提供了新的视角，通过结合质量奖励和速度奖励，展示了在保持图像质量的同时大幅提升生成速度的潜力。

Abstract: Masked Generative Models (MGM)s demonstrate strong capabilities in generating high-fidelity images. However, they need many sampling steps to create high-quality generations, resulting in slow inference speed. In this work, we propose Speed-RL, a novel paradigm for accelerating a pretrained MGMs to generate high-quality images in fewer steps. Unlike conventional distillation methods which formulate the acceleration problem as a distribution matching problem, where a few-step student model is trained to match the distribution generated by a many-step teacher model, we consider this problem as a reinforcement learning problem. Since the goal of acceleration is to generate high quality images in fewer steps, we can combine a quality reward with a speed reward and finetune the base model using reinforcement learning with the combined reward as the optimization target. Through extensive experiments, we show that the proposed method was able to accelerate the base model by a factor of 3x while maintaining comparable image quality.

</details>


### [106] [CycliST: A Video Language Model Benchmark for Reasoning on Cyclical State Transitions](https://arxiv.org/abs/2512.01095)
*Simon Kohaut,Daniel Ochs,Shun Zhang,Benedict Flade,Julian Eggert,Kristian Kersting,Devendra Singh Dhami*

Main category: cs.CV

TL;DR: CycliST 是一个新颖的数据集，用于评估视频语言模型在处理周期性状态转换方面的文本推理能力。该数据集通过合成和结构丰富的视频序列，涵盖物体运动和视觉属性中的周期性模式来捕捉现实世界过程的基本方面。该基准采用分层评估系统，逐步增加难度，挑战当前最先进的模型在时空认知上的能力。


<details>
  <summary>Details</summary>
Motivation: 当前视频语言模型在处理周期性动态（如线性和轨道运动、时间依赖的视觉属性变化）方面存在困难，这一数据集旨在揭示这些模型在识别和利用周期模式方面的限制，促进未来在这一领域的研究和改进。

Method: CycliST 通过生成合成、结构丰富的视频序列，涵盖了周期性模式的物体运动和视觉属性。数据集采用分层评估系统，分级增加难度，基于周期物体的数量、场景杂乱程度和光照条件的变化，挑战最先进的模型。

Result: 通过与当前最先进的视频语言模型进行广泛的实验，结果显示这些模型在识别和利用周期性模式方面表现不佳，缺乏时间理解的概念，无法从场景中提取定量见解，如运动中的物体数量。没有单一模型在整个任务中始终表现出色，大小和架构与性能结果之间不存在强烈的相关性。

Conclusion: CycliST 为视觉推理模型提供了一个有针对性的挑战和全面的评估框架，旨在超越当前的最先进的理解和周期性模式以及推动相关研究。

Abstract: We present CycliST, a novel benchmark dataset designed to evaluate Video Language Models (VLM) on their ability for textual reasoning over cyclical state transitions. CycliST captures fundamental aspects of real-world processes by generating synthetic, richly structured video sequences featuring periodic patterns in object motion and visual attributes. CycliST employs a tiered evaluation system that progressively increases difficulty through variations in the number of cyclic objects, scene clutter, and lighting conditions, challenging state-of-the-art models on their spatio-temporal cognition. We conduct extensive experiments with current state-of-the-art VLMs, both open-source and proprietary, and reveal their limitations in generalizing to cyclical dynamics such as linear and orbital motion, as well as time-dependent changes in visual attributes like color and scale. Our results demonstrate that present-day VLMs struggle to reliably detect and exploit cyclic patterns, lack a notion of temporal understanding, and are unable to extract quantitative insights from scenes, such as the number of objects in motion, highlighting a significant technical gap that needs to be addressed. More specifically, we find no single model consistently leads in performance: neither size nor architecture correlates strongly with outcomes, and no model succeeds equally well across all tasks. By providing a targeted challenge and a comprehensive evaluation framework, CycliST paves the way for visual reasoning models that surpass the state-of-the-art in understanding periodic patterns.

</details>


### [107] [SocialFusion: Addressing Social Degradation in Pre-trained Vision-Language Models](https://arxiv.org/abs/2512.01148)
*Hamza Tahboub,Weiyan Shi,Gang Hua,Huaizu Jiang*

Main category: cs.CV

TL;DR: 本研究发现，现有的预训练视觉语言模型在同时学习多种社会感知任务时会出现负迁移，这是因为视觉编码器在泛化预训练过程中，对社交信息的表示能力受损。为此，研究提出了一种名为SocialFusion的统一框架，该框架通过最小化视觉编码器和语言模型之间的连接来解决这个问题，实现了在各个社会感知任务上的正迁移，并在基准测试上达到了与特定任务模型相当的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的预训练视觉语言模型在同时处理多种社会感知任务时表现不佳，存在负迁移的问题，这阻碍了AI的社会适应性。

Method: 研究通过线性表示探测和梯度冲突分析揭示了视觉编码器在预训练过程中的“社交降解”现象，并据此提出了名为SocialFusion的统一框架。

Result: SocialFusion框架在各个社会感知任务上实现了正迁移，利用任务间的协同作用提升整体性能，并在多种基准测试上达到了可与特定任务状态最先进技术相媲美的性能。

Conclusion: 研究结果表明，当前的预训练策略可能不利于获取通用的社会能力，强调了需要更有社会意识的训练方法。

Abstract: Understanding social interactions from visual cues is a fundamental challenge for a socially competent AI. While powerful pre-trained vision-language models (VLMs) have shown remarkable general capabilities, they surprisingly struggle to unify and learn multiple social perception tasks simultaneously, often exhibiting negative transfer. We identify that this negative transfer stems from a critical issue we term "social degradation," whereby the general visual-linguistic pre-training process of VLMs impairs the visual encoder's ability to represent nuanced social information. We investigate this behavior further under two lenses: decodability through linear representation probing and compatibility through gradient conflict analysis, revealing that both play a role in the degradation, especially the former, which is significantly compromised in the VLM pre-training process. To address these issues, we propose SocialFusion, a unified framework that learns a minimal connection between a frozen visual encoder and a language model. Compared with existing VLMs, it exhibits positive transfer across all five social tasks, leveraging synergies between them to enhance overall performance and achieves comparable performance to task-specific state-of-the-art models on various benchmarks. Our findings suggest that current VLM pre-training strategies may be detrimental to acquiring general social competence and highlight the need for more socially-aware training paradigms.

</details>


### [108] [Structural Prognostic Event Modeling for Multimodal Cancer Survival Analysis](https://arxiv.org/abs/2512.01116)
*Yilan Zhang,Li Nanbo,Changchun Yang,Jürgen Schmidhuber,Xin Gao*

Main category: cs.CV

TL;DR: SlotSPE 提出了一种基于槽的框架来建模结构化的预后事件，通过基于因子编码原理将多模态输入压缩为模态特定的具有区分性的槽表示，实现了复杂内模态和跨模态相互作用的有效建模，并增强了预后相关性。


<details>
  <summary>Details</summary>
Motivation: 目前的计算方法在建模癌症输入的内模态和跨模态交互时，难以处理高维度和复杂性的问题。 SlotSPE 提出了一种解决方案，通过槽注意力机制来压缩和处理多模态输入，旨在捕捉关键的预后事件。

Method: SlotSPE 基于因子编码原理，将每个患者的多模态输入压缩为模态特定的具有区分性的槽表示。通过利用这些槽表示作为预后事件的编码，框架能够高效有效地建模复杂的内模态和跨模态交互，并且还支持生物先验知识的集成，以增强预后相关性。

Result: 在十个癌症基准测试中，SlotSPE 在八组数据中优于现有方法，总体性能提高了2.9%。此外，SlotSPE 对缺乏基因组数据依然保持鲁棒性，并通过结构化事件分解提高了可解释性。

Conclusion: SlotSPE 框架展示了在多模态数据处理和复杂事件建模方面的优势，显示出在癌症预后预测中有潜力的提高。

Abstract: The integration of histology images and gene profiles has shown great promise for improving survival prediction in cancer. However, current approaches often struggle to model intra- and inter-modal interactions efficiently and effectively due to the high dimensionality and complexity of the inputs. A major challenge is capturing critical prognostic events that, though few, underlie the complexity of the observed inputs and largely determine patient outcomes. These events, manifested as high-level structural signals such as spatial histologic patterns or pathway co-activations, are typically sparse, patient-specific, and unannotated, making them inherently difficult to uncover. To address this, we propose SlotSPE, a slot-based framework for structural prognostic event modeling. Specifically, inspired by the principle of factorial coding, we compress each patient's multimodal inputs into compact, modality-specific sets of mutually distinctive slots using slot attention. By leveraging these slot representations as encodings for prognostic events, our framework enables both efficient and effective modeling of complex intra- and inter-modal interactions, while also facilitating seamless incorporation of biological priors that enhance prognostic relevance. Extensive experiments on ten cancer benchmarks show that SlotSPE outperforms existing methods in 8 out of 10 cohorts, achieving an overall improvement of 2.9%. It remains robust under missing genomic data and delivers markedly improved interpretability through structured event decomposition.

</details>


### [109] [DPAC: Distribution-Preserving Adversarial Control for Diffusion Sampling](https://arxiv.org/abs/2512.01153)
*Han-Jin Lee,Han-Ju Lee,Jin-Seong Kim,Seok-Hwan Choi*

Main category: cs.CV

TL;DR: 本文通过引入路径上的Kullback-Leibler散度 (path-KL) 来量化对抗性控制的质量退化问题，理论分析表明，最小化路径-KL 同时能收紧 Wassertein 距离和 Fréchet Inception Distance (FID) 的上界，并提出了基于生成分布几何的梯度投影方法 DPAC 来改进对抗性控制效果。


<details>
  <summary>Details</summary>
Motivation: 现有对抗性引导扩散采样的方法在达到目标类别时，样本质量会随着对抗性控制和基础轨迹之间偏差的累积而下降。为了改进这一问题，本文提出了路径-KL 来量化质量问题，并基于此建立指导性方法。

Method: 首先，通过 Girsanov 定理建立了路径-KL 与控制能量的等价关系；其次，提出了利用极大似然原则中的条件最优性条件来优化对抗性控制的梯度方向；最后，在离散求解器中引入了梯度的切空间投影方法 DPAC，来进一步改进计算质量。

Result: 本文提出了一个新颖的方法 DPAC，通过切空间投影梯度有效减少路径-KL 的标准，并证明了该方法能够在减少模型泛化偏差，计算误差率上优于其他方法。在基准数据集 ImageNet-100 的实验中，DPAC 达到了较低的 FID 和估计的路径-KL。同时进一步表明该方法已被证明在计算上是二阶鲁棒性。

Conclusion: 本文为企业提供了有效的对抗性控制框架和路径-KL 求解方法。基于 DPAC 的解决方案提高了在对抗性控制中的样本质量，并且在计算上具有较高的鲁棒性。

Abstract: Adversarially guided diffusion sampling often achieves the target class, but sample quality degrades as deviations between the adversarially controlled and nominal trajectories accumulate. We formalize this degradation as a path-space Kullback-Leibler divergence(path-KL) between controlled and nominal (uncontrolled) diffusion processes, thereby showing via Girsanov's theorem that it exactly equals the control energy. Building on this stochastic optimal control (SOC) view, we theoretically establish that minimizing this path-KL simultaneously tightens upper bounds on both the 2-Wasserstein distance and Fréchet Inception Distance (FID), revealing a principled connection between adversarial control energy and perceptual fidelity. From a variational perspective, we derive a first-order optimality condition for the control: among all directions that yield the same classification gain, the component tangent to iso-(log-)density surfaces (i.e., orthogonal to the score) minimizes path-KL, whereas the normal component directly increases distributional drift. This leads to DPAC (Distribution-Preserving Adversarial Control), a diffusion guidance rule that projects adversarial gradients onto the tangent space defined by the generative score geometry. We further show that in discrete solvers, the tangent projection cancels the O(Δt) leading error term in the Wasserstein distance, achieving an O(Δt^2) quality gap; moreover, it remains second-order robust to score or metric approximation. Empirical studies on ImageNet-100 validate the theoretical predictions, confirming that DPAC achieves lower FID and estimated path-KL at matched attack success rates.

</details>


### [110] [OmniFD: A Unified Model for Versatile Face Forgery Detection](https://arxiv.org/abs/2512.01128)
*Haotian Liu,Haoyu Chen,Chenhui Pan,You Hu,Guoying Zhao,Xiaobai Li*

Main category: cs.CV

TL;DR: OmniFD 提出了一种统一的框架，能够高效地联合处理人脸识别伪造的多个任务，包括图像和视频分类、空间定位和时间定位，通过共享特征提取和自注意力机制实现跨任务学习。


<details>
  <summary>Details</summary>
Motivation: 当前的人脸伪造检测方法通常使用独立的模型处理每项任务，导致计算冗余并忽略了任务之间的潜在关联。OmniFD 旨在通过统一框架解决这些问题，提供一个更高效且全面的解决方案。

Method: OmniFD 包含三个主要组成部分：共享的 Swin Transformer 编码器，用于从图像和视频中提取统一的 4D 空间时间特征；交叉任务交互模块，该模块基于注意力机制动态捕捉跨任务依赖关系；以及轻量级的解码头，用于将精炼的表示转换为相应预测。

Result: OmniFD 在多种基准测试中显示出了比专用模型更好的性能，如减少 63% 的模型参数和50% 的训练时间，并能够实现细粒度的知识迁移。视频分类准确性在结合图像数据时提高了 4.63%。

Conclusion: OmniFD 为现实世界应用中的全面人脸伪造检测提供了一个实用且可扩展的解决方案，其统一设计能够促进多任务学习，从而提高模型的效率和性能。

Abstract: Face forgery detection encompasses multiple critical tasks, including identifying forged images and videos and localizing manipulated regions and temporal segments. Current approaches typically employ task-specific models with independent architectures, leading to computational redundancy and ignoring potential correlations across related tasks. We introduce OmniFD, a unified framework that jointly addresses four core face forgery detection tasks within a single model, i.e., image and video classification, spatial localization, and temporal localization. Our architecture consists of three principal components: (1) a shared Swin Transformer encoder that extracts unified 4D spatiotemporal representations from both images and video inputs, (2) a cross-task interaction module with learnable queries that dynamically captures inter-task dependencies through attention-based reasoning, and (3) lightweight decoding heads that transform refined representations into corresponding predictions for all FFD tasks. Extensive experiments demonstrate OmniFD's advantage over task-specific models. Its unified design leverages multi-task learning to capture generalized representations across tasks, especially enabling fine-grained knowledge transfer that facilitates other tasks. For example, video classification accuracy improves by 4.63% when image data are incorporated. Furthermore, by unifying images, videos and the four tasks within one framework, OmniFD achieves superior performance across diverse benchmarks with high efficiency and scalability, e.g., reducing 63% model parameters and 50% training time. It establishes a practical and generalizable solution for comprehensive face forgery detection in real-world applications. The source code is made available at https://github.com/haotianll/OmniFD.

</details>


### [111] [Real-Time On-the-Go Annotation Framework Using YOLO for Automated Dataset Generation](https://arxiv.org/abs/2512.01165)
*Mohamed Abdallah Salem,Ahmed Harb Rabia*

Main category: cs.CV

TL;DR: 本研究提出了一种利用YOLO模型的实时标注方法，通过评估YOLOv5、YOLOv8和YOLOv12在单类和多类标注、预训练和从零训练下的性能，展示了该方法在标注质量和效率上的优势。


<details>
  <summary>Details</summary>
Motivation: 在农业等需要快速决策的应用场景中，传统的数据标注技术因为需要大量的人工标注而效率低下。本研究旨在利用YOLO模型实现实时自动标注，提高数据准备效率。

Method: 研究利用YOLO模型在边缘设备上实现实时自动标注，并通过对比分析YOLOv5、YOLOv8和YOLOv12在单类和多类标注、预训练和从零训练下的性能。

Result: 统计测试和学习动力学的对比分析表明，预训练和单类配置在模型收敛、性能和鲁棒性方面表现出显著优势。

Conclusion: 研究表明，所提出的方法在保持高标注质量的同时，大大降低了数据准备时间，验证了其实时自动标注框架的有效性。

Abstract: Efficient and accurate annotation of datasets remains a significant challenge for deploying object detection models such as You Only Look Once (YOLO) in real-world applications, particularly in agriculture where rapid decision-making is critical. Traditional annotation techniques are labor-intensive, requiring extensive manual labeling post data collection. This paper presents a novel real-time annotation approach leveraging YOLO models deployed on edge devices, enabling immediate labeling during image capture. To comprehensively evaluate the efficiency and accuracy of our proposed system, we conducted an extensive comparative analysis using three prominent YOLO architectures (YOLOv5, YOLOv8, YOLOv12) under various configurations: single-class versus multi-class annotation and pretrained versus scratch-based training. Our analysis includes detailed statistical tests and learning dynamics, demonstrating significant advantages of pretrained and single-class configurations in terms of model convergence, performance, and robustness. Results strongly validate the feasibility and effectiveness of our real-time annotation framework, highlighting its capability to drastically reduce dataset preparation time while maintaining high annotation quality.

</details>


### [112] [M4-BLIP: Advancing Multi-Modal Media Manipulation Detection through Face-Enhanced Local Analysis](https://arxiv.org/abs/2512.01214)
*Hang Wu,Ke Sun,Jiayi Ji,Xiaoshuai Sun,Rongrong Ji*

Main category: cs.CV

TL;DR: 本文提出了一种名为M4-BLIP的框架，结合BLIP-2模型和局部面部信息，有效识别多模态媒体中的操纵，同时增强检测结果的解释性。


<details>
  <summary>Details</summary>
Motivation: 当前的多模态媒体操纵检测方法往往忽视了局部信息的重要性，而局部改变往往集中在面部等关键区域。因此，提出了M4-BLIP框架来解决这一问题。

Method: M4-BLIP框架基于BLIP-2模型，该模型擅长提取局部特征。通过设计的对齐和融合模块，将局部和全局特征有机结合，从而提高检测准确性。此外，该方法还与大型语言模型（LLM）无缝集成，提高了检测结果的解释性。

Result: 大量的定量和可视化实验证明，M4-BLIP框架在检测多模态媒体操纵方面优于现有最先进的方法。

Conclusion: 本文提出了一种新颖的方法，可以更准确地检测多模态媒体操纵，同时提高了检测结果的可解释性。

Abstract: In the contemporary digital landscape, multi-modal media manipulation has emerged as a significant societal threat, impacting the reliability and integrity of information dissemination. Current detection methodologies in this domain often overlook the crucial aspect of localized information, despite the fact that manipulations frequently occur in specific areas, particularly in facial regions. In response to this critical observation, we propose the M4-BLIP framework. This innovative framework utilizes the BLIP-2 model, renowned for its ability to extract local features, as the cornerstone for feature extraction. Complementing this, we incorporate local facial information as prior knowledge. A specially designed alignment and fusion module within M4-BLIP meticulously integrates these local and global features, creating a harmonious blend that enhances detection accuracy. Furthermore, our approach seamlessly integrates with Large Language Models (LLM), significantly improving the interpretability of the detection outcomes. Extensive quantitative and visualization experiments validate the effectiveness of our framework against the state-of-the-art competitors.

</details>


### [113] [S$^2$-MLLM: Boosting Spatial Reasoning Capability of MLLMs for 3D Visual Grounding with Structural Guidance](https://arxiv.org/abs/2512.01223)
*Beining Xu,Siting Zhu,Zhao Jin,Junxian Li,Hesheng Wang*

Main category: cs.CV

TL;DR: 本文提出了一种高效的框架S$^2$-MLLM，通过利用前向3D重建的结构意识来进行隐式空间推理，从而增强多模态大语言模型在3D视觉定位任务中的空间推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大型语言模型在处理3D场景时主要依赖于二维视觉输入，无法有效理解场景的三维空间结构。本文旨在通过设计一种新的结构增强模块和空间指导策略，提高多模态大语言模型在3D视觉定位任务中的性能。

Method: 提出了一种名为S$^2$-MLLM的框架，该框架通过在训练过程中获取3D结构理解，使模型能够进行隐式空间推理，而无需依赖低效的点云重建。框架包括一个结构增强模块，该模块通过视图内和视图间注意力机制捕捉视图内的依赖关系和跨视图的对应关系，并整合多级位置编码将视觉表示与空间位置和视点信息关联起来。

Result: 在ScanRefer、Nr3D和Sr3D数据集上的实验显示，S$^2$-MLLM在性能、泛化能力和效率方面均超过了现有方法。

Conclusion: S$^2$-MLLM通过隐式空间推理和有效的结构感知模块，提高了多模态大语言模型处理3D视觉定位任务的能力，为该领域的研究提供了新的思路。

Abstract: 3D Visual Grounding (3DVG) focuses on locating objects in 3D scenes based on natural language descriptions, serving as a fundamental task for embodied AI and robotics. Recent advances in Multi-modal Large Language Models (MLLMs) have motivated research into extending them to 3DVG. However, MLLMs primarily process 2D visual inputs and struggle with understanding 3D spatial structure of scenes solely from these limited perspectives. Existing methods mainly utilize viewpoint-dependent rendering of reconstructed point clouds to provide explicit structural guidance for MLLMs in 3DVG tasks, leading to inefficiency and limited spatial reasoning. To address this issue, we propose S$^2$-MLLM, an efficient framework that enhances spatial reasoning in MLLMs through implicit spatial reasoning. We introduce a spatial guidance strategy that leverages the structure awareness of feed-forward 3D reconstruction. By acquiring 3D structural understanding during training, our model can implicitly reason about 3D scenes without relying on inefficient point cloud reconstruction. Moreover, we propose a structure-enhanced module (SE), which first employs intra-view and inter-view attention mechanisms to capture dependencies within views and correspondences across views. The module further integrates multi-level position encoding to associate visual representations with spatial positions and viewpoint information, enabling more accurate structural understanding. Extensive experiments demonstrate that S$^2$-MLLM unifies superior performance, generalization, and efficiency, achieving significant performance over existing methods across the ScanRefer, Nr3D, and Sr3D datasets. Code will be available upon acceptance.

</details>


### [114] [VSRD++: Autolabeling for 3D Object Detection via Instance-Aware Volumetric Silhouette Rendering](https://arxiv.org/abs/2512.01178)
*Zihua Liu,Hiroki Sakuma,Masatoshi Okutomi*

Main category: cs.CV

TL;DR: VSRD++ 提出了一种新颖的弱监督框架，通过多视图自标注和后续单目3D检测器训练的双阶段流程，消除了对3D注释的依赖，利用基于神经场的体绘制和弱2D监督，提升单目3D物体检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有的3D物体检测方法依赖于通过劳动密集型标签过程获取的LiDAR点云中的大量3D注释，而VSRD++通过弱监督解决了这个问题，减少数据标注需求，提高了检测性能。

Method: VSRD++ 方法包含两个阶段：多视图自标注阶段和随后的单目3D检测器训练阶段。在多视图自标注阶段，通过实例感知的体绘制轮廓渲染将物体表面表示为符号距离场（SDF），并生成实例掩码。3D边界框优化时，将每个实例的SDF分解为立方体SDF和残差距离场（RDF）。对于动态物体体积渲染方法中常见的几何不一致性，VSRD++通过将速度纳入边界框属性并分配置信度来建模动态物体。此外，还采用了3D属性初始化模块来初始化动态边界框参数。在单目3D物体检测阶段，优化后的3D边界框被用作单目3D物体检测器训练的伪标签。

Result: 基于KITTI-360数据集的广泛实验表明，VSRD++显著优于现有弱监督方法，无论在静态场景还是动态场景中。同时方法在GitHub上开源。

Conclusion: VSRD++ 通过弱监督改进了单目 3D 物体检测，为减少数据标注成本和提升检测性能提供了新思路。

Abstract: Monocular 3D object detection is a fundamental yet challenging task in 3D scene understanding. Existing approaches heavily depend on supervised learning with extensive 3D annotations, which are often acquired from LiDAR point clouds through labor-intensive labeling processes. To tackle this problem, we propose VSRD++, a novel weakly supervised framework for monocular 3D object detection that eliminates the reliance on 3D annotations and leverages neural-field-based volumetric rendering with weak 2D supervision. VSRD++ consists of a two-stage pipeline: multi-view 3D autolabeling and subsequent monocular 3D detector training. In the multi-view autolabeling stage, object surfaces are represented as signed distance fields (SDFs) and rendered as instance masks via the proposed instance-aware volumetric silhouette rendering. To optimize 3D bounding boxes, we decompose each instance's SDF into a cuboid SDF and a residual distance field (RDF) that captures deviations from the cuboid. To address the geometry inconsistency commonly observed in volume rendering methods applied to dynamic objects, we model the dynamic objects by including velocity into bounding box attributes as well as assigning confidence to each pseudo-label. Moreover, we also employ a 3D attribute initialization module to initialize the dynamic bounding box parameters. In the monocular 3D object detection phase, the optimized 3D bounding boxes serve as pseudo labels for training monocular 3D object detectors. Extensive experiments on the KITTI-360 dataset demonstrate that VSRD++ significantly outperforms existing weakly supervised approaches for monocular 3D object detection on both static and dynamic scenes. Code is available at https://github.com/Magicboomliu/VSRD_plus_plus

</details>


### [115] [TabletopGen: Instance-Level Interactive 3D Tabletop Scene Generation from Text or Single Image](https://arxiv.org/abs/2512.01204)
*Ziqian Wang,Yonghao He,Licheng Yang,Wei Zou,Hongxuan Ma,Liu Liu,Wei Sui,Yuxin Guo,Hu Su*

Main category: cs.CV

TL;DR: TabletopGen是一种无需训练的全自动框架，根据参考图像生成丰富的实例级交互3D桌面场景，显著改进了现有的方法在视觉保真度、布局精度和物理合理性方面的表现。


<details>
  <summary>Details</summary>
Motivation: 当前的3D场景生成方法主要关注大规模场景，难以捕捉桌面场景中的高密度布局和复杂的空间关系。本文提出TabletopGen框架，旨在生成更高质量、更多样性的交互式3D桌面场景，以支持机器人操作策略的学习和数据合成。

Method: TabletopGen框架接受参考图像作为输入，进行实例分割和补全，将每个实例重建为3D模型，并通过规范坐标对齐，进行姿态和比例估计，最后将这些3D模型组装成无碰撞、可模拟的桌面场景。核心创新在于一种新颖的姿态和平比例对齐方法，该方法将复杂的空间推理分解为两个阶段：不同的旋转优化器用于精确的姿态恢复，而俯视图空间对齐机制则用于鲁棒的比例和位置估计。

Result: 大量的实验和用户研究表明，TabletopGen在视觉保真度、布局精度和物理合理性方面大幅超越现有方法，能够生成具有丰富风格和空间多样性的真实桌面场景。

Conclusion: TabletopGen为生成高质量的3D桌面场景提供了一种有效的解决方案，并强调了空间推理在其中的关键作用，未来有望进一步改善框架的效率和灵活性。

Abstract: Generating high-fidelity, physically interactive 3D simulated tabletop scenes is essential for embodied AI--especially for robotic manipulation policy learning and data synthesis. However, current text- or image-driven 3D scene generation methods mainly focus on large-scale scenes, struggling to capture the high-density layouts and complex spatial relations that characterize tabletop scenes. To address these challenges, we propose TabletopGen, a training-free, fully automatic framework that generates diverse, instance-level interactive 3D tabletop scenes. TabletopGen accepts a reference image as input, which can be synthesized by a text-to-image model to enhance scene diversity. We then perform instance segmentation and completion on the reference to obtain per-instance images. Each instance is reconstructed into a 3D model followed by canonical coordinate alignment. The aligned 3D models then undergo pose and scale estimation before being assembled into a collision-free, simulation-ready tabletop scene. A key component of our framework is a novel pose and scale alignment approach that decouples the complex spatial reasoning into two stages: a Differentiable Rotation Optimizer for precise rotation recovery and a Top-view Spatial Alignment mechanism for robust translation and scale estimation, enabling accurate 3D reconstruction from 2D reference. Extensive experiments and user studies show that TabletopGen achieves state-of-the-art performance, markedly surpassing existing methods in visual fidelity, layout accuracy, and physical plausibility, capable of generating realistic tabletop scenes with rich stylistic and spatial diversity. Our code will be publicly available.

</details>


### [116] [Closing the Approximation Gap of Partial AUC Optimization: A Tale of Two Formulations](https://arxiv.org/abs/2512.01213)
*Yangbangyan Jiang,Qianqian Xu,Huiyang Shao,Zhiyong Yang,Shilong Bao,Xiaochun Cao,Qingming Huang*

Main category: cs.CV

TL;DR: 本文提出了一种PAUC优化的方法，通过引入实例级的最小最大重写，降低了算法的时间复杂度，并提供了线性每迭代复杂度。实验结果验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有PAUC优化方法在精度控制和可扩展性方面存在不足。本文旨在解决这一问题，提出了一种新的优化方法，以提高PAUC优化的效率和准确性。

Method: 本文提出了一种实例级的最小最大重写法，首先将问题等价转换为实例级问题，简化样本选择过程，然后使用不同的光滑技术，最终获得具有线性每迭代复杂度和收敛速度为$O(ε^{-1/3})$的高效算法。

Result: 所提出的算法在典型的一向和两向PAUC上都取得了好的性能，示例复杂度为$O(α^{-1}
_+^{-1} + β^{-1}
_-^{-1})$。实验结果表明，该方法在几个基准数据集上的表现优于现有方法。

Conclusion: 本文提出的最小最大重写法为PAUC优化提供了一种更有效的方法，解决了现有方法中难以控制的近似误差和有限的可扩展性问题。

Abstract: As a variant of the Area Under the ROC Curve (AUC), the partial AUC (PAUC) focuses on a specific range of false positive rate (FPR) and/or true positive rate (TPR) in the ROC curve. It is a pivotal evaluation metric in real-world scenarios with both class imbalance and decision constraints. However, selecting instances within these constrained intervals during its calculation is NP-hard, and thus typically requires approximation techniques for practical resolution. Despite the progress made in PAUC optimization over the last few years, most existing methods still suffer from uncontrollable approximation errors or a limited scalability when optimizing the approximate PAUC objectives. In this paper, we close the approximation gap of PAUC optimization by presenting two simple instance-wise minimax reformulations: one with an asymptotically vanishing gap, the other with the unbiasedness at the cost of more variables. Our key idea is to first establish an equivalent instance-wise problem to lower the time complexity, simplify the complicated sample selection procedure by threshold learning, and then apply different smoothing techniques. Equipped with an efficient solver, the resulting algorithms enjoy a linear per-iteration computational complexity w.r.t. the sample size and a convergence rate of $O(ε^{-1/3})$ for typical one-way and two-way PAUCs. Moreover, we provide a tight generalization bound of our minimax reformulations. The result explicitly demonstrates the impact of the TPR/FPR constraints $α$/$β$ on the generalization and exhibits a sharp order of $\tilde{O}(α^{-1}\n_+^{-1} + β^{-1}\n_-^{-1})$. Finally, extensive experiments on several benchmark datasets validate the strength of our proposed methods.

</details>


### [117] [Diffusion Model in Latent Space for Medical Image Segmentation Task](https://arxiv.org/abs/2512.01292)
*Huynh Trinh Ngoc,Toan Nguyen Hai,Ba Luong Son,Long Tran Quoc*

Main category: cs.CV

TL;DR: MedSegLatDiff 是一种结合变分自编码器（VAE）和潜扩散模型的高效医学图像分割框架，可在低维度潜空间中进行去噪和加速训练，并使用加权交叉熵损失改进小结构的保真度。


<details>
  <summary>Details</summary>
Motivation: 传统医学图像分割方法通常会产生单一分割掩码，忽略内在不确定性；而MedSegLatDiff通过结合VAE和潜扩散模型，能够生成多样化的分割假设和置信图，提高模型的可解释性和可靠性，适应用于临床。

Method: MedSegLatDiff 采用了一个基于扩散的框架，该框架基于VAE模型进行降噪和加速训练，并在VAE掩码重构路径中使用加权交叉熵损失以保留细微结构。另外，该框架还采用潜扩散机制直接在低维隐空间中操作。整个框架的评估结果表明其具有对抗其他先进技术的优越表现。

Result: MedSegLatDiff 在 ISIC-2018、CVC-Clinic 和 LIDC-IDRI 数据集上实现了最先进的Dice和IoU评分，同时产生了多样化的分割假设和置信图。

Conclusion: MedSegLatDiff 的提出解决了传统分割方法和基于生成模型方法的计算压力问题，提供了一种高效且高置信度的医学图像分割方案，特别是在小结构保护方面表现优异，适用于临床部署。

Abstract: Medical image segmentation is crucial for clinical diagnosis and treatment planning. Traditional methods typically produce a single segmentation mask, failing to capture inherent uncertainty. Recent generative models enable the creation of multiple plausible masks per image, mimicking the collaborative interpretation of several clinicians. However, these approaches remain computationally heavy. We propose MedSegLatDiff, a diffusion based framework that combines a variational autoencoder (VAE) with a latent diffusion model for efficient medical image segmentation. The VAE compresses the input into a low dimensional latent space, reducing noise and accelerating training, while the diffusion process operates directly in this compact representation. We further replace the conventional MSE loss with weighted cross entropy in the VAE mask reconstruction path to better preserve tiny structures such as small nodules. MedSegLatDiff is evaluated on ISIC-2018 (skin lesions), CVC-Clinic (polyps), and LIDC-IDRI (lung nodules). It achieves state of the art or highly competitive Dice and IoU scores while simultaneously generating diverse segmentation hypotheses and confidence maps. This provides enhanced interpretability and reliability compared to deterministic baselines, making the model particularly suitable for clinical deployment.

</details>


### [118] [FOD-S2R: A FOD Dataset for Sim2Real Transfer Learning based Object Detection](https://arxiv.org/abs/2512.01315)
*Ashish Vashist,Qiranul Saadiyean,Suresh Sundaram,Chandra Sekhar Seelamantula*

Main category: cs.CV

TL;DR: 该研究提出了一种名为FOD-S2R的新数据集，用于检测飞机油箱内异物。该数据集包含真实和合成图像，旨在评估合成数据在提高封闭结构中FOD检测模型性能方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏针对飞机油箱等封闭环境内FOD（外来物）检测的数据集，该研究旨在提供一个包含实际和合成图像的FOD-S2R数据集，以填补这一空白，同时也评估了合成数据对模型性能的提升。

Method: FOD-S2R数据集由真实和合成图像组成。真实图像来自受控油箱复制品，合成图像则使用Unreal Engine生成。该数据集考虑了多种因素，如视场、对象距离、光照条件、颜色和对象大小。使用多种先进的物体检测模型进行基准测试。

Result: 基准研究表明，引入合成数据可以提高检测准确率，增强模型对真实世界条件的泛化能力，缩小了模拟数据与现实之间的差距。

Conclusion: 该研究提出的数据集和实验结果证明了合成数据对提高飞机油箱内FOD检测模型性能的有效性，为开发自动化FOD检测系统奠定了基础。

Abstract: Foreign Object Debris (FOD) within aircraft fuel tanks presents critical safety hazards including fuel contamination, system malfunctions, and increased maintenance costs. Despite the severity of these risks, there is a notable lack of dedicated datasets for the complex, enclosed environments found inside fuel tanks. To bridge this gap, we present a novel dataset, FOD-S2R, composed of real and synthetic images of the FOD within a simulated aircraft fuel tank. Unlike existing datasets that focus on external or open-air environments, our dataset is the first to systematically evaluate the effectiveness of synthetic data in enhancing the real-world FOD detection performance in confined, closed structures. The real-world subset consists of 3,114 high-resolution HD images captured in a controlled fuel tank replica, while the synthetic subset includes 3,137 images generated using Unreal Engine. The dataset is composed of various Field of views (FOV), object distances, lighting conditions, color, and object size. Prior research has demonstrated that synthetic data can reduce reliance on extensive real-world annotations and improve the generalizability of vision models. Thus, we benchmark several state-of-the-art object detection models and demonstrate that introducing synthetic data improves the detection accuracy and generalization to real-world conditions. These experiments demonstrate the effectiveness of synthetic data in enhancing the model performance and narrowing the Sim2Real gap, providing a valuable foundation for developing automated FOD detection systems for aviation maintenance.

</details>


### [119] [PSR: Scaling Multi-Subject Personalized Image Generation with Pairwise Subject-Consistency Rewards](https://arxiv.org/abs/2512.01236)
*Shulei Wang,Longhui Wei,Xin He,Jianbo Ouyang,Hui Lu,Zhou Zhao,Qi Tian*

Main category: cs.CV

TL;DR: 本文提出了一种可扩展的多主题数据生成管道，通过利用强大的单主题生成模型构建高质量的多主题训练数据集，并设计了一套双主题一致性奖励和通用奖励，将其融入到改进的强化学习阶段。该方法在新的基准测试中展示了多主题个性化图像生成的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的单个主题生成模型在扩展到多个主题时，常常在一致性维持和文本控制方面表现不佳，原因是缺乏高质量的多主题数据集和精细的后训练策略。

Method: 本文提出了一种方法，首先利用强大的单主题生成模型构建多主题训练数据集；然后在强化学习阶段中加入双主题一致性奖励和通用奖励以提高主题一致性和文本控制。

Result: 实验结果显示，本文提出的方法在多主题个性化图像生成方面表现出了有效性。

Conclusion: 本文提出了一种系统性的方法来改进多主题个性化图像生成，该方法在新的基准测试中表现出色。

Abstract: Personalized generation models for a single subject have demonstrated remarkable effectiveness, highlighting their significant potential. However, when extended to multiple subjects, existing models often exhibit degraded performance, particularly in maintaining subject consistency and adhering to textual prompts. We attribute these limitations to the absence of high-quality multi-subject datasets and refined post-training strategies. To address these challenges, we propose a scalable multi-subject data generation pipeline that leverages powerful single-subject generation models to construct diverse and high-quality multi-subject training data. Through this dataset, we first enable single-subject personalization models to acquire knowledge of synthesizing multi-image and multi-subject scenarios. Furthermore, to enhance both subject consistency and text controllability, we design a set of Pairwise Subject-Consistency Rewards and general-purpose rewards, which are incorporated into a refined reinforcement learning stage. To comprehensively evaluate multi-subject personalization, we introduce a new benchmark that assesses model performance using seven subsets across three dimensions. Extensive experiments demonstrate the effectiveness of our approach in advancing multi-subject personalized image generation. Github Link: https://github.com/wang-shulei/PSR

</details>


### [120] [Rethinking Intracranial Aneurysm Vessel Segmentation: A Perspective from Computational Fluid Dynamics Applications](https://arxiv.org/abs/2512.01319)
*Feiyang Xiao,Yichi Zhang,Xigui Li,Yuanye Zhou,Chen Jiang,Xin Guo,Limei Han,Yuxin Li,Fengping Zhu,Yuan Cheng*

Main category: cs.CV

TL;DR: 该研究提出了一个针对颅内动脉瘤及其供血动脉的首个多中心标注数据集，涵盖了详细的血流动力学分析结果，并为语义分割方法提供了全面的评价标准。


<details>
  <summary>Details</summary>
Motivation: 当前的分割方法主要基于图像评估指标，缺乏对后续CFD应用的实际效果，因此，研究旨在构建一个既能评估图像分割精确度又能评估CFD应用的多阶段评估标准的数据集。

Method: 该研究创建了IAVS数据集，包含641个3D MRA图像和587个动脉瘤及供血动脉的注释，并建立了一个两阶段的分割框架。更重要的是，该研究开发了一个自动化且一致的将分割掩码转化为CFD模型的系统，确保评估的全面性和可对比性。

Result: 研究人员提出的数据集和评价标准，为开发和评估临床相关的颅内动脉瘤及其供血动脉分割方法提供了有力支持。

Conclusion: 该研究为颅内动脉瘤及其供血动脉的分割方法评估提供了重要工具，有助于提高血流动力学分析的准确性和有效性。

Abstract: The precise segmentation of intracranial aneurysms and their parent vessels (IA-Vessel) is a critical step for hemodynamic analyses, which mainly depends on computational fluid dynamics (CFD). However, current segmentation methods predominantly focus on image-based evaluation metrics, often neglecting their practical effectiveness in subsequent CFD applications. To address this deficiency, we present the Intracranial Aneurysm Vessel Segmentation (IAVS) dataset, the first comprehensive, multi-center collection comprising 641 3D MRA images with 587 annotations of aneurysms and IA-Vessels. In addition to image-mask pairs, IAVS dataset includes detailed hemodynamic analysis outcomes, addressing the limitations of existing datasets that neglect topological integrity and CFD applicability. To facilitate the development and evaluation of clinically relevant techniques, we construct two evaluation benchmarks including global localization of aneurysms (Stage I) and fine-grained segmentation of IA-Vessel (Stage II) and develop a simple and effective two-stage framework, which can be used as a out-of-the-box method and strong baseline. For comprehensive evaluation of applicability of segmentation results, we establish a standardized CFD applicability evaluation system that enables the automated and consistent conversion of segmentation masks into CFD models, offering an applicability-focused assessment of segmentation outcomes. The dataset, code, and model will be public available at https://github.com/AbsoluteResonance/IAVS.

</details>


### [121] [TRivia: Self-supervised Fine-tuning of Vision-Language Models for Table Recognition](https://arxiv.org/abs/2512.01248)
*Junyuan Zhang,Bin Wang,Qintong Zhang,Fan Wu,Zichen Wen,Jialin Lu,Junjie Shan,Ziqi Zhao,Shuya Yang,Ziling Wang,Ziyang Miao,Huaping Zhong,Yuhang Zang,Xiaoyi Dong,Ka-Ho Chow,Conghui He*

Main category: cs.CV

TL;DR: TRivia 是一种无需标注数据即可训练视觉语言模型进行表格识别的方法，通过自动生成多样化问题和自闭环优化机制提升表格识别性能。


<details>
  <summary>Details</summary>
Motivation: 考虑到监督学习依赖大量标注数据的成本问题，TRivia 提供了一种基于自监督学习的方法，利用未标注的数据进行表格识别训练，减少人工标注的需求，特别适用于受隐私法规限制的企业。

Method: TRivia 使用 Group Relative Policy Optimization 的自监督微调方法，通过自动问题回答问答机制生成多样化的问题，并结合注意力机制指导微调过程。这种方法不依赖人工标注，而是通过模型对生成问题的准确回答来优化模型。

Result: 该方法推出开源模型 TRivia-3B，该模型在三个流行的表格识别基准测试上超越了现有的系统（如 Gemini 2.5 Pro、MinerU2.5）。

Conclusion: TRivia 开创性地提出了一个无需人工标注，即能自动优化表格识别模型的新方法，并释放了其开源模型和代码，进一步推动了视觉语言模型在表格识别任务的应用。

Abstract: Table recognition (TR) aims to transform table images into semi-structured representations such as HTML or Markdown. As a core component of document parsing, TR has long relied on supervised learning, with recent efforts dominated by fine-tuning vision-language models (VLMs) using labeled data. While VLMs have brought TR to the next level, pushing performance further demands large-scale labeled data that is costly to obtain. Consequently, although proprietary models have continuously pushed the performance boundary, open-source models, often trained with limited resources and, in practice, the only viable option for many due to privacy regulations, still lag far behind. To bridge this gap, we introduce TRivia, a self-supervised fine-tuning method that enables pretrained VLMs to learn TR directly from unlabeled table images in the wild. Built upon Group Relative Policy Optimization, TRivia automatically identifies unlabeled samples that most effectively facilitate learning and eliminates the need for human annotations through a question-answering-based reward mechanism. An attention-guided module generates diverse questions for each table image, and the ability to interpret the recognition results and answer them correctly provides feedback to optimize the TR model. This closed-loop process allows the TR model to autonomously learn to recognize, structure, and reason over tables without labeled data. Leveraging this pipeline, we present TRivia-3B, an open-sourced, compact, and state-of-the-art TR model that surpasses existing systems (e.g., Gemini 2.5 Pro, MinerU2.5) on three popular benchmarks. Model and code are released at: https://github.com/opendatalab/TRivia

</details>


### [122] [Rice-VL: Evaluating Vision-Language Models for Cultural Understanding Across ASEAN Countries](https://arxiv.org/abs/2512.01419)
*Tushar Pranav,Eshan Pandey,Austria Lyka Diane Bala,Aman Chadha,Indriyati Atmosukarto,Donny Soh Cheng Lock*

Main category: cs.CV

TL;DR: RICE-VL 是一个针对东南亚国家文化的新型基准测试，评估 VLM 的文化理解能力。


<details>
  <summary>Details</summary>
Motivation: 针对现有的视觉-语言模型（VLMs）存在西方文化偏向的问题，研究者开发了 RICE-VL 来评估 VLM 在东南亚文化中的理解能力，以促进其在多元文化地区的应用。

Method: RICE-VL 包含 28,000 个由文化专家注释的真实或假、填空和开放式视觉问答样本，以及 1,000 个带边框的图像配对，用于视觉定位任务。研究者引入了一个新的评估指标 SEA-LAVE，综合考虑文本准确性、文化契合度和国家识别等多个维度。

Result: 研究发现，现有 VLM 在低资源国家和抽象文化领域的表现存在显著差距。视觉定位任务考察模型在复杂场景中识别文化重要元素的能力。

Conclusion: RICE-VL 暴露出 VLM 在文化理解上的不足，强调需要开发更具包容性的人工智能模型以更好地服务于全球多元文化群体。

Abstract: Vision-Language Models (VLMs) excel in multimodal tasks but often exhibit Western-centric biases, limiting their effectiveness in culturally diverse regions like Southeast Asia (SEA). To address this, we introduce RICE-VL, a novel benchmark evaluating VLM cultural understanding across 11 ASEAN countries. RICE-VL includes over 28,000 human-curated Visual Question Answering (VQA) samples -- covering True or False, Fill-in-the-Blank, and open-ended formats -- and 1,000 image-bounding box pairs for Visual Grounding, annotated by culturally informed experts across 14 sub-ground categories. We propose SEA-LAVE, an extension of the LAVE metric, assessing textual accuracy, cultural alignment, and country identification. Evaluations of six open- and closed-source VLMs reveal significant performance gaps in low-resource countries and abstract cultural domains. The Visual Grounding task tests models' ability to localize culturally significant elements in complex scenes, probing spatial and contextual accuracy. RICE-VL exposes limitations in VLMs' cultural comprehension and highlights the need for inclusive model development to better serve diverse global populations.

</details>


### [123] [ViscNet: Vision-Based In-line Viscometry for Fluid Mixing Process](https://arxiv.org/abs/2512.01268)
*Jongwon Sohn,Juhyeon Moon,Hyunjoon Jung,Jaewook Nam*

Main category: cs.CV

TL;DR: 该研究提出了一种基于计算机视觉的粘度计，无需侵入操作且无需严格控制实验室环境。通过固定背景图案在流体表面折射时的光学畸变，实现了粘度的无接触测量。在不同照明条件下，该系统在对数m²s⁻¹单位的回归中达到了0.113的平均绝对误差，并能达到81%的粘度类别预测准确率。


<details>
  <summary>Details</summary>
Motivation: 传统粘度计存在侵入性和需要严格控制实验室环境的问题，为此研究旨在开发一种非侵入、无需严格控制环境的新型粘度测量方法。

Method: 该研究采用计算机视觉技术，通过分析固定背景图案在流体表面折射时的视觉畸变，实现粘度的无接触测量。通过回归模型获取粘度值，并采用多图案策略提高鲁棒性。

Result: 在不同照明条件下，系统实现了0.113的平均绝对误差，并能达到81%的粘度类别预测准确率。多图案策略提高了系统的鲁棒性。

Conclusion: 该研究提出了一种新型粘度测量方法，具有非侵入、无需严格控制环境、可自动化操作等优点，为现有粘度测量方法提供了新的替代方案。

Abstract: Viscosity measurement is essential for process monitoring and autonomous laboratory operation, yet conventional viscometers remain invasive and require controlled laboratory environments that differ substantially from real process conditions. We present a computer-vision-based viscometer that infers viscosity by exploiting how a fixed background pattern becomes optically distorted as light refracts through the mixing-driven, continuously deforming free surface. Under diverse lighting conditions, the system achieves a mean absolute error of 0.113 in log m2 s^-1 units for regression and reaches up to 81% accuracy in viscosity-class prediction. Although performance declines for classes with closely clustered viscosity values, a multi-pattern strategy improves robustness by providing enriched visual cues. To ensure sensor reliability, we incorporate uncertainty quantification, enabling viscosity predictions with confidence estimates. This stand-off viscometer offers a practical, automation-ready alternative to existing viscometry methods.

</details>


### [124] [nnMobileNet++: Towards Efficient Hybrid Networks for Retinal Image Analysis](https://arxiv.org/abs/2512.01273)
*Xin Li,Wenhui Zhu,Xuanzhao Dong,Hao Wang,Yujian Xiong,Oana Dumitrascu,Yalin Wang*

Main category: cs.CV

TL;DR: nnMobileNet++ 是一种混合架构，它将动态蛇形卷积和阶段特定的变压器块与视网膜图像预训练相结合，以提高对长距离依赖性和不规则病灶及血管模式的建模能力，从而实现高准确性和低计算成本。


<details>
  <summary>Details</summary>
Motivation: 传统的纯卷积架构在捕捉视网膜图像中的细长血管模式和不规则病变时存在局限性，这影响了临床诊断的可靠性。nnMobileNet++ 旨在解决这一问题。

Method: nnMobileNet++ 引入了动态蛇形卷积、阶段特定的变压器块和视网膜图像预训练，以促进卷积和变压器表示的逐步结合。

Result: 在多个公开视网膜数据集上的分类实验中，nnMobileNet++ 达到了最先进的或高度竞争的准确性，同时保持了较低的计算成本。

Conclusion: nnMobileNet++ 是一种轻量级且有效的视网膜图像分析框架，具有解决视网膜图像分析领域挑战的潜力。

Abstract: Retinal imaging is a critical, non-invasive modality for the early detection and monitoring of ocular and systemic diseases. Deep learning, particularly convolutional neural networks (CNNs), has significant progress in automated retinal analysis, supporting tasks such as fundus image classification, lesion detection, and vessel segmentation. As a representative lightweight network, nnMobileNet has demonstrated strong performance across multiple retinal benchmarks while remaining computationally efficient. However, purely convolutional architectures inherently struggle to capture long-range dependencies and model the irregular lesions and elongated vascular patterns that characterize on retinal images, despite the critical importance of vascular features for reliable clinical diagnosis. To further advance this line of work and extend the original vision of nnMobileNet, we propose nnMobileNet++, a hybrid architecture that progressively bridges convolutional and transformer representations. The framework integrates three key components: (i) dynamic snake convolution for boundary-aware feature extraction, (ii) stage-specific transformer blocks introduced after the second down-sampling stage for global context modeling, and (iii) retinal image pretraining to improve generalization. Experiments on multiple public retinal datasets for classification, together with ablation studies, demonstrate that nnMobileNet++ achieves state-of-the-art or highly competitive accuracy while maintaining low computational cost, underscoring its potential as a lightweight yet effective framework for retinal image analysis.

</details>


### [125] [Diffusion Fuzzy System: Fuzzy Rule Guided Latent Multi-Path Diffusion Modeling](https://arxiv.org/abs/2512.01533)
*Hailong Yang,Te Zhang,Kup-sze Choi,Zhaohong Deng*

Main category: cs.CV

TL;DR: 本文引入了一种新的扩散模糊系统（DFS），其通过利用多种专门针对不同图像特征的学习路径以及基于规则链的高效协调机制，解决了传统多路径扩散模型在处理具有显著特征差异的图像集合时的不足。


<details>
  <summary>Details</summary>
Motivation: 尽管扩散模型在生成高质量图像方面表现出色，但在处理具有显著特征差异的图像集合时仍存在挑战。

Method: DFS利用多个专门针对不同图像特征的学习路径，并通过基于规则链的推理机制动态指导扩散过程，以实现路径之间的高效协调。此外，DFS还引入了一种基于模糊隶属度的潜在空间压缩机制，以降低多路径扩散模型的计算成本。

Result: 在LSUN Bedroom、LSUN Church和MS COCO三个公开数据集上的实验结果显示，DFS在训练稳定性、收敛速度、图像质量以及文本和图像配准方面优于现有的单路径和多路径扩散模型，并在生成图像与目标参考的准确性上也有所提升。

Conclusion: DFS提供了一种新的解决方案，通过更有效的特征学习和路径协调机制，克服传统多路径扩散模型的不足。

Abstract: Diffusion models have emerged as a leading technique for generating images due to their ability to create high-resolution and realistic images. Despite their strong performance, diffusion models still struggle in managing image collections with significant feature differences. They often fail to capture complex features and produce conflicting results. Research has attempted to address this issue by learning different regions of an image through multiple diffusion paths and then combining them. However, this approach leads to inefficient coordination among multiple paths and high computational costs. To tackle these issues, this paper presents a Diffusion Fuzzy System (DFS), a latent-space multi-path diffusion model guided by fuzzy rules. DFS offers several advantages. First, unlike traditional multi-path diffusion methods, DFS uses multiple diffusion paths, each dedicated to learning a specific class of image features. By assigning each path to a different feature type, DFS overcomes the limitations of multi-path models in capturing heterogeneous image features. Second, DFS employs rule-chain-based reasoning to dynamically steer the diffusion process and enable efficient coordination among multiple paths. Finally, DFS introduces a fuzzy membership-based latent-space compression mechanism to reduce the computational costs of multi-path diffusion effectively. We tested our method on three public datasets: LSUN Bedroom, LSUN Church, and MS COCO. The results show that DFS achieves more stable training and faster convergence than existing single-path and multi-path diffusion models. Additionally, DFS surpasses baseline models in both image quality and alignment between text and images, and also shows improved accuracy when comparing generated images to target references.

</details>


### [126] [Supervised Contrastive Machine Unlearning of Background Bias in Sonar Image Classification with Fine-Grained Explainable AI](https://arxiv.org/abs/2512.01291)
*Kamal Basha S,Athira Nambiar*

Main category: cs.CV

TL;DR: 本文提出了一种新的框架，通过引入Targeted Contrastive Unlearning (TCU) 模块和Unlearn to Explain Sonar Framework (UESF) 模块，以减少海底特征引起的背景偏差，提高模型的泛化能力及解释性。


<details>
  <summary>Details</summary>
Motivation: 现有AI模型在声纳图像分析中过度依赖海底特征，导致泛化能力差。

Method: 本文提出了一个集成Targeted Contrastive Unlearning (TCU) 模块和Unlearn to Explain Sonar Framework (UESF) 模块的新框架。

Result: 实验表明，该方法在真实和合成声纳数据集上都取得了显著提高，提升了去学习的有效性、模型的稳健性和可解释性。

Conclusion: 本文的方法可以有效减少海底特征引起的背景偏差，提高模型的泛化和解释能力，为声纳图像分析提供了新的解决方案。

Abstract: Acoustic sonar image analysis plays a critical role in object detection and classification, with applications in both civilian and defense domains. Despite the availability of real and synthetic datasets, existing AI models that achieve high accuracy often over-rely on seafloor features, leading to poor generalization. To mitigate this issue, we propose a novel framework that integrates two key modules: (i) a Targeted Contrastive Unlearning (TCU) module, which extends the traditional triplet loss to reduce seafloor-induced background bias and improve generalization, and (ii) the Unlearn to Explain Sonar Framework (UESF), which provides visual insights into what the model has deliberately forgotten while adapting the LIME explainer to generate more faithful and localized attributions for unlearning evaluation. Extensive experiments across both real and synthetic sonar datasets validate our approach, demonstrating significant improvements in unlearning effectiveness, model robustness, and interpretability.

</details>


### [127] [Deep Unsupervised Anomaly Detection in Brain Imaging: Large-Scale Benchmarking and Bias Analysis](https://arxiv.org/abs/2512.01534)
*Alexander Frotscher,Christian F. Baumgartner,Thomas Wolfers*

Main category: cs.CV

TL;DR: 本研究通过大规模多中心基准测试了深度无监督异常检测在脑成像中的应用，探索了不同算法在不同类型脑磁共振成像数据上的表现及其在不同方面的稳健性，并提出了未来研究和临床转化的方向。


<details>
  <summary>Details</summary>
Motivation: 当前无监督异常检测算法在脑磁共振成像中存在评估不统一、数据集异质性以及指标不一致的问题，阻碍了向临床应用的转化。因此，本研究旨在通过大规模多中心基准测试，评估不同方法在脑影像上的表现和稳健性，为未来研究和临床转化提供参考。

Method: 本研究构建了一个包含来自六个扫描器的2,976个T1和2,972个T2加权健康个体扫描数据的训练集，92个扫描数据用于参数微调和无偏阈值估计，2,221个T1w和1,262个T2w扫描数据用于验证和测试。研究系统性地评估了不同扫描器、病变类型和大小以及人口统计学（年龄、性别）对重建基方法和特征基方法的影响。

Result: 在所有算法中，基于分割的性能差异较大，依赖扩散的方法具有最强的病变分割性能，而基于特征的方法在分布变化下更具稳健性。然而，大多数算法存在系统性偏差，如扫描器相关差异，导致小和对比度低的病变被遗漏，以及假阳性率因年龄和性别而异。

Conclusion: 健康的训练数据增加对提高算法性能的帮助有限，研究认为这些无监督异常检测框架在算法层面上存在局限性，而不是数据不足。提出了未来研究的方向，包括图像原生预训练、原理上偏差衡量、公平意识建模以及鲁棒领域适应。

Abstract: Deep unsupervised anomaly detection in brain magnetic resonance imaging offers a promising route to identify pathological deviations without requiring lesion-specific annotations. Yet, fragmented evaluations, heterogeneous datasets, and inconsistent metrics have hindered progress toward clinical translation. Here, we present a large-scale, multi-center benchmark of deep unsupervised anomaly detection for brain imaging. The training cohort comprised 2,976 T1 and 2,972 T2-weighted scans from healthy individuals across six scanners, with ages ranging from 6 to 89 years. Validation used 92 scans to tune hyperparameters and estimate unbiased thresholds. Testing encompassed 2,221 T1w and 1,262 T2w scans spanning healthy datasets and diverse clinical cohorts. Across all algorithms, the Dice-based segmentation performance varied between 0.03 and 0.65, indicating substantial variability. To assess robustness, we systematically evaluated the impact of different scanners, lesion types and sizes, as well as demographics (age, sex). Reconstruction-based methods, particularly diffusion-inspired approaches, achieved the strongest lesion segmentation performance, while feature-based methods showed greater robustness under distributional shifts. However, systematic biases, such as scanner-related effects, were observed for the majority of algorithms, including that small and low-contrast lesions were missed more often, and that false positives varied with age and sex. Increasing healthy training data yields only modest gains, underscoring that current unsupervised anomaly detection frameworks are limited algorithmically rather than by data availability. Our benchmark establishes a transparent foundation for future research and highlights priorities for clinical translation, including image native pretraining, principled deviation measures, fairness-aware modeling, and robust domain adaptation.

</details>


### [128] [MasHeNe: A Benchmark for Head and Neck CT Mass Segmentation using Window-Enhanced Mamba with Frequency-Domain Integration](https://arxiv.org/abs/2512.01563)
*Thao Thi Phuong Dao,Tan-Cong Nguyen,Nguyen Chi Thanh,Truong Hoang Viet,Trong-Le Do,Mai-Khiem Tran,Minh-Khoi Pham,Trung-Nghia Le,Minh-Triet Tran,Thanh Dinh Le*

Main category: cs.CV

TL;DR: MasHeNe 是一个专注于头颈部肿瘤和囊肿的初始数据集，通过 WEMF 模型实现了在该数据集上的最佳分割性能，提出了新的挑战并提供了数据集和代码开源。


<details>
  <summary>Details</summary>
Motivation: 现有公共数据集主要关注恶性病变，忽视了其他空间占位性病变，MasHeNe 数据集旨在填补这一空白，提供了一个涵盖多种头颈部占位性病变的数据集，以促进进一步的研究。

Method: MasHeNe 数据集包含了 3,779 张增强CT切片，具有像素级别的注释。提出了一种新的基于 U-shaped Mamba 主干的 WEMF 模型，该模型通过多窗口增强和多频率注意机制提高分割性能。

Result: WEMF 模型在 MasHeNe 数据集上取得了最佳表现，指标包括 Dice 为 70.45%，IoU 为 66.89%，NSD 为 72.33%，HD95 为 5.12 mm。同时，观察到了一些误差模式，表明该任务具有挑战性。

Conclusion: MasHeNe 数据集和 WEMF 模型为头颈部占位性病变的分割任务提供了新的基准，并展示了在这一复杂任务上的稳定和强大的结果。

Abstract: Head and neck masses are space-occupying lesions that can compress the airway and esophagus and may affect nerves and blood vessels. Available public datasets primarily focus on malignant lesions and often overlook other space-occupying conditions in this region. To address this gap, we introduce MasHeNe, an initial dataset of 3,779 contrast-enhanced CT slices that includes both tumors and cysts with pixel-level annotations. We also establish a benchmark using standard segmentation baselines and report common metrics to enable fair comparison. In addition, we propose the Windowing-Enhanced Mamba with Frequency integration (WEMF) model. WEMF applies tri-window enhancement to enrich the input appearance before feature extraction. It further uses multi-frequency attention to fuse information across skip connections within a U-shaped Mamba backbone. On MasHeNe, WEMF attains the best performance among evaluated methods, with a Dice of 70.45%, IoU of 66.89%, NSD of 72.33%, and HD95 of 5.12 mm. This model indicates stable and strong results on this challenging task. MasHeNe provides a benchmark for head-and-neck mass segmentation beyond malignancy-only datasets. The observed error patterns also suggest that this task remains challenging and requires further research. Our dataset and code are available at https://github.com/drthaodao3101/MasHeNe.git.

</details>


### [129] [EGG-Fusion: Efficient 3D Reconstruction with Geometry-aware Gaussian Surfel on the Fly](https://arxiv.org/abs/2512.01296)
*Xiaokun Pan,Zhenzhe Li,Zhichao Ye,Hongjia Zhai,Guofeng Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种名为EGG-Fusion的实时系统，通过引入鲁棒稀疏到稠密的摄像机跟踪和几何感知的Gaussian surfel映射模块，利用基于信息滤波的融合方法来准确地融合传感器噪声，从而实现了高质量的表面重建，并保持了实时处理能力。


<details>
  <summary>Details</summary>
Motivation: 当前不同iable渲染方法在实时计算和传感器噪声敏感性方面面临挑战，导致场景重建中的几何保真度降低。因此，本文旨在通过提出EGG-Fusion系统来解决这些问题，以提高表面重建的质量和实时性。

Method: 该方法采用了基于信息滤波的融合方法，明确考虑传感器噪声，提高精度。同时，通过引进几何感知的Gaussian surfel映射模块，对多视图一致的表面进行有效建模，优化参数提升效率。

Result: 实验结果显示，该系统在标准化基准数据集Replica和ScanNet++上的表面重建误差为0.6cm，比最先进的基于Gaussian surfel的方法提高了20%以上的精度。同时，系统能够保持每秒24帧的实时处理能力。

Conclusion: 本文提出的EGG-Fusion系统为基于不同iable渲染的实时重建系统树立了新的标准，提供了高精度和实时性的统一平台。

Abstract: Real-time 3D reconstruction is a fundamental task in computer graphics. Recently, differentiable-rendering-based SLAM system has demonstrated significant potential, enabling photorealistic scene rendering through learnable scene representations such as Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS). Current differentiable rendering methods face dual challenges in real-time computation and sensor noise sensitivity, leading to degraded geometric fidelity in scene reconstruction and limited practicality. To address these challenges, we propose a novel real-time system EGG-Fusion, featuring robust sparse-to-dense camera tracking and a geometry-aware Gaussian surfel mapping module, introducing an information filter-based fusion method that explicitly accounts for sensor noise to achieve high-precision surface reconstruction. The proposed differentiable Gaussian surfel mapping effectively models multi-view consistent surfaces while enabling efficient parameter optimization. Extensive experimental results demonstrate that the proposed system achieves a surface reconstruction error of 0.6\textit{cm} on standardized benchmark datasets including Replica and ScanNet++, representing over 20\% improvement in accuracy compared to state-of-the-art (SOTA) GS-based methods. Notably, the system maintains real-time processing capabilities at 24 FPS, establishing it as one of the most accurate differentiable-rendering-based real-time reconstruction systems. Project Page: https://zju3dv.github.io/eggfusion/

</details>


### [130] [RoleMotion: A Large-Scale Dataset towards Robust Scene-Specific Role-Playing Motion Synthesis with Fine-grained Descriptions](https://arxiv.org/abs/2512.01582)
*Junran Peng,Yiheng Huang,Silei Shen,Zeji Wei,Jingwei Yang,Baojie Wang,Yonghao He,Chuanchen Luo,Man Zhang,Xucheng Yin,Wei Sui*

Main category: cs.CV

TL;DR: RoleMotion是一个大规模的人体动作数据集，包含了各种角色扮演和功能动作数据，特别针对多种具体场景设计。与现有文本数据集相比，该数据集更注重场景与角色的匹配，包含25种经典场景、110种功能性角色、500多种行为，以及高质体态和手部动作序列，并提供27831个细粒度的文本描述。通过测试和分析各种文本到动作的方法，展示了数据集在文本驱动的整体身体生成方面的高质量和功能。


<details>
  <summary>Details</summary>
Motivation: 现有的文本数据集主要是分散地构建而成，缺乏关联性和功能性，而RoleMotion致力于填补这一空白，通过专门设计和收集数据来更好地服务于特定场景和角色，从而改善生成的质量和实用性。

Method: RoleMotion集成了场景和角色细节，包含了25种经典场景、110种功能性角色、500多种行为，以及超过5000个高质量的人体和手部运动序列，并且附有27831个细粒度的文本描述，用于支持多角色场景的运动生成。数据集还建立了一套更加可靠的评估器，用于检验各种文本到动作方法。

Result: RoleMotion展示了在文本驱动的整体身体生成方面的高质量和功能性。它能够在特定场景和角色之间有效传递动作，证明了与现有方法相比的优势。

Conclusion: RoleMotion作为一个高质量的人体动作数据集，在多角色场景中的应用具有重要意义，能够为改善和优化高级人形虚拟角色的动作生成提供重要支持。

Abstract: In this paper, we introduce RoleMotion, a large-scale human motion dataset that encompasses a wealth of role-playing and functional motion data tailored to fit various specific scenes. Existing text datasets are mainly constructed decentrally as amalgamation of assorted subsets that their data are nonfunctional and isolated to work together to cover social activities in various scenes. Also, the quality of motion data is inconsistent, and textual annotation lacks fine-grained details in these datasets. In contrast, RoleMotion is meticulously designed and collected with a particular focus on scenes and roles. The dataset features 25 classic scenes, 110 functional roles, over 500 behaviors, and 10296 high-quality human motion sequences of body and hands, annotated with 27831 fine-grained text descriptions. We build an evaluator stronger than existing counterparts, prove its reliability, and evaluate various text-to-motion methods on our dataset. Finally, we explore the interplay of motion generation of body and hands. Experimental results demonstrate the high-quality and functionality of our dataset on text-driven whole-body generation.

</details>


### [131] [DCText: Scheduled Attention Masking for Visual Text Generation via Divide-and-Conquer Strategy](https://arxiv.org/abs/2512.01302)
*Jaewoo Song,Jooyoung Choi,Kanghyun Baek,Sangyub Lee,Daemin Park,Sungroh Yoon*

Main category: cs.CV

TL;DR: DCText 是一种无需训练的视觉文本生成方法，采用分而治之策略，通过 Text-Focus 和 Context-Expansion 注意力掩膜以及局部噪声初始化在保持图像质量的同时提升文本生成的准确性。


<details>
  <summary>Details</summary>
Motivation: 尽管当前的文本到图像模型在文本渲染的高保真度方面取得了显著进展，但在处理较长或多个文本时仍存在挑战，尤其是由于全局注意力的稀疏性。DCText 方法通过对多模态扩散变换器中可信的短文本生成进行分而治之，旨在解决这一问题。

Method: DCText 通过将提示符分解为多个区域并针对每个区域分别生成文本，引入了 Text-Focus 和 Context-Expansion 注意力掩膜，以及局部噪声初始化来提升文本生成的准确性并保持图像的一致性。

Result: DCText 在单句和多句基准测试中表现出最高的文本准确性，同时保持了图像质量，并且生成延迟最低。

Conclusion: DCText 通过新颖的方法显著改善了长文本或多文本的图像生成效果，展示了在视觉文本生成领域的一种创新途径。

Abstract: Despite recent text-to-image models achieving highfidelity text rendering, they still struggle with long or multiple texts due to diluted global attention. We propose DCText, a training-free visual text generation method that adopts a divide-and-conquer strategy, leveraging the reliable short-text generation of Multi-Modal Diffusion Transformers. Our method first decomposes a prompt by extracting and dividing the target text, then assigns each to a designated region. To accurately render each segment within their regions while preserving overall image coherence, we introduce two attention masks - Text-Focus and Context-Expansion - applied sequentially during denoising. Additionally, Localized Noise Initialization further improves text accuracy and region alignment without increasing computational cost. Extensive experiments on single- and multisentence benchmarks show that DCText achieves the best text accuracy without compromising image quality while also delivering the lowest generation latency.

</details>


### [132] [Gaussian Swaying: Surface-Based Framework for Aerodynamic Simulation with 3D Gaussians](https://arxiv.org/abs/2512.01306)
*Hongru Yan,Xiang Zhang,Zeyuan Chen,Fangyin Wei,Zhuowen Tu*

Main category: cs.CV

TL;DR: 本文提出了一种基于3D高斯分布的表面框架Gaussian Swaying，用于气动力学模拟，该方法在不依赖复杂网格或离散位置数据的情况下实现了高效的气动力学交互，适用于计算动力学同时提供法线实现轻量级着色。


<details>
  <summary>Details</summary>
Motivation: 当前的气动力学模拟方法，无论是基于网格的还是基于粒子的，都存在一定的局限性，如网格化成本高或位置数据离散等问题。为了克服这些问题并提高模拟性能，本文提出了一种新的方法。

Method: Gaussian Swaying通过使用3D高斯分布来连续建模表面，这种方法可以为动力学计算提供支持，同时提供法线用于轻量级着色。该方法在同一表示上统一了模拟和渲染：高斯片。

Result: 该方法在合成和现实世界数据集上的广泛实验中表现出色，得到了最新的性能和效率，提供了一种可扩展的方法来实现真实的气动场景模拟。

Conclusion: Gaussian Swaying为气动力学模拟提供了一种新的、高效的方法，克服了传统方法的局限性，并提升了模拟的真实性和性能。

Abstract: Branches swaying in the breeze, flags rippling in the wind, and boats rocking on the water all show how aerodynamics shape natural motion -- an effect crucial for realism in vision and graphics. In this paper, we present Gaussian Swaying, a surface-based framework for aerodynamic simulation using 3D Gaussians. Unlike mesh-based methods that require costly meshing, or particle-based approaches that rely on discrete positional data, Gaussian Swaying models surfaces continuously with 3D Gaussians, enabling efficient and fine-grained aerodynamic interaction. Our framework unifies simulation and rendering on the same representation: Gaussian patches, which support force computation for dynamics while simultaneously providing normals for lightweight shading. Comprehensive experiments on both synthetic and real-world datasets across multiple metrics demonstrate that Gaussian Swaying achieves state-of-the-art performance and efficiency, offering a scalable approach for realistic aerodynamic scene simulation.

</details>


### [133] [Envision: Benchmarking Unified Understanding & Generation for Causal World Process Insights](https://arxiv.org/abs/2512.01816)
*Juanxi Tian,Siyuan Li,Conghui He,Lijun Wu,Cheng Tan*

Main category: cs.CV

TL;DR: 本文提出了一种新的基准Envision，以解决当前多模态模型在静态图像生成中的局限性，并引入Envision-Score评估其在因果时间序列上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有模型在处理动态过程中受限于静态单一图像的表现，可能导致模式匹配而非动态世界建模。

Method: 提出了Envision基准，包含1000个四阶段提示，覆盖六个学科领域；并引入Envision-Score，综合了多维度的一致性、物理性和美学，全面评估15个模型。

Result: 结果显示，专门的T2I模型擅长美学渲染但缺乏世界知识；统一的多模态模型表现更好，在因果叙述连贯性上显著优于专门模型。然而，它们在时空一致性上仍受限。

Conclusion: 重心应放在因果上隔离的单个图像上，这阻碍了多帧推理和生成，推广静态模式匹配而不是动态世界建模，最终限制了世界知识的内部化生成。

Abstract: Current multimodal models aim to transcend the limitations of single-modality representations by unifying understanding and generation, often using text-to-image (T2I) tasks to calibrate semantic consistency. However, their reliance on static, single-image generation in training and evaluation leads to overfitting to static pattern matching and semantic fusion, while fundamentally hindering their ability to model dynamic processes that unfold over time. To address these constraints, we propose Envision-a causal event progression benchmark for chained text-to-multi-image generation. Grounded in world knowledge and structured by spatiotemporal causality, it reorganizes existing evaluation dimensions and includes 1,000 four-stage prompts spanning six scientific and humanities domains. To transition evaluation from single images to sequential frames and assess whether models truly internalize world knowledge while adhering to causal-temporal constraints, we introduce Envision-Score, a holistic metric integrating multi-dimensional consistency, physicality, and aesthetics. Comprehensive evaluation of 15 models (10 specialized T2I models, 5 unified models) uncovers: specialized T2I models demonstrate proficiency in aesthetic rendering yet lack intrinsic world knowledge. Unified multimodal models bridge this gap, consistently outperforming specialized counterparts in causal narrative coherence. However, even these unified architectures remain subordinate to closed-source models and struggle to overcome the core challenge of spatiotemporal consistency. This demonstrates that a focus on causally-isolated single images impedes multi-frame reasoning and generation, promoting static pattern matching over dynamic world modeling-ultimately limiting world knowledge internalization, generation.

</details>


### [134] [Lost in Distortion: Uncovering the Domain Gap Between Computer Vision and Brain Imaging - A Study on Pretraining for Age Prediction](https://arxiv.org/abs/2512.01310)
*Yanteng Zhang,Songheng Li,Zeyu Shen,Qizhen Lan,Lipei Zhang,Yang Liu,Vince Calhoun*

Main category: cs.CV

TL;DR: 研究探讨了不同质量级别的神经影像数据在预训练中的作用及其对下游任务的影响，发现性能存在显著差异，强调了领域意识数据整理的重要性。


<details>
  <summary>Details</summary>
Motivation: 探讨预训练模型在不同质量水平的神经影像数据上的表现，以填补计算机视觉和临床神经影像之间的差距，确保领域特定的预训练模型的可信性和泛化能力。

Method: 在具有不同质量水平的数据集上进行预训练，并在外部队列中进行针对大脑年龄预测的微调。

Result: 不同质量级别的数据集上的预训练表现出显著的性能差异。

Conclusion: 强调了高质量数据整理在构建通用且可靠的领域特定预训练模型中的必要性。

Abstract: Large-scale brain imaging datasets provide unprecedented opportunities for developing domain foundation models through pretraining. However, unlike natural image datasets in computer vision, these neuroimaging data often exhibit high heterogeneity in quality, ranging from well-structured scans to severely distorted or incomplete brain volumes. This raises a fundamental question: can noise or low-quality scans contribute meaningfully to pretraining, or do they instead hinder model learning? In this study, we systematically explore the role of data quality level in pretraining and its impact on downstream tasks. Specifically, we perform pretraining on datasets with different quality levels and perform fine-tuning for brain age prediction on external cohorts. Our results show significant performance differences across quality levels, revealing both opportunities and limitations. We further discuss the gap between computer vision practices and clinical neuroimaging standards, emphasizing the necessity of domain-aware curation to ensure trusted and generalizable domain-specific foundation models.

</details>


### [135] [IVCR-200K: A Large-Scale Multi-turn Dialogue Benchmark for Interactive Video Corpus Retrieval](https://arxiv.org/abs/2512.01312)
*Ning Han,Yawen Zeng,Shaohua Long,Chengqing Li,Sijie Yang,Dun Tan,Jianfeng Dong,Jingjing Chen*

Main category: cs.CV

TL;DR: 本文提出了一种新的交互视频语料检索任务（IVCR），采用高质双语多轮对话数据集IVCR-200K及基于多模态大语言模型的框架，旨在实现用户与检索系统的多轮、双向交互。


<details>
  <summary>Details</summary>
Motivation: 当前视频检索和视频片段检索技术已取得长足进展，但缺乏用户与检索系统之间的互动，无法满足高度个性化和动态需求。

Method: 提出了IVCR任务并构建IVCR-200K数据集以及基于多模态大语言模型的交互框架。

Result: IVCR-200K数据集及框架在广泛实验中展现了优异效果。

Conclusion: 本研究为交互式视频检索领域提供了新的工具和思路，有助于提升用户体验。

Abstract: In recent years, significant developments have been made in both video retrieval and video moment retrieval tasks, which respectively retrieve complete videos or moments for a given text query. These advancements have greatly improved user satisfaction during the search process. However, previous work has failed to establish meaningful "interaction" between the retrieval system and the user, and its one-way retrieval paradigm can no longer fully meet the personalization and dynamic needs of at least 80.8\% of users. In this paper, we introduce the Interactive Video Corpus Retrieval (IVCR) task, a more realistic setting that enables multi-turn, conversational, and realistic interactions between the user and the retrieval system. To facilitate research on this challenging task, we introduce IVCR-200K, a high-quality, bilingual, multi-turn, conversational, and abstract semantic dataset that supports video retrieval and even moment retrieval. Furthermore, we propose a comprehensive framework based on multi-modal large language models (MLLMs) to help users interact in several modes with more explainable solutions. The extensive experiments demonstrate the effectiveness of our dataset and framework.

</details>


### [136] [TokenPure: Watermark Removal through Tokenized Appearance and Structural Guidance](https://arxiv.org/abs/2512.01314)
*Pei Yang,Yepeng Liu,Kelly Peng,Yuan Gao,Yiren Song*

Main category: cs.CV

TL;DR: TokenPure是一种利用Diffusion Transformer设计的新型框架，用于有效且一致地去除水印。通过将水marked图像分解为视觉和结构令牌集，TokenPure实现了领先的研究结果。


<details>
  <summary>Details</summary>
Motivation: 随着数字经济的发展，数字水印在证明大量可复制内容的所有权方面变得尤为重要，尤其是在AI生成及其他虚拟资产领域。因此，设计能够抵御各种攻击和处理操作的坚固水印变得更为关键。

Method: TokenPure通过将带水印图像分解为视觉令牌（处理纹理）和结构令牌（处理几何形状），并利用基于令牌的条件重构技术，将任务重新定义为条件生成，以完全绕过初始携带水印的噪声。框架利用这些令牌重新构造图像，从而实现精细粒度的一致性和结构完整性。

Result: 经全面实验表明，TokenPure在视觉质量和一致性方面显著优于现有基线方法，实现了最先进的水印去除和重构保真度。

Conclusion: TokenPure为数字水印的去除提供了一个有效且一致性高的解决方案，为信息安全领域的发展做出重要贡献。

Abstract: In the digital economy era, digital watermarking serves as a critical basis for ownership proof of massive replicable content, including AI-generated and other virtual assets. Designing robust watermarks capable of withstanding various attacks and processing operations is even more paramount. We introduce TokenPure, a novel Diffusion Transformer-based framework designed for effective and consistent watermark removal. TokenPure solves the trade-off between thorough watermark destruction and content consistency by leveraging token-based conditional reconstruction. It reframes the task as conditional generation, entirely bypassing the initial watermark-carrying noise. We achieve this by decomposing the watermarked image into two complementary token sets: visual tokens for texture and structural tokens for geometry. These tokens jointly condition the diffusion process, enabling the framework to synthesize watermark-free images with fine-grained consistency and structural integrity. Comprehensive experiments show that TokenPure achieves state-of-the-art watermark removal and reconstruction fidelity, substantially outperforming existing baselines in both perceptual quality and consistency.

</details>


### [137] [Optimizing Stroke Risk Prediction: A Machine Learning Pipeline Combining ROS-Balanced Ensembles and XAI](https://arxiv.org/abs/2512.01333)
*A S M Ahsanul Sarkar Akib,Raduana Khawla,Abdul Hasib*

Main category: cs.CV

TL;DR: 该研究利用集成学习和可解释AI技术，建立了可解释的机器学习框架以预测中风风险，结果显示模型具有99.09%的准确率。


<details>
  <summary>Details</summary>
Motivation: 早期风险评估对于中风的及时介入和预防策略至关重要，因此需要一个准确且可解释的模型来预测中风风险。

Method: 研究采用了10种不同的机器学习模型，并通过5折交叉验证在多个数据集上进行了评估。模型还通过随机过采样来解决类别不平衡问题，并使用LIME进行了可解释性分析。

Result: 优化后的集成模型（随机森林 + 额外树 + XGBoost）在中风预测数据集上的准确率为99.09%。LIME分析确定了三个重要的临床变量：年龄、高血压和血糖水平。

Conclusion: 研究通过结合集成学习与可解释AI技术，增强了模型的透明度和临床应用性，展示了其在中风预测和心血管风险管理中的潜力。

Abstract: Stroke is a major cause of death and permanent impairment, making it a major worldwide health concern. For prompt intervention and successful preventative tactics, early risk assessment is essential. To address this challenge, we used ensemble modeling and explainable AI (XAI) techniques to create an interpretable machine learning framework for stroke risk prediction. A thorough evaluation of 10 different machine learning models using 5-fold cross-validation across several datasets was part of our all-inclusive strategy, which also included feature engineering and data pretreatment (using Random Over-Sampling (ROS) to solve class imbalance). Our optimized ensemble model (Random Forest + ExtraTrees + XGBoost) performed exceptionally well, obtaining a strong 99.09% accuracy on the Stroke Prediction Dataset (SPD). We improved the model's transparency and clinical applicability by identifying three important clinical variables using LIME-based interpretability analysis: age, hypertension, and glucose levels. Through early prediction, this study highlights how combining ensemble learning with explainable AI (XAI) can deliver highly accurate and interpretable stroke risk assessment. By enabling data-driven prevention and personalized clinical decisions, our framework has the potential to transform stroke prediction and cardiovascular risk management.

</details>


### [138] [GrndCtrl: Grounding World Models via Self-Supervised Reward Alignment](https://arxiv.org/abs/2512.01952)
*Haoyang He,Jay Patrikar,Dong-Ki Kim,Max Smith,Daniel McGann,Ali-akbar Agha-mohammadi,Shayegan Omidshafiei,Sebastian Scherer*

Main category: cs.CV

TL;DR: 该研究提出了一种自监督后训练框架RLWG，通过几何和感知奖励将预先训练的环境模型与物理可验证的结构对齐，增强了导航任务中的空间一致性和长期稳定性。


<details>
  <summary>Details</summary>
Motivation: 虽然现有的大尺度生成模型能够模拟具有高视觉真实感的环境，但它们往往缺乏几何结构，限制了在需要空间连贯性和长时稳定性导航任务中的应用。

Method: RLWG框架通过引入GrndCtrl奖励对齐适应方法，利用群组相对策略优化（GRPO）基于多个可验证奖励（如姿势循环一致性、深度重投影和时间一致性）将预训练的环境模型与物理结构对齐。

Result: GrndCtrl方法实现了具有稳定轨迹、一致几何和可靠运行时模型的环境模型，表现出优于监督微调的空间一致性和导航稳定性。

Conclusion: 该研究通过RLWG框架提升了环境模型在户外导航任务中的性能，证明了自监督后训练框架在生成模型与实际任务结合方面的重要性。

Abstract: Recent advances in video world modeling have enabled large-scale generative models to simulate embodied environments with high visual fidelity, providing strong priors for prediction, planning, and control. Yet, despite their realism, these models often lack geometric grounding, limiting their use in navigation tasks that require spatial coherence and long-horizon stability. We introduce Reinforcement Learning with World Grounding (RLWG), a self-supervised post-training framework that aligns pretrained world models with a physically verifiable structure through geometric and perceptual rewards. Analogous to reinforcement learning from verifiable feedback (RLVR) in language models, RLWG can use multiple rewards that measure pose cycle-consistency, depth reprojection, and temporal coherence. We instantiate this framework with GrndCtrl, a reward-aligned adaptation method based on Group Relative Policy Optimization (GRPO), yielding world models that maintain stable trajectories, consistent geometry, and reliable rollouts for embodied navigation. Like post-training alignment in large language models, GrndCtrl leverages verifiable rewards to bridge generative pretraining and grounded behavior, achieving superior spatial coherence and navigation stability over supervised fine-tuning in outdoor environments.

</details>


### [139] [Visual Sync: Multi-Camera Synchronization via Cross-View Object Motion](https://arxiv.org/abs/2512.02017)
*Shaowei Liu,David Yifan Yao,Saurabh Gupta,Shenlong Wang*

Main category: cs.CV

TL;DR: 本文介绍了一种名为VisualSync的新优化框架，用于无摆造型、未同步视频的毫秒级对齐。


<details>
  <summary>Details</summary>
Motivation: 目前，人们可以使用多种消费者相机记录众多生活中的重要时刻，但跨相机流的同步依然是一个挑战。现有方法假设了受控环境、特定目标、手动校正或昂贵的硬件。因此，本文提出了一种基于多视角动力学的优化框架VisualSync，以实现无摆造型、未同步视频的毫秒级对齐。

Method: 通过结合现有的3D重建、特征匹配和密集跟踪技术，提取轨迹段、相对姿态和跨视角对应关系。针对这些信息，VisualSync提出了联合最小化李波误差的方法来估计每个相机的时间偏移。

Result: 实验表明，在四个多样且具有挑战性的数据集上，VisualSync的方法优于基础方法，平均同步误差低于50毫秒。

Conclusion: 综上，VisualSync成功地解决了跨相机视频的同步问题，达到了毫秒级的对齐效果。

Abstract: Today, people can easily record memorable moments, ranging from concerts, sports events, lectures, family gatherings, and birthday parties with multiple consumer cameras. However, synchronizing these cross-camera streams remains challenging. Existing methods assume controlled settings, specific targets, manual correction, or costly hardware. We present VisualSync, an optimization framework based on multi-view dynamics that aligns unposed, unsynchronized videos at millisecond accuracy. Our key insight is that any moving 3D point, when co-visible in two cameras, obeys epipolar constraints once properly synchronized. To exploit this, VisualSync leverages off-the-shelf 3D reconstruction, feature matching, and dense tracking to extract tracklets, relative poses, and cross-view correspondences. It then jointly minimizes the epipolar error to estimate each camera's time offset. Experiments on four diverse, challenging datasets show that VisualSync outperforms baseline methods, achieving an median synchronization error below 50 ms.

</details>


### [140] [EvalTalker: Learning to Evaluate Real-Portrait-Driven Multi-Subject Talking Humans](https://arxiv.org/abs/2512.01340)
*Yingjie Zhou,Xilei Zhu,Siyu Ren,Ziyi Zhao,Ziwen Wang,Farong Wen,Yu Zhou,Jiezhang Cao,Xiongkuo Min,Fengjiao Chen,Xiaoyu Li,Xuezhi Cao,Guangtao Zhai,Xiaohong Liu*

Main category: cs.CV

TL;DR: 本文介绍了THQA-MT数据集和EvalTalker评估框架，旨在提升多说话人驱动的谈话人物生成质量。


<details>
  <summary>Details</summary>
Motivation: 当前多说话人驱动的谈话人物（Multi-Talker）存在质量下降的问题，影响用户体验，因此需要构建一个高质量的数据集和评估框架来解决这些问题。

Method: 首先，作者构建了一个名为THQA-MT的大规模Multi-Talker生成谈话人物质量评估数据集，包含来自15个代表性Multi-Talker的5,492个生成的谈话人物。然后，他们引入了一个名为EvalTalker的新评估框架，该框架能够感知图像的整体质量、人类特征和身份一致性，并且集成了用于多模态同步感知的Qwen-Sync。

Result: 通过实验证明，EvalTalker与主观评分高度相关，为未来高质量Multi-Talker生成和评估提供了坚实的基础。

Conclusion: 该研究为多说话人驱动的生成技术的评估和改进做出了重要贡献。

Abstract: Speech-driven Talking Human (TH) generation, commonly known as "Talker," currently faces limitations in multi-subject driving capabilities. Extending this paradigm to "Multi-Talker," capable of animating multiple subjects simultaneously, introduces richer interactivity and stronger immersion in audiovisual communication. However, current Multi-Talkers still exhibit noticeable quality degradation caused by technical limitations, resulting in suboptimal user experiences. To address this challenge, we construct THQA-MT, the first large-scale Multi-Talker-generated Talking Human Quality Assessment dataset, consisting of 5,492 Multi-Talker-generated THs (MTHs) from 15 representative Multi-Talkers using 400 real portraits collected online. Through subjective experiments, we analyze perceptual discrepancies among different Multi-Talkers and identify 12 common types of distortion. Furthermore, we introduce EvalTalker, a novel TH quality assessment framework. This framework possesses the ability to perceive global quality, human characteristics, and identity consistency, while integrating Qwen-Sync to perceive multimodal synchrony. Experimental results demonstrate that EvalTalker achieves superior correlation with subjective scores, providing a robust foundation for future research on high-quality Multi-Talker generation and evaluation.

</details>


### [141] [InternVideo-Next: Towards General Video Foundation Models without Video-Text Supervision](https://arxiv.org/abs/2512.01342)
*Chenting Wang,Yuhan Zhu,Yicheng Xu,Jiange Yang,Ziang Yan,Yali Wang,Yi Wang,Limin Wang*

Main category: cs.CV

TL;DR: 该研究提出了InternVideo-Next，通过将传统的编码解码器设计分解为编码器-预测器-解码器（EPD）框架，并采用两级预训练策略，解决了一系列架构问题，从而在保持语义一致性的同时保留细节，为视频表征学习提供了一条可扩展的路径。


<details>
  <summary>Details</summary>
Motivation: 动机在于改善视频预训练模型在封闭且低级任务表现上的不足，通过解决像素级重构和高层次语义抽象之间的冲突，以及缩短学习的问题，提升模型在视频关联任务上的性能。

Method: 该方法首先通过条件扩散解码器（Stage 1）注入可靠的图像级语义先验，增强语义抽象与像素级保真度之间的平衡，然后在Stage 2中通过预测冻结的Stage 1目标，学习隐含的世界知识，减少捷径学习，从而构建一个语义一致性好并且细节保留的潜在空间。

Result: 实验结果表明，InternVideo-Next在多个基准测试上实现了最先进的性能，提供了通用视频表征学习的可扩展路径。

Conclusion: 该研究通过改进视频理解模型的设计，为视频表示学习提供了新的视角和技术路径，特别是在处理复杂的视觉和语义信息方面表现出色。

Abstract: Large-scale video-text pretraining achieves strong performance but depends on noisy, synthetic captions with limited semantic coverage, often overlooking implicit world knowledge such as object motion, 3D geometry, and physical cues. In contrast, masked video modeling (MVM) directly exploits spatiotemporal structures but trails text-supervised methods on general tasks. We find this gap arises from overlooked architectural issues: pixel-level reconstruction struggles with convergence and its low-level requirement often conflicts with semantics, while latent prediction often encourages shortcut learning. To address these, we disentangle the traditional encoder-decoder design into an Encoder-Predictor-Decoder (EPD) framework, where the predictor acts as a latent world model, and propose InternVideo-Next, a two-stage pretraining scheme that builds a semantically consistent yet detail-preserving latent space for this world model. First, conventional linear decoder in pixel MVM enforces the predictor output latent to be linearly projected to, thus separable in pixel space, causing the conflict with semantic abstraction. Our Stage 1 proposes a conditional diffusion decoder and injects reliable image-level semantic priors to enhance semantics and convergence, thus bridging pixel-level fidelity with high-level semantic abstraction. Stage 2 further learns world knowledge by predicting frozen Stage 1 targets within this space, mitigating shortcut learning. Trained on public, unlabeled videos, InternVideo-Next achieves state-of-the-art results across benchmarks and provides a scalable path toward general video representation learning.

</details>


### [142] [Handwritten Text Recognition for Low Resource Languages](https://arxiv.org/abs/2512.01348)
*Sayantan Dey,Alireza Alaei,Partha Pratim Roy*

Main category: cs.CV

TL;DR: 本文介绍了BharatOCR，一种用于手写单字节段Hindi和Urdu文本识别的新颖的分割免费模型。该模型采用了Vision Transformer（ViT）、Transformer解码器和预训练语言模型（LM），并在多个数据集上实现了竞争性的识别率。


<details>
  <summary>Details</summary>
Motivation: 低资源语言的手写文本识别仍面临挑战，特别是Hindi和Urdu等语言。为了应对这些语言在光学字符识别（OCR）中面临的困难，作者开发了BharatOCR以提供更准确的识别结果。

Method: 模型采用Vision Transformer (ViT) 提取视觉特征，Transformer解码器生成文本序列，并通过预训练的Language Model (LM) 提高了识别结果的准确性和流畅性。提出了使用Data-efficient Image Transformer (DeiT) 模型进行掩码图像建模，并采用了优化的RoBERTa架构以增强语言理解和生成能力。

Result: 在自定义数据集（Parimal Urdu和Parimal Hindi）以及两个公开数据集上进行了评估，模型在NUST-UHWR、PUCIT-OUHL和Parimal-Urdu数据集上分别获得了96.24%、92.05%和94.80%的字符识别率；在Hindi数据集上，交得了80.64%的字符识别率。模型的表现优于多个最先进的Urdu文本识别方法。

Conclusion: BharatOCR模型证明了其在处理低资源语言的手写文本识别任务中具有优越的性能。

Abstract: Despite considerable progress in handwritten text recognition, paragraph-level handwritten text recognition, especially in low-resource languages, such as Hindi, Urdu and similar scripts, remains a challenging problem. These languages, often lacking comprehensive linguistic resources, require special attention to develop robust systems for accurate optical character recognition (OCR). This paper introduces BharatOCR, a novel segmentation-free paragraph-level handwritten Hindi and Urdu text recognition. We propose a ViT-Transformer Decoder-LM architecture for handwritten text recognition, where a Vision Transformer (ViT) extracts visual features, a Transformer decoder generates text sequences, and a pre-trained language model (LM) refines the output to improve accuracy, fluency, and coherence. Our model utilizes a Data-efficient Image Transformer (DeiT) model proposed for masked image modeling in this research work. In addition, we adopt a RoBERTa architecture optimized for masked language modeling (MLM) to enhance the linguistic comprehension and generative capabilities of the proposed model. The transformer decoder generates text sequences from visual embeddings. This model is designed to iteratively process a paragraph image line by line, called implicit line segmentation. The proposed model was evaluated using our custom dataset ('Parimal Urdu') and ('Parimal Hindi'), introduced in this research work, as well as two public datasets. The proposed model achieved benchmark results in the NUST-UHWR, PUCIT-OUHL, and Parimal-Urdu datasets, achieving character recognition rates of 96.24%, 92.05%, and 94.80%, respectively. The model also provided benchmark results using the Hindi dataset achieving a character recognition rate of 80.64%. The results obtained from our proposed model indicated that it outperformed several state-of-the-art Urdu text recognition methods.

</details>


### [143] [OpenBox: Annotate Any Bounding Boxes in 3D](https://arxiv.org/abs/2512.01352)
*In-Jae Lee,Mungyeom Kim,Kwonyoung Ryu,Pierre Musacchio,Jaesik Park*

Main category: cs.CV

TL;DR: 该研究提出了OpenBox，一种无需自我训练的两阶段自动注解流水线，通过跨模态实例对齐将2D图像中的实例级线索与对应的3D点云关联起来，然后根据刚性和运动状态对实例进行分类，并生成具有特定类尺寸统计信息的自适应边框。


<details>
  <summary>Details</summary>
Motivation: 目前大部分基于2D基础视觉模型的自动注解方法在注解质量和计算效率上存在不足，尤其是在注解稀疏或者包含惯性和运动状态的对象时。因此，提出一种能够提高注解质量、提升效率且无需自我迭代的注解方法来满足自动驾驶等场景下的需求。

Method: OpenBox采用两阶段方法。第一阶段使用跨模态实例对齐技术将2D图像中的实例信息与3D点云联系起来，第二阶段通过分析实例的刚性和运动状态，生成适应性强、具有特定类尺寸统计信息的边框。

Result: 在Waymo Open Dataset、Lyft Level 5 Perception Dataset和nuScenes数据集上的实验表明，OpenBox方法相较于基线方法，在准确性和效率上均有所提升。

Conclusion: OpenBox证实了一种有效的两阶段自动注解方法，能够显著提高3D对象检测的注解质量与效率，特别适用于自动驾驶等应用。

Abstract: Unsupervised and open-vocabulary 3D object detection has recently gained attention, particularly in autonomous driving, where reducing annotation costs and recognizing unseen objects are critical for both safety and scalability. However, most existing approaches uniformly annotate 3D bounding boxes, ignore objects' physical states, and require multiple self-training iterations for annotation refinement, resulting in suboptimal quality and substantial computational overhead. To address these challenges, we propose OpenBox, a two-stage automatic annotation pipeline that leverages a 2D vision foundation model. In the first stage, OpenBox associates instance-level cues from 2D images processed by a vision foundation model with the corresponding 3D point clouds via cross-modal instance alignment. In the second stage, it categorizes instances by rigidity and motion state, then generates adaptive bounding boxes with class-specific size statistics. As a result, OpenBox produces high-quality 3D bounding box annotations without requiring self-training. Experiments on the Waymo Open Dataset, the Lyft Level 5 Perception dataset, and the nuScenes dataset demonstrate improved accuracy and efficiency over baselines.

</details>


### [144] [BlinkBud: Detecting Hazards from Behind via Sampled Monocular 3D Detection on a Single Earbud](https://arxiv.org/abs/2512.01366)
*Yunzhe Li,Jiajun Yan,Yuzhou Wei,Kechen Liu,Yize Zhao,Chong Zhang,Hongzi Zhu,Li Lu,Shan Chang,Minyi Guo*

Main category: cs.CV

TL;DR: BlinkBud 是一种利用耳塞和手机来在线检测用户身后危险物体的系统。通过结合卡尔曼滤波轨迹估计方案和基于强化学习的图像采样优化策略，该系统能够实现低功耗下的高效3D物体跟踪，并通过头部运动补偿提高跟踪准确性。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决行人和骑行者面临的后方来车速度感知不足的问题，以提升道路安全。

Method: BlinkBud系统通过耳塞和手机配合，利用小数量的耳塞相机拍摄图像，结合卡尔曼滤波器轨迹估计和基于强化学习的最优图像采样策略，实现低功耗下高效的3D目标跟踪，并通过头部运动的估计值进行深度和坐标系统的校正，提高跟踪准确性。

Result: BlinkBud系统原型实现了轻量级设计，耳塞和手机的平均功耗分别为29.8毫瓦和702.6毫瓦，同时具有较低的假阳性率为4.90%，和假阴性率为1.47%的准确检测性能。

Conclusion: BlinkBud系统能够在低功耗条件下有效检测身后危险，适用于提升行人与骑行者的道路安全。

Abstract: Failing to be aware of speeding vehicles approaching from behind poses a huge threat to the road safety of pedestrians and cyclists. In this paper, we propose BlinkBud, which utilizes a single earbud and a paired phone to online detect hazardous objects approaching from behind of a user. The core idea is to accurately track visually identified objects utilizing a small number of sampled camera images taken from the earbud. To minimize the power consumption of the earbud and the phone while guaranteeing the best tracking accuracy, a novel 3D object tracking algorithm is devised, integrating both a Kalman filter based trajectory estimation scheme and an optimal image sampling strategy based on reinforcement learning. Moreover, the impact of constant user head movements on the tracking accuracy is significantly eliminated by leveraging the estimated pitch and yaw angles to correct the object depth estimation and align the camera coordinate system to the user's body coordinate system, respectively. We implement a prototype BlinkBud system and conduct extensive real-world experiments. Results show that BlinkBud is lightweight with ultra-low mean power consumptions of 29.8 mW and 702.6 mW on the earbud and smartphone, respectively, and can accurately detect hazards with a low average false positive ratio (FPR) and false negative ratio (FNR) of 4.90% and 1.47%, respectively.

</details>


### [145] [SRAM: Shape-Realism Alignment Metric for No Reference 3D Shape Evaluation](https://arxiv.org/abs/2512.01373)
*Sheng Liu,Tianyu Luan,Phani Nuney,Xuelu Feng,Junsong Yuan*

Main category: cs.CV

TL;DR: 提出了一种新的3D形状真实度评价方法，利用大型语言模型将3D形状编码并与人类真实感知对齐，同时构建了一个新的现实评分数据集，该方法在不同物体上的表现良好。


<details>
  <summary>Details</summary>
Motivation: 传统的真实度评估依赖于真实的地面参考，但在很多实际情况下，真实度不依赖于真实参考。为解决这一问题，文中提出了一种借助大型语言模型来评价3D形状真实度的方法。

Method: 通过将3D形状编码为语言标记空间中的形式，并设计一个专门的真实感解码器来调整大型语言模型的输出，使模型的输出与人类对真实感的感知相匹配。同时提出了一个名为RealismGrading的新数据集，该数据集包含由多种算法在多个物体上生成的3D形状，并由人类打分。

Result: 实验结果显示，该方法与人类感知的真实度高度相关，并且优于现有的方法，证明其具有良好的泛化能力。

Conclusion: 该工作提出的方法为3D形状的真实度评价提供了一种新的有效手段，特别适用于没有真实参考的情况下。

Abstract: 3D generation and reconstruction techniques have been widely used in computer games, film, and other content creation areas. As the application grows, there is a growing demand for 3D shapes that look truly realistic. Traditional evaluation methods rely on a ground truth to measure mesh fidelity. However, in many practical cases, a shape's realism does not depend on having a ground truth reference. In this work, we propose a Shape-Realism Alignment Metric that leverages a large language model (LLM) as a bridge between mesh shape information and realism evaluation. To achieve this, we adopt a mesh encoding approach that converts 3D shapes into the language token space. A dedicated realism decoder is designed to align the language model's output with human perception of realism. Additionally, we introduce a new dataset, RealismGrading, which provides human-annotated realism scores without the need for ground truth shapes. Our dataset includes shapes generated by 16 different algorithms on over a dozen objects, making it more representative of practical 3D shape distributions. We validate our metric's performance and generalizability through k-fold cross-validation across different objects. Experimental results show that our metric correlates well with human perceptions and outperforms existing methods, and has good generalizability.

</details>


### [146] [Textured Geometry Evaluation: Perceptual 3D Textured Shape Metric via 3D Latent-Geometry Network](https://arxiv.org/abs/2512.01380)
*Tianyu Luan,Xuelu Feng,Zixin Zhu,Phani Nuney,Sheng Liu,Xuan Gong,David Doermann,Chunming Qiao,Junsong Yuan*

Main category: cs.CV

TL;DR: 本文提出了一种名为Textured Geometry Evaluation (TGE) 的新评价方法，旨在直接基于3D网格和纹理信息来评估3D模型的保真度，而无需渲染。实验结果表明，TGE 在现实世界扭曲数据集上的表现优于基于渲染和仅几何的方法。


<details>
  <summary>Details</summary>
Motivation: 现有的3D模型保真度评估方法存在难以与人类评估一致、渲染依赖性强、对视点敏感以及训练数据与现实场景不符等问题。本文提出的新方法旨在改进这些问题。

Method: TGE 方法直接使用几何和颜色信息来计算输入纹理网格与参考彩色形状之间的保真度。该方法通过设计包含真实场景扭曲的人工标注数据集进行训练和评估。

Result: 实验表明，TGE 在处理现实世界中的扭曲时，优于基于渲染的方法和仅几何的方法。

Conclusion: TGE 是一种创新的3D模型保真度评估方法，可以更真实地反映现实世界的扭曲情况，从而提高了评估的准确性和实用性。

Abstract: Textured high-fidelity 3D models are crucial for games, AR/VR, and film, but human-aligned evaluation methods still fall behind despite recent advances in 3D reconstruction and generation. Existing metrics, such as Chamfer Distance, often fail to align with how humans evaluate the fidelity of 3D shapes. Recent learning-based metrics attempt to improve this by relying on rendered images and 2D image quality metrics. However, these approaches face limitations due to incomplete structural coverage and sensitivity to viewpoint choices. Moreover, most methods are trained on synthetic distortions, which differ significantly from real-world distortions, resulting in a domain gap. To address these challenges, we propose a new fidelity evaluation method that is based directly on 3D meshes with texture, without relying on rendering. Our method, named Textured Geometry Evaluation TGE, jointly uses the geometry and color information to calculate the fidelity of the input textured mesh with comparison to a reference colored shape. To train and evaluate our metric, we design a human-annotated dataset with real-world distortions. Experiments show that TGE outperforms rendering-based and geometry-only methods on real-world distortion dataset.

</details>


### [147] [Reversible Inversion for Training-Free Exemplar-guided Image Editing](https://arxiv.org/abs/2512.01382)
*Yuke Li,Lianli Gao,Ji Zhang,Pengpeng Zeng,Lichuan Xiang,Hongkai Wen,Heng Tao Shen,Jingkuan Song*

Main category: cs.CV

TL;DR: 该研究提出了一种新的ReInversion方法，通过两阶段去噪过程和掩码引导的选择性去噪策略，实现高质量且高效的示例引导的图像编辑。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过大规模预训练来学习源图像和参考图像之间的关系，计算成本高。为了提供一种无需训练的方法，研究引入了ReInversion方法来改善示例引导的图像编辑效果。

Method: ReInversion方法采用两阶段去噪过程，首先条件化在源图像上，然后在参考图像上。此外，引入了掩码引导的选择性去噪策略，限制编辑仅在目标区域进行，从而保持背景结构的一致性。

Result: 实验结果表明，ReInversion方法在定性和定量比较上均表现优异，达到了最先进的示例引导图像编辑性能，并且具有最低的计算开销。

Conclusion: 该研究改进了示例引导的图像编辑方法，通过创新的去噪策略和掩码引导技术，实现了高质量和高效编辑的效果。

Abstract: Exemplar-guided Image Editing (EIE) aims to modify a source image according to a visual reference. Existing approaches often require large-scale pre-training to learn relationships between the source and reference images, incurring high computational costs. As a training-free alternative, inversion techniques can be used to map the source image into a latent space for manipulation. However, our empirical study reveals that standard inversion is sub-optimal for EIE, leading to poor quality and inefficiency. To tackle this challenge, we introduce \textbf{Reversible Inversion ({ReInversion})} for effective and efficient EIE. Specifically, ReInversion operates as a two-stage denoising process, which is first conditioned on the source image and subsequently on the reference. Besides, we introduce a Mask-Guided Selective Denoising (MSD) strategy to constrain edits to target regions, preserving the structural consistency of the background. Both qualitative and quantitative comparisons demonstrate that our ReInversion method achieves state-of-the-art EIE performance with the lowest computational overhead.

</details>


### [148] [MDiff4STR: Mask Diffusion Model for Scene Text Recognition](https://arxiv.org/abs/2512.01422)
*Yongkun Du,Miaomiao Zhao,Songlin Fan,Zhineng Chen,Caiyan Jia,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: 该研究引入了Mask Diffusion Models (MDMs)到场景文本识别（STR）任务中，通过针对性改进策略解决了MDMs在训练与推理之间差异以及推理时过于自信的问题，提高了模型性能和效率。


<details>
  <summary>Details</summary>
Motivation: 随着Mask Diffusion Models (MDMs)作为自动回归模型 (ARMs) 的一种灵活替代方案在视觉语言任务中的出现，该研究旨在将MDMs应用于场景文本识别任务，探索其在该领域的优势和改进空间。

Method: 研究不仅指出了MDMs在STR任务中的局限性，还提出了两种针对性的改进策略：六种更好地将训练与推理行为对齐的噪声策略，以及一种促进模型重新评估过于自信预测的标记替换噪声机制。并通过在标准和具有挑战性的STR基准上进行广泛的评估来验证这些改进的效果。

Result: 实验结果表明，MDiff4STR在大多数情况下超越了流行的STR模型及最新的自动回归模型，在准确性上超过了最先进的模型，同时保持了快速推理，仅需三次去噪步骤。

Conclusion: 该研究提出的MDiff4STR在场景文本识别任务中展示出了显著的优势，极大地提升了模型的性能和效率，为未来的工作提供了宝贵的参考。

Abstract: Mask Diffusion Models (MDMs) have recently emerged as a promising alternative to auto-regressive models (ARMs) for vision-language tasks, owing to their flexible balance of efficiency and accuracy. In this paper, for the first time, we introduce MDMs into the Scene Text Recognition (STR) task. We show that vanilla MDM lags behind ARMs in terms of accuracy, although it improves recognition efficiency. To bridge this gap, we propose MDiff4STR, a Mask Diffusion model enhanced with two key improvement strategies tailored for STR. Specifically, we identify two key challenges in applying MDMs to STR: noising gap between training and inference, and overconfident predictions during inference. Both significantly hinder the performance of MDMs. To mitigate the first issue, we develop six noising strategies that better align training with inference behavior. For the second, we propose a token-replacement noise mechanism that provides a non-mask noise type, encouraging the model to reconsider and revise overly confident but incorrect predictions. We conduct extensive evaluations of MDiff4STR on both standard and challenging STR benchmarks, covering diverse scenarios including irregular, artistic, occluded, and Chinese text, as well as whether the use of pretraining. Across these settings, MDiff4STR consistently outperforms popular STR models, surpassing state-of-the-art ARMs in accuracy, while maintaining fast inference with only three denoising steps. Code: https://github.com/Topdu/OpenOCR.

</details>


### [149] [\textit{ViRectify}: A Challenging Benchmark for Video Reasoning Correction with Multimodal Large Language Models](https://arxiv.org/abs/2512.01424)
*Xusen Hei,Jiali Chen,Jinyu Yang,Mengchen Zhao,Yi Cai*

Main category: cs.CV

TL;DR: 文章提出了一个名为ViRectify的基准，用于评估大型多模态语言模型在视频推理错误识别和纠正能力上的微调性能。通过AI辅助注释流程和人工验证构建了超过30K实例的多模态数据集。评价结果显示，ViRectify是具有挑战性的测试平台，尤其是对于视频推理错误纠正，显示出显著的效果。


<details>
  <summary>Details</summary>
Motivation: 现有的基准无法系统地评估多模态大型语言模型在视频推理中的错误识别和纠正能力。因此，开发ViRectify以填补这一空白，提供一个评估这些模型复杂视频推理错误的新基准。

Method: 通过结合AI辅助注释和人工验证手段，构建了一个跨越动态感知、科学推理和体感决策领域的大规模数据集。提出了轨迹证据驱动的纠正框架，包含逐步错误轨迹和基于视觉证据的奖励建模。

Result: 在16种先进的多模态大型语言模型上进行了广泛的评估，结果表明ViRectify是一个具有挑战性的测试平台，GPT-5的纠正准确率仅为31.94%。我们的框架使Qwen2.5-VL-7B在ViRectify上的一致表现优于72B的变体，显示出方法的有效性。

Conclusion: ViRectify为全面评估高级大型多模态模型在视频推理中的错误纠正提供了新方向，揭示了模型在错误纠正方面的系统不对称性。

Abstract: As multimodal large language models (MLLMs) frequently exhibit errors in complex video reasoning scenarios, correcting these errors is critical for uncovering their weaknesses and improving performance. However, existing benchmarks lack systematic evaluation of MLLMs' ability to identify and correct these video reasoning errors. To bridge this gap, we propose \textit{ViRectify}, a comprehensive benchmark to evaluate their fine-grained correction capability. Through an AI-assisted annotation pipeline with human verification, we construct a dataset of over 30\textit{K} instances spanning dynamic perception, scientific reasoning, and embodied decision-making domains. In \textit{ViRectify}, we challenge MLLMs to perform step-wise error identification and generate rationales with key video evidence grounding. In addition, we further propose the trajectory evidence-driven correction framework, comprising step-wise error trajectory and reward modeling on visual evidence-grounded correction. It encourages the model to explicitly concentrate on error propagation and key timestamps for correction. Extensive evaluation across 16 advanced MLLMs demonstrates that our \textit{ViRectify} serves as a challenging testbed, where GPT-5 achieves only 31.94\% correction accuracy. Our framework enables a Qwen2.5-VL-7B to consistently outperform the variants of 72B on \textit{ViRectify}, showing the effectiveness of our approach. Further analysis uncovers systematic asymmetries in error correction across models, and our dataset is also a valuable data resource to perform reflection learning. We believe \textit{ViRectify} provides a new direction for comprehensively evaluating the advanced MLLMs in video reasoning.

</details>


### [150] [ResDiT: Evoking the Intrinsic Resolution Scalability in Diffusion Transformers](https://arxiv.org/abs/2512.01426)
*Yiyang Ma,Feng Zhou,Xuedan Yin,Pu Cao,Yonghao Dang,Jianqin Yin*

Main category: cs.CV

TL;DR: ResDiT 是一种无需训练的方法，通过调整位置嵌入和局部增强机制来提高高分辨率图像生成的质量，从而实现高质量的高分辨率图像合成，并与后续任务无缝集成。


<details>
  <summary>Details</summary>
Motivation: 现有方法在高分辨率图像合成时存在空间布局崩溃和纹理保真度下降的问题。ResDiT 旨在通过修正位置嵌入和引入局部增强机制来解决这些问题，提高合成图像的质量。

Method: ResDiT 通过调整位置嵌入（特别是解决了高分辨率时的位置编码问题）和引入局部增强机制（基于低分辨率局部注意的局部增益）来进行高分辨率图像合成。此外，还设计了一个基于补丁级别的融合模块和高斯加权拼接策略来消除网格伪影。

Result: 通过 ResDiT 的优化，高分辨率图像的合成质量得到了提升，包括高保真的细节和无伪影的效果。方法还证明了与下游任务的兼容性和良好集成。

Conclusion: ResDiT 展现了在不依赖训练的情况下高效提升高分辨率图像合成质量的潜力，为该领域的进一步研究提供了新的思路。

Abstract: Leveraging pre-trained Diffusion Transformers (DiTs) for high-resolution (HR) image synthesis often leads to spatial layout collapse and degraded texture fidelity. Prior work mitigates these issues with complex pipelines that first perform a base-resolution (i.e., training-resolution) denoising process to guide HR generation. We instead explore the intrinsic generative mechanisms of DiTs and propose ResDiT, a training-free method that scales resolution efficiently. We identify the core factor governing spatial layout, position embeddings (PEs), and show that the original PEs encode incorrect positional information when extrapolated to HR, which triggers layout collapse. To address this, we introduce a PE scaling technique that rectifies positional encoding under resolution changes. To further remedy low-fidelity details, we develop a local-enhancement mechanism grounded in base-resolution local attention. We design a patch-level fusion module that aggregates global and local cues, together with a Gaussian-weighted splicing strategy that eliminates grid artifacts. Comprehensive evaluations demonstrate that ResDiT consistently delivers high-fidelity, high-resolution image synthesis and integrates seamlessly with downstream tasks, including spatially controlled generation.

</details>


### [151] [Language-Guided Open-World Anomaly Segmentation](https://arxiv.org/abs/2512.01427)
*Klara Reichard,Nikolas Brasch,Nassir Navab,Federico Tombari*

Main category: cs.CV

TL;DR: 本文提出了一种基于CLIP的开集和异常分割方法Clipomaly，能够在不进行特定于异常类别的训练数据的情况下，实现未知对象的分割和赋予其可解释的名称。


<details>
  <summary>Details</summary>
Motivation: 现有的开放世界和异常分割方法未能为未知区域赋予语义意义的标签，且难以区分和学习未知类别的表示。Clipomaly旨在解决这些问题，通过利用CLIP的共享图像-文本嵌入空间实现未知对象的分割，并赋予其可解释的名称。

Method: Clipomaly方法利用CLIP的多模态嵌入能力，无需特定于异常类别的训练数据，能够在零样本情况下进行未知对象的分割，并动态扩展其词汇量以适应新的异常类别。这种方法提供了对异常对象的鲁棒检测和命名。

Result: Clipomaly在已有的异常分割基准上达到了最先进的性能，同时提供了对异常检测和命名的可解释性和灵活性，这对于实际部署至关重要。

Conclusion: 本文提出的Clipomaly方法为开放世界和异常分割领域提供了一种新颖解决方案，具备较强的泛化能力和灵活性，是对现有方法的补充和完善。

Abstract: Open-world and anomaly segmentation methods seek to enable autonomous driving systems to detect and segment both known and unknown objects in real-world scenes. However, existing methods do not assign semantically meaningful labels to unknown regions, and distinguishing and learning representations for unknown classes remains difficult. While open-vocabulary segmentation methods show promise in generalizing to novel classes, they require a fixed inference vocabulary and thus cannot be directly applied to anomaly segmentation where unknown classes are unconstrained. We propose Clipomaly, the first CLIP-based open-world and anomaly segmentation method for autonomous driving. Our zero-shot approach requires no anomaly-specific training data and leverages CLIP's shared image-text embedding space to both segment unknown objects and assign human-interpretable names to them. Unlike open-vocabulary methods, our model dynamically extends its vocabulary at inference time without retraining, enabling robust detection and naming of anomalies beyond common class definitions such as those in Cityscapes. Clipomaly achieves state-of-the-art performance on established anomaly segmentation benchmarks while providing interpretability and flexibility essential for practical deployment.

</details>


### [152] [FastAnimate: Towards Learnable Template Construction and Pose Deformation for Fast 3D Human Avatar Animation](https://arxiv.org/abs/2512.01444)
*Jian Shu,Nanjie Yao,Gangjian Zhang,Junlong Ren,Yu Feng,Hao Wang*

Main category: cs.CV

TL;DR: 该研究提出了一种基于学习的统一框架来解决3D人体姿态动画中的模板构造和姿态变形问题，通过U-Net架构快速生成模板并在后续阶段采用数据驱动的精细化技术提升结构完整性。


<details>
  <summary>Details</summary>
Motivation: 当前方法在模板构造和姿态变形上存在效率低、特定姿态出现瑕疵及LBS造成的结构失真等问题，影响动画的真实感。

Method: 采用U-Net架构进行前一阶段的模板生成，解决纹理和姿态信息分离与快速生成的问题；在后一阶段利用数据驱动的细化技术提升结构完整性。

Result: 实验表明该模型在各种姿态下表现均衡，效率与质量兼备，优于最新的基准方法。

Conclusion: 该研究提出的方法能够有效地生成高质量的3D人体模板并进行姿态变形，提高了动画的真实性和整体效果。

Abstract: 3D human avatar animation aims at transforming a human avatar from an arbitrary initial pose to a specified target pose using deformation algorithms. Existing approaches typically divide this task into two stages: canonical template construction and target pose deformation. However, current template construction methods demand extensive skeletal rigging and often produce artifacts for specific poses. Moreover, target pose deformation suffers from structural distortions caused by Linear Blend Skinning (LBS), which significantly undermines animation realism. To address these problems, we propose a unified learning-based framework to address both challenges in two phases. For the former phase, to overcome the inefficiencies and artifacts during template construction, we leverage a U-Net architecture that decouples texture and pose information in a feed-forward process, enabling fast generation of a human template. For the latter phase, we propose a data-driven refinement technique that enhances structural integrity. Extensive experiments show that our model delivers consistent performance across diverse poses with an optimal balance between efficiency and quality,surpassing state-of-the-art (SOTA) methods.

</details>


### [153] [ChronosObserver: Taming 4D World with Hyperspace Diffusion Sampling](https://arxiv.org/abs/2512.01481)
*Qisen Wang,Yifan Zhao,Peisen Shen,Jialu Li,Jia Li*

Main category: cs.CV

TL;DR: ChronosObserver是一种无需训练的方法，通过World State Hyperspace表示4D世界的时空约束，并使用Hyperspace Guided Sampling同步多视图的扩散采样轨迹，从而生成高质量、3D一致的时间同步多视图视频。


<details>
  <summary>Details</summary>
Motivation: 现有的基于相机控制的视频生成模型可以生成电影级的效果，但在生成3D一致和高保真的时间同步多视图视频方面仍存在挑战。文章提出了ChronosObserver方法来解决这一问题。

Method: ChronosObserver包含World State Hyperspace表示4D世界的时空约束，以及Hyperspace Guided Sampling同步多视图的扩散采样轨迹。

Result: ChronosObserver方法在不进行扩散模型训练或微调的情况下，能够生成高质量和3D一致的时间同步多视图视频。

Conclusion: ChronosObserver为处理4D世界提供了一种无需训练的方法，并展示了其在生成高质量多视图视频方面的潜力。

Abstract: Although prevailing camera-controlled video generation models can produce cinematic results, lifting them directly to the generation of 3D-consistent and high-fidelity time-synchronized multi-view videos remains challenging, which is a pivotal capability for taming 4D worlds. Some works resort to data augmentation or test-time optimization, but these strategies are constrained by limited model generalization and scalability issues. To this end, we propose ChronosObserver, a training-free method including World State Hyperspace to represent the spatiotemporal constraints of a 4D world scene, and Hyperspace Guided Sampling to synchronize the diffusion sampling trajectories of multiple views using the hyperspace. Experimental results demonstrate that our method achieves high-fidelity and 3D-consistent time-synchronized multi-view videos generation without training or fine-tuning for diffusion models.

</details>


### [154] [A variational method for curve extraction with curvature-dependent energies](https://arxiv.org/abs/2512.01494)
*Majid Arthaud,Antonin Chambolle,Vincent Duval*

Main category: cs.CV

TL;DR: 该研究提出了一种变分方法，用于从一张图像中自动提取曲线和1D结构，通过离散化能量和Smirnov的向量场分解定理，结合曲率依赖的能量，增强方法的适应性。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一种高效的、自动化的图像分析方法，能够从大量图像中提取复杂的1D结构信息，减少人工干预的需求。

Method: 研究采用了变分方法，结合了Smirnov的向量场分解定理和曲率依赖的能量函数，引入了两层优化框架，即首先通过最小化基础能量函数自动寻找可能的终点，接着通过考虑曲率因素来优化曲线。

Result: 通过这种方法，研究者能够从图像中高效准确地提取出复杂的1D结构，实现了算法的自动运行，且无需大量监督数据。

Conclusion: 该方法在处理具有复杂1D特征的图像时表现出色，特别是在不要求高度精确叠加和噪声容忍度方面展现了优势。

Abstract: We introduce a variational approach for extracting curves between a list of possible endpoints, based on the discretization of an energy and Smirnov's decomposition theorem for vector fields. It is used to design a bi-level minimization approach to automatically extract curves and 1D structures from an image, which is mostly unsupervised. We extend then the method to curvature-dependent energies, using a now classical lifting of the curves in the space of positions and orientations equipped with an appropriate sub-Riemanian or Finslerian metric.

</details>


### [155] [QuantumCanvas: A Multimodal Benchmark for Visual Learning of Atomic Interactions](https://arxiv.org/abs/2512.01519)
*Can Polat,Erchin Serpedin,Mustafa Kurban,Hasan Kurban*

Main category: cs.CV

TL;DR: QuantumCanvas 提供了一种新的基准，用于评估分子和材料机器学习模型在理解量子两体相互作用方面的表现，并展示了如何通过结合电子轨道物理和基于视觉的表示学习来学习可转移的量子相互作用。


<details>
  <summary>Details</summary>
Motivation: 当前大多数机器学习模型在处理分子和晶体时，关注的是整体的分子或晶体之间的关系，而非研究定义多体系统中局部量子场的原子对之间的两体相互作用。因此，需要一个基准来评估模型学习这些两体相互作用的能力及其物理含义。

Method: QuantumCanvas 基准包含2850种元素对的数据集，每个元素对都标注了18个电子、热力学和几何属性，并与来自轨道密度、角度场变换、共占据图和电荷密度投影的10通道图像表示相关联。基准测试了8种架构的表现，并通过结合可视化和数值模态方法，学习可传递的量子相互作用。

Result: GATv2在能隙上的平均绝对误差为0.201 eV，EGNN在HOMO上的误差为0.265 eV，LUMO为0.274 eV；DimeNet在总能上的平均绝对误差为2.27 eV，在斥力能上的误差为0.132 eV；多模态融合模型在Mermin自由能上的误差为2.15 eV。预训练在 QuantumCanvas 上并调整到更大的数据集 QM9、MD17 和 CrysMTM 后，模型的收敛稳定性和泛化能力有所提升。

Conclusion: QuantumCanvas 为研究可传递量子相互作用提供了一个物理上合理的依据，并展示了通过结合电子轨道物理和基于视觉的表示学习所能取得的性能。未来的改进可以从更多样化的视角进行，比如结合不同的模态以增强模型的鲁棒性。

Abstract: Despite rapid advances in molecular and materials machine learning, most models still lack physical transferability: they fit correlations across whole molecules or crystals rather than learning the quantum interactions between atomic pairs. Yet bonding, charge redistribution, orbital hybridization, and electronic coupling all emerge from these two-body interactions that define local quantum fields in many-body systems. We introduce QuantumCanvas, a large-scale multimodal benchmark that treats two-body quantum systems as foundational units of matter. The dataset spans 2,850 element-element pairs, each annotated with 18 electronic, thermodynamic, and geometric properties and paired with ten-channel image representations derived from l- and m-resolved orbital densities, angular field transforms, co-occupancy maps, and charge-density projections. These physically grounded images encode spatial, angular, and electrostatic symmetries without explicit coordinates, providing an interpretable visual modality for quantum learning. Benchmarking eight architectures across 18 targets, we report mean absolute errors of 0.201 eV on energy gap using GATv2, 0.265 eV on HOMO and 0.274 eV on LUMO using EGNN. For energy-related quantities, DimeNet attains 2.27 eV total-energy MAE and 0.132 eV repulsive-energy MAE, while a multimodal fusion model achieves a 2.15 eV Mermin free-energy MAE. Pretraining on QuantumCanvas further improves convergence stability and generalization when fine-tuned on larger datasets such as QM9, MD17, and CrysMTM. By unifying orbital physics with vision-based representation learning, QuantumCanvas provides a principled and interpretable basis for learning transferable quantum interactions through coupled visual and numerical modalities. Dataset and model implementations are available at https://github.com/KurbanIntelligenceLab/QuantumCanvas.

</details>


### [156] [FlashVGGT: Efficient and Scalable Visual Geometry Transformers with Compressed Descriptor Attention](https://arxiv.org/abs/2512.01540)
*Zipeng Wang,Dan Xu*

Main category: cs.CV

TL;DR: FlashVGGT通过引入基于描述符的注意力机制，在保持与VGGT相当的重建准确性的同时，将1000张图像的推理时间减少到VGGT的9.3%，并且能效地扩展到超过3000张图像的序列。


<details>
  <summary>Details</summary>
Motivation: 解决传统自注意力机制在处理大量图像时的时间复杂度过高和效率低下的问题，提高3D重建的速度与效率。

Method: FlashVGGT采用了描述符注意力机制，将每一帧的空间信息压缩成紧凑的描述符矩阵，利用跨注意力机制简化计算负担，并通过分块递归机制利用缓存描述符实现长时间序列的在线推理。

Result: FlashVGGT实现了与VGGT相当的重建精度，并将1,000张图像的推理时间减少到VGGT的9.3%。对于超过3,000张图像的长序列，也能有效扩展。

Conclusion: FlashVGGT是一种有效的解决方案，解决了大规模图像序列处理中的瓶颈问题，提供了一种在保持重建准确性的同时提升重建速度的方法。

Abstract: 3D reconstruction from multi-view images is a core challenge in computer vision. Recently, feed-forward methods have emerged as efficient and robust alternatives to traditional per-scene optimization techniques. Among them, state-of-the-art models like the Visual Geometry Grounding Transformer (VGGT) leverage full self-attention over all image tokens to capture global relationships. However, this approach suffers from poor scalability due to the quadratic complexity of self-attention and the large number of tokens generated in long image sequences. In this work, we introduce FlashVGGT, an efficient alternative that addresses this bottleneck through a descriptor-based attention mechanism. Instead of applying dense global attention across all tokens, FlashVGGT compresses spatial information from each frame into a compact set of descriptor tokens. Global attention is then computed as cross-attention between the full set of image tokens and this smaller descriptor set, significantly reducing computational overhead. Moreover, the compactness of the descriptors enables online inference over long sequences via a chunk-recursive mechanism that reuses cached descriptors from previous chunks. Experimental results show that FlashVGGT achieves reconstruction accuracy competitive with VGGT while reducing inference time to just 9.3% of VGGT for 1,000 images, and scaling efficiently to sequences exceeding 3,000 images. Our project page is available at https://wzpscott.github.io/flashvggt_page/.

</details>


### [157] [Toward Content-based Indexing and Retrieval of Head and Neck CT with Abscess Segmentation](https://arxiv.org/abs/2512.01589)
*Thao Thi Phuong Dao,Tan-Cong Nguyen,Trong-Le Do,Truong Hoang Viet,Nguyen Chi Thanh,Huynh Nguyen Thuan,Do Vo Cong Nguyen,Minh-Khoi Pham,Mai-Khiem Tran,Viet-Tham Huynh,Trong-Thuan Nguyen,Trung-Nghia Le,Vo Thanh Toan,Tam V. Nguyen,Minh-Triet Tran,Thanh Dinh Le*

Main category: cs.CV

TL;DR: 该研究介绍了一个名为AbscessHeNe的新数据集，包含4,926张增强CT切片，用于头颈部脓肿的分割。研究评估了几种先进的分割架构，并且平台将开源。


<details>
  <summary>Details</summary>
Motivation: 介绍为主要解决头颈部脓肿诊断和界定中的影像学难题，提高诊断准确性和治疗效率。

Method: 构建了一个包含4,926张增强CT切片的ABSCESSHeNE数据集，这些切片都经过临床确诊。使用CNN，Transformer和Mamba等先进分割模型进行评估。

Result: 最高性能模型在Dice相似系数为0.39，交并比为0.27，标化表面距离为0.67，表明了进一步研究的需求。

Conclusion: 该数据集将开源，以便辅助未来基于内容的多媒体索引和病例检索应用的开发。

Abstract: Abscesses in the head and neck represent an acute infectious process that can potentially lead to sepsis or mortality if not diagnosed and managed promptly. Accurate detection and delineation of these lesions on imaging are essential for diagnosis, treatment planning, and surgical intervention. In this study, we introduce AbscessHeNe, a curated and comprehensively annotated dataset comprising 4,926 contrast-enhanced CT slices with clinically confirmed head and neck abscesses. The dataset is designed to facilitate the development of robust semantic segmentation models that can accurately delineate abscess boundaries and evaluate deep neck space involvement, thereby supporting informed clinical decision-making. To establish performance baselines, we evaluate several state-of-the-art segmentation architectures, including CNN, Transformer, and Mamba-based models. The highest-performing model achieved a Dice Similarity Coefficient of 0.39, Intersection-over-Union of 0.27, and Normalized Surface Distance of 0.67, indicating the challenges of this task and the need for further research. Beyond segmentation, AbscessHeNe is structured for future applications in content-based multimedia indexing and case-based retrieval. Each CT scan is linked with pixel-level annotations and clinical metadata, providing a foundation for building intelligent retrieval systems and supporting knowledge-driven clinical workflows. The dataset will be made publicly available at https://github.com/drthaodao3101/AbscessHeNe.git.

</details>


### [158] [Depth Matching Method Based on ShapeDTW for Oil-Based Mud Imager](https://arxiv.org/abs/2512.01611)
*Fengfeng Li,Zhou Feng,Hongliang Wu,Hao Zhang,Han Tian,Peng Liu,Lixin Yuan*

Main category: cs.CV

TL;DR: 本文介绍了一种基于ShapeDTW算法的深度匹配方法，用于解决油基泥浆微电阻率成像中深度错位问题，通过结合一维HOG特征和原始信号实现了精确对齐，特别适用于复杂纹理、深度偏移或局部缩放的情况。


<details>
  <summary>Details</summary>
Motivation: 在使用油基泥浆微电阻率成像的井下作业中，即使经过速度校正，上下垫片图像之间仍然存在深度对齐问题。本文提出了一种基于ShapeDTW算法的方法，以解决这一问题。

Method: 该方法提取局部形状特征，构建具有形态敏感性的距离矩阵，在对齐过程中更好地保持序列间的结构相似性。通过结合一维HOG特征和原始信号作为形状描述符。

Result: 实验结果表明，该方法能够精确对齐具有复杂纹理、深度偏移或局部缩放特性的图像。同时，该方法提供了灵活的特征扩展框架，允许集成其他特制地质特征的描述符。

Conclusion: 本文提出的基于ShapeDTW的深度匹配方法为解决油基泥浆微电阻率成像中的深度对齐问题提供了一种有效的解决方案，具有广泛应用前景。

Abstract: In well logging operations using the oil-based mud (OBM) microresistivity imager, which employs an interleaved design with upper and lower pad sets, depth misalignment issues persist between the pad images even after velocity correction. This paper presents a depth matching method for borehole images based on the Shape Dynamic Time Warping (ShapeDTW) algorithm. The method extracts local shape features to construct a morphologically sensitive distance matrix, better preserving structural similarity between sequences during alignment. We implement this by employing a combined feature set of the one-dimensional Histogram of Oriented Gradients (HOG1D) and the original signal as the shape descriptor. Field test examples demonstrate that our method achieves precise alignment for images with complex textures, depth shifts, or local scaling. Furthermore, it provides a flexible framework for feature extension, allowing the integration of other descriptors tailored to specific geological features.

</details>


### [159] [SPARK: Sim-ready Part-level Articulated Reconstruction with VLM Knowledge](https://arxiv.org/abs/2512.01629)
*Yumeng He,Ying Jiang,Jiayin Lu,Yin Yang,Chenfanfu Jiang*

Main category: cs.CV

TL;DR: SPARK框架可以从单张RGB图像中重建出物理上一致的、基于动力学的部件级详细对象，通过结合视觉语言模型、生成扩散变换器、可微前向动力学和可微渲染来生成高质量的模拟准备就绪的关节模型。


<details>
  <summary>Details</summary>
Motivation: 目前创建模拟就绪的部件级详细对象需要大量的手动建模工作，SPARK框架旨在通过利用视觉语言模型和生成扩散变换器来自动化这一过程，从而提高效率并扩展应用范围。

Method: SPARK框架采用以下步骤：首先利用视觉语言模型从单张RGB图像中提取粗略的URDF参数并生成参考图像；接着利用这些参考图像和推断出的结构图来生成一致的部件和完整的物体形状；最后通过包含可微前向动力学和可微渲染的优化来进一步细化URDF参数。

Result: 实验结果表明，SPARK框架能够生成高质量的、模拟就绪的关节模型，涵盖多种类别，支持机器人操作和交互建模等下游应用。

Conclusion: SPARK框架提供了一种创新的方法来自动化复杂关节物体的重建过程，这对相关领域具有重要意义。

Abstract: Articulated 3D objects are critical for embodied AI, robotics, and interactive scene understanding, yet creating simulation-ready assets remains labor-intensive and requires expert modeling of part hierarchies and motion structures. We introduce SPARK, a framework for reconstructing physically consistent, kinematic part-level articulated objects from a single RGB image. Given an input image, we first leverage VLMs to extract coarse URDF parameters and generate part-level reference images. We then integrate the part-image guidance and the inferred structure graph into a generative diffusion transformer to synthesize consistent part and complete shapes of articulated objects. To further refine the URDF parameters, we incorporate differentiable forward kinematics and differentiable rendering to optimize joint types, axes, and origins under VLM-generated open-state supervision. Extensive experiments show that SPARK produces high-quality, simulation-ready articulated assets across diverse categories, enabling downstream applications such as robotic manipulation and interaction modeling.

</details>


### [160] [Generative Editing in the Joint Vision-Language Space for Zero-Shot Composed Image Retrieval](https://arxiv.org/abs/2512.01636)
*Xin Wang,Haipeng Zhang,Mang Li,Zhaohui Xia,Yueguo Chen,Yu Zhang,Chunyu Wei*

Main category: cs.CV

TL;DR: 本文提出了一种名为Fusion-Diff的新颖生成编辑框架，通过在联合视觉-语言空间中的多模态融合特征编辑策略，显著减小了视觉-语言模态差距。此外，引入了轻量级的Control-Adapter，仅通过少量合成数据集实现了卓越的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的零样本图像检索方法由于对难以获取的三元组注释的依赖性而导致性能受限，而Fusion-Diff旨在通过更有效地桥接视觉-语言模态差距来解决这一问题。

Method: Fusion-Diff框架结合了多模态融合特征编辑策略和轻量级的Control-Adapter，能够在少量标注数据的情况下实现强大的性能。

Result: 实验证明，Fusion-Diff在标准CIR基准数据集（CIRR、FashionIQ和CIRCO）上显著优于此前的零样本方法。

Conclusion: 本研究通过设计Fusion-Diff框架推进了零样本图像检索的发展，进一步提高了模型的可解释性。

Abstract: Composed Image Retrieval (CIR) enables fine-grained visual search by combining a reference image with a textual modification. While supervised CIR methods achieve high accuracy, their reliance on costly triplet annotations motivates zero-shot solutions. The core challenge in zero-shot CIR (ZS-CIR) stems from a fundamental dilemma: existing text-centric or diffusion-based approaches struggle to effectively bridge the vision-language modality gap. To address this, we propose Fusion-Diff, a novel generative editing framework with high effectiveness and data efficiency designed for multimodal alignment. First, it introduces a multimodal fusion feature editing strategy within a joint vision-language (VL) space, substantially narrowing the modality gap. Second, to maximize data efficiency, the framework incorporates a lightweight Control-Adapter, enabling state-of-the-art performance through fine-tuning on only a limited-scale synthetic dataset of 200K samples. Extensive experiments on standard CIR benchmarks (CIRR, FashionIQ, and CIRCO) demonstrate that Fusion-Diff significantly outperforms prior zero-shot approaches. We further enhance the interpretability of our model by visualizing the fused multimodal representations.

</details>


### [161] [ViT$^3$: Unlocking Test-Time Training in Vision](https://arxiv.org/abs/2512.01643)
*Dongchen Han,Yining Li,Tianyu Li,Zixuan Cao,Ziming Wang,Jun Song,Yu Cheng,Bo Zheng,Gao Huang*

Main category: cs.CV

TL;DR: 论文系统地研究了视觉序列建模中的Test-Time Training (TTT) 设计，提出了ViT$^3$模型，该模型在保持线性复杂度的同时实现了可并行计算，并在多种视觉任务上表现与先进模型相当或更优。


<details>
  <summary>Details</summary>
Motivation: 当前针对视觉TTT的内核模块和内训设计缺乏全面的理解和实用指南，可通过系统性的实验和分析来填补这一关键缺口。

Method: 通过一系列实验和分析，论文提炼出六个实用的见解，作为有效的视觉TTT设计原则，并推出ViT$^3$模型。

Result: ViT$^3$模型在图像分类、图像生成、目标检测和语义分割等多种视觉任务上表现出与先进线性复杂度模型相当或更优的性能。

Conclusion: 研究表明，ViT$^3$模型为视觉TTT模型的未来研究提供了指导，并通过可并行计算的方式实现了线性复杂度。

Abstract: Test-Time Training (TTT) has recently emerged as a promising direction for efficient sequence modeling. TTT reformulates attention operation as an online learning problem, constructing a compact inner model from key-value pairs at test time. This reformulation opens a rich and flexible design space while achieving linear computational complexity. However, crafting a powerful visual TTT design remains challenging: fundamental choices for the inner module and inner training lack comprehensive understanding and practical guidelines. To bridge this critical gap, in this paper, we present a systematic empirical study of TTT designs for visual sequence modeling. From a series of experiments and analyses, we distill six practical insights that establish design principles for effective visual TTT and illuminate paths for future improvement. These findings culminate in the Vision Test-Time Training (ViT$^3$) model, a pure TTT architecture that achieves linear complexity and parallelizable computation. We evaluate ViT$^3$ across diverse visual tasks, including image classification, image generation, object detection, and semantic segmentation. Results show that ViT$^3$ consistently matches or outperforms advanced linear-complexity models (e.g., Mamba and linear attention variants) and effectively narrows the gap to highly optimized vision Transformers. We hope this study and the ViT$^3$ baseline can facilitate future work on visual TTT models. Code is available at https://github.com/LeapLabTHU/ViTTT.

</details>


### [162] [Bridging the Scale Gap: Balanced Tiny and General Object Detection in Remote Sensing Imagery](https://arxiv.org/abs/2512.01665)
*Zhicheng Zhao,Yin Huang,Lingma Sun,Chenglong Li,Jin Tang*

Main category: cs.CV

TL;DR: 该研究提出了ScaleBridge-Det框架，针对遥感图像中小目标检测中的尺度差异问题，通过引入Routing-Enhanced Mixture Attention (REM)和Density-Guided Dynamic Query (DGQ)模块，实现了在多元尺度上性能的均衡。


<details>
  <summary>Details</summary>
Motivation: 面向遥感图像中小目标检测的研究挑战，现有大规模基础模型难以兼顾不同尺度目标的检测效果，因此提出了一种新的检测框架以解决此问题。

Method: 提出了一种名为ScaleBridge-Det的检测框架，包括Routing-Enhanced Mixture Attention (REM)模块和Density-Guided Dynamic Query (DGQ)模块，分别通过自适应路由和密度指导下的动态查询进行特征融合与资源分配，以平衡不同尺度目标的检测性能。

Result: 实验表明，ScaleBridge-Det在AI-TOD-V2和DTOD数据集上达到了最先进的检测性能，并在VisDrone数据集上展示了更好的跨域鲁棒性。

Conclusion: 该研究为解决遥感图像中尺度变化带来的检测难题提供了一个有效的解决方案，具有较高的跨域应用潜力。

Abstract: Tiny object detection in remote sensing imagery has attracted significant research interest in recent years. Despite recent progress, achieving balanced detection performance across diverse object scales remains a formidable challenge, particularly in scenarios where dense tiny objects and large objects coexist. Although large foundation models have revolutionized general vision tasks, their application to tiny object detection remains unexplored due to the extreme scale variation and density distribution inherent to remote sensing imagery. To bridge this scale gap, we propose ScaleBridge-Det, to the best of our knowledge, the first large detection framework designed for tiny objects, which could achieve balanced performance across diverse scales through scale-adaptive expert routing and density-guided query allocation. Specifically, we introduce a Routing-Enhanced Mixture Attention (REM) module that dynamically selects and fuses scale-specific expert features via adaptive routing to address the tendency of standard MoE models to favor dominant scales. REM generates complementary and discriminative multi-scale representations suitable for both tiny and large objects. Furthermore, we present a Density-Guided Dynamic Query (DGQ) module that predicts object density to adaptively adjust query positions and numbers, enabling efficient resource allocation for objects of varying scales. The proposed framework allows ScaleBridge-Det to simultaneously optimize performance for both dense tiny and general objects without trade-offs. Extensive experiments on benchmark and cross-domain datasets demonstrate that ScaleBridge-Det achieves state-of-the-art performance on AI-TOD-V2 and DTOD, while exhibiting superior cross-domain robustness on VisDrone.

</details>


### [163] [GRASP: Guided Residual Adapters with Sample-wise Partitioning](https://arxiv.org/abs/2512.01675)
*Felix Nützel,Mischa Dombrowski,Bernhard Kainz*

Main category: cs.CV

TL;DR: 提出了GRASP方法，通过外部先验对样本进行分簇，减少梯度冲突，提高了长尾数据生成的质量与多样性。GRASP方法在MIMIC-CXR-LT和ImageNet-LT上的测试表明了其优越性。


<details>
  <summary>Details</summary>
Motivation: 当前的文本到图像的扩散模型在处理医学影像中的罕见病理时表现不佳，导致模式崩溃，即尾部类别的输出缺乏质量和多样性。为解决此问题，我们提出了GRASP方法。

Method: GRASP通过利用外部先验对样本进行分簇，通过特定簇的残差适配器对预训练模型进行微调，以减少梯度冲突并提高生成的图像质量与多样性。

Result: 在长尾MIMIC-CXR-LT数据集上，GRASP在FID和多样性指标上表现优异，尤其是对于罕见类别。在下游的NIH-CXR-LT分类中，尾部标签的表现有显著提高。此外，GRASP方法在ImageNet-LT上的测试也证实了其广泛适用性。

Conclusion: GRASP方法通过减少梯度冲突提高了扩散模型在生成罕见病理图像时的质量和多样性，展示了其在实际应用中的潜力。

Abstract: Recent advances in text-to-image diffusion models enable high-fidelity generation across diverse prompts. However, these models falter in long-tail settings, such as medical imaging, where rare pathologies comprise a small fraction of data. This results in mode collapse: tail-class outputs lack quality and diversity, undermining the goal of synthetic data augmentation for underrepresented conditions. We pinpoint gradient conflicts between frequent head and rare tail classes as the primary culprit, a factor unaddressed by existing sampling or conditioning methods that mainly steer inference without altering the learned distribution. To resolve this, we propose GRASP: Guided Residual Adapters with Sample-wise Partitioning. GRASP uses external priors to statically partition samples into clusters that minimize intra-group gradient clashes. It then fine-tunes pre-trained models by injecting cluster-specific residual adapters into transformer feedforward layers, bypassing learned gating for stability and efficiency. On the long-tail MIMIC-CXR-LT dataset, GRASP yields superior FID and diversity metrics, especially for rare classes, outperforming baselines like vanilla fine-tuning and Mixture of Experts variants. Downstream classification on NIH-CXR-LT improves considerably for tail labels. Generalization to ImageNet-LT confirms broad applicability. Our method is lightweight, scalable, and readily integrates with diffusion pipelines.

</details>


### [164] [Open-world Hand-Object Interaction Video Generation Based on Structure and Contact-aware Representation](https://arxiv.org/abs/2512.01677)
*Haodong Yan,Hang Yu,Zhide Zhong,Weilin Yuan,Xin Gong,Zehang Luo,Chengxi Heyu,Junfeng Li,Wenxuan Song,Shunbo Zhou,Haoang Li*

Main category: cs.CV

TL;DR: 本文提出了一种结构和接触感知的表示法，能够在无需3D注释的情况下捕捉手对象接触、手对象遮挡和整体结构上下文，从而实现物理逼真且时序一致的手对象交互视频生成。实验表明该方法在两个现实世界数据集上超过现有最先进的方法，并且具有强大的开放世界场景泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法使用手对象交互（HOI）表示作为辅助生成目标来指导视频合成，但2D和3D表示方式难以同时保证可扩展性和交互精度。本文旨在提出一种结构和接触感知表示法，解决了这一局限性。

Method: 本文提出了一种结构和接触感知表示法，能够捕捉手对象接触、手对象遮挡和整体结构上下文，无需3D注释。通过引入联合生成范式和共享与专业化策略，生成手对象交互导向表示法和视频。

Result: 本文方法在两个现实世界数据集上生成了物理逼真且时序一致的手对象交互视频，结果优于现有最先进的方法。该方法在开放世界场景下表现出强大的泛化能力。

Conclusion: 本文提出的方法不仅解决了手对象交互视频生成中的物理精度和可扩展性问题，还提高了在未知场景中的适应性。

Abstract: Generating realistic hand-object interactions (HOI) videos is a significant challenge due to the difficulty of modeling physical constraints (e.g., contact and occlusion between hands and manipulated objects). Current methods utilize HOI representation as an auxiliary generative objective to guide video synthesis. However, there is a dilemma between 2D and 3D representations that cannot simultaneously guarantee scalability and interaction fidelity. To address this limitation, we propose a structure and contact-aware representation that captures hand-object contact, hand-object occlusion, and holistic structure context without 3D annotations. This interaction-oriented and scalable supervision signal enables the model to learn fine-grained interaction physics and generalize to open-world scenarios. To fully exploit the proposed representation, we introduce a joint-generation paradigm with a share-and-specialization strategy that generates interaction-oriented representations and videos. Extensive experiments demonstrate that our method outperforms state-of-the-art methods on two real-world datasets in generating physics-realistic and temporally coherent HOI videos. Furthermore, our approach exhibits strong generalization to challenging open-world scenarios, highlighting the benefit of our scalable design. Our project page is https://hgzn258.github.io/SCAR/.

</details>


### [165] [Cross-Domain Validation of a Resection-Trained Self-Supervised Model on Multicentre Mesothelioma Biopsies](https://arxiv.org/abs/2512.01681)
*Farzaneh Seyedshahi,Francesca Damiola,Sylvie Lantuejoul,Ke Yuan,John Le Quesne*

Main category: cs.CV

TL;DR: 该研究展示了自监督编码器可以应用于小型活检材料，通过捕获有意义的形态学模式来预测患者的生存率和分类肿瘤亚型，从而支持恶性间皮瘤的诊断和治疗计划。


<details>
  <summary>Details</summary>
Motivation: 目前的计算病理学模型主要基于大型手术标本组织图像进行训练，这限制了它们在实际应用中的使用，尤其是小活检样本。因此，研究旨在探索自监督编码器在活检材料中的应用。

Method: 研究提出了一个自监督编码器，该编码器已经在大型手术标本组织图像上进行过训练。该研究采用了迁移学习的方法，将此编码器应用于小型活检材料，以预测患者的生存率和分类肿瘤亚型。

Result: 该研究展示了自监督编码器可以应用于小型活检材料，可以通过捕获有意义的形态学模式预测患者的生存率并分类肿瘤亚型。

Conclusion: 该研究结果显示，AI驱动的工具在支持恶性间皮瘤的诊断与治疗计划中有很大的潜在价值。

Abstract: Accurate subtype classification and outcome prediction in mesothelioma are essential for guiding therapy and patient care. Most computational pathology models are trained on large tissue images from resection specimens, limiting their use in real-world settings where small biopsies are common. We show that a self-supervised encoder trained on resection tissue can be applied to biopsy material, capturing meaningful morphological patterns. Using these patterns, the model can predict patient survival and classify tumor subtypes. This approach demonstrates the potential of AI-driven tools to support diagnosis and treatment planning in mesothelioma.

</details>


### [166] [DreamingComics: A Story Visualization Pipeline via Subject and Layout Customized Generation using Video Models](https://arxiv.org/abs/2512.01686)
*Patrick Kwon,Chen Chen*

Main category: cs.CV

TL;DR: DreamingComics 提出了一种基于布局感知的故事可视化框架，通过引入 RegionRoPE 和 masked condition loss 来增强身份和风格一致性，并利用大模型生成符合漫画风格的布局。


<details>
  <summary>Details</summary>
Motivation: 当前的故事可视化方法主要依赖文字定位主体，难以保持艺术连贯性。DreamingComics 旨在解决这一问题，通过引入布局意识框架，改善这一领域的现有挑战。

Method: 该方法基于预训练的视频扩散转换器（DiT）模型，利用其空间时间先验增强身份和风格一致性。此外，还提出了一种基于区域的罗佩编码方案 (RegionalRoPE)，以及一种掩码条件损失，以进一步限制每个主体的视觉特征。同时，引入了一个基于大模型的布局生成器，能够产生符合漫画风格的布局。

Result: 实验结果显示，与先前的方法相比，DreamingComics 可以提高 29.2% 的角色一致性，并且风格相似性提高了 36.2%。同时，其空间准确性也非常高。

Conclusion: DreamingComics 成功地展示了一种新型的故事可视化方法，相较于传统方法，该方法具有更高的角色一致性、风格相似性和空间准确性。

Abstract: Current story visualization methods tend to position subjects solely by text and face challenges in maintaining artistic consistency. To address these limitations, we introduce DreamingComics, a layout-aware story visualization framework. We build upon a pretrained video diffusion-transformer (DiT) model, leveraging its spatiotemporal priors to enhance identity and style consistency. For layout-based position control, we propose RegionalRoPE, a region-aware positional encoding scheme that re-indexes embeddings based on the target layout. Additionally, we introduce a masked condition loss to further constrain each subject's visual features to their designated region. To infer layouts from natural language scripts, we integrate an LLM-based layout generator trained to produce comic-style layouts, enabling flexible and controllable layout conditioning. We present a comprehensive evaluation of our approach, showing a 29.2% increase in character consistency and a 36.2% increase in style similarity compared to previous methods, while displaying high spatial accuracy. Our project page is available at https://yj7082126.github.io/dreamingcomics/

</details>


### [167] [SSR: Semantic and Spatial Rectification for CLIP-based Weakly Supervised Segmentation](https://arxiv.org/abs/2512.01701)
*Xiuli Bi,Die Xiao,Junchao Fan,Bin Xiao*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的语义和空间校正(SSR)方法，通过对比模态原型对齐(CMPA)和超像素引导校正(SGC)解决现有的基于CLIP的弱监督语义分割方法中的非目标前景和背景的过度激活问题。在PASCAL VOC和MS COCO数据集上进行了广泛的实验，表明该方法优于所有单阶段方法和更复杂的多阶段方法，分别实现了79.5%和50.6%的mIoU得分。


<details>
  <summary>Details</summary>
Motivation: 现有基于CLIP的弱监督语义分割方法存在非目标前景和背景过度激活的问题，影响了模型的性能。

Method: 本文提出了一种SSR方法，包括两个部分。首先，CMPA通过对比学习机制实现了模态特征空间对齐，减少类别间的重叠并增强语义相关性，解决了非目标前景的过度激活问题。其次，SGC利用超像素的空间先验，在语义分割过程中精确过滤来自非目标区域的干扰，显著减少背景的过度激活。

Result: 在PASCAL VOC和MS COCO数据集上进行了广泛的实验，表明方法在单阶段和多阶段方法中表现出优越性，分别达到了79.5%和50.6%的mIoU得分。

Conclusion: 提出的SSR方法能够有效解决非目标前景和背景的过度激活问题，显著提升了基于CLIP的弱监督语义分割模型的性能。

Abstract: In recent years, Contrastive Language-Image Pretraining (CLIP) has been widely applied to Weakly Supervised Semantic Segmentation (WSSS) tasks due to its powerful cross-modal semantic understanding capabilities. This paper proposes a novel Semantic and Spatial Rectification (SSR) method to address the limitations of existing CLIP-based weakly supervised semantic segmentation approaches: over-activation in non-target foreground regions and background areas. Specifically, at the semantic level, the Cross-Modal Prototype Alignment (CMPA) establishes a contrastive learning mechanism to enforce feature space alignment across modalities, reducing inter-class overlap while enhancing semantic correlations, to rectify over-activation in non-target foreground regions effectively; at the spatial level, the Superpixel-Guided Correction (SGC) leverages superpixel-based spatial priors to precisely filter out interference from non-target regions during affinity propagation, significantly rectifying background over-activation. Extensive experiments on the PASCAL VOC and MS COCO datasets demonstrate that our method outperforms all single-stage approaches, as well as more complex multi-stage approaches, achieving mIoU scores of 79.5% and 50.6%, respectively.

</details>


### [168] [FreqEdit: Preserving High-Frequency Features for Robust Multi-Turn Image Editing](https://arxiv.org/abs/2512.01755)
*Yucheng Liao,Jiajun Liang,Kaiqian Cui,Baoquan Zhao,Haoran Xie,Wei Liu,Qing Li,Xudong Mao*

Main category: cs.CV

TL;DR: FreqEdit是一种无需训练的框架，能够实现跨10多次连续编辑的稳定图像编辑，通过高频率特征注入、自适应注入策略和路径补偿机制，有效解决了高质量多轮编辑的问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于指令的图像编辑模型在多次编辑后会出现质量下降的问题，研究人员发现高频细节信息的逐步丢失是主要原因。因此，研究提出了一种无需训练的频域编辑框架(FreqEdit)，以解决这一问题。

Method: FreqEdit框架包括三个主要组件：1) 从参考速度场注入高频率特征，以保持细粒度的细节；2) 适应性注入策略，空间上调整注入强度，实现精确的区域特定控制；3) 路径补偿机制，定期重新校准编辑轨迹，防止过度约束。

Result: 实验结果表明，FreqEdit在身份保留和指令跟随方面均优于七个最先进的基准方法。

Conclusion: FreqEdit为高质量多轮编辑提供了一个有效解决方案，具有显著的实际应用潜力，并为后续研究提供了新的思路。

Abstract: Instruction-based image editing through natural language has emerged as a powerful paradigm for intuitive visual manipulation. While recent models achieve impressive results on single edits, they suffer from severe quality degradation under multi-turn editing. Through systematic analysis, we identify progressive loss of high-frequency information as the primary cause of this quality degradation. We present FreqEdit, a training-free framework that enables stable editing across 10+ consecutive iterations. Our approach comprises three synergistic components: (1) high-frequency feature injection from reference velocity fields to preserve fine-grained details, (2) an adaptive injection strategy that spatially modulates injection strength for precise region-specific control, and (3) a path compensation mechanism that periodically recalibrates the editing trajectory to prevent over-constraint. Extensive experiments demonstrate that FreqEdit achieves superior performance in both identity preservation and instruction following compared to seven state-of-the-art baselines.

</details>


### [169] [VideoScoop: A Non-Traditional Domain-Independent Framework For Video Analysis](https://arxiv.org/abs/2512.01769)
*Hafsa Billah*

Main category: cs.CV

TL;DR: 该论文提出了一种通用的视频情况分析框架，解决了传统方法中需要针对不同情况或领域开发独立算法的问题。


<details>
  <summary>Details</summary>
Motivation: 当前的视频情况分析方法要么依赖人力且费时费力，要么只能针对特定类型的视频或情况开发定制算法，通用性不高。

Method: 该方法首先使用最先进的视频内容提取技术提取视频内容，然后使用扩展关系模型（R++）和图模型表示这些内容。借助提出的连续查询语言，R++模型使得通过数据流进行连续查询处理成为可能。图模型则提供了R++模型无法单独完成的复杂情况检测能力。通过参数化的模板形式定义跨领域的原始情况变体，使得算法适用于多个领域。

Result: 通过在三个不同领域的多种类型视频上进行大规模实验，证明了所提方法在准确性、效率和鲁棒性方面的有效性。

Conclusion: 综上所述，该通用框架为实现视频情况的自动分析提供了一个新的解决途径。

Abstract: Automatically understanding video contents is important for several applications in Civic Monitoring (CM), general Surveillance (SL), Assisted Living (AL), etc. Decades of Image and Video Analysis (IVA) research have advanced tasks such as content extraction (e.g., object recognition and tracking). Identifying meaningful activities or situations (e.g., two objects coming closer) remains difficult and cannot be achieved by content extraction alone. Currently, Video Situation Analysis (VSA) is done manually with a human in the loop, which is error-prone and labor-intensive, or through custom algorithms designed for specific video types or situations. These algorithms are not general-purpose and require a new algorithm/software for each new situation or video from a new domain.
  This report proposes a general-purpose VSA framework that overcomes the above limitations. Video contents are extracted once using state-of-the-art Video Content Extraction technologies. They are represented using two alternative models -- the extended relational model (R++) and graph models. When represented using R++, the extracted contents can be used as data streams, enabling Continuous Query Processing via the proposed Continuous Query Language for Video Analysis. The graph models complement this by enabling the detection of situations that are difficult or impossible to detect using the relational model alone. Existing graph algorithms and newly developed algorithms support a wide variety of situation detection. To support domain independence, primitive situation variants across domains are identified and expressed as parameterized templates. Extensive experiments were conducted across several interesting situations from three domains -- AL, CM, and SL-- to evaluate the accuracy, efficiency, and robustness of the proposed approach using a dataset of videos of varying lengths from these domains.

</details>


### [170] [Robust Rigid and Non-Rigid Medical Image Registration Using Learnable Edge Kernels](https://arxiv.org/abs/2512.01771)
*Ahsan Raza Siyal,Markus Haltmeier,Ruth Steiger,Malik Galijasevic,Elke Ruth Gizewski,Astrid Ellen Grams*

Main category: cs.CV

TL;DR: 该研究提出了一种结合学习边缘核与学习引导的刚性及非刚性配准技术的方法，通过自适应边缘检测增强图像配准效果，实验结果显示此方法在多模态图像配准和解剖结构分析中优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统配准技术在处理对比度差异、空间扭曲和模态特定变异性方面的局限性，以提高医疗图像配准的效果和准确性。

Method: 提出了一种结合学习可调节边缘核与学习引导的刚性及非刚性配准技术的方法。首先使用预定义的边缘检测核，然后通过随机噪声进行扰动以适应任务需求。通过学习提取最优边缘特征，增强了配准过程。

Result: 该方法在多模态图像配准和解剖结构分析相关的多种测试场景中表现出色，特别是在基于医学大学提供的数据集和两个公开数据集的评估中，均优于当前最先进的技术。

Conclusion: 该研究提出的方法可以通过自适应边缘检测显著提高医疗图像配准的效果，未来有望在多模态图像对齐和解剖结构分析中应用。

Abstract: Medical image registration is crucial for various clinical and research applications including disease diagnosis or treatment planning which require alignment of images from different modalities, time points, or subjects. Traditional registration techniques often struggle with challenges such as contrast differences, spatial distortions, and modality-specific variations. To address these limitations, we propose a method that integrates learnable edge kernels with learning-based rigid and non-rigid registration techniques. Unlike conventional layers that learn all features without specific bias, our approach begins with a predefined edge detection kernel, which is then perturbed with random noise. These kernels are learned during training to extract optimal edge features tailored to the task. This adaptive edge detection enhances the registration process by capturing diverse structural features critical in medical imaging. To provide clearer insight into the contribution of each component in our design, we introduce four variant models for rigid registration and four variant models for non-rigid registration. We evaluated our approach using a dataset provided by the Medical University across three setups: rigid registration without skull removal, with skull removal, and non-rigid registration. Additionally, we assessed performance on two publicly available datasets. Across all experiments, our method consistently outperformed state-of-the-art techniques, demonstrating its potential to improve multi-modal image alignment and anatomical structure analysis.

</details>


### [171] [Learned Image Compression for Earth Observation: Implications for Downstream Segmentation Tasks](https://arxiv.org/abs/2512.01788)
*Christian Mollière,Iker Cumplido,Marco Zeulner,Lukas Liesenhoff,Matthias Schubert,Julia Gottfriedsen*

Main category: cs.CV

TL;DR: 研究比较了传统压缩（JPEG 2000）和学习型压缩（离散混合高斯似然性）算法在地球观测（EO）系统数据压缩中的效果，发现在大规模、多通道光学图像中，学习型压缩在重构质量和分割精度上显著优于JPEG 2000，但在小规模单通道热红外数据集上，传统编解码器表现出竞争力。


<details>
  <summary>Details</summary>
Motivation: 随着卫星地球观测系统生成的数据量快速增长，数据传输和存储成为重大挑战。本研究旨在评估特定任务学习型压缩算法在保留关键信息的前提下减少数据量的潜力。

Method: 研究通过将传统压缩方法（JPEG 2000）与学习型压缩方法（离散混合高斯似然性）应用于三种不同地球观测任务（火灾检测、云检测和建筑检测）的光谱数据中，进行了详细的比较分析。

Result: 研究表明，在大规模多通道光学图像上，学习型压缩方法在重构质量和分割精度方面显著优于JPEG 2000。但对于小规模单通道热红外数据集，传统编解码器仍具有竞争优势。

Conclusion: 研究结果表明，学习型压缩在地球观测任务中具有优势，尤其是在大规模数据集上，预测未来可以在这一领域进一步探索此类压缩方法的潜力。同时，联合优化压缩和分割模型并未提高性能。

Abstract: The rapid growth of data from satellite-based Earth observation (EO) systems poses significant challenges in data transmission and storage. We evaluate the potential of task-specific learned compression algorithms in this context to reduce data volumes while retaining crucial information. In detail, we compare traditional compression (JPEG 2000) versus a learned compression approach (Discretized Mixed Gaussian Likelihood) on three EO segmentation tasks: Fire, cloud, and building detection. Learned compression notably outperforms JPEG 2000 for large-scale, multi-channel optical imagery in both reconstruction quality (PSNR) and segmentation accuracy. However, traditional codecs remain competitive on smaller, single-channel thermal infrared datasets due to limited data and architectural constraints. Additionally, joint end-to-end optimization of compression and segmentation models does not improve performance over standalone optimization.

</details>


### [172] [SAM3-UNet: Simplified Adaptation of Segment Anything Model 3](https://arxiv.org/abs/2512.01789)
*Xinyu Xiong,Zihuang Wu,Lei Lu,Yufa Xia*

Main category: cs.CV

TL;DR: SAM3-UNet 是 SAM3 的简化变体，专为下游任务进行设计，具有参数高效微调和轻量级解码器，实验表明其性能优于 SAM2-UNet 及其他方法，且训练时所需显存小于 6 GB。


<details>
  <summary>Details</summary>
Motivation: 为适应 SAM3 用于下游任务的需求，同时保持低成本和高效率。

Method: SAM3-UNet 包含三个部分：SAM3 图像编码器、简单的适配器用于参数高效微调以及轻量级 U-Net 风格的解码器。

Result: 在多个任务上，如镜子检测和显著目标检测中，SAM3-UNet 的性能优于 SAM2-UNet 和其他先进方法，且训练时显存需求低于 6 GB。

Conclusion: SAM3-UNet 提供了一种低成本、高效的解决方案来适应 SAM3 用于下游任务。

Abstract: In this paper, we introduce SAM3-UNet, a simplified variant of Segment Anything Model 3 (SAM3), designed to adapt SAM3 for downstream tasks at a low cost. Our SAM3-UNet consists of three components: a SAM3 image encoder, a simple adapter for parameter-efficient fine-tuning, and a lightweight U-Net-style decoder. Preliminary experiments on multiple tasks, such as mirror detection and salient object detection, demonstrate that the proposed SAM3-UNet outperforms the prior SAM2-UNet and other state-of-the-art methods, while requiring less than 6 GB of GPU memory during training with a batch size of 12. The code is publicly available at https://github.com/WZH0120/SAM3-UNet.

</details>


### [173] [Generative Action Tell-Tales: Assessing Human Motion in Synthesized Videos](https://arxiv.org/abs/2512.01803)
*Xavier Thomas,Youngsun Lim,Ananya Srinivasan,Audrey Zheng,Deepti Ghadiyaram*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的评估指标，通过结合外观无关的人体骨骼几何特征和外观相关特征，捕捉真实世界动作的细微差异、约束和时间流畅性。该指标在基准测试中显著优于现有方法，并且能够更好地反映人类感知。


<details>
  <summary>Details</summary>
Motivation: 现有的纯视觉编码器和多模态大型语言模型在鉴别生成视频中的复杂运动动态和解剖不可行性方面存在局限，缺乏对真实世界运动的全面理解。本文旨在弥合这一差距，通过一个从真实世界人类动作学习出的潜在空间中提取的指标进行评估。

Method: 该方法首先通过结合外观无关的人体骨骼几何特征和外观相关特征，捕捉真实世界动作的复杂性和时间流畅性。然后，通过测量生成视频底层表示与真实动作分布之间的距离来量化其动作质量。

Result: 在新的多方面基准测试中，本文的方法在动作质量评估上优于现有的最先进的技术，取得了超过68%的提高，并在其他公认的基准测试中表现出竞争力。此外，该方法与人类感知的关联性更强。

Conclusion: 本文提出的方法代表了视频生成模型评估的新标准，深刻揭示了当前视频生成模型的关键局限，并建立了未来研究的新标准。

Abstract: Despite rapid advances in video generative models, robust metrics for evaluating visual and temporal correctness of complex human actions remain elusive. Critically, existing pure-vision encoders and Multimodal Large Language Models (MLLMs) are strongly appearance-biased, lack temporal understanding, and thus struggle to discern intricate motion dynamics and anatomical implausibilities in generated videos. We tackle this gap by introducing a novel evaluation metric derived from a learned latent space of real-world human actions. Our method first captures the nuances, constraints, and temporal smoothness of real-world motion by fusing appearance-agnostic human skeletal geometry features with appearance-based features. We posit that this combined feature space provides a robust representation of action plausibility. Given a generated video, our metric quantifies its action quality by measuring the distance between its underlying representations and this learned real-world action distribution. For rigorous validation, we develop a new multi-faceted benchmark specifically designed to probe temporally challenging aspects of human action fidelity. Through extensive experiments, we show that our metric achieves substantial improvement of more than 68% compared to existing state-of-the-art methods on our benchmark, performs competitively on established external benchmarks, and has a stronger correlation with human perception. Our in-depth analysis reveals critical limitations in current video generative models and establishes a new standard for advanced research in video generation.

</details>


### [174] [Seeing through Imagination: Learning Scene Geometry via Implicit Spatial World Modeling](https://arxiv.org/abs/2512.01821)
*Meng Cao,Haokun Lin,Haoyuan Li,Haoran Tang,Rongtao Xu,Dong An,Xue Liu,Ian Reid,Xiaodan Liang*

Main category: cs.CV

TL;DR: MILO（包含视觉生成模块的隐式空间世界建模框架）和RePE（相对位置编码）通过将符号推理隐式地与感知体验联系起来，增强了MLLM的三维空间理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有的MMLM在空间推理能力方面存在缺陷，主要依赖于文本符号的训练，缺乏与视觉表象的联系，MILO框架旨在填补这一空白。

Method: MILO框架包含视觉生成器，提供几何感知反馈，使MMLM的符号推理与感知体验融为一体；同时提出了RePE，捕捉相对相机姿态变换的新型编码方式。

Result: 实验结果表明，与多种基线和标准相比，该方法显著提升了MLLM的空间推理能力，提供了对三维空间的更全面的理解。

Conclusion: MILO和RePE有助于改善MMLM的空间理解能力，为未来研究提供了新的思路和技术基础。

Abstract: Spatial reasoning, the ability to understand and interpret the 3D structure of the world, is a critical yet underdeveloped capability in Multimodal Large Language Models (MLLMs). Current methods predominantly rely on verbal descriptive tuning, which suffers from visual illiteracy, i.e., they learn spatial concepts through textual symbols alone, devoid of connection to their visual manifestations. To bridge this gap, this paper introduces MILO, an Implicit spatIaL wOrld modeling paradigm that simulates human-like spatial imagination. MILO integrates a visual generator to provide geometry-aware feedback, thereby implicitly grounding the MLLM's symbolic reasoning in perceptual experience. Complementing this paradigm, we propose RePE (Relative Positional Encoding), a novel encoding scheme that captures relative camera-pose transformations, offering superior performance over absolute coordinate systems. To support the training, we construct GeoGen, a large-scale Geometry-aware Generative dataset with approximately 2,241 videos and 67,827 observation-action-outcome triplets. Experiments demonstrate that our approach significantly enhances spatial reasoning capabilities across multiple baselines and benchmarks, offering a more holistic understanding of 3D space.

</details>


### [175] [CauSight: Learning to Supersense for Visual Causal Discovery](https://arxiv.org/abs/2512.01827)
*Yize Zhang,Meiqi Chen,Sirui Chen,Bo Peng,Yanxi Zhang,Tianyu Li,Chaochao Lu*

Main category: cs.CV

TL;DR: 本研究旨在通过构建Visual Causal Graph（VCG-32K）数据集并开发CauSight模型，提升现代AI系统在视觉因果发现任务上的能力。CauSight模型结合了数据集构建、因果推理轨迹合成和强化学习等方法，显著提升了视觉因果发现任务的性能。


<details>
  <summary>Details</summary>
Motivation: 在现代AI系统中复制人类的因果思维能力，以更好地理解和预测视觉实体之间的因果关系。

Method: 本研究通过三个关键步骤进行：首先构建VCG-32K数据集，包含大量带有实体级因果图的图像；其次开发CauSight模型，通过因果感知推理来执行视觉因果发现；最后采用数据集构建、因果推理轨迹合成和基于因果奖励的强化学习作为训练方法。

Result: 实验表明，CauSight模型在视觉因果发现任务中大幅优于GPT-4.1，绝对性能提升了21%，达到三倍以上。

Conclusion: CauSight模型代表了在AI系统中处理复杂视觉因果关系的最新进展，并开启了进一步研究和应用的可能性。

Abstract: Causal thinking enables humans to understand not just what is seen, but why it happens. To replicate this capability in modern AI systems, we introduce the task of visual causal discovery. It requires models to infer cause-and-effect relations among visual entities across diverse scenarios instead of merely perceiving their presence. To this end, we first construct the Visual Causal Graph dataset (VCG-32K), a large-scale collection of over 32,000 images annotated with entity-level causal graphs, and further develop CauSight, a novel vision-language model to perform visual causal discovery through causally aware reasoning. Our training recipe integrates three components: (1) training data curation from VCG-32K, (2) Tree-of-Causal-Thought (ToCT) for synthesizing reasoning trajectories, and (3) reinforcement learning with a designed causal reward to refine the reasoning policy. Experiments show that CauSight outperforms GPT-4.1 on visual causal discovery, achieving over a threefold performance boost (21% absolute gain). Our code, model, and dataset are fully open-sourced at project page: https://github.com/OpenCausaLab/CauSight.

</details>


### [176] [OpenREAD: Reinforced Open-Ended Reasoing for End-to-End Autonomous Driving with LLM-as-Critic](https://arxiv.org/abs/2512.01830)
*Songyan Zhang,Wenhui Huang,Zhan Chen,Chua Jiahao Collister,Qihang Huang,Chen Lv*

Main category: cs.CV

TL;DR: 该研究提出了一种名为OpenREAD的框架，结合了视觉语言模型和强化学习，旨在实现从高层次推理到低层次轨迹规划的端到端增强学习，通过构建大型链式思考注释和使用强有力的Qwen3大语言模型作为强化学习中的评论家，量化开放性问题中的推理质量。


<details>
  <summary>Details</summary>
Motivation: 当前的两阶段精细调优策略虽然表现出色，但存在推理泛化能力受限和强化学习应用下游任务难以量化等问题，因此该研究针对上述问题提出了OpenREAD框架。

Method: OpenREAD框架首先构建了大规模的链式思考注释在开源驾驶相关知识数据集上，然后利用强大的Qwen3大语言模型作为强化学习中的评论家，在奖励建模期间量化开放性问题中的推理质量。

Result: 实验表明，端到端强化学习结合视觉语言模型能够显著提高上下游任务的表现，使OpenREAD在推理和规划基准上达到最新技术水平。

Conclusion: 该研究为实现自主驾驶中的推理与规划之间的有效强化学习提供了新的解决方案，并为类似问题的未来研究奠定了基础。

Abstract: Recently, two-stage fine-tuning strategies, e.g., acquiring essential driving knowledge through supervised fine-tuning (SFT) and further enhancing decision-making and planning via reinforcement fine-tuning (RFT), have shown strong potential in advancing the knowledge-driven autonomous driving (AD) paradigm. However, the learning nature of SFT still limits the generalization of reasoning, thereby constraining the full potential of driving performance. Meanwhile, current RFT approaches are primarily applied to downstream tasks, since scene understanding is an open-ended problem where corresponding rewards are difficult to quantify. To address these limitations, we propose OpenREAD, an OPEN-ended REasoning reinforced vision-language model (VLM)-based autonomous driving (AD) framework that enables end-to-end RFT across the full spectrum from high-level reasoning to low-level trajectory planning. Specifically, we begin by constructing large-scale Chain-of-Thought (CoT) annotations on open-source driving-related knowledge datasets, and employ the powerful Qwen3 large language model (LLM) as the critic in RFT to quantify reasoning quality for open-ended questions during reward modeling. Extensive experiments confirm that joint end-to-end RFT yields substantial improvements in both upstream and downstream tasks, enabling OpenREAD to achieve state-of-the-art performance on reasoning and planning benchmarks.

</details>


### [177] [PhyDetEx: Detecting and Explaining the Physical Plausibility of T2V Models](https://arxiv.org/abs/2512.01843)
*Zeqing Wang,Keze Wang,Lei Zhang*

Main category: cs.CV

TL;DR: 该研究构建了一个包含人工标注视频和生成的物理不合理的视频的数据集，并开发了一种轻量级微调方法，使视觉-语言模型能够检测物理不合理的内容并解释违反的物理原理。基准测试显示，尽管最近的文本到视频生成模型在生成物理合理内容方面取得了显著进展，但理解和遵循物理规律仍然具有挑战性。


<details>
  <summary>Details</summary>
Motivation: 尽管当前的文本到视频生成模型在视频质量、长度和指令遵循能力方面取得了显著进步，但它们是否能理解物理原理并生成物理合理的视频仍然存疑。当前的视觉-语言模型难以识别生成视频中的物理不合理内容。

Method: 该研究构建了一个名为PID的数据集，包含测试集和训练集。通过精细调整视觉语言模型PhyDetEx，能够检测生成视频中的物理不合理事件并提供文本解释，违反的物理原理。

Result: 研究发现，尽管最新的文本到视频生成模型在生成物理合理内容方面取得了显著进展，但理解和遵守物理法规则仍然具有挑战性。PhyDetEx框架能够有效地检测并解释视频中的物理不合理现象，有助于提高模型生成内容的真实性和合理性。

Conclusion: 该研究开发了一个新的数据集和检测框架，有助于推进文本到视频生成模型对于物理合理性和规则的遵循，提供了一种新的评估和改进技术。

Abstract: Driven by the growing capacity and training scale, Text-to-Video (T2V) generation models have recently achieved substantial progress in video quality, length, and instruction-following capability. However, whether these models can understand physics and generate physically plausible videos remains a question. While Vision-Language Models (VLMs) have been widely used as general-purpose evaluators in various applications, they struggle to identify the physically impossible content from generated videos. To investigate this issue, we construct a \textbf{PID} (\textbf{P}hysical \textbf{I}mplausibility \textbf{D}etection) dataset, which consists of a \textit{test split} of 500 manually annotated videos and a \textit{train split} of 2,588 paired videos, where each implausible video is generated by carefully rewriting the caption of its corresponding real-world video to induce T2V models producing physically implausible content. With the constructed dataset, we introduce a lightweight fine-tuning approach, enabling VLMs to not only detect physically implausible events but also generate textual explanations on the violated physical principles. Taking the fine-tuned VLM as a physical plausibility detector and explainer, namely \textbf{PhyDetEx}, we benchmark a series of state-of-the-art T2V models to assess their adherence to physical laws. Our findings show that although recent T2V models have made notable progress toward generating physically plausible content, understanding and adhering to physical laws remains a challenging issue, especially for open-source models. Our dataset, training code, and checkpoints are available at \href{https://github.com/Zeqing-Wang/PhyDetEx}{https://github.com/Zeqing-Wang/PhyDetEx}.

</details>


### [178] [Register Any Point: Scaling 3D Point Cloud Registration by Flow Matching](https://arxiv.org/abs/2512.01850)
*Yue Pan,Tao Sun,Liyuan Zhu,Lucas Nunes,Iro Armeni,Jens Behley,Cyrill Stachniss*

Main category: cs.CV

TL;DR: 该研究将点云配准问题重新定义为条件生成任务，利用学习得到的连续点 wise 位移场生成配准后的点云，无需传统方法中的对应匹配步骤和多次优化。


<details>
  <summary>Details</summary>
Motivation: 当前方法在处理低重叠、多尺度和多传感器模态场景的点云配准时表现不佳。因此，研究提出了一种新的方法，利用轻量级局部特征提取器和测试时间刚性约束，以实现更优秀的配准效果。

Method: 该方法通过学习一个连续的、点 wise 的位移场，直接生成配准后的点云，而不是传统方法中的对应匹配和多次优化。

Result: 该方法在一对点云和多视角配准基准测试中取得了最先进的结果，特别是在低重叠场景中表现突出。并且该方法具有多尺度通用性和传感器模态兼容性。

Conclusion: 该工作展示了一种新的点云配准方法，能够有效解决低重叠、多尺度和多传感器模态场景的问题，对未来的多机器人 SLAM 和多会话地图合并等下游任务具有潜在应用价值。

Abstract: Point cloud registration aligns multiple unposed point clouds into a common frame, and is a core step for 3D reconstruction and robot localization. In this work, we cast registration as conditional generation: a learned continuous, point-wise velocity field transports noisy points to a registered scene, from which the pose of each view is recovered. Unlike previous methods that conduct correspondence matching to estimate the transformation between a pair of point clouds and then optimize the pairwise transformations to realize multi-view registration, our model directly generates the registered point cloud. With a lightweight local feature extractor and test-time rigidity enforcement, our approach achieves state-of-the-art results on pairwise and multi-view registration benchmarks, particularly with low overlap, and generalizes across scales and sensor modalities. It further supports downstream tasks including relocalization, multi-robot SLAM, and multi-session map merging. Source code available at: https://github.com/PRBonn/RAP.

</details>


### [179] [COACH: Collaborative Agents for Contextual Highlighting - A Multi-Agent Framework for Sports Video Analysis](https://arxiv.org/abs/2512.01853)
*Tsz-To Wong,Ching-Chun Huang,Hong-Han Shuai*

Main category: cs.CV

TL;DR: 本文提出了一种可重构的多智能体系统（MAS），该系统作为一个基础框架用于体育视频理解。该系统通过迭代调用和灵活组合，构建适配的分析管道，实现从微尺度动作到宏观策略的理解。


<details>
  <summary>Details</summary>
Motivation: 现有的一体化模型在处理长短期任务时往往表现不佳，无法泛化，需高开发成本，并且缺乏解释性。因此，介绍MAS作为可重构框架，旨在提供一种灵活、可扩展且可解释的解决方案，以处理复杂的体育视频分析任务。

Method: 该研究提出了一种多智能体系统，每个智能体专注于特定分析方面的认知工具。系统通过迭代调用和灵活组合这些智能体，可以构建适用于短期和长期任务的适应性管道。

Result: 该框架在羽毛球分析任务中展示了适应性，能够在细粒度事件检测和全局语义组织之间建立桥梁。

Conclusion: 研究成果表明，MAS为体育视频智能分析提供了一种新的方向，具备跨任务的灵活性、可扩展性和解释性。

Abstract: Intelligent sports video analysis demands a comprehensive understanding of temporal context, from micro-level actions to macro-level game strategies. Existing end-to-end models often struggle with this temporal hierarchy, offering solutions that lack generalization, incur high development costs for new tasks, and suffer from poor interpretability. To overcome these limitations, we propose a reconfigurable Multi-Agent System (MAS) as a foundational framework for sports video understanding. In our system, each agent functions as a distinct "cognitive tool" specializing in a specific aspect of analysis. The system's architecture is not confined to a single temporal dimension or task. By leveraging iterative invocation and flexible composition of these agents, our framework can construct adaptive pipelines for both short-term analytic reasoning (e.g., Rally QA) and long-term generative summarization (e.g., match summaries). We demonstrate the adaptability of this framework using two representative tasks in badminton analysis, showcasing its ability to bridge fine-grained event detection and global semantic organization. This work presents a paradigm shift towards a flexible, scalable, and interpretable system for robust, cross-task sports video intelligence.The project homepage is available at https://aiden1020.github.io/COACH-project-page

</details>


### [180] [TransientTrack: Advanced Multi-Object Tracking and Classification of Cancer Cells with Transient Fluorescent Signals](https://arxiv.org/abs/2512.01885)
*Florian Bürger,Martim Dias Gomes,Nica Gutu,Adrián E. Granada,Noémie Moreau,Katarzyna Bozek*

Main category: cs.CV

TL;DR: TransientTrack 是一个基于深度学习的框架，用于在具有瞬态荧光信号的多通道显微镜视频数据中追踪细胞。该方法能够识别关键细胞事件，如细胞分裂和细胞凋亡，构建完整的轨迹，并通过集成Transformer Network、多阶段匹配和Kalman滤波补全缺失的追踪片段。


<details>
  <summary>Details</summary>
Motivation: 当前的细胞追踪方法多针对单一时不变信号的视频数据，无法检测如细胞凋亡等关键细胞事件。TransientTrack旨在处理含有瞬态荧光信号、波动随细胞周期进程的多通道显微镜视频数据，实现细胞轨迹完整性和细胞谱系信息的构建。

Method: TransientTrack 使用 Transformer Network 和多阶段匹配方法，直接在细胞检测嵌入中进行匹配，无需量化追踪特异性细胞特征。此外，该方法结合了 Kalman 滤波器用于补全缺失的追踪片段。

Result: 该方法在多种条件下表现出色，可以有效追踪细胞并捕捉细胞分裂和细胞凋亡事件。已通过分析化疗药物的单细胞疗效验证了其有效性。

Conclusion: TransientTrack 为癌症细胞动力学的定量研究提供了新的方法，有助于详细解析治疗反应和耐药机制。

Abstract: Tracking cells in time-lapse videos is an essential technique for monitoring cell population dynamics at a single-cell level. Current methods for cell tracking are developed on videos with mostly single, constant signals and do not detect pivotal events such as cell death. Here, we present TransientTrack, a deep learning-based framework for cell tracking in multi-channel microscopy video data with transient fluorescent signals that fluctuate over time following processes such as the circadian rhythm of cells. By identifying key cellular events - mitosis (cell division) and apoptosis (cell death) our method allows us to build complete trajectories, including cell lineage information. TransientTrack is lightweight and performs matching on cell detection embeddings directly, without the need for quantification of tracking-specific cell features. Furthermore, our approach integrates Transformer Networks, multi-stage matching using all detection boxes, and the interpolation of missing tracklets with the Kalman Filter. This unified framework achieves strong performance across diverse conditions, effectively tracking cells and capturing cell division and death. We demonstrate the use of TransientTrack in an analysis of the efficacy of a chemotherapeutic drug at a single-cell level. The proposed framework could further advance quantitative studies of cancer cell dynamics, enabling detailed characterization of treatment response and resistance mechanisms. The code is available at https://github.com/bozeklab/TransientTrack.

</details>


### [181] [KM-ViPE: Online Tightly Coupled Vision-Language-Geometry Fusion for Open-Vocabulary Semantic SLAM](https://arxiv.org/abs/2512.01889)
*Zaid Nasser,Mikhail Iumanov,Tianhao Li,Maxim Popov,Jaafar Mahmoud,Malik Mohrat,Ilya Obrubov,Ekaterina Derevyanka,Ivan Sosin,Sergey Kolyubin*

Main category: cs.CV

TL;DR: KM-ViPE是一种实时、开放词汇的SLAM系统，能够直接处理无校准的单目摄像机的原始RGB流，适用于动态环境下的自主机器人和AR/VR应用。


<details>
  <summary>Details</summary>
Motivation: 为了在多样化和变化的环境下，特别是以自我中心视角，构建有效的实时视觉定位与语义映射系统，尤其是那些不需要深度传感器和预先校准的系统。

Method: KM-ViPE通过结合DINO视觉特征和几何约束，使用高阶特征自适应鲁棒核来处理移动对象和可移动的静态对象，通过几何和深度视觉特征的融合以及与语言嵌入的对齐来进行同步在线定位和开放词汇语义建模。

Result: KM-ViPE在性能上与最先进的方法相当，特别是它能够在没有深度数据或里程计估计需求的情况下实时运行，同时能够稳健地处理动态场景。

Conclusion: KM-ViPE代表了在动态环境下处理单目摄像机的先进解决方案，为自主机器人和AR/VR等应用提供了新的可能性，提升了实体人工智能的空间智能应用能力。

Abstract: We present KM-ViPE (Knowledge Mapping Video Pose Engine), a real-time open-vocabulary SLAM framework for uncalibrated monocular cameras in dynamic environments. Unlike systems requiring depth sensors and offline calibration, KM-ViPE operates directly on raw RGB streams, making it ideal for ego-centric applications and harvesting internet-scale video data for training. KM-ViPE tightly couples DINO visual features with geometric constraints through a high-level features based adaptive robust kernel that handles both moving objects and movable static objects (e.g., moving furniture in ego-centric views). The system performs simultaneous online localization and open-vocabulary semantic mapping by fusing geometric and deep visual features aligned with language embeddings. Our results are competitive with state-of-the-art approaches, while existing solutions either operate offline, need depth data and/or odometry estimation, or lack dynamic scene robustness. KM-ViPE benefits from internet-scale training and uniquely combines online operation, uncalibrated monocular input, and robust handling of dynamic scenes, which makes it a good fit for autonomous robotics and AR/VR applications and advances practical spatial intelligence capabilities for embodied AI.

</details>


### [182] [StyleYourSmile: Cross-Domain Face Retargeting Without Paired Multi-Style Data](https://arxiv.org/abs/2512.01895)
*Avirup Dey,Vinay Namboodiri*

Main category: cs.CV

TL;DR: StyleYourSmile 提出了一种无需精选多风格配对数据的单步跨域人脸重定位方法，通过一个高效的扩展策略和双编码器框架，实现跨域一致的身份特征提取与特定领域风格变体捕捉，利用这些解耦控制信号，条件化一个扩散模型进行面部表情跨域重定位。


<details>
  <summary>Details</summary>
Motivation: 现有的跨域人脸重定位方法往往需要精心编排的多风格配对数据，无法很好地泛化到不同领域，且需要在测试时优化或对细调，而 StyleYourSmile 则解决了这些问题。

Method: StyleYourSmile 提出了一个高效的扩展策略和双编码器框架。通过此方法，有效提取跨域一致的身份特征，并捕捉特定领域风格变化。基于解耦控制信号，利用扩散模型实现跨域面部表情重定位。

Result: 广泛的实验表明，StyleYourSmile 在各种视觉领域中实现了优秀的身份保真和重定位准确性。

Conclusion: StyleYourSmile 在跨域人脸重定位方面表现出色，解决了现有方法的诸多问题，特别适用于无需精细数据构建的跨领域应用。

Abstract: Cross-domain face retargeting requires disentangled control over identity, expressions, and domain-specific stylistic attributes. Existing methods, typically trained on real-world faces, either fail to generalize across domains, need test-time optimizations, or require fine-tuning with carefully curated multi-style datasets to achieve domain-invariant identity representations. In this work, we introduce \textit{StyleYourSmile}, a novel one-shot cross-domain face retargeting method that eliminates the need for curated multi-style paired data. We propose an efficient data augmentation strategy alongside a dual-encoder framework, for extracting domain-invariant identity cues and capturing domain-specific stylistic variations. Leveraging these disentangled control signals, we condition a diffusion model to retarget facial expressions across domains. Extensive experiments demonstrate that \textit{StyleYourSmile} achieves superior identity preservation and retargeting fidelity across a wide range of visual domains.

</details>


### [183] [SARL: Spatially-Aware Self-Supervised Representation Learning for Visuo-Tactile Perception](https://arxiv.org/abs/2512.01908)
*Gurmeher Khurana,Lan Wei,Dandan Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种新的自监督学习框架SARL，通过增加自注意力匹配、子块原型分布匹配和区域亲和匹配三个地图级目标，保持了视触觉数据跨视角下的注意力焦点、部件组成和几何关系一致性，从而使SARL在六项下游任务中均优于九种基线方法，特别是在几何敏感的边缘姿态回归任务上显著优于其他方法。


<details>
  <summary>Details</summary>
Motivation: 当前大多数自监督学习框架会压缩特征图到全局向量中，忽略了空间结构，与机器人操作任务所需的视觉和触觉信息不匹配。

Method: SARL框架扩展了BYOL架构，引入了三种图级目标：注意匹配(SAL)、块原型分布匹配(PPDA)和区域相关度匹配(RAM)，确保中间特征图中的注意力焦点、部分组成和几何关系保持一致性。

Result: SARL在六项下游任务中均优于九种基线方法，特别是在几何敏感的边缘姿态回归任务中，均方绝对误差(MAE)为0.3955，比第二名高出30%，接近监督学习的上限。

Conclusion: 对于融合视触觉数据，SARL表明最有效的信号是结构化的空间等变性，这使得机器人感知更加强大。

Abstract: Contact-rich robotic manipulation requires representations that encode local geometry. Vision provides global context but lacks direct measurements of properties such as texture and hardness, whereas touch supplies these cues. Modern visuo-tactile sensors capture both modalities in a single fused image, yielding intrinsically aligned inputs that are well suited to manipulation tasks requiring visual and tactile information. Most self-supervised learning (SSL) frameworks, however, compress feature maps into a global vector, discarding spatial structure and misaligning with the needs of manipulation. To address this, we propose SARL, a spatially-aware SSL framework that augments the Bootstrap Your Own Latent (BYOL) architecture with three map-level objectives, including Saliency Alignment (SAL), Patch-Prototype Distribution Alignment (PPDA), and Region Affinity Matching (RAM), to keep attentional focus, part composition, and geometric relations consistent across views. These losses act on intermediate feature maps, complementing the global objective. SARL consistently outperforms nine SSL baselines across six downstream tasks with fused visual-tactile data. On the geometry-sensitive edge-pose regression task, SARL achieves a Mean Absolute Error (MAE) of 0.3955, a 30% relative improvement over the next-best SSL method (0.5682 MAE) and approaching the supervised upper bound. These findings indicate that, for fused visual-tactile data, the most effective signal is structured spatial equivariance, in which features vary predictably with object geometry, which enables more capable robotic perception.

</details>


### [184] [Med-VCD: Mitigating Hallucination for Medical Large Vision Language Models through Visual Contrastive Decoding](https://arxiv.org/abs/2512.01922)
*Zahra Mahdavi,Zahra Khodakaramimaghsoud,Hooman Khaloo,Sina Bakhshandeh Taleshani,Erfan Hashemi,Javad Mirzapour Kaleybar,Omid Nejati Manzari*

Main category: cs.CV

TL;DR: Med-VCD 提出了一种在医疗领域的大规模视觉语言模型中减少幻觉输出的方法，通过一种新颖的按需稀疏视觉对比解码策略，在保证效率的同时提高了事实准确性和幻觉准确性。


<details>
  <summary>Details</summary>
Motivation: VLANMs 在医疗领域如医学视觉问答和图像报告生成等应用中变得非常重要，但普遍存在幻觉输出问题。现有的缓解幻觉的方法主要依赖于二次解码或回滚过程，这会显著增加推理时间，且现有解决方案多具有领域特定性，可能导致模态间或生成内容与真实内容之间的对齐问题。

Method: Med-VCD 通过引入一种新颖的按需稀疏视觉对比解码方法，直接在视觉证据中进行解码处理，选择视觉信息丰富的令牌，降低冗余，保留关键视觉上下文，从而平衡效率与可靠性。

Result: 实验在八个涉及眼科、放射学和病理学等任务的医疗数据集上显示，与基线医疗 VLANMs 相比，Med-VCD 方法在视觉问答、报告生成和专门的幻觉基准测试中，分别提高了 13% 的事实准确率和 6% 的幻觉准确率。

Conclusion: Med-VCD 方法显著提高了医疗 VLANMs 的事实准确性和幻觉准确性，展示了其在医疗场景下减少幻觉输出的有效性。

Abstract: Large vision-language models (LVLMs) are now central to healthcare applications such as medical visual question answering and imaging report generation. Yet, these models remain vulnerable to hallucination outputs that appear plausible but are in fact incorrect. In the natural image domain, several decoding strategies have been proposed to mitigate hallucinations by reinforcing visual evidence, but most rely on secondary decoding or rollback procedures that substantially slow inference. Moreover, existing solutions are often domain-specific and may introduce misalignment between modalities or between generated and ground-truth content. We introduce Med-VCD, a sparse visual-contrastive decoding method that mitigates hallucinations in medical LVLMs without the time overhead of secondary decoding. Med-VCD incorporates a novel token-sparsification strategy that selects visually informed tokens on the fly, trimming redundancy while retaining critical visual context and thus balancing efficiency with reliability. Evaluations on eight medical datasets, spanning ophthalmology, radiology, and pathology tasks in visual question answering, report generation, and dedicated hallucination benchmarks, show that Med-VCD raises factual accuracy by an average of 13\% and improves hallucination accuracy by 6\% relative to baseline medical LVLMs.

</details>


### [185] [Physical ID-Transfer Attacks against Multi-Object Tracking via Adversarial Trajectory](https://arxiv.org/abs/2512.01934)
*Chenyi Wang,Yanmao Man,Raymond Muller,Ming Li,Z. Berkay Celik,Ryan Gerdes,Jonathan Petit*

Main category: cs.CV

TL;DR: 本文介绍了AdvTraj，一种针对基于检测跟踪的多对象跟踪系统的首个在线物理ID操纵攻击，攻击者通过敌对轨迹将目标ID转移到目标对象，从而欺骗跟踪系统，并展示了在CARLA中的仿真结果表明，对于白盒攻击，AdvTraj可以100%成功，具有一定的攻击迁移性。


<details>
  <summary>Details</summary>
Motivation: 当前的多对象跟踪(MOT)算法缺乏对攻击的广泛研究，尤其是攻击者可以通过操纵跟踪系统中的ID分配来误导跟踪结果，这可能导致严重的后果。因此，本文提出了AdvTraj，旨在揭示SOTA MOT系统的潜在弱点，提升系统鲁棒性。

Method: 本文提出了一种在线的物理ID操纵攻击，通过在现实场景中生成敌对轨迹并转移目标ID来欺骗跟踪系统。该攻击基于模拟研究，验证了其在不同场景下的成功和跨算法的通用性。

Result: AdvTraj在CARLA中的仿真结果显示，它能够100%成功欺骗ID分配，并且对SOTA跟踪算法具有一般适用性，成功率达93%。

Conclusion: 本文揭示了SOTA MOT系统中未充分探索的弱点，特别是对象关联阶段，提供的额外见解有助于提高MOT系统的鲁棒性。

Abstract: Multi-Object Tracking (MOT) is a critical task in computer vision, with applications ranging from surveillance systems to autonomous driving. However, threats to MOT algorithms have yet been widely studied. In particular, incorrect association between the tracked objects and their assigned IDs can lead to severe consequences, such as wrong trajectory predictions. Previous attacks against MOT either focused on hijacking the trackers of individual objects, or manipulating the tracker IDs in MOT by attacking the integrated object detection (OD) module in the digital domain, which are model-specific, non-robust, and only able to affect specific samples in offline datasets. In this paper, we present AdvTraj, the first online and physical ID-manipulation attack against tracking-by-detection MOT, in which an attacker uses adversarial trajectories to transfer its ID to a targeted object to confuse the tracking system, without attacking OD. Our simulation results in CARLA show that AdvTraj can fool ID assignments with 100% success rate in various scenarios for white-box attacks against SORT, which also have high attack transferability (up to 93% attack success rate) against state-of-the-art (SOTA) MOT algorithms due to their common design principles. We characterize the patterns of trajectories generated by AdvTraj and propose two universal adversarial maneuvers that can be performed by a human walker/driver in daily scenarios. Our work reveals under-explored weaknesses in the object association phase of SOTA MOT systems, and provides insights into enhancing the robustness of such systems.

</details>


### [186] [Script: Graph-Structured and Query-Conditioned Semantic Token Pruning for Multimodal Large Language Models](https://arxiv.org/abs/2512.01949)
*Zhongyu Yang,Dannong Xu,Wei Pang,Yingfang Yuan*

Main category: cs.CV

TL;DR: Script 是一种无需重新训练的插件式剪枝方法，适用于多种 MLLMs，能够高效去除视觉冗余并保留与用户查询相关的视觉信息，从而在各种多模态任务中提高模型效率和预测准确性。


<details>
  <summary>Details</summary>
Motivation: 随着视觉标记在 MLLMs 中的快速增长，模型面临内存占用和推理延迟增加的问题。现有剪枝方法要么忽视查询相关性，要么受限于注意力机制，降低了其适应性和有效性。因此，需要一种插件式剪枝方法，能够在无需重新训练的情况下，广泛适用于不同 MLLMs 并有效处理视觉冗余。

Method: Script 方法由两个模块组成：图形结构化的剪枝模块和查询条件语义剪枝模块。图形结构化修剪模块通过剪枝视觉冗余标记来去除冗余，而查询条件语义修剪模块则保留与查询相关的视觉信息。二者结合，增强了多模态任务的表现。

Result: Script 在来自图像和视频理解任务的 14 个基准测试中，相比现有剪枝方法，表现出更高的模型效率和预测准确性。在 LLaVA-NeXT-7B 上，其填充值提升高达 6.8 倍，浮点运算减少 10 倍，同时保留了 96.88% 的原始性能。

Conclusion: Script 是一种有效的无重新训练插件式剪枝方法，能够在多种 MLLMs 中高效去除冗余视觉信息和保留相关视觉信息，从而改善多模态任务中的模型效率和预测表现。

Abstract: The rapid growth of visual tokens in multimodal large language models (MLLMs) leads to excessive memory consumption and inference latency, especially when handling high-resolution images and videos. Token pruning is a technique used to mitigate this issue by removing redundancy, but existing methods often ignore relevance to the user query or suffer from the limitations of attention mechanisms, reducing their adaptability and effectiveness. To address these challenges, we propose Script, a plug-and-play pruning method that requires no retraining and generalizes across diverse MLLMs. Script comprises two modules: a graph-structured pruning module that removes visually redundant tokens, and a query-conditioned semantic pruning module that preserves query-relevant visual information. Together, they enhance performance on multimodal tasks. Experiments on fourteen benchmarks across image and video understanding tasks show that Script consistently achieves higher model efficiency and predictive accuracy compared to existing pruning methods. On LLaVA-NeXT-7B, it achieves up to 6.8x prefill speedup and 10x FLOP reduction, while retaining 96.88% of the original performance.

</details>


### [187] [SpriteHand: Real-Time Versatile Hand-Object Interaction with Autoregressive Video Generation](https://arxiv.org/abs/2512.01960)
*Zisu Li,Hengye Lyu,Jiaxin Shi,Yufeng Zeng,Mingming Fan,Hanwang Zhang,Chen Liang*

Main category: cs.CV

TL;DR: SpriteHand 是一个自回归视频生成框架，用于实时合成各种手物体交互视频，支持不同物体类型和运动模式，能在单张 RTX 5090 显卡上以约 18 FPS 和 640x368 分辨率实现实时流式生成，且具有约 150ms 延迟，同时在视觉保真度、物理可信度和交互真实性方面优于同类基准.


<details>
  <summary>Details</summary>
Motivation: 当前的模拟基视频生成框架依赖于明确的刚体模型和预编排的手势，对于处理非刚体或铰接结构实体（如可变形面料、弹性材料、铰链结构、毛茸表面或活体生物）的动态交互存在局限。SpriteHand旨在克服这些局限，通过引入一个自回归视频生成框架，实现对多种物体类型和运动模式的实时手物交互效果合成。

Method: SpriteHand采用因果推断架构进行自回归生成，并结合混合后训练方法来增强视觉真实性和时间一致性。它将静态对象图像和想象中的手与虚拟对象进行交互的视频流作为输入，生成实时的手物体交互效果。

Result: SpriteHand在视觉保真度、物理可信度和交互真实性方面优于现有生成模型和物理引擎基准，支持每秒约18帧的实时视频生成，延迟约150ms，同时对物体类型和运动模式具有广泛适用性。

Conclusion: SpriteHand为手物体交互视频的实时生成提供了新的解决方案，显著增强了视频生成的真实性和交互性，有助于提升虚拟现实和增强现实领域的用户体验。

Abstract: Modeling and synthesizing complex hand-object interactions remains a significant challenge, even for state-of-the-art physics engines. Conventional simulation-based approaches rely on explicitly defined rigid object models and pre-scripted hand gestures, making them inadequate for capturing dynamic interactions with non-rigid or articulated entities such as deformable fabrics, elastic materials, hinge-based structures, furry surfaces, or even living creatures. In this paper, we present SpriteHand, an autoregressive video generation framework for real-time synthesis of versatile hand-object interaction videos across a wide range of object types and motion patterns. SpriteHand takes as input a static object image and a video stream in which the hands are imagined to interact with the virtual object embedded in a real-world scene, and generates corresponding hand-object interaction effects in real time. Our model employs a causal inference architecture for autoregressive generation and leverages a hybrid post-training approach to enhance visual realism and temporal coherence. Our 1.3B model supports real-time streaming generation at around 18 FPS and 640x368 resolution, with an approximate 150 ms latency on a single NVIDIA RTX 5090 GPU, and more than a minute of continuous output. Experiments demonstrate superior visual quality, physical plausibility, and interaction fidelity compared to both generative and engine-based baselines.

</details>


### [188] [SGDiff: Scene Graph Guided Diffusion Model for Image Collaborative SegCaptioning](https://arxiv.org/abs/2512.01975)
*Xu Zhang,Jin Yuan,Hanwang Zhang,Guojin Zhong,Yongsheng Zang,Jiacheng Lin,Zhiyong Li*

Main category: cs.CV

TL;DR: 该研究提出了一种新的图像协作分割和字幕生成任务（SegCaptioning），通过一个新颖的场景图引导的扩散模型（SGDiff）实现从简明的图像提示生成多个语义一致的字幕和掩码对，通过多实体对比学习确保视觉和文本实体间的一致性。


<details>
  <summary>Details</summary>
Motivation: 现有图像语义理解任务如字幕生成和分割受限于高成本的提示输入或信息量不足的问题，因此提出了一种新的任务SegCaptioning，旨在通过简明的图像提示生成多样化的语义解读。

Method: 研究提出了一种新的Scene Graph Guided Diffusion Model。首先，通过Prompt-Centric Scene Graph Adaptor将用户提示映射到场景图，然后利用场景图引导的二模态变换器进行扩散过程，预测语义一致的字幕和掩码对，同时设计了多实体对比学习损失以确保视觉与文本实体间的对齐。

Result: 实验结果表明，SGDiff在SegCaptioning任务中表现出优异性能，相较于现有方法，该模型能够通过简明的图像提示生成良好的字幕和分割结果。

Conclusion: 研究提出的方法SGDiff在新任务SegCaptioning中实现了良好的效果，通过简明的提示生成了高质量的字幕和分割结果，解决了一些现有的挑战。

Abstract: Controllable image semantic understanding tasks, such as captioning or segmentation, necessitate users to input a prompt (e.g., text or bounding boxes) to predict a unique outcome, presenting challenges such as high-cost prompt input or limited information output. This paper introduces a new task ``Image Collaborative Segmentation and Captioning'' (SegCaptioning), which aims to translate a straightforward prompt, like a bounding box around an object, into diverse semantic interpretations represented by (caption, masks) pairs, allowing flexible result selection by users. This task poses significant challenges, including accurately capturing a user's intention from a minimal prompt while simultaneously predicting multiple semantically aligned caption words and masks. Technically, we propose a novel Scene Graph Guided Diffusion Model that leverages structured scene graph features for correlated mask-caption prediction. Initially, we introduce a Prompt-Centric Scene Graph Adaptor to map a user's prompt to a scene graph, effectively capturing his intention. Subsequently, we employ a diffusion process incorporating a Scene Graph Guided Bimodal Transformer to predict correlated caption-mask pairs by uncovering intricate correlations between them. To ensure accurate alignment, we design a Multi-Entities Contrastive Learning loss to explicitly align visual and textual entities by considering inter-modal similarity, resulting in well-aligned caption-mask pairs. Extensive experiments conducted on two datasets demonstrate that SGDiff achieves superior performance in SegCaptioning, yielding promising results for both captioning and segmentation tasks with minimal prompt input.

</details>


### [189] [Artemis: Structured Visual Reasoning for Perception Policy Learning](https://arxiv.org/abs/2512.01988)
*Wei Tang,Yanpeng Sun,Shan Zhang,Xiaofan Li,Piotr Koniusz,Wei Li,Na Zhao,Zechao Li*

Main category: cs.CV

TL;DR: 文章提出了一种名为Artemis的视觉感知政策学习框架，该框架采用结构化的提案推理，每一中间步骤表示为带有边界框的标签对，以捕捉可验证的视觉状态。实验结果显示，这种框架在多种感知任务中表现出色，并且能够通过空间化的推理增强感知政策的学习效果。


<details>
  <summary>Details</summary>
Motivation: 研究解决了传统基于纯语言的中间推理在视觉感知任务中性能下降的问题，认为关键不在于推理本身，而在于推理的表述方式，即在一个未经结构化的语言空间内进行的语义推理无法满足视觉感知的需求。因此，需要一种更符合视觉感知需求的推理方式。

Method: Artemis框架采用了结构化的提案推理方法，将每一中间步骤表示为带有边界框的标签对，这样不仅能够明确跟踪中间状态，还可以为提案的质量提供直接监督，避免语言推理带来的模糊性。

Result: 在多种感知任务上，如定位和检测任务中，Artemis框架表现出了强大的性能，并且在计数和几何感知任务上也表现出色。此外，该框架也展示了在通用多模态语言模型基准测试中的竞争力。

Conclusion: 通过强化视觉推理，Artemis框架为构建可扩展且通用的感知政策提供了一条原则性途径，证明了遵循空间表示进行推理能够提升视觉感知政策的学习效果。

Abstract: Recent reinforcement-learning frameworks for visual perception policy have begun to incorporate intermediate reasoning chains expressed in natural language. Empirical observations indicate that such purely linguistic intermediate reasoning often reduces performance on perception tasks. We argue that the core issue lies not in reasoning per se but in the form of reasoning: while these chains perform semantic reasoning in an unstructured linguistic space, visual perception requires reasoning in a spatial and object-centric space. In response, we introduce Artemis, a perception-policy learning framework that performs structured proposal-based reasoning, where each intermediate step is represented as a (label, bounding-box) pair capturing a verifiable visual state. This design enables explicit tracking of intermediate states, direct supervision for proposal quality, and avoids ambiguity introduced by language-based reasoning. Artemis is built on Qwen2.5-VL-3B, achieves strong performance on grounding and detection task and exhibits substantial generalization to counting and geometric-perception tasks. The consistent improvements across these diverse settings confirm that aligning reasoning with spatial representations enhances perception-policy learning. Owing to its strengthened visual reasoning, Artemis also achieves competitive performance on general MLLM benchmarks, illustrating that spatially grounded reasoning provides a principled route toward scalable and general perception policies.

</details>


### [190] [PAI-Bench: A Comprehensive Benchmark For Physical AI](https://arxiv.org/abs/2512.01989)
*Fengzhe Zhou,Jiannan Huang,Jialuo Li,Deva Ramanan,Humphrey Shi*

Main category: cs.CV

TL;DR: PAI-Bench 提供了一个评估物理 AI 能力的平台，展示了现有的视频生成模型和多模态大语言模型在物理感知和预测方面的不足。


<details>
  <summary>Details</summary>
Motivation: 当前的多模态大语言模型和视频生成模型在感知和预测真实世界动态方面的能力尚未得到充分理解，因此需要一个统一且全面的基准来评估这些能力。

Method: 设计并构建了一个名为 PAI-Bench 的基准，包含 2,808 个现实世界案例，以任务对齐的指标评估感知和预测能力，特别是关注物理合理性和领域专知识别。

Result: 研究显示，视频生成模型尽管在视觉保真度上表现优异，但在维持物理一致性方面有困难，而多模态大语言模型在预测和因果解释方面表现出有限的能力。

Conclusion: PAI-Bench 为评估物理 AI 提供了现实基础，并指出了未来系统需要解决的关键缺口。

Abstract: Physical AI aims to develop models that can perceive and predict real-world dynamics; yet, the extent to which current multi-modal large language models and video generative models support these abilities is insufficiently understood. We introduce Physical AI Bench (PAI-Bench), a unified and comprehensive benchmark that evaluates perception and prediction capabilities across video generation, conditional video generation, and video understanding, comprising 2,808 real-world cases with task-aligned metrics designed to capture physical plausibility and domain-specific reasoning. Our study provides a systematic assessment of recent models and shows that video generative models, despite strong visual fidelity, often struggle to maintain physically coherent dynamics, while multi-modal large language models exhibit limited performance in forecasting and causal interpretation. These observations suggest that current systems are still at an early stage in handling the perceptual and predictive demands of Physical AI. In summary, PAI-Bench establishes a realistic foundation for evaluating Physical AI and highlights key gaps that future systems must address.

</details>


### [191] [Learning Visual Affordance from Audio](https://arxiv.org/abs/2512.02005)
*Lidong Lu,Guo Chen,Zhu Wei,Yicheng Liu,Tong Lu*

Main category: cs.CV

TL;DR: 本文提出了一个新的任务 Audio-Visual Affordance Grounding (AV-AG)，旨在从动作声音中分割出物体交互区域。该任务的新颖性在于利用音频提供的实时、语义丰富且视觉独立的线索，克服了文本指令或演示视频中的模糊性和遮挡问题。为了支持这一任务，作者构建了首个AV-AG数据集，并提出了AVAGFormer模型，该模型通过使用语义条件交叉模态混合器和双重解码器有效地融合了音频和视觉信号进行掩码预测。实验结果表明，AVAGFormer在AV-AG任务上超越了相关任务的 baselines。


<details>
  <summary>Details</summary>
Motivation: 当前基于文本指令或演示视频的方法在表达交互意图时往往存在模糊性和遮挡问题，而音频则提供了实时的、语义丰富的、且与视觉独立的线索，这一方法有望提高交互理解的直观性。

Method: 本文构建了首个AV-AG数据集，包含大量的动作声音、物体图像和像素级别的交互注释。并且引入了AVAGFormer模型，该模型包括一个语义条件交叉模态混合器和一个多头解码器，能够有效地融合音频和视觉信号进行掩码预测。

Result: 实验结果显示，AVAGFormer在AV-AG任务上取得了最先进的性能，超越了相关任务的 baseline 模型。

Conclusion: 研究表明，端到端建模对于该任务是有效的，且每个组件的贡献被详细分析。同时，提供了该模型的代码和数据库。

Abstract: We introduce Audio-Visual Affordance Grounding (AV-AG), a new task that segments object interaction regions from action sounds. Unlike existing approaches that rely on textual instructions or demonstration videos, which often limited by ambiguity or occlusion, audio provides real-time, semantically rich, and visually independent cues for affordance grounding, enabling more intuitive understanding of interaction regions. To support this task, we construct the first AV-AG dataset, comprising a large collection of action sounds, object images, and pixel-level affordance annotations. The dataset also includes an unseen subset to evaluate zero-shot generalization. Furthermore, we propose AVAGFormer, a model equipped with a semantic-conditioned cross-modal mixer and a dual-head decoder that effectively fuses audio and visual signals for mask prediction. Experiments show that AVAGFormer achieves state-of-the-art performance on AV-AG, surpassing baselines from related tasks. Comprehensive analyses highlight the distinctions between AV-AG and AVS, the benefits of end-to-end modeling, and the contribution of each component. Code and dataset have been released on https://jscslld.github.io/AVAGFormer/.

</details>


### [192] [MV-TAP: Tracking Any Point in Multi-View Videos](https://arxiv.org/abs/2512.02006)
*Jahyeok Koo,Inès Hyeonsu Kim,Mungyeom Kim,Junghyun Park,Seohyun Park,Jaeyeong Kim,Jung Yi,Seokju Cho,Seungryong Kim*

Main category: cs.CV

TL;DR: MV-TAP 是一种通过利用跨视图信息和相机几何学在多视图视频中跨视图跟踪动态场景中的点的新技术，展现优异的轨迹估计效果。


<details>
  <summary>Details</summary>
Motivation: 多视图摄像头系统能够捕捉复杂场景的丰富信息，并在各种应用中理解动态物体变得至关重要。

Method: MV-TAP 通过一种跨视图注意力机制和相机几何学来聚集多视图之间的空间-时间信息，提升多视图视频中轨迹估计的完整性和可靠性。

Result: 研究团队构建了一个大规模合成训练集和专门针对多视图跟踪的现实世界评估集，并在多个基准测试中展示了 MV-TAP 的优越性能。

Conclusion: MV-TAP 为多视图点跟踪的研究提供了一个有效的基准，助力相关技术的进步。

Abstract: Multi-view camera systems enable rich observations of complex real-world scenes, and understanding dynamic objects in multi-view settings has become central to various applications. In this work, we present MV-TAP, a novel point tracker that tracks points across multi-view videos of dynamic scenes by leveraging cross-view information. MV-TAP utilizes camera geometry and a cross-view attention mechanism to aggregate spatio-temporal information across views, enabling more complete and reliable trajectory estimation in multi-view videos. To support this task, we construct a large-scale synthetic training dataset and real-world evaluation sets tailored for multi-view tracking. Extensive experiments demonstrate that MV-TAP outperforms existing point-tracking methods on challenging benchmarks, establishing an effective baseline for advancing research in multi-view point tracking.

</details>


### [193] [AirSim360: A Panoramic Simulation Platform within Drone View](https://arxiv.org/abs/2512.02009)
*Xian Ge,Yuling Pan,Yuhang Zhang,Xiang Li,Weijun Zhang,Dizhe Zhang,Zhaoliang Wan,Xin Lin,Xiangkai Zhang,Juntao Liang,Jason Li,Wenjie Jiang,Bo Du,Ming-Hsuan Yang,Lu Qi*

Main category: cs.CV

TL;DR: 该研究提出了AirSim360，一个用于源自空中视角的全景数据仿真的平台，包括渲染对齐的数据和标注框架、交互式的行人感知系统以及自动轨迹生成框架。该平台涵盖工具包、插件和数据集，旨在促进多视角理解领域的研究。


<details>
  <summary>Details</summary>
Motivation: 当前，360度全景数据的缺乏限制了空间智能的发展，尤其是在无人机视角下的广域场景采样方面。因此，有必要开发一个全面的模拟平台来弥补这一不足。

Method: AirSim360结合渲染对齐的数据标注框架、行人感知系统和自动轨迹生成来构建一个灵感源空中视角的全景数据模拟平台。

Result: 研究收集了超过6万张全景样本，并针对多个任务进行了广泛的实验，证明了模拟器的有效性。与现有的模拟器不同，AirSim360首次系统地在全景设置下建模了4D现实世界。

Conclusion: AirSim360平台将开源，为多视角理解领域的研究提供资源和技术支持。

Abstract: The field of 360-degree omnidirectional understanding has been receiving increasing attention for advancing spatial intelligence. However, the lack of large-scale and diverse data remains a major limitation. In this work, we propose AirSim360, a simulation platform for omnidirectional data from aerial viewpoints, enabling wide-ranging scene sampling with drones. Specifically, AirSim360 focuses on three key aspects: a render-aligned data and labeling paradigm for pixel-level geometric, semantic, and entity-level understanding; an interactive pedestrian-aware system for modeling human behavior; and an automated trajectory generation paradigm to support navigation tasks. Furthermore, we collect more than 60K panoramic samples and conduct extensive experiments across various tasks to demonstrate the effectiveness of our simulator. Unlike existing simulators, our work is the first to systematically model the 4D real world under an omnidirectional setting. The entire platform, including the toolkit, plugins, and collected datasets, will be made publicly available at https://insta360-research-team.github.io/AirSim360-website.

</details>


### [194] [TUNA: Taming Unified Visual Representations for Native Unified Multimodal Models](https://arxiv.org/abs/2512.02014)
*Zhiheng Liu,Weiming Ren,Haozhe Liu,Zijian Zhou,Shoufa Chen,Haonan Qiu,Xiaoke Huang,Zhaochong An,Fanny Yang,Aditya Patel,Viktar Atliha,Tony Ng,Xiao Han,Chuyan Zhu,Chenyang Zhang,Ding Liu,Juan-Manuel Perez-Rua,Sen He,Jürgen Schmidhuber,Wenhu Chen,Ping Luo,Wei Liu,Tao Xiang,Jonas Schult,Yuren Cong*

Main category: cs.CV

TL;DR: TUNA 是一种统一多模态模型（UMM），通过级联 VAE 编码器和表示编码器构建统一的连续视觉表示空间，适用于图像和视频的理解与生成任务，优于分离表示的先前 UMM。


<details>
  <summary>Details</summary>
Motivation: 当前的多模态模型通常采用分离的表示来分别处理图像和视频，这会导致表示格式不一致的问题。TUNA 旨在通过构建统一的表示空间来解决这些问题，提高多模态任务的整体性能。

Method: TUNA 通过结合 VAE 编码器和代表编码器，构建统一的视觉表示空间。具体而言，通过级联 VAE 编码器生成潜在的视觉表示，并使用表示编码器进一步增强该表示，从而实现连续的视觉表示。这种方法避免了分离表示带来的格式不匹配问题，有助于图像和视频之间的端到端处理。

Result: 实验表明，TUNA 在图像和视频理解、生成及编辑任务中均显示出优越的表现。特别是在多模态任务中，联合训练理解与生成数据可以互相促进而非相互干扰，这进一步提升了模型的性能。

Conclusion: TUNA 模型凭借其统一的表示设计，在多模态理解与生成领域取得了最先进的成果，证明了该方法的有效性和可扩展性。

Abstract: Unified multimodal models (UMMs) aim to jointly perform multimodal understanding and generation within a single framework. We present TUNA, a native UMM that builds a unified continuous visual representation by cascading a VAE encoder with a representation encoder. This unified representation space allows end-to-end processing of images and videos for both understanding and generation tasks. Compared to prior UMMs with decoupled representations, TUNA's unified visual space avoids representation format mismatches introduced by separate encoders, outperforming decoupled alternatives in both understanding and generation. Moreover, we observe that stronger pretrained representation encoders consistently yield better performance across all multimodal tasks, highlighting the importance of the representation encoder. Finally, in this unified setting, jointly training on both understanding and generation data allows the two tasks to benefit from each other rather than interfere. Our extensive experiments on multimodal understanding and generation benchmarks show that TUNA achieves state-of-the-art results in image and video understanding, image and video generation, and image editing, demonstrating the effectiveness and scalability of its unified representation design.

</details>


### [195] [Generative Video Motion Editing with 3D Point Tracks](https://arxiv.org/abs/2512.02015)
*Yao-Chih Lee,Zhoutong Zhang,Jiahui Huang,Jui-Hsien Wang,Joon-Young Lee,Jia-Bin Huang,Eli Shechtman,Zhengqi Li*

Main category: cs.CV

TL;DR: 本文提出了一种基于轨迹条件的视频到视频框架，通过在源视频和配对的3D点轨迹上条件化一种视频生成模型，实现了相机和物体运动的联合编辑。3D轨迹提供了明确的深度线索，有助于精确的运动编辑。


<details>
  <summary>Details</summary>
Motivation: 当前的图像到视频和视频到视频的方法在处理复杂的物体运动和精细的物体运动编辑时存在局限性。因此，需要一种能够同时编辑相机和物体运动的新框架。

Method: 该方法使用3D点轨迹作为条件来同步编辑相机和物体运动。通过合成数据和真实数据的两阶段训练，模型能够进行多种运动编辑，如联合相机/物体操作、运动转移和非刚性变形。

Result: 模型能够在保留时空连贯性的前提下，实现精确的运动编辑，并且能够应对深度顺序和遮挡问题，支持多种类型的运动编辑。

Conclusion: 该工作为视频编辑领域提供了一种新的、更为精确和灵活的运动编辑方法。

Abstract: Camera and object motions are central to a video's narrative. However, precisely editing these captured motions remains a significant challenge, especially under complex object movements. Current motion-controlled image-to-video (I2V) approaches often lack full-scene context for consistent video editing, while video-to-video (V2V) methods provide viewpoint changes or basic object translation, but offer limited control over fine-grained object motion. We present a track-conditioned V2V framework that enables joint editing of camera and object motion. We achieve this by conditioning a video generation model on a source video and paired 3D point tracks representing source and target motions. These 3D tracks establish sparse correspondences that transfer rich context from the source video to new motions while preserving spatiotemporal coherence. Crucially, compared to 2D tracks, 3D tracks provide explicit depth cues, allowing the model to resolve depth order and handle occlusions for precise motion editing. Trained in two stages on synthetic and real data, our model supports diverse motion edits, including joint camera/object manipulation, motion transfer, and non-rigid deformation, unlocking new creative potential in video editing.

</details>


### [196] [Objects in Generated Videos Are Slower Than They Appear: Models Suffer Sub-Earth Gravity and Don't Know Galileo's Principle...for now](https://arxiv.org/abs/2512.02016)
*Varun Varma Thozhiyoor,Shivam Tripathi,Venkatesh Babu Radhakrishnan,Anand Bhattad*

Main category: cs.CV

TL;DR: 文章探讨了视频生成器对重力这一基本物理法则的表示能力。尽管大多数视频生成器生成的物体下落加速度较慢，作者提出了一种无需单位的两物体协议，证实了违反伽利略等价原理的物理差距并展示了通过对少量数据进行微调，可以让生成器对重力的表示接近真实值。


<details>
  <summary>Details</summary>
Motivation: 评估视频生成器作为世界模型的潜力，特别是在物理法则的表示上。现有的模型普遍未能准确表示重力加速度，文章旨在揭示并解决此问题。

Method: 首先，研究者们分析了物理误差是否可归因于缩放比、帧率假设等模棱两可的因素。发现这些因素不能解决值高度变异的重力缺陷。之后，提出了一种无量纲的双物体协议，测试时间比$t_1^2/t_2^2 = h_1/h_2$这一与重力无关的关系式，进一步验证了物理现象。另外，采用一个轻量级的低秩适配器对少量单球剪辑进行微调，提升了加速度表示，尝试复现地球重力的65％。

Result: 该微调后的适配器不仅应用于单球下落场景，还能够零样本泛化到双球下落和倾斜面场景，表明对特定物理定律的修正可能在少量数据上也能有效。

Conclusion: 研究展示了通过微调即可部分缓解视频生成器在重力表示上的不足，尽管仍有改进空间但提供了初步的证据，证明针对特定物理定律的微调能有效提升生成器的物理准确度。此工作表明未来可能通过更少的数据来增强生成器对物理法则的建模能力。

Abstract: Video generators are increasingly evaluated as potential world models, which requires them to encode and understand physical laws. We investigate their representation of a fundamental law: gravity. Out-of-the-box video generators consistently generate objects falling at an effectively slower acceleration. However, these physical tests are often confounded by ambiguous metric scale. We first investigate if observed physical errors are artifacts of these ambiguities (e.g., incorrect frame rate assumptions). We find that even temporal rescaling cannot correct the high-variance gravity artifacts. To rigorously isolate the underlying physical representation from these confounds, we introduce a unit-free, two-object protocol that tests the timing ratio $t_1^2/t_2^2 = h_1/h_2$, a relationship independent of $g$, focal length, and scale. This relative test reveals violations of Galileo's equivalence principle. We then demonstrate that this physical gap can be partially mitigated with targeted specialization. A lightweight low-rank adaptor fine-tuned on only 100 single-ball clips raises $g_{\mathrm{eff}}$ from $1.81\,\mathrm{m/s^2}$ to $6.43\,\mathrm{m/s^2}$ (reaching $65\%$ of terrestrial gravity). This specialist adaptor also generalizes zero-shot to two-ball drops and inclined planes, offering initial evidence that specific physical laws can be corrected with minimal data.

</details>


### [197] [Data-Centric Visual Development for Self-Driving Labs](https://arxiv.org/abs/2512.02018)
*Anbang Liu,Guanzhong Hu,Jiayi Wang,Ping Guo,Han Liu*

Main category: cs.CV

TL;DR: 该研究通过结合现实和虚拟数据生成，构建了一种混合管道，以解决生物实验室自动化中由于稀缺的训练数据导致的严格精度要求问题。这种方法不仅提高了准确性，还降低了数据收集和审查的负担。


<details>
  <summary>Details</summary>
Motivation: 现有的生物实验室工作流程存在劳动密集、耗时且难以复现的问题。特别是缺乏高质量的标注数据，尤其是在获取负样本方面。

Method: 研究设计了一种混合数据生成管道，其中包括现实数据收集和虚拟数据生成两部分。现实数据通过人类在环（Human-in-the-loop）机制结合自动化获取和选择性的人工验证，以确保准确性。虚拟数据则是基于参考条件和提示指导的图像生成，并经过进一步的可靠性筛选。

Result: 在独立的真实测试数据集上，仅使用自动收集的真实图像训练的模型达到了99.6%的准确率，而在训练期间混合使用真实和生成数据则维持了99.4%的准确率，同时减少了数据收集和审查的工作量。

Conclusion: 该方法提供了一种可扩展且成本效益高的策略，用于向生物实验室自动化流水线供应视感知反馈数据，并为罕见事件检测和更广泛的视觉任务数据稀缺问题提供了一种实用解决方案。

Abstract: Self-driving laboratories offer a promising path toward reducing the labor-intensive, time-consuming, and often irreproducible workflows in the biological sciences. Yet their stringent precision requirements demand highly robust models whose training relies on large amounts of annotated data. However, this kind of data is difficult to obtain in routine practice, especially negative samples. In this work, we focus on pipetting, the most critical and precision sensitive action in SDLs. To overcome the scarcity of training data, we build a hybrid pipeline that fuses real and virtual data generation. The real track adopts a human-in-the-loop scheme that couples automated acquisition with selective human verification to maximize accuracy with minimal effort. The virtual track augments the real data using reference-conditioned, prompt-guided image generation, which is further screened and validated for reliability. Together, these two tracks yield a class-balanced dataset that enables robust bubble detection training. On a held-out real test set, a model trained entirely on automatically acquired real images reaches 99.6% accuracy, and mixing real and generated data during training sustains 99.4% accuracy while reducing collection and review load. Our approach offers a scalable and cost-effective strategy for supplying visual feedback data to SDL workflows and provides a practical solution to data scarcity in rare event detection and broader vision tasks.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [198] [Text Annotation via Inductive Coding: Comparing Human Experts to LLMs in Qualitative Data Analysis](https://arxiv.org/abs/2512.00046)
*Angelina Parfenova,Andreas Marfurt,Alexander Denzler,Juergen Pfeffer*

Main category: cs.CL

TL;DR: 本研究探讨了利用大型语言模型（LLMs）进行归纳编码的自动化质量数据分析，对比了六种开源LLMs与人类专家的表现。


<details>
  <summary>Details</summary>
Motivation: 通过对繁琐且依赖于人工标注的任务实现自动化，提高数据分析效率和准确性。

Method: 研究采用了六种开源LLMs与人类专家进行数据编码的对比实验，评估了它们在不同编码难度上的性能。

Result: 研究结果显示，人类专家在处理复杂句子时表现优于LLMs，在处理简单句子时则相反。此外，与人类标注相比，尽管某些LLMs在标签准确性上更接近真实标签，但它们往往获得了较低的人类专家评价。

Conclusion: 研究强调了传统人工编码和现代自动化的互补性，表明在不同类型的编码任务中，人类专家和LLMs各自有其优势。

Abstract: This paper investigates the automation of qualitative data analysis, focusing on inductive coding using large language models (LLMs). Unlike traditional approaches that rely on deductive methods with predefined labels, this research investigates the inductive process where labels emerge from the data. The study evaluates the performance of six open-source LLMs compared to human experts. As part of the evaluation, experts rated the perceived difficulty of the quotes they coded. The results reveal a peculiar dichotomy: human coders consistently perform well when labeling complex sentences but struggle with simpler ones, while LLMs exhibit the opposite trend. Additionally, the study explores systematic deviations in both human and LLM generated labels by comparing them to the golden standard from the test set. While human annotations may sometimes differ from the golden standard, they are often rated more favorably by other humans. In contrast, some LLMs demonstrate closer alignment with the true labels but receive lower evaluations from experts.

</details>


### [199] [Tree Matching Networks for Natural Language Inference: Parameter-Efficient Semantic Understanding via Dependency Parse Trees](https://arxiv.org/abs/2512.00204)
*Jason Lunder*

Main category: cs.CL

TL;DR: 本文提出了基于依赖解析树的Tree Matching Networks (TMN)，在SNLI推理任务中，TMN以更少的内存使用和训练时间获得了显著更好的结果，而SemEval任务中两个模型均表现不佳。本文还提出了一种多头注意力聚合方法来解决当前聚合方法在可扩展性上的限制。


<details>
  <summary>Details</summary>
Motivation: 目前的Transformer模型虽然准确率高，但参数量大，学习效率不高。因此，本文探索了一种基于依赖解析树的Graph Matching Networks (GMN)的变体——Tree Matching Networks (TMN)，以期望提高学习效率。

Method: 本文通过将GMN应用于依赖解析树，创造性地构建了TMN模型，并将其与基于BERT的模型在SNLI蕴含任务和SemEval相似性任务上进行对比。为了实现这一目标，作者采用一种多头注意力聚合方法来增加模型的可扩展性。

Result: 在SNLI任务上，TMN在较大大规模数据集和模型复杂性下，能够以更少的内存消耗和训练时间获得显著更好的效果，而BERT模型则遇到性能瓶颈。但在SemEval任务上，两种模型在不同任务中表现不一，表明当前基于结构的模型在某些任务上的表现为可提高。

Conclusion: 尽管基于结构的模型在某些场景下能够提供更好的学习效率和性能，但当前的聚合方法限制了其在更大规模下的应用。本文提出的多头注意力聚合方法有助于解决这一问题，并提供了改进的方法。

Abstract: In creating sentence embeddings for Natural Language Inference (NLI) tasks, using transformer-based models like BERT leads to high accuracy, but require hundreds of millions of parameters. These models take in sentences as a sequence of tokens, and learn to encode the meaning of the sequence into embeddings such that those embeddings can be used reliably for NLI tasks. Essentially, every word is considered against every other word in the sequence, and the transformer model is able to determine the relationships between them, entirely from scratch. However, a model that accepts explicit linguistic structures like dependency parse trees may be able to leverage prior encoded information about these relationships, without having to learn them from scratch, thus improving learning efficiency. To investigate this, we adapt Graph Matching Networks (GMN) to operate on dependency parse trees, creating Tree Matching Networks (TMN). We compare TMN to a BERT based model on the SNLI entailment task and on the SemEval similarity task. TMN is able to achieve significantly better results with a significantly reduced memory footprint and much less training time than the BERT based model on the SNLI task, while both models struggled to preform well on the SemEval. Explicit structural representations significantly outperform sequence-based models at comparable scales, but current aggregation methods limit scalability. We propose multi-headed attention aggregation to address this limitation.

</details>


### [200] [Minimal-Edit Instruction Tuning for Low-Resource Indic GEC](https://arxiv.org/abs/2512.00219)
*Akhil Rajeev P*

Main category: cs.CL

TL;DR: 本文提出了一种无需数据增强的语法纠错方法，利用指令调优的大语言模型和保守解码，并通过分类器指导的提示设计、适配器基础的指令调优和确定性解码，改善了印度语言的语法纠错性能。


<details>
  <summary>Details</summary>
Motivation: 本文旨在为印度语言的语法纠错（Indic GEC）提供一种解决方案，面对有限监督、多元字体和丰富的词形变化等挑战。

Method: 该方法使用指令调优的大语言模型进行参数有效性微调（PEFT），并采用轻量级规范化进行保守解码。同时，通过分类器指导的提示设计，确定性解码规则来提高模型的鲁棒性和解码质量。

Result: 该方法在马拉雅拉姆语和印地语上的GLEU评价值分别为92.41和81.44，显示出相比于依赖增强的方法，该方法提供了一种可重复且计算效率高的替代方案。

Conclusion: 该研究确认了分类器指导的提示设计、适配器基础的指令调优及确定性解码框架的有效性，并指出了未来在形态语法约束和人类导向评价保守修改方面的研究方向。

Abstract: Grammatical error correction for Indic languages faces limited supervision, diverse scripts, and rich morphology. We propose an augmentation-free setup that uses instruction-tuned large language models and conservative decoding. A 12B GEMMA 3 model is instruction-tuned in bnb 4-bit precision with parameter-efficient fine-tuning (PEFT) and Alpaca-style formatting. Decoding follows a deterministic, constraint-aware procedure with a lightweight normaliser that encourages minimal, meaning-preserving edits. We operationalise inference, subsequent to instruction fine-tuning (IFT), via a fixed, language-specific prompt directly synthesised from a deterministic error classifier's taxonomy, label distributions, and precedence ordering computed on the training corpus.
  Under the official untuned GLEU evaluation, the system scores 92.41 on Malayalam, sixth overall, and 81.44 on Hindi, third overall. These results indicate that classifier-informed prompt design, adapter-based instruction tuning, and deterministic decoding provide a reproducible and a computationally efficient alternative to augmentation-centred pipelines for Indic GEC. The approach also motivates future work on stronger morphosyntactic constraints and human-centred evaluation of conservative edits.

</details>


### [201] [OmniFusion: Simultaneous Multilingual Multimodal Translations via Modular Fusion](https://arxiv.org/abs/2512.00234)
*Sai Koneru,Matthias Huck,Jan Niehues*

Main category: cs.CL

TL;DR: 本研究提出了一种端到端的多模态翻译系统OmniFusion，通过融合预训练的多模态基础模型（MMFM）与文本翻译大语言模型（LLM），它能够进行语音到文本、语音和图像到文本以及文本和图像到文本的翻译，且在连续演讲翻译中表现出更快的延迟和更好的翻译质量。


<details>
  <summary>Details</summary>
Motivation: 当前的开源文本翻译大语言模型尽管在语言覆盖和质量上有显著进步，但只能通过声学翻译管道使用，增加了延迟并限制了利用多模态上下文的能力。尽管预训练多模态基础模型具有跨模态的强大感知和推理能力，但它们通常缺乏专精于翻译的大语言模型的多语言覆盖和翻译性能。因此，研究旨在提出一个端到端的多模态翻译方法，融合多模态基础模型与翻译模型，以实现语音、图像和文本之间的高效多模态翻译。

Method: 该研究提出了一种创新的融合策略，将预训练多模态基础模型的隐藏状态连接到翻译大语言模型，实现了联合端到端训练。通过这种方式，OmniFusion能够同时处理多模态输入，并在连续演讲翻译（SimulST）中显著减少延迟和提高翻译质量。

Result: 实验结果表明，OmniFusion能够有效地利用语音和视觉输入，相较于级联管道在连续演讲翻译中减少了1秒的延迟，并提升了整体翻译质量。

Conclusion: 研究证明了全新提出的端到端融合模型OmniFusion在实现高效多模态翻译方面的有效性，展示了其在实际应用中的潜力。

Abstract: There has been significant progress in open-source text-only translation large language models (LLMs) with better language coverage and quality. However, these models can be only used in cascaded pipelines for speech translation (ST), performing automatic speech recognition first followed by translation. This introduces additional latency, which is particularly critical in simultaneous ST (SimulST), and prevents the model from exploiting multimodal context, such as images, which can aid disambiguation. Pretrained multimodal foundation models (MMFMs) already possess strong perception and reasoning capabilities across multiple modalities, but generally lack the multilingual coverage and specialized translation performance of dedicated translation LLMs. To build an effective multimodal translation system, we propose an end-to-end approach that fuses MMFMs with translation LLMs. We introduce a novel fusion strategy that connects hidden states from multiple layers of a pretrained MMFM to a translation LLM, enabling joint end-to-end training. The resulting model, OmniFusion, built on Omni 2.5-7B as the MMFM and SeedX PPO-7B as the translation LLM, can perform speech-to-text, speech-and-image-to-text, and text-and-image-to-text translation. Experiments demonstrate that OmniFusion effectively leverages both audio and visual inputs, achieves a 1-second latency reduction in SimulST compared to cascaded pipelines and also improves the overall translation quality\footnote{Code is available at https://github.com/saikoneru/OmniFusion}.

</details>


### [202] [Lost without translation -- Can transformer (language models) understand mood states?](https://arxiv.org/abs/2512.00274)
*Prakrithi Shivaprakash,Diptadhi Mukherjee,Lekhansh Shukla,Animesh Mukherjee,Prabhat Chand,Pratima Murthy*

Main category: cs.CL

TL;DR: 当前的大语言模型无法直接理解印度语言中的情绪状态，使用高质量的翻译可以显著提高性能，但依赖专有模型或复杂的翻译流水线是不可持续的，需要首先构建能够理解多样本地语言的模型以适应全球心理健康应用。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过比较大语言模型处理印度本地语言和翻译成其他语言后的情绪状态表示，来评估大语言模型在印度情绪识别中的能力。

Method: 该研究收集了11种印度语言中与四种情绪状态（抑郁、欣快躁狂、躁狂、抑郁躁狂）相关的247个独特短语，通过k-means聚类算法进行测试，比较原语言表示和翻译成英语及汉语后的表示，使用复合评分衡量模型性能。

Result: 直接在印度语言上进行嵌入未能有效识别情绪状态（复合评分=0.002），翻译至英语和汉语的所有方法都显示出显著改进，其中人类翻译的英语嵌入gemini-001模型表现最佳（复合评分=0.67）。

Conclusion: 当前模型无法直接从印度语言中理解情绪状态，这对精神病学诊断和治疗构成了根本障碍。高质量的翻译可以解决问题，但依赖专有模型或复杂的翻译流程是不可持续的。需要首先构建能够理解多样本地语言的模型，以提高全球心理健康领域的应用效果。

Abstract: Background: Large Language Models show promise in psychiatry but are English-centric. Their ability to understand mood states in other languages is unclear, as different languages have their own idioms of distress. Aim: To quantify the ability of language models to faithfully represent phrases (idioms of distress) of four distinct mood states (depression, euthymia, euphoric mania, dysphoric mania) expressed in Indian languages. Methods: We collected 247 unique phrases for the four mood states across 11 Indic languages. We tested seven experimental conditions, comparing k-means clustering performance on: (a) direct embeddings of native and Romanised scripts (using multilingual and Indic-specific models) and (b) embeddings of phrases translated to English and Chinese. Performance was measured using a composite score based on Adjusted Rand Index, Normalised Mutual Information, Homogeneity and Completeness. Results: Direct embedding of Indic languages failed to cluster mood states (Composite Score = 0.002). All translation-based approaches showed significant improvement. High performance was achieved using Gemini-translated English (Composite=0.60) and human-translated English (Composite=0.61) embedded with gemini-001. Surprisingly, human-translated English, further translated into Chinese and embedded with a Chinese model, performed best (Composite = 0.67). Specialised Indic models (IndicBERT and Sarvam-M) performed poorly. Conclusion: Current models cannot meaningfully represent mood states directly from Indic languages, posing a fundamental barrier to their psychiatric application for diagnostic or therapeutic purposes in India. While high-quality translation bridges this gap, reliance on proprietary models or complex translation pipelines is unsustainable. Models must first be built to understand diverse local languages to be effective in global mental health.

</details>


### [203] [EduEval: A Hierarchical Cognitive Benchmark for Evaluating Large Language Models in Chinese Education](https://arxiv.org/abs/2512.00290)
*Guoqing Ma,Jia Zhu,Hanghui Guo,Weijie Shi,Yue Cui,Jiawei Shen,Zilong Li,Yidan Liang*

Main category: cs.CL

TL;DR: EduEval 提出了一套针对中国K-12教育的全面层级基准，包含认知框架、现实性和规模三个方面，评估了14个主流语言模型在多个任务类型上的性能。


<details>
  <summary>Details</summary>
Motivation: 鉴于大语言模型（LLMs）在教育应用中的潜在价值和未被审视的部署风险，有必要建立一个严格的标准来进行评估。

Method: EduEval 通过构建认知框架（EduAbility Taxonomy）、整合真实教育场景中的任务、以及大规模的任务集来实现全面评估。

Result: 研究发现，模型在事实性任务上表现良好，但在课堂对话分类和创造性内容生成上表现不佳。此外，开源模型在复杂教育推理任务上优于闭源系统。

Conclusion: EduEval 为开发针对多元中国教育任务优化的大语言模型提供了靶向基准评估指标。

Abstract: Large language models (LLMs) demonstrate significant potential for educational applications. However, their unscrutinized deployment poses risks to educational standards, underscoring the need for rigorous evaluation. We introduce EduEval, a comprehensive hierarchical benchmark for evaluating LLMs in Chinese K-12 education. This benchmark makes three key contributions: (1) Cognitive Framework: We propose the EduAbility Taxonomy, which unifies Bloom's Taxonomy and Webb's Depth of Knowledge to organize tasks across six cognitive dimensions including Memorization, Understanding, Application, Reasoning, Creativity, and Ethics. (2) Authenticity: Our benchmark integrates real exam questions, classroom conversation, student essays, and expert-designed prompts to reflect genuine educational challenges; (3) Scale: EduEval comprises 24 distinct task types with over 11,000 questions spanning primary to high school levels. We evaluate 14 leading LLMs under both zero-shot and few-shot settings, revealing that while models perform well on factual tasks, they struggle with classroom dialogue classification and exhibit inconsistent results in creative content generation. Interestingly, several open source models outperform proprietary systems on complex educational reasoning. Few-shot prompting shows varying effectiveness across cognitive dimensions, suggesting that different educational objectives require tailored approaches. These findings provide targeted benchmarking metrics for developing LLMs specifically optimized for diverse Chinese educational tasks.

</details>


### [204] [Comparative Analysis of 47 Context-Based Question Answer Models Across 8 Diverse Datasets](https://arxiv.org/abs/2512.00323)
*Muhammad Muneeb,David B. Ascher,Ahsan Baidar Bakht*

Main category: cs.CL

TL;DR: 该研究评估了47个来自Hugging Face的CBQA模型在8个不同数据集上的表现，未进行额外微调即确定了表现最佳的模型，发现ahotrod/electra_large_discriminator_squad2_512在多种数据集上表现出色，同时也指出模型性能受上下文长度、复杂度及答案长度影响，并利用遗传算法提升整体准确率。


<details>
  <summary>Details</summary>
Motivation: 针对CBQA模型在实际应用中无需额外微调便能达到良好表现的需求，研究旨在通过广泛评测以确定通用性强的模型，简化在不同场景中的部署。

Method: 研究对47个CBQA模型在8个不同数据集上进行了评估，未进行额外的微调，使用遗传算法整合多个模型的结果进一步提升整体准确性。

Result: 研究发现表现在多个数据集上的最佳模型为ahotrod/electra_large_discriminator_squad2_512，其在所有数据集上的平均准确率为43%，并在特定生物医学和事实查询数据集上取得了显著成绩。而Bert-large-uncased-whole-word-masking-finetuned-squad则在IELTS数据集上表现突出，准确率为82%。

Conclusion: 研究结果显示，ahotrod/electra_large_discriminator_squad2_512是表现最稳定的CBQA模型之一，它可以应用于多种场景而无需额外的微调。此外，模型性能受上下文长度、复杂度及答案长度影响显著，遗传算法的使用能够进一步提升模型的整体表现。

Abstract: Context-based question answering (CBQA) models provide more accurate and relevant answers by considering the contextual information. They effectively extract specific information given a context, making them functional in various applications involving user support, information retrieval, and educational platforms. In this manuscript, we benchmarked the performance of 47 CBQA models from Hugging Face on eight different datasets. This study aims to identify the best-performing model across diverse datasets without additional fine-tuning. It is valuable for practical applications where the need to retrain models for specific datasets is minimized, streamlining the implementation of these models in various contexts. The best-performing models were trained on the SQuAD v2 or SQuAD v1 datasets. The best-performing model was ahotrod/electra_large_discriminator_squad2_512, which yielded 43\% accuracy across all datasets. We observed that the computation time of all models depends on the context length and the model size. The model's performance usually decreases with an increase in the answer length. Moreover, the model's performance depends on the context complexity. We also used the Genetic algorithm to improve the overall accuracy by integrating responses from other models. ahotrod/electra_large_discriminator_squad2_512 generated the best results for bioasq10b-factoid (65.92\%), biomedical\_cpgQA (96.45\%), QuAC (11.13\%), and Question Answer Dataset (41.6\%). Bert-large-uncased-whole-word-masking-finetuned-squad achieved an accuracy of 82\% on the IELTS dataset.

</details>


### [205] [Evidence-Guided Schema Normalization for Temporal Tabular Reasoning](https://arxiv.org/abs/2512.00329)
*Ashish Thanga,Vibhu Dixit,Abhilash Shankarampeta,Vivek Gupta*

Main category: cs.CL

TL;DR: 该研究提出了一种基于SQL的方法来处理维基百科信息框演化出的半结构化表格中的时间推理问题，通过规范化、语义命名和时间锚定，成功提升了QA系统的性能。


<details>
  <summary>Details</summary>
Motivation: 当前的问答系统对于动态的半结构化表格在时间推理方面存在挑战，因此研究提出了一种新的方法来改进这一问题。

Method: 该方法包括从维基百科信息框生成3NF数据库模式，生成SQL查询，并进行查询执行。

Result: 研究的最佳配置（Gemini 2.5 Flash模式+ Gemini-2.0-Flash查询）取得了80.39的EM值，比基线（68.89的EM值）提高了16.8%。

Conclusion: 研究发现模式设计的质量对QA精度的影响比模型容量的影响更大，提出了三个证据为基础的原则：保持上下文的规范化、减少模糊性的语义命名以及一致的时间锚定。

Abstract: Temporal reasoning over evolving semi-structured tables poses a challenge to current QA systems. We propose a SQL-based approach that involves (1) generating a 3NF schema from Wikipedia infoboxes, (2) generating SQL queries, and (3) query execution. Our central finding challenges model scaling assumptions: the quality of schema design has a greater impact on QA precision than model capacity. We establish three evidence-based principles: normalization that preserves context, semantic naming that reduces ambiguity, and consistent temporal anchoring. Our best configuration (Gemini 2.5 Flash schema + Gemini-2.0-Flash queries) achieves 80.39 EM, a 16.8\% improvement over the baseline (68.89 EM).

</details>


### [206] [IndicParam: Benchmark to evaluate LLMs on low-resource Indic Languages](https://arxiv.org/abs/2512.00333)
*Ayush Maheshwari,Kaushal Sharma,Vivek Patel,Aditya Maheshwari*

Main category: cs.CL

TL;DR: IndicParam是一个涵盖11种不同Indic语言的人类策划基准，其中10种是极低资源，一种是混合编码设置，用于评估大型语言模型的性能，揭示即使是顶级的GPT-5也只达到45.0%的平均准确率。


<details>
  <summary>Details</summary>
Motivation: 鉴于大型语言模型在多语言任务中的高资源多数语言上表现出色，但低资源和极低资源的印地语系语言却严重缺乏评估。因此，创建了一个覆盖多种低资源和极低资源印地语的语言理解基准IndicParam，以推动这些语言的自然语言处理研究。

Method: 该研究创建了一个包含13,000多个多项选择题的基准集，覆盖11种不同的印地语系语言，详细评估了19种大型语言模型（包括自定义和开源模型）的表现。

Result: 评估结果显示，即使是表现最佳的GPT-5也只能达到45.0%的平均准确度，随后是DeepSeek-3.2（43.1%）和Claude-4.5（42.7%）。此外，研究还分析了语言模型对不同问题格式（如列表匹配、断言-理由对、序列排序等）的处理能力。

Conclusion: 研究得出结论，大型语言模型在处理印地语系语言时存在显著限制，并强调了在这些语言上建立更具挑战性的基准的重要性。

Abstract: While large language models excel on high-resource multilingual tasks, low- and extremely low-resource Indic languages remain severely under-evaluated. We present IndicParam, a human-curated benchmark of over 13,000 multiple-choice questions covering 11 such languages (Nepali, Gujarati, Marathi, Odia as low-resource; Dogri, Maithili, Rajasthani, Sanskrit, Bodo, Santali, Konkani as extremely low-resource) plus Sanskrit-English code-mixed set. We evaluated 19 LLMs, both proprietary and open-weights, which reveals that even the top-performing GPT-5 reaches only 45.0% average accuracy, followed by DeepSeek-3.2 (43.1) and Claude-4.5 (42.7). We additionally label each question as knowledge-oriented or purely linguistic to discriminate factual recall from grammatical proficiency. Further, we assess the ability of LLMs to handle diverse question formats-such as list-based matching, assertion-reason pairs, and sequence ordering-alongside conventional multiple-choice questions. IndicParam provides insights into limitations of cross-lingual transfer and establishes a challenging benchmark for Indic languages. The dataset is available at https://huggingface.co/datasets/bharatgenai/IndicParam. Scripts to run benchmark are present at https://github.com/ayushbits/IndicParam.

</details>


### [207] [CourseTimeQA: A Lecture-Video Benchmark and a Latency-Constrained Cross-Modal Fusion Method for Timestamped QA](https://arxiv.org/abs/2512.00360)
*Vsevolod Kovalev,Parteek Kumar*

Main category: cs.CL

TL;DR: 本文研究了在单GPU延迟/内存预算下，如何高效地为教育讲座视频提供带时间戳的问题-答案。系统针对自然语言查询，检索相关的时间戳片段并生成定位的答案。实验结果表明，提出的CrossFusion-RAG提高了检索效果，同时保持了较低的延迟。


<details>
  <summary>Details</summary>
Motivation: 在教育视频中，用户常需要快速找到特定部分的答案。本文旨在提供一种高效的方法，即使在单GPU资源限制下也能实现这一目标。

Method: 使用冻结编码器、学习的视觉投影、浅层查询无关的跨模态注意力以及小型跨注意力重排序器。通过CrossFusion-RAG模型结合ASR和帧数据，优化检索结果并减少延迟。

Result: CrossFusion-RAG在CourseTimeQA数据集上实现了nDCG@10提高0.10，MRR提高0.08，同时在单A100 GPU上实现约1.55秒的中位端到端延迟。在不同硬件和索引设置下进行的评估显示了其鲁棒性。

Conclusion: 研究通过全面的实验设计和详细的操作细节，证明了在教育讲座视频领域改进问题答案检索系统的可行性。

Abstract: We study timestamped question answering over educational lecture videos under a single-GPU latency/memory budget. Given a natural-language query, the system retrieves relevant timestamped segments and synthesizes a grounded answer. We present CourseTimeQA (52.3 h, 902 queries across six courses) and a lightweight, latency-constrained cross-modal retriever (CrossFusion-RAG) that combines frozen encoders, a learned 512->768 vision projection, shallow query-agnostic cross-attention over ASR and frames with a temporal-consistency regularizer, and a small cross-attentive reranker. On CourseTimeQA, CrossFusion-RAG improves nDCG@10 by 0.10 and MRR by 0.08 over a strong BLIP-2 retriever while achieving approximately 1.55 s median end-to-end latency on a single A100. Closest comparators (zero-shot CLIP multi-frame pooling; CLIP + cross-encoder reranker + MMR; learned late-fusion gating; text-only hybrid with cross-encoder reranking and its MMR variant; caption-augmented text retrieval; non-learned temporal smoothing) are evaluated under matched hardware and indexing. We report robustness across ASR noise (WER quartiles), diagnostics for temporal localization, and full training/tuning details to support reproducible comparison.

</details>


### [208] [Mitigating the Threshold Priming Effect in Large Language Model-Based Relevance Judgments via Personality Infusing](https://arxiv.org/abs/2512.00390)
*Nuo Chen,Hanpei Fang,Jiqun Liu,Wilson Wei,Tetsuya Sakai,Xiao-Ming Wu*

Main category: cs.CL

TL;DR: 研究表明，LLM中的人格特征（如高开放性和低神经质）可以减少标签相关性中的启动效应，但最有效的人格特征可能因模型和任务类型的不同而有所不同。


<details>
  <summary>Details</summary>
Motivation: LLM在大规模相关性标注中具有潜力，但易受启动效应影响。通过探究LLM中人格特征如何影响启动效应，研究希望能提出一种新的方法来减轻这一问题。

Method: 研究者使用多种LLM在TREC 2021和2022深学习赛道数据集上检验了不同人格特征对于启动效应的影响。

Result: 研究发现，特定的人格特征（如高开放性和低神经质）有助于减少启动效应。然而，最有效的缓解方法可能因不同模型和任务类型而异。

Conclusion: 研究建议使用人格提示来缓解阈值启动效应，将心理学实验证据与LLM评估实践相结合。

Abstract: Recent research has explored LLMs as scalable tools for relevance labeling, but studies indicate they are susceptible to priming effects, where prior relevance judgments influence later ones. Although psychological theories link personality traits to such biases, it is unclear whether simulated personalities in LLMs exhibit similar effects. We investigate how Big Five personality profiles in LLMs influence priming in relevance labeling, using multiple LLMs on TREC 2021 and 2022 Deep Learning Track datasets. Our results show that certain profiles, such as High Openness and Low Neuroticism, consistently reduce priming susceptibility. Additionally, the most effective personality in mitigating priming may vary across models and task types. Based on these findings, we propose personality prompting as a method to mitigate threshold priming, connecting psychological evidence with LLM-based evaluation practices.

</details>


### [209] [A Taxonomy of Errors in English as she is spoke: Toward an AI-Based Method of Error Analysis for EFL Writing Instruction](https://arxiv.org/abs/2512.00392)
*Damian Heywood,Joseph Andrew Carrier,Kyu-Hong Hwang*

Main category: cs.CL

TL;DR: 本研究开发了一个基于大型语言模型的AI辅助错误分析系统，能够识别、分类和纠正英语中的拼写、语法和标点错误。该系统通过Python编码的API调用提供详细的反馈，初步测试显示系统对复杂错误处理有一定局限。


<details>
  <summary>Details</summary>
Motivation: 鉴于当前英语教学中错误分析的复杂性和人工教学的局限性，本研究提出利用大型语言模型开发一个AI辅助错误分析系统，旨在自动化英语写作错误的详细分析和反馈，以期提高英语教学的效率和质量。

Method: 本研究采用大型语言模型如Claude 3.5 Sonnet和DeepSeek R1，结合Corder (1967)、Richards (1971)和James (1998)的语言理论构建了一个分类详尽的语言错误分类体系，通过Python编程API调用进行系统实施。

Result: 系统在单一错误测试中完成了技术调试，并在一个充满真实语言错误的老文本中进行了最终测试。结果显示，系统能够识别多种错误类型，但在上下文理解和新错误类别生成方面存在局限。

Conclusion: 研究表明，该系统为进一步改进上下文准确性并扩展至风格和话语层面错误分类提供了基础。同时，还指出需要进一步开发以提高系统的准确性和广泛的适用性，以实现对英语教学的彻底融合与支持。

Abstract: This study describes the development of an AI-assisted error analysis system designed to identify, categorize, and correct writing errors in English. Utilizing Large Language Models (LLMs) like Claude 3.5 Sonnet and DeepSeek R1, the system employs a detailed taxonomy grounded in linguistic theories from Corder (1967), Richards (1971), and James (1998). Errors are classified at both word and sentence levels, covering spelling, grammar, and punctuation. Implemented through Python-coded API calls, the system provides granular feedback beyond traditional rubric-based assessments. Initial testing on isolated errors refined the taxonomy, addressing challenges like overlapping categories. Final testing used "English as she is spoke" by Jose da Fonseca (1855), a text rich with authentic linguistic errors, to evaluate the system's capacity for handling complex, multi-layered analysis. The AI successfully identified diverse error types but showed limitations in contextual understanding and occasionally generated new error categories when encountering uncoded errors. This research demonstrates AI's potential to transform EFL instruction by automating detailed error analysis and feedback. While promising, further development is needed to improve contextual accuracy and expand the taxonomy to stylistic and discourse-level errors.

</details>


### [210] [SCALE: Selective Resource Allocation for Overcoming Performance Bottlenecks in Mathematical Test-time Scaling](https://arxiv.org/abs/2512.00466)
*Yang Xiao,Chunpu Xu,Ruifeng Yuan,Jiashuo Wang,Wenjie Li,Pengfei Liu*

Main category: cs.CL

TL;DR: SCALE框架通过基于子问题难度的选择性资源分配提高了大型语言模型的数学推理性能，同时降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 当前的测试时计算量扩展方法在所有推理子问题上均匀分配计算资源，导致性能瓶颈和资源浪费。在这种背景下，SCALE框架通过根据子问题的难度进行选择性资源分配来解决这个问题。

Method: SCALE框架包含四个阶段：问题是为顺序推理子问题分解；对每个子问题进行难度评估；根据子问题的简单或复杂程度选择系统1或系统2进行处理；最后是带有上下文传播的顺序执行。

Result: 实验表明，与均匀扩展基线相比，SCALE显著提高了性能，最多提高了13.75个百分点，在AIME25数据集上从57.50%提升到71.25%，同时将计算成本降低了33%到53%，展示了比当前方法更先进的测试时扩展。

Conclusion: 因此，SCALE是有效提高大型语言模型数学推理能力的测试时计算量扩展技术，具有广泛的应用前景。

Abstract: Test-time compute scaling has emerged as a powerful paradigm for enhancing mathematical reasoning in large language models (LLMs) by allocating additional computational resources during inference. However, current methods employ uniform resource distribution across all reasoning sub-problems, creating fundamental bottlenecks where challenging sub-problems receive insufficient attention while routine operations consume disproportionate resources. This uniform allocation creates performance bottlenecks where additional computational resources yield diminishing returns. Inspired by dual-process theory, we propose \textbf{SCALE} (Selective Resource Allocation), a framework that selectively allocates computational resources based on sub-problem difficulty. SCALE operates through four stages: (1) problem decomposition into sequential reasoning sub-problems, (2) difficulty assessment of each sub-problem to distinguish between routine operations and computationally challenging sub-problems, (3) selective processing mode assignment between System 1 for simple sub-problems and System 2 for complex ones, and (4) sequential execution with context propagation. By concentrating resources on challenging sub-problems while processing routine operations efficiently, SCALE achieves substantial performance improvements with superior resource utilization. Extensive experiments demonstrate that SCALE significantly outperforms uniform scaling baselines, achieving accuracy improvements of up to 13.75 percentage points (57.50% to 71.25% on AIME25) while reducing computational costs by 33%-53%, representing a major advance in test-time scaling that addresses fundamental limitations of current approaches.

</details>


### [211] [CACARA: Cross-Modal Alignment Leveraging a Text-Centric Approach for Cost-Effective Multimodal and Multilingual Learning](https://arxiv.org/abs/2512.00496)
*Diego A. B. Moreira,Alef I. Ferreira,Jhessica Silva,Gabriel O. dos Santos,Gustavo Bonil,João Gondim,Marina dos Santos,Helena Maia,Simone Hashiguti,Nádia da Silva,Carolina Scarton,Helio Pedrini,Sandra Avila*

Main category: cs.CL

TL;DR: 本文提出了一种名为CACARA的多模态与多语言架构，该架构通过新兴对齐学习实现了无需全量重新训练即可无缝集成新模态的功能，并能从单语训练中获得多语言能力。通过只在与英语对齐的数据上调整新增模态，模型能够在保持先前学习的知识的同时，高效地支持超过100种语言。实验结果显示，在音频到文本检索任务中，该方法比最先进的多模态模型提高了14.24个百分点，而无需每种模态和语言都重新训练。


<details>
  <summary>Details</summary>
Motivation: 随着深度学习模型的发展，单模态任务逐渐转向多模态交互。目前的多模态模型大多需要跨模态的资源密集型训练，扩展到新语言时也遵循类似的策略。为此，本文提出了CACARA，旨在通过新兴对齐学习来简化模型的扩展过程，从而实现多模态和多语言的无缝集成。

Method: 本文的方法基于新兴对齐学习，通过仅对新增模态的数据进行与英语对齐的微调，从而实现对多语言的支持。这种方法在保持跨模态知识方面表现出色，且训练成本与单语模型相当。

Result: 实验结果显示，本文提出的方法在音频到文本检索任务上的表现比最先进的多模态模型提高了14.24个百分点，且在无需对所有模态和语言进行重新训练的情况下，实现了高效且多语言的模型性能。

Conclusion: 本文提出的CACARA架构及其新兴对齐学习策略，为多模态模型的扩展提供了一种高效且资源友好的解决方案，展示了从单语训练中获得多语言能力的潜力。

Abstract: As deep learning models evolve, new applications and challenges are rapidly emerging. Tasks that once relied on a single modality, such as text, images, or audio, are now enriched by seamless interactions between multimodal data. These connections bridge information gaps: an image can visually materialize a text, while audio can add context to an image. Researchers have developed numerous multimodal models, but most rely on resource-intensive training across multiple modalities. Similarly, extending these models to new languages often follows the same resource-heavy training strategy. In this work, we propose a multimodal and multilingual architecture, CACARA, trained through emergent alignment learning, enabling the seamless integration of new modalities into an existing bimodal/multimodal model without requiring full retraining. This work breaks new ground by demonstrating that this emergent alignment paradigm can unlock multilingual capabilities from monolingual training. By fine-tuning the newly incorporated modality only on data aligned with the English language, our model develops support for over 100 languages without explicit multilingual pretraining or tuning of the text encoder. Such emergent multimodal and multilingual properties are gained efficiently, preserving previously learned knowledge at a training cost comparable to that of a monolingual model. Our strategy achieves up to a 14.24 percentage points improvement in R@1 audio-to-text retrieval, outperforming state-of-the-art multimodal models -- all without the heavy computational cost of retraining across every modality and language.

</details>


### [212] [G-KV: Decoding-Time KV Cache Eviction with Global Attention](https://arxiv.org/abs/2512.00504)
*Mengqi Liao,Lu Wang,Chaoyun Zhang,Zekai Shen,Xiaowei Mao,Si Qin,Qingwei Lin,Saravan Rajmohan,Dongmei Zhang,Huaiyu Wan*

Main category: cs.CL

TL;DR: 提出了名为G-KV的KV缓存淘汰方法，通过结合局部和历史注意分数进行全球评分机制来更准确地评估令牌的重要性。此外，还介绍了在压缩KV缓存设置下优化模型的后训练技术，包括强化学习和知识蒸馏。


<details>
  <summary>Details</summary>
Motivation: 为了克服大型语言模型（LLMs）在处理长序列时面临的计算和内存挑战，通过引入G-KV缓存淘汰方法和后训练优化技术来提高效率和准确性。

Method: 提出了G-KV方法，结合局部和历史注意分数进行全球评分，并使用强化学习和知识蒸馏等后训练技术来优化模型。

Result: G-KV方法能够在保持或提高模型性能的同时，显著减少KV缓存的大小和减少推理时间。

Conclusion: G-KV方法和后训练技术在提高长文本处理的效率和准确性方面展现出巨大潜力。

Abstract: Recent reasoning large language models (LLMs) excel in complex tasks but encounter significant computational and memory challenges due to long sequence lengths. KV cache compression has emerged as an effective approach to greatly enhance the efficiency of reasoning. However, existing methods often focus on prompt compression or token eviction with local attention score, overlooking the long-term importance of tokens. We propose G-KV, a KV cache eviction method that employs a global scoring mechanism, combining local and historical attention scores to more accurately assess token importance. Additionally, we introduce post-training techniques, including reinforcement learning and distillation, to optimize models for compressed KV cache settings. The code of this paper is available on: https://github.com/microsoft/G-KV.

</details>


### [213] [Catch Me If You Can: How Smaller Reasoning Models Pretend to Reason with Mathematical Fidelity](https://arxiv.org/abs/2512.00552)
*Subramanyam Sahoo,Vinija Jain,Saanidhya Vats,Siddharth Mohapatra,Rui Min,Aman Chadha,Divya Chaudhary*

Main category: cs.CL

TL;DR: 该研究提出了一种诊断框架，通过四个维度评估语言模型的数学推理能力，指出即使表面准确率较高，模型也可能依赖于表面模式匹配而非真正的逻辑计算。


<details>
  <summary>Details</summary>
Motivation: 当前评估语言模型数学推理主要依赖答案准确性，可能掩盖了逻辑计算的根本失败。研究旨在推出一种诊断框架，以区分真正的数学推理和浅层的模式匹配。

Method: 研究引入了四个互补的评估维度：前向-后向一致性、传递性覆盖率、反事实敏感性和扰动稳健性，通过Qwen3-0.6B模型在MenatQA数据集上的案例研究来验证其有效性。

Result: 研究发现，尽管该模型在表面上表现出70%以上的答案准确率，但在前向-后向一致性（15%）、传递性覆盖率（32.2%）和对扰动的敏感性方面表现较差，揭示了表面准确率与推理准确性之间的巨大差距，表明模型可能依赖于模式匹配而非逻辑计算。

Conclusion: 研究框架是非模型特定的，可应用于不同规模和架构的模型评估，推动数学推理从表面准确性向可验证性发展。

Abstract: Current evaluation of mathematical reasoning in language models relies primarily on answer accuracy, potentially masking fundamental failures in logical computation. We introduce a diagnostic framework that distinguishes genuine mathematical reasoning from superficial pattern matching through four complementary axes: forward-backward consistency, transitivity coverage, counterfactual sensitivity, and perturbation robustness. Through a case study applying this framework to Qwen3-0.6B on the MenatQA dataset, we reveal a striking disconnect between surface performance and reasoning fidelity. While the model achieves reasonable answer accuracy (70%+), it demonstrates poor backward consistency (15%), limited transitivity coverage (32.2%), and brittle sensitivity to perturbations. Our diagnostics expose reasoning failures invisible to traditional accuracy metrics, suggesting that this small model relies heavily on pattern matching rather than genuine logical computation. While our empirical findings are based on a single 600M-parameter model, the diagnostic framework itself is model-agnostic and generalizable. We release our evaluation protocols to enable the research community to assess reasoning fidelity across different model scales and architectures, moving beyond surface-level accuracy toward verifiable mathematical reasoning.

</details>


### [214] [Slovak Conceptual Dictionary](https://arxiv.org/abs/2512.00579)
*Miroslav Blšták*

Main category: cs.CL

TL;DR: 本文介绍了斯洛伐克语言的第一个概念字典，旨在解决斯洛伐克语资源稀缺的问题，有助于提高文本自动化处理任务的效果。


<details>
  <summary>Details</summary>
Motivation: 由于斯洛伐克语资源稀缺，特别是缺乏足够的机器可读的语料库，许多依赖于自动化处理文本的任务表现不佳或根本无法解决。

Method: 本文构建了一个新的概念字典，作为斯洛伐克语的第一个语言工具，用于填补这一空白。

Result: 通过引入这一新的概念字典，斯洛伐克语的自然语言处理任务能够获得更好的结果，但这需要进一步的努力以提供更全面的语料。

Conclusion: 这一概念字典的建立对于促进斯洛伐克语自然语言处理的发展具有重要意义，但仍需更多的研究和数据来支持进一步的发展。

Abstract: When solving tasks in the field of natural language processing, we sometimes need dictionary tools, such as lexicons, word form dictionaries or knowledge bases. However, the availability of dictionary data is insufficient in many languages, especially in the case of low resourced languages. In this article, we introduce a new conceptual dictionary for the Slovak language as the first linguistic tool of this kind. Since Slovak language is a language with limited linguistic resources and there are currently not available any machine-readable linguistic data sources with a sufficiently large volume of data, many tasks which require automated processing of Slovak text achieve weaker results compared to other languages and are almost impossible to solve.

</details>


### [215] [Wikontic: Constructing Wikidata-Aligned, Ontology-Aware Knowledge Graphs with Large Language Models](https://arxiv.org/abs/2512.00590)
*Alla Chepurova,Aydar Bulatov,Yuri Kuratov,Mikhail Burtsev*

Main category: cs.CL

TL;DR: Wikontic 是一个从开放域文本构建知识图谱的多阶段管道，通过提取候选三元组并应用 Wikidata 基础类型的约束来生成紧凑、与本体一致且高度连接的知识图谱。与基于文本检索的方法相比，Wikontic 在信息保留方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的知识图谱系统通常使用知识图谱作为辅助结构进行文本检索，但缺乏对知识图谱本身内在质量的探索和利用。因此，提出 Wikontic 来构建高质量的知识图谱，以增强大语言模型中的结构化知识利用。

Method: Wikontic 使用多阶段方法从开放域文本中构建知识图谱。首先，提取带有资格的候选三元组；然后，应用 Wikidata 基础类型的约束来限制实体和关系；最后，通过规范化实体来减少重复。该方法生成的图谱紧凑且与本体一致。

Result: Wikontic 在多个评估基准上表现出色。例如，穆西克的正确答案实体出现率高达 96%；在热扑 QA 中，仅使用三元组的设置达到了 76.0 F1，超过多个检索增强生成基线，且在 MINE-1 指标上达到最先进的信息保留性能 86%。同时，建设知识图谱时更高效。

Conclusion: Wikontic 通过多阶段管道提高了知识图谱构建的质量，为大语言模型中利用结构化知识提供了可扩展的解决方案。

Abstract: Knowledge graphs (KGs) provide structured, verifiable grounding for large language models (LLMs), but current LLM-based systems commonly use KGs as auxiliary structures for text retrieval, leaving their intrinsic quality underexplored. In this work, we propose Wikontic, a multi-stage pipeline that constructs KGs from open-domain text by extracting candidate triplets with qualifiers, enforcing Wikidata-based type and relation constraints, and normalizing entities to reduce duplication. The resulting KGs are compact, ontology-consistent, and well-connected; on MuSiQue, the correct answer entity appears in 96% of generated triplets. On HotpotQA, our triplets-only setup achieves 76.0 F1, and on MuSiQue 59.8 F1, matching or surpassing several retrieval-augmented generation baselines that still require textual context. In addition, Wikontic attains state-of-the-art information-retention performance on the MINE-1 benchmark (86%), outperforming prior KG construction methods. Wikontic is also efficient at build time: KG construction uses less than 1,000 output tokens, about 3$\times$ fewer than AriGraph and $<$1/20 of GraphRAG. The proposed pipeline enhances the quality of the generated KG and offers a scalable solution for leveraging structured knowledge in LLMs.

</details>


### [216] [ART: Adaptive Response Tuning Framework -- A Multi-Agent Tournament-Based Approach to LLM Response Optimization](https://arxiv.org/abs/2512.00617)
*Omer Jauhar Khan*

Main category: cs.CL

TL;DR: ART框架通过多agent森图尔赛制ELO排名与多agent推理来系统优化LLM输出，显著提升了一致性、准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: LLM单模型响应存在不一致性、幻觉及质量波动问题，通过ART框架可显著改进这些问题。

Method: 采用竞争-批评-合作的多agent结构锦标赛流程，结合ELO排名和多agent推理机制。

Result: ART框架在响应精度、连贯性及可靠性方面优于基线单模型，提升整体质量指标8.4%，ELO评级收敛的R22值超过0.96。

Conclusion: ART为需要高质量审核的LLM应用场景提供了一个可扩展的、生产就绪的解决方案。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in natural language understanding and generation. However, single-model responses often exhibit inconsistencies, hallucinations, and varying quality across different query domains. This paper presents ART (Adaptive Response Tuning), a novel framework that employs tournament-style ELO ranking and multi-agent reasoning to systematically optimize LLM outputs. By enabling multiple LLM agents to compete, critique, and collaborate through structured tournament workflows, ART produces consensus responses that outperform individual model outputs. Our framework introduces configurable tournament parameters, dynamic agent selection, and multiple consensus fusion strategies. Experimental evaluations demonstrate significant improvements in response accuracy, coherence, and reliability compared to baseline single-model approaches. The ART framework provides a scalable, production-ready solution for applications requiring high-quality, vetted LLM responses, achieving an 8.4% improvement in overall quality metrics and R22 values exceeding 0.96 in ELO rating convergence.

</details>


### [217] [Sycophancy Claims about Language Models: The Missing Human-in-the-Loop](https://arxiv.org/abs/2512.00656)
*Jan Batzner,Volker Stocker,Stefan Schmid,Gjergji Kasneci*

Main category: cs.CL

TL;DR: 文章回顾了测量大型语言模型奉承行为的方法挑战，识别了五种核心操作定义，并指出当前研究未评估人类感知，提出了未来研究的实际建议。


<details>
  <summary>Details</summary>
Motivation: 随着对大型语言模型（LLMs）奉承行为的关注增加，文章旨在解决当前测量方法中的挑战，并指出进一步研究的方向。

Method: 文章通过文献回顾的方法，探讨了测量LLM奉承行为的各种方法，并在此基础上指出了相关挑战。

Result: 文章识别了五种核心操作定义，并发现当前研究尚未考虑人类的感知。

Conclusion: 文章结论呼吁未来的研究需要进一步重视人类感知，并对测量工具的使用提出了具体建议。

Abstract: Sycophantic response patterns in Large Language Models (LLMs) have been increasingly claimed in the literature. We review methodological challenges in measuring LLM sycophancy and identify five core operationalizations. Despite sycophancy being inherently human-centric, current research does not evaluate human perception. Our analysis highlights the difficulties in distinguishing sycophantic responses from related concepts in AI alignment and offers actionable recommendations for future research.

</details>


### [218] [Graphing the Truth: Structured Visualizations for Automated Hallucination Detection in LLMs](https://arxiv.org/abs/2512.00663)
*Tanmay Agrawal*

Main category: cs.CL

TL;DR: 该论文提出了一种框架，通过将企业和模型生成的内容组织成交互式的可视化知识图谱，为用户提供潜在幻觉区域的清晰直观视图，并通过视觉界面提供诊断和反馈机制，以增强模型的可靠性和不断提升响应质量。


<details>
  <summary>Details</summary>
Motivation: 现有的应对大语言模型幻象问题的方法成本高昂且缺乏确定性。为了提供一种成本效益高且可靠的方式来减少幻觉并改善模型性能，作者提出了这种方法。

Method: 方法论涉及创建一个知识图谱框架，将企业专有知识和模型生成的内容链接起来，以提供给用户一个直观的方式来追踪模型的断言及其根据的底层事实，并标识置信水平。这种方法允许用户诊断不一致并提供纠正反馈。

Result: 通过这种方法，可以实现一个有人参与的流程，有利于增强模型的可靠性并持续提高响应质量。

Conclusion: 结论指出了该框架在提升企业级大语言模型应用中的实际价值和潜在影响。

Abstract: Large Language Models have rapidly advanced in their ability to interpret and generate natural language. In enterprise settings, they are frequently augmented with closed-source domain knowledge to deliver more contextually informed responses. However, operational constraints such as limited context windows and inconsistencies between pre-training data and supplied knowledge often lead to hallucinations, some of which appear highly credible and escape routine human review. Current mitigation strategies either depend on costly, large-scale gold-standard Q\&A curation or rely on secondary model verification, neither of which offers deterministic assurance. This paper introduces a framework that organizes proprietary knowledge and model-generated content into interactive visual knowledge graphs. The objective is to provide end users with a clear, intuitive view of potential hallucination zones by linking model assertions to underlying sources of truth and indicating confidence levels. Through this visual interface, users can diagnose inconsistencies, identify weak reasoning chains, and supply corrective feedback. The resulting human-in-the-loop workflow creates a structured feedback loop that can enhance model reliability and continuously improve response quality.

</details>


### [219] [A Comparison of Human and ChatGPT Classification Performance on Complex Social Media Data](https://arxiv.org/abs/2512.00673)
*Breanna E. Green,Ashley L. Shea,Pengfei Zhao,Drew B. Margolin*

Main category: cs.CL

TL;DR: 本文研究了GPT-4在分类含复杂语言的数据集方面的表现，通过与人类标注者的比较，发现GPT-4在处理复杂语言分类任务方面存在局限性。


<details>
  <summary>Details</summary>
Motivation: 随着生成型人工智能工具如ChatGPT的广泛应用，科研人员对其在复杂任务中的表现有了更深入的研究动机。

Method: 研究者测试了GPT-4和不同版本的ChatGPT（版本3.5, 4, 4o）在特定任务上的表现，并通过精准率、召回率和F1分数进行量化评估。实验中提出了四种不同类型的任务提示，进行定性和定量的综合分析。

Result: 实验结果表明，虽然将标签定义包含在提示中对表现有所帮助，但总体来说，GPT-4在分类复杂语言方面遇到了困难。定性分析揭示了四个具体的发现。

Conclusion: 研究结果建议，ChatGPT在处理含有复杂语言的分类任务时应谨慎使用。

Abstract: Generative artificial intelligence tools, like ChatGPT, are an increasingly utilized resource among computational social scientists. Nevertheless, there remains space for improved understanding of the performance of ChatGPT in complex tasks such as classifying and annotating datasets containing nuanced language. Method. In this paper, we measure the performance of GPT-4 on one such task and compare results to human annotators. We investigate ChatGPT versions 3.5, 4, and 4o to examine performance given rapid changes in technological advancement of large language models. We craft four prompt styles as input and evaluate precision, recall, and F1 scores. Both quantitative and qualitative evaluations of results demonstrate that while including label definitions in prompts may help performance, overall GPT-4 has difficulty classifying nuanced language. Qualitative analysis reveals four specific findings. Our results suggest the use of ChatGPT in classification tasks involving nuanced language should be conducted with prudence.

</details>


### [220] [FastPOS: Language-Agnostic Scalable POS Tagging Framework Low-Resource Use Case](https://arxiv.org/abs/2512.00745)
*Md Abdullah Al Kafi,Sumit Kumar Banshal*

Main category: cs.CL

TL;DR: 该研究提出了一种跨语言的基于Transformer的词性标注框架，通过孟加拉语和印地语作为案例研究，展示了高效迁移与最小修改。该框架在两个语言上分别实现了96.85%和97%的词级准确性，并在语料库不平衡和语言重叠的情况下保持了强F1分数。


<details>
  <summary>Details</summary>
Motivation: 鉴于资源匮乏的语言在自然语言处理领域的研究较为薄弱，该研究旨在探索一种通用且高效的词性标注方法，以促进低资源语言的NLP研究。

Method: 研究者采用基于Transformer的模型构建框架，针对孟加拉语和印地语进行了具体实现，并证明了该框架在不同语言间的迁移能力。

Result: 研究结果显示该框架在孟加拉语和印地语上的词性标注准确性高，同时在不同类别中表现出较好的F1分数，尽管存在数据不平衡和语言重叠的问题。

Conclusion: 该研究证明了基于Transformer框架的词性标注模型在低资源语言上的应用潜力，强调了持续优化数据集和进行语言预处理的重要性。

Abstract: This study proposes a language-agnostic transformer-based POS tagging framework designed for low-resource languages, using Bangla and Hindi as case studies. With only three lines of framework-specific code, the model was adapted from Bangla to Hindi, demonstrating effective portability with minimal modification. The framework achieves 96.85 percent and 97 percent token-level accuracy across POS categories in Bangla and Hindi while sustaining strong F1 scores despite dataset imbalance and linguistic overlap. A performance discrepancy in a specific POS category underscores ongoing challenges in dataset curation. The strong results stem from the underlying transformer architecture, which can be replaced with limited code adjustments. Its modular and open-source design enables rapid cross-lingual adaptation while reducing model design and tuning overhead, allowing researchers to focus on linguistic preprocessing and dataset refinement, which are essential for advancing NLP in underrepresented languages.

</details>


### [221] [Auxiliary-Hyperparameter-Free Sampling: Entropy Equilibrium for Text Generation](https://arxiv.org/abs/2512.00789)
*Xiaodong Cai,Hai Lin,Shaoxiong Zhan,Weiqi Luo,Hong-Gee Kim,Hongyan Hao,Yu Yang,Hai-Tao Zheng*

Main category: cs.CL

TL;DR: Entropy Equilibrium Sampling (EES)是一种基于信息论的无超参数辅助采样策略，能够在不牺牲多样性的前提下，为大型语言模型（LLMs）中的文本生成任务提供高质量的结果。


<details>
  <summary>Details</summary>
Motivation: 现有的采样策略引入了额外的超参数，增加了调参复杂度和部署难度。EES试图通过动态平衡标准化熵与概率质量来解决这一问题。

Method: EES通过引入一个基于熵和概率质量的平衡策略，实现了候选集的动态调整。

Result: EES在多种语言模型上进行评估，结果显示它在不同温度设置下都能保持高质量的准确性和连贯性，同时维持多样性。

Conclusion: EES简化了部署过程并提高了性能，有望成为LLMs中的一种有效文本生成采样策略。

Abstract: Token sampling strategies critically influence text generation quality in large language models (LLMs). However, existing methods introduce additional hyperparameters, requiring extensive tuning and complicating deployment. We present Entropy Equilibrium Sampling (EES), an auxiliary hyperparameter-free approach inspired by information theory that can dynamically adjust candidate sets by balancing normalized entropy with probability mass. We evaluate EES on both reasoning and generation tasks across a range of model architectures. Our results show that EES consistently performs well across temperature settings, delivering competitive accuracy and coherence while maintaining diversity. By eliminating the need for hyperparameter tuning, EES greatly simplifies deployment while improving performance. Code is available at https://github.com/shuanncai/EES

</details>


### [222] [Accelerating Bangla NLP Tasks with Automatic Mixed Precision: Resource-Efficient Training Preserving Model Efficacy](https://arxiv.org/abs/2512.00829)
*Md Mehrab Hossain Opi,Sumaiya Khan,Moshammad Farzana Rahman*

Main category: cs.CL

TL;DR: 通过采用自动混合精度（AMP）训练，本研究展示了其在四类典型孟加拉语NLP任务中的有效性，实现了训练加速44.5%，内存减少17.6%的效果，同时保持了接近全精度模型的F-1分数。


<details>
  <summary>Details</summary>
Motivation: 现有的自然语言处理（NLP）训练过程需要大量的计算资源和时间，对于资源受限的背景下，特别是孟加拉语NLP开发，这是一个巨大挑战。本研究旨在探索通过自动混合精度（AMP）训练来提高计算效率，同时保持模型性能，以缓解这一问题。

Method: 研究采用了基于变压器架构的四种NLP模型：BanglaBERT、BanglishBERT、XLM-R和mBERT，对四种典型孟加拉语NLP任务（情感分析、命名实体识别、错误分类和问答）进行了自动混合精度训练效果的评估。

Result: 研究结果表明，自动混合精度训练可以使训练速度提高44.5%，内存消耗降低17.6%，同时保持F-1分数与全精度基线相差不到1%。

Conclusion: 本研究证明了自动混合精度训练法在资源受限环境下大幅降低计算障碍的潜力，有助于推广先进技术至更多场景。

Abstract: Training models for Natural Language Processing (NLP) requires substantial computational resources and time, posing significant challenges, especially for NLP development in Bangla, where access to high-end hardware is often limited. In this work, we explore automatic mixed precision (AMP) training as a means to improve computational efficiency without sacrificing model performance. By leveraging a dynamic mix of 16-bit and 32-bit floating-point computations, AMP lowers GPU memory requirements and speeds up training without degrading model performance. We evaluate AMP across four standard Bangla NLP tasks, namely sentiment analysis, named entity recognition, error classification, and question answering, using four transformer-based models: BanglaBERT, BanglishBERT, XLM-R, and mBERT. Our results demonstrate that AMP accelerates training by 44.5% and reduces memory consumption by 17.6%, while maintaining F-1 score within 99.7% of the full-precision baselines. This empirical study highlights AMP's potential to democratize access to state-of-the-art NLP capabilities in hardware-constrained settings by lowering computational barriers.

</details>


### [223] [WaterSearch: A Quality-Aware Search-based Watermarking Framework for Large Language Models](https://arxiv.org/abs/2512.00837)
*Yukang Lin,Jiahao Shao,Shuoran Jiang,Wentao Zhu,Bingjie Lu,Xiangping Wu,Joanna Siebert,Qingcai Chen*

Main category: cs.CL

TL;DR: 本文提出了一种名为WaterSearch的新嵌入方案，该方案通过控制种子池以促进水印文本的多样并行生成。WaterSearch框架在保持高检测率的同时，通过优化分布保真度和水印信号特征来提升文本质量，同时具有强大的抗攻击能力。


<details>
  <summary>Details</summary>
Motivation: 现有嵌入方案在提高水印的鲁棒性时，会降低下游任务的效果。本文旨在设计一个能够同时提升文本质量和水印检测率的新框架。

Method: 设计了一个基于控制种子池的自适应嵌入方案，并提出了WaterSearch，这是一种基于句子的搜索框架，可以在多种现有方法的基础上提高文本的分布保真度和水印信号特征，同时引入了一种具有强大抗攻击能力的句子级别的检测方法。

Result: 在三个流行的大型语言模型上进行了十余种任务的评估，结果表明在最高的检测强度下，WaterSearch方法的性能平均提高了51.01%。对于挑战性场景如短文本生成和低熵输出生成，其提升分别达到47.78%和36.47%。此外，在插入、同义替换和改写等攻击场景下，WaterSearch保持了高的检测率，验证了其抗攻击能力。

Conclusion: 本文提出了WaterSearch，这是一种基于句子的搜索框架，能够同时增强文本质量和水印检测率，并展示了其在多个模型和任务上的显著性能提升和抗攻击能力。

Abstract: Watermarking acts as a critical safeguard in text generated by Large Language Models (LLMs). By embedding identifiable signals into model outputs, watermarking enables reliable attribution and enhances the security of machine-generated content. Existing approaches typically embed signals by manipulating token generation probabilities. Despite their effectiveness, these methods inherently face a trade-off between detectability and text quality: the signal strength and randomness required for robust watermarking tend to degrade the performance of downstream tasks.
  In this paper, we design a novel embedding scheme that controls seed pools to facilitate diverse parallel generation of watermarked text. Based on that scheme, we propose WaterSearch, a sentence-level, search-based watermarking framework adaptable to a wide range of existing methods. WaterSearch enhances text quality by jointly optimizing two key aspects: 1) distribution fidelity and 2) watermark signal characteristics. Furthermore, WaterSearch is complemented by a sentence-level detection method with strong attack robustness. We evaluate our method on three popular LLMs across ten diverse tasks. Extensive experiments demonstrate that our method achieves an average performance improvement of 51.01\% over state-of-the-art baselines at a watermark detectability strength of 95\%. In challenging scenarios such as short text generation and low-entropy output generation, our method yields performance gains of 47.78\% and 36.47\%, respectively. Moreover, under different attack senarios including insertion, synonym substitution and paraphrase attasks, WaterSearch maintains high detectability, further validating its robust anti-attack capabilities. Our code is available at \href{https://github.com/Yukang-Lin/WaterSearch}{https://github.com/Yukang-Lin/WaterSearch}.

</details>


### [224] [Less is More: Resource-Efficient Low-Rank Adaptation](https://arxiv.org/abs/2512.00878)
*Chunlin Tian,Xuyang Wei,Huanrong Liu,Zhijiang Guo,Li Li*

Main category: cs.CL

TL;DR: EffiLoRA是一种轻量级且可泛化的资源高效低秩适应方法，适用于语言、多模态和扩散模型。该方法使用统一的A矩阵跨所有转换器层，并引入了基于运行时选择的B矩阵更新，以动态权衡系统资源预算和模型性能。


<details>
  <summary>Details</summary>
Motivation: LoRA虽然提高了参数效率，但在复杂数据集上仍存在性能瓶颈和参数干扰问题，并且近期的研究虽然试图通过矩阵级不对称来降低训练成本，但效果有限。

Method: EffiLoRA采用了统一的A矩阵贯穿所有变换器层，并引入了运行时选择的B矩阵更新机制，实现资源预算和模型性能之间的动态平衡。

Result: EffiLoRA在多种模型类型上表现出优于LoRA的效果，特别是在常识推理、视觉指令微调和图像生成等模态上，显示出更高的效率和更强的稳健性。

Conclusion: EffiLoRA提出了一种改进的低秩适应方法，旨在提高大型语言模型和其他类型的模型的参数效率和性能，特别是在复杂数据集上提供了更好的表现。

Abstract: Low-Rank Adaptation (LoRA) is a widely adopted parameter-efficient fine-tuning (PEFT) method for Large Language Models (LLMs), but it still incurs notable overhead and suffers from parameter interference in complex datasets. While re- cent works decouple LoRA update matrices to exploit matrix-wise asymmetry, training costs remain high. We revisit LoRA from the perspective of inter-matrix and intra-layer parameter redundancy and propose Resource-Efficient Low-Rank Adaptation, EffiLoRA, a lightweight and generalizable approach for language, multimodal, and diffusion models. EffiLoRA employs a unified A matrix across all transformer layers and introduces a runtime selective B matrices up- date to dynamically trade-off the system resource budget and model performance. EffiLoRA consistently outperforms LoRA across diverse modalities, including commonsense reasoning, visual instruction tuning, and image generation, demon- strating improved efficiency and robustness.

</details>


### [225] [Reward Auditor: Inference on Reward Modeling Suitability in Real-World Perturbed Scenarios](https://arxiv.org/abs/2512.00920)
*Jianxiang Zang,Yongda Wei,Ruxue Bai,Shiyu Jiang,Nijia Mo,Binhong Li,Qiang Sun,Hui Liu*

Main category: cs.CL

TL;DR: 本文提出了一种名为Reward Auditor的新框架，用于评估奖励模型在特定现实世界扰动下的适用性。它通过科学审计方法来检测奖励模型在现实场景中的系统性漏洞，从而推动构建更安全、更稳健和值得信赖的LLM系统。


<details>
  <summary>Details</summary>
Motivation: 当前的奖励模型评估方法仅关注给定特定场景下的偏好感知准确性，而忽略了现实世界中的关键脆弱性。本文旨在提出一个新框架来评估奖励模型的适用性，以应对这些挑战。

Method: 引入了一个假设测试框架——Reward Auditor，用于评估奖励模型的适用性。通过科学审计方法，在现实世界扰动情景下，定量分析奖励模型偏好感知置信度的分布降级，从而推断奖励模型在特定现实场景中的系统性漏洞。

Result: Reward Auditor框架能够在现实世界扰动情景下，量化统计显著性和效应大小，推断奖励模型的可靠性和严重性。这为建立可验证安全、更稳健和可信的LLM对齐系统奠定了基础。

Conclusion: 本文提出的Reward Auditor框架为奖励模型在现实世界中的性能评估提供了一种新的视角，有助于提升LLM的对齐系统的安全性、鲁棒性和可信性。

Abstract: Reliable reward models (RMs) are critical for ensuring the safe alignment of large language models (LLMs). However, current evaluation methods focus solely on preference perception accuracies in given specific scenarios, obscuring the critical vulnerabilities of RMs in real-world scenarios. We identify the true challenge lies in assessing a novel dimension: Suitability, defined as conditional reliability under specific real-world perturbations. To this end, we introduce Reward Auditor, a hypothesis-testing framework specifically designed for RM suitability inference. Rather than answering "How accurate is the RM's preference perception for given samples?", it employs scientific auditing to answer: "Can we infer RMs exhibit systematic vulnerabilities in specific real-world scenarios?". Under real-world perturbed scenarios, Reward Auditor quantifies statistical significance and effect size by auditing distribution degradation of RM preference perception confidence. This enables inference of both the certainty and severity of RM vulnerabilities across diverse real-world scenarios. This lays a solid foundation for building next-generation LLM alignment systems that are verifiably safe, more robust, and trustworthy.

</details>


### [226] [Mitigating Hallucinations in Zero-Shot Scientific Summarisation: A Pilot Study](https://arxiv.org/abs/2512.00931)
*Imane Jaaouine,Ross D. King*

Main category: cs.CL

TL;DR: 研究通过不同提示工程方法改善了零样本科学总结中的语义一致性，特别指出重复关键句子和随机句子能显著提升总结的词法一致性。


<details>
  <summary>Details</summary>
Motivation: 研究希望探索提示工程方法是否可以在零样本大语言模型总结科学文本时减轻上下文不一致的幻觉问题。

Method: 研究选取了8篇酵母生物技术研究的摘要，并使用六种不同的提示工程技术（包括基线提示、不同复杂度的提示、不同重复句子数量的提示和不同随机添加句子数量的提示）来测试其效果。研究使用了六种评价指标来衡量生成的总结与原始摘要之间的语义和词法一致性。

Result: 统计分析表明，重复关键句子和随机添加句子这两种提示工程技术显著提高了生成摘要与原始摘要之间的词法一致性。

Conclusion: 研究表明提示工程技术在零样本科学总结任务中对抗幻觉问题具有潜在效果，尤其是重复关键句子和随机添加句子的方法更为有效。

Abstract: Large language models (LLMs) produce context inconsistency hallucinations, which are LLM generated outputs that are misaligned with the user prompt. This research project investigates whether prompt engineering (PE) methods can mitigate context inconsistency hallucinations in zero-shot LLM summarisation of scientific texts, where zero-shot indicates that the LLM relies purely on its pre-training data. Across eight yeast biotechnology research paper abstracts, six instruction-tuned LLMs were prompted with seven methods: a base- line prompt, two levels of increasing instruction complexity (PE-1 and PE-2), two levels of context repetition (CR-K1 and CR-K2), and two levels of random addition (RA-K1 and RA-K2). Context repetition involved the identification and repetition of K key sentences from the abstract, whereas random addition involved the repetition of K randomly selected sentences from the abstract, where K is 1 or 2. A total of 336 LLM-generated summaries were evaluated using six metrics: ROUGE-1, ROUGE-2, ROUGE-L, BERTScore, METEOR, and cosine similarity, which were used to compute the lexical and semantic alignment be- tween the summaries and the abstracts. Four hypotheses on the effects of prompt methods on summary alignment with the reference text were tested. Statistical analysis on 3744 collected datapoints was performed using bias-corrected and accelerated (BCa) bootstrap confidence intervals and Wilcoxon signed-rank tests with Bonferroni-Holm correction. The results demonstrated that CR and RA significantly improve the lexical alignment of LLM-generated summaries with the abstracts. These findings indicate that prompt engineering has the potential to impact hallucinations in zero-shot scientific summarisation tasks.

</details>


### [227] [DeformAr: Rethinking NER Evaluation through Component Analysis and Visual Analytics](https://arxiv.org/abs/2512.00938)
*Ahmed Mustafa Younes*

Main category: cs.CL

TL;DR: 该研究提出了一种名为DeformAr的新框架，旨在调查和解释阿拉伯语和英语命名实体识别系统之间的性能差异。DeformAr结合了数据提取库和交互式仪表盘，支持跨组件分析和行为分析两种评估模式。


<details>
  <summary>Details</summary>
Motivation: 目前，基于Transformer的阿拉伯语命名实体识别系统的表现与英语相比仍存在差距，现有研究多从单一角度出发未能充分理解这些差异。DeformAr旨在填补这一空白。

Method: DeformAr框架通过数据提取库和交互式仪表盘支持两种评估模式。在跨组件分析阶段，它使用系统性的诊断措施来探究数据和模型子组件的差异。在行为分析阶段，则结合可解释性技术、词级别度量、交互式可视化和表示空间分析，进一步揭示模型行为背后的模式和数据因素。

Result: 通过DeformAr，研究者能够更全面地理解阿拉伯语和英语命名实体识别系统之间的性能差异，这有助于提高阿拉伯语命名实体识别系统的性能。

Conclusion: DeformAr是首个针对阿拉伯语的组件基础可解释性工具，为资源不足的语言建模分析提供了重要资源。

Abstract: Transformer models have significantly advanced Natural Language Processing (NLP), demonstrating strong performance in English. However, their effectiveness in Arabic, particularly for Named Entity Recognition (NER), remains limited, even with larger pre-trained models. This performance gap stems from multiple factors, including tokenisation, dataset quality, and annotation inconsistencies. Existing studies often analyze these issues in isolation, failing to capture their joint effect on system behaviour and performance.
  We introduce DeformAr (Debugging and Evaluation Framework for Transformer-based NER Systems), a novel framework designed to investigate and explain the performance discrepancy between Arabic and English NER systems. DeformAr integrates a data extraction library and an interactive dashboard, supporting two modes of evaluation: cross-component analysis and behavioural analysis. The framework divides each language into dataset and model components to examine their interactions.
  The analysis proceeds in two stages. First, cross-component analysis provides systematic diagnostic measures across data and model subcomponents, addressing the "what," "how," and "why" behind observed discrepancies. The second stage applies behavioural analysis by combining interpretability techniques with token-level metrics, interactive visualisations, and representation space analysis. These stages enable a component-aware diagnostic process that detects model behaviours and explains them by linking them to underlying representational patterns and data factors. DeformAr is the first Arabic-specific, component-based interpretability tool, offering a crucial resource for advancing model analysis in under-resourced languages.

</details>


### [228] [Fine-tuning of lightweight large language models for sentiment classification on heterogeneous financial textual data](https://arxiv.org/abs/2512.00946)
*Alvaro Paredes Amorin,Andre Python,Christoph Weisser*

Main category: cs.CL

TL;DR: 本研究评估了轻量级开源大语言模型（LLMs）在不同规模、来源、格式和语言的金融数据集上的情感理解能力，发现即便是使用5%的训练数据，Qwen3 8B 和 Llama3 8B 在大多数场景下表现最佳。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于分析轻量级开源大语言模型是否能在缺乏大量专用数据集的情况下，依然保持与传统大模型相当甚至更好的表现，从而为研究人员和从业者提供一种更具成本效益的选择。

Method: 研究方法包括选择五组公开可用的金融数据集进行实验，比较基准的金融自然语言处理模型FinBERT与三个开源轻量级大语言模型DeepSeek-LLM 7B、Llama3 8B Instruct 及 Qwen3 8B 的性能。

Result: 研究结果显示，轻量级模型在各种金融数据集上，尤其在仅使用5%训练数据的情况下，表现最佳，尤其是在零样本和少样本学习场景中。

Conclusion: 研究结论表明，轻量级开源模型具有成本效益，能有效处理异质性文本数据，即便是使用大规模标注语料库的有限部分也能获得与传统大型模型相当的性能。

Abstract: Large language models (LLMs) play an increasingly important role in finan- cial markets analysis by capturing signals from complex and heterogeneous textual data sources, such as tweets, news articles, reports, and microblogs. However, their performance is dependent on large computational resources and proprietary datasets, which are costly, restricted, and therefore inacces- sible to many researchers and practitioners. To reflect realistic situations we investigate the ability of lightweight open-source LLMs - smaller and publicly available models designed to operate with limited computational resources - to generalize sentiment understanding from financial datasets of varying sizes, sources, formats, and languages. We compare the benchmark finance natural language processing (NLP) model, FinBERT, and three open-source lightweight LLMs, DeepSeek-LLM 7B, Llama3 8B Instruct, and Qwen3 8B on five publicly available datasets: FinancialPhraseBank, Financial Question Answering, Gold News Sentiment, Twitter Sentiment and Chinese Finance Sentiment. We find that LLMs, specially Qwen3 8B and Llama3 8B, perform best in most scenarios, even from using only 5% of the available training data. These results hold in zero-shot and few-shot learning scenarios. Our findings indicate that lightweight, open-source large language models (LLMs) consti- tute a cost-effective option, as they can achieve competitive performance on heterogeneous textual data even when trained on only a limited subset of the extensive annotated corpora that are typically deemed necessary.

</details>


### [229] [Advancing Academic Chatbots: Evaluation of Non Traditional Outputs](https://arxiv.org/abs/2512.00991)
*Nicole Favero,Francesca Salute,Daniel Hardt*

Main category: cs.CL

TL;DR: 该研究扩展了对大型语言模型的评估范围，不仅比较了两种检索策略（基于结构知识图的Graph RAG和混合关键词-语义搜索的Advanced RAG）在问答(QA)中的表现，还评估了模型生成非传统学术输出（如幻灯片和播客脚本）的能力。


<details>
  <summary>Details</summary>
Motivation: 由于现有的评估大多集中在标准任务上，因此进行这项研究旨在扩展评估范围，以更好地理解大型语言模型在生成复杂和创意学术输出方面的潜力。

Method: 研究通过实现一个结合了Meta的LLaMA 3 70B开源权重和OpenAI的GPT 4o mini API的原型，对两种检索策略进行了比较，并使用人类评分和大语言模型裁判进行QA性能评估。此外，还对模型生成幻灯片和播客脚本的能力进行了测试。

Result: GPT 4o mini结合Advanced RAG在QA上表现最佳，Graph RAG虽然有一定改进但容易产生幻觉。在幻灯片和播客脚本生成方面，GPT 4o mini表现最好，但LLaMA 3在叙事连贯性方面也有潜力。人类评审者对于检测布局和风格上的错误至关重要。

Conclusion: 研究发现，虽然大型语言模型在生成非传统学术作品方面表现出色，但结合人类评审仍然是评估这些作品质量的重要手段。

Abstract: Most evaluations of large language models focus on standard tasks such as factual question answering or short summarization. This research expands that scope in two directions: first, by comparing two retrieval strategies, Graph RAG, structured knowledge-graph based, and Advanced RAG, hybrid keyword-semantic search, for QA; and second, by evaluating whether LLMs can generate high quality non-traditional academic outputs, specifically slide decks and podcast scripts. We implemented a prototype combining Meta's LLaMA 3 70B open weight and OpenAI's GPT 4o mini API based. QA performance was evaluated using both human ratings across eleven quality dimensions and large language model judges for scalable cross validation. GPT 4o mini with Advanced RAG produced the most accurate responses. Graph RAG offered limited improvements and led to more hallucinations, partly due to its structural complexity and manual setup. Slide and podcast generation was tested with document grounded retrieval. GPT 4o mini again performed best, though LLaMA 3 showed promise in narrative coherence. Human reviewers were crucial for detecting layout and stylistic flaws, highlighting the need for combined human LLM evaluation in assessing emerging academic outputs.

</details>


### [230] [When Safety Blocks Sense: Measuring Semantic Confusion in LLM Refusals](https://arxiv.org/abs/2512.01037)
*Riad Ahmed Anonto,Md Labid Al Nahiyan,Md Tanvir Hassan,Ch. Md. Rakin Haider*

Main category: cs.CL

TL;DR: 该研究引入了“语义混淆”作为评估语言模型安全性的新方法，通过构建ParaGuard语料库，提出三种基于标记级别的模型无关度量指标，揭示了全局错误拒绝率未能捕获的局部不一致性。实验表明，这三种度量指标能帮助开发者在减小误拒绝的同时保证模型的安全性。


<details>
  <summary>Details</summary>
Motivation: 当前评估语言模型安全性的方法过于笼统，未能捕捉到细微的局部不一致性问题。因此，研究团队希望找到一种新的评估方式来更准确地诊断和调整模型的安全性。

Method: 研究团队通过构建一个包含10000个受控重述簇的ParaGuard语料库，固定意图内容、改变表面形式。基于此语料库，提出了三种模型无关的标记级别度量指标：混淆指数、混淆率和混淆深度。

Result: 研究结果表明，全球错误拒绝率可能隐藏了关键的结构问题，而新的度量指标揭示了模型边界在不同场景下的不稳定性和局部不一致性。此外，这些度量指标还有助于区分系统拒绝频率和其拒绝合理性之间的区别。

Conclusion: 此研究为评估和调优语言模型的安全性提供了新的视角和工具，帮助开发者更好地理解模型的脆弱性和改进方向。

Abstract: Safety-aligned language models often refuse prompts that are actually harmless. Current evaluations mostly report global rates such as false rejection or compliance. These scores treat each prompt alone and miss local inconsistency, where a model accepts one phrasing of an intent but rejects a close paraphrase. This gap limits diagnosis and tuning. We introduce "semantic confusion," a failure mode that captures such local inconsistency, and a framework to measure it. We build ParaGuard, a 10k-prompt corpus of controlled paraphrase clusters that hold intent fixed while varying surface form. We then propose three model-agnostic metrics at the token level: Confusion Index, Confusion Rate, and Confusion Depth. These metrics compare each refusal to its nearest accepted neighbors and use token embeddings, next-token probabilities, and perplexity signals. Experiments across diverse model families and deployment guards show that global false-rejection rate hides critical structure. Our metrics reveal globally unstable boundaries in some settings, localized pockets of inconsistency in others, and cases where stricter refusal does not increase inconsistency. We also show how confusion-aware auditing separates how often a system refuses from how sensibly it refuses. This gives developers a practical signal to reduce false refusals while preserving safety.

</details>


### [231] [ELR-1000: A Community-Generated Dataset for Endangered Indic Indigenous Languages](https://arxiv.org/abs/2512.01077)
*Neha Joshi,Pamir Gogoi,Aasim Mirza,Aayush Jansari,Aditya Yadavalli,Ayushi Pandey,Arunima Shukla,Deepthi Sudharsan,Kalika Bali,Vivek Seshadri*

Main category: cs.CL

TL;DR: 本文介绍了来自印度东部偏远地区10种濒危语言的1060份传统食谱的多媒体数据集。通过为低数字素养的贡献者设计的移动界面收集，该数据集不仅记录了烹饪实践，还捕获了嵌入在原生食品传统中的社会文化背景。通过对几种最先进的大型语言模型进行评估，研究发现这些模型在低资源、文化特异性语言上的翻译表现不佳，但在提供针对性上下文后，其翻译质量显著提升。这强调了为那些受代表不足的语言和技术领域设立基准的重要性。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型在处理低资源、文化特殊性的语言方面存在局限性，因此有必要汇集一个文化根基深厚的数据集来推动对濒危语言的保护和语言技术的发展。

Method: 该研究通过设计适合低数字素养贡献者的移动界面来收集食谱，并对几款最先进的大型语言模型进行翻译评估，提供针对性的上下文信息以改进翻译质量。

Result: 大型语言模型虽然强大，但在低资源、文化特异性语言上的翻译表现不佳，但在提供背景信息、翻译示例和文化保护指南后，其翻译质量得到了显著提高。

Conclusion: 研究确认了对低资源语言设置基准的重要性，并强调了文化保护和公平的语言技术发展的必要性。同时，该研究发布了ELR-1000数据集，希望能激发对濒危语言技术开发的兴趣。

Abstract: We present a culturally-grounded multimodal dataset of 1,060 traditional recipes crowdsourced from rural communities across remote regions of Eastern India, spanning 10 endangered languages. These recipes, rich in linguistic and cultural nuance, were collected using a mobile interface designed for contributors with low digital literacy. Endangered Language Recipes (ELR)-1000 -- captures not only culinary practices but also the socio-cultural context embedded in indigenous food traditions. We evaluate the performance of several state-of-the-art large language models (LLMs) on translating these recipes into English and find the following: despite the models' capabilities, they struggle with low-resource, culturally-specific language. However, we observe that providing targeted context -- including background information about the languages, translation examples, and guidelines for cultural preservation -- leads to significant improvements in translation quality. Our results underscore the need for benchmarks that cater to underrepresented languages and domains to advance equitable and culturally-aware language technologies. As part of this work, we release the ELR-1000 dataset to the NLP community, hoping it motivates the development of language technologies for endangered languages.

</details>


### [232] [How do we measure privacy in text? A survey of text anonymization metrics](https://arxiv.org/abs/2512.01109)
*Yaxuan Ren,Krithika Ramesh,Yaxing Yao,Anjalie Field*

Main category: cs.CL

TL;DR: 该研究通过系统性回顾47篇关于隐私评估的文献，识别并比较了六种不同的隐私概念，并分析了相关指标如何捕捉隐私风险的不同方面。研究还评估了这些概念与HIPAA和GDPR法律标准以及基于HCI的用户期望的契合度，旨在为更稳健、可比和法律意识强烈的隐私评估提供实用指导。


<details>
  <summary>Details</summary>
Motivation: 随着自然语言处理（NLP）研究和模型开发在包含敏感数据的领域中越来越重要，如何评估脱敏方法是否充分保护隐私仍是一个开放的挑战。因此，这项研究旨在系统地审查文献，以澄清和协调隐私评估的度量标准，从而实现对隐私风险的全面评价。

Method: 通过手动回顾47篇关于隐私评估的文献，识别和比较六种不同的隐私概念，并分析这些概念与当前法律标准和用户期望的契合度，以评估不同指标如何捕捉隐私风险的不同方面。

Result: 研究发现六种隐私概念及其度量标准能够捕捉隐私风险的不同方面。并在评估这些隐私概念与HIPAA、GDPR和用户期望之间的契合度之后，提出了实用的指导建议。

Conclusion: 研究最终指出，在文本脱敏领域的隐私评估中应采取更为稳健、可比和法律意识强烈的策略，并且强调了当前实践中存在的空白。

Abstract: In this work, we aim to clarify and reconcile metrics for evaluating privacy protection in text through a systematic survey. Although text anonymization is essential for enabling NLP research and model development in domains with sensitive data, evaluating whether anonymization methods sufficiently protect privacy remains an open challenge. In manually reviewing 47 papers that report privacy metrics, we identify and compare six distinct privacy notions, and analyze how the associated metrics capture different aspects of privacy risk. We then assess how well these notions align with legal privacy standards (HIPAA and GDPR), as well as user-centered expectations grounded in HCI studies. Our analysis offers practical guidance on navigating the landscape of privacy evaluation approaches further and highlights gaps in current practices. Ultimately, we aim to facilitate more robust, comparable, and legally aware privacy evaluations in text anonymization.

</details>


### [233] [TempPerturb-Eval: On the Joint Effects of Internal Temperature and External Perturbations in RAG Robustness](https://arxiv.org/abs/2512.01183)
*Yongxin Zhou,Philippe Mulhem,Didier Schwab*

Main category: cs.CL

TL;DR: 该研究系统地分析了文本扰动（模拟嘈杂检索）与温度设置之间的交互作用，并提出了一个全面的RAG扰动-温度分析框架。研究发现高温度设置会一致地放大对扰动的脆弱性，并且某些类型的扰动在温度范围内具有非线性敏感性。贡献包括诊断基准、分析框架和在嘈杂检索条件下的模型选择和参数调整指南。


<details>
  <summary>Details</summary>
Motivation: 当前评估RAG系统的方法通常将检索质量和生成参数（如温度）分开评估，忽略了它们之间的交互作用。该研究旨在补充这一不足，通过实验研究它们之间的交互作用，提供更全面的分析框架。

Method: 该研究通过应用一个全面的RAG扰动-温度分析框架，利用不同类型的文本扰动和多个温度设置，在HotpotQA数据集上进行了大量实验，使用了开源和专有LLM。

Result: 研究表明，高温度设置会持续放大对抗扰动的脆弱性，特定类型的扰动在温度范围内表现出非线性敏感性。通过实验获得了具体的结果，验证了假设。

Conclusion: 研究提出了三个关键贡献：（1）评估RAG鲁棒性的诊断基准；（2）定量分析扰动-温度交互作用的分析框架；（3）在噪声检索条件下进行模型选择和参数调整的实用指南。

Abstract: The evaluation of Retrieval-Augmented Generation (RAG) systems typically examines retrieval quality and generation parameters like temperature in isolation, overlooking their interaction. This work presents a systematic investigation of how text perturbations (simulating noisy retrieval) interact with temperature settings across multiple LLM runs. We propose a comprehensive RAG Perturbation-Temperature Analysis Framework that subjects retrieved documents to three distinct perturbation types across varying temperature settings. Through extensive experiments on HotpotQA with both open-source and proprietary LLMs, we demonstrate that performance degradation follows distinct patterns: high-temperature settings consistently amplify vulnerability to perturbations, while certain perturbation types exhibit non-linear sensitivity across the temperature range. Our work yields three key contributions: (1) a diagnostic benchmark for assessing RAG robustness, (2) an analytical framework for quantifying perturbation-temperature interactions, and (3) practical guidelines for model selection and parameter tuning under noisy retrieval conditions.

</details>


### [234] [Generalist Large Language Models Outperform Clinical Tools on Medical Benchmarks](https://arxiv.org/abs/2512.01191)
*Krithik Vishwanath,Mrigayu Ghosh,Anton Alyakin,Daniel Alexander Alber,Yindalon Aphinyanaphongs,Eric Karl Oermann*

Main category: cs.CL

TL;DR: 研究评估了两个广泛使用的临床AI系统（OpenEvidence和UpToDate Expert AI）与三种顶尖的通用大型语言模型（GPT-5、Gemini 3 Pro和Claude Sonnet 4.5），结果表明通用模型的性能优于临床工具，揭示了临床辅助工具可能落后于前沿LLMs的现状，强调了在实际应用前需要透明、独立的评估。


<details>
  <summary>Details</summary>
Motivation: 研究旨在填补临床专业AI工具缺乏独立、定量评估的空白，这些工具在诊断、分流和指南解释中日益发挥着重要作用。

Method: 研究使用了一个包含1,000项任务的小型基准测试，结合了MedQA（医学知识）和HealthBench（临床一致性）评估。

Result: 通用模型在所有检测领域均优于临床工具，GPT-5表现最佳，而OpenEvidence和UpToDate在完整性和沟通质量、情境意识及系统性安全推理方面存在不足。

Conclusion: 研究结果指出，临床辅助工具可能在决策支持功能上落后于前沿LLMs，强调了在临床工作流程中使用前进行透明、独立评估的紧迫性。

Abstract: Specialized clinical AI assistants are rapidly entering medical practice, often framed as safer or more reliable than general-purpose large language models (LLMs). Yet, unlike frontier models, these clinical tools are rarely subjected to independent, quantitative evaluation, creating a critical evidence gap despite their growing influence on diagnosis, triage, and guideline interpretation. We assessed two widely deployed clinical AI systems (OpenEvidence and UpToDate Expert AI) against three state-of-the-art generalist LLMs (GPT-5, Gemini 3 Pro, and Claude Sonnet 4.5) using a 1,000-item mini-benchmark combining MedQA (medical knowledge) and HealthBench (clinician-alignment) tasks. Generalist models consistently outperformed clinical tools, with GPT-5 achieving the highest scores, while OpenEvidence and UpToDate demonstrated deficits in completeness, communication quality, context awareness, and systems-based safety reasoning. These findings reveal that tools marketed for clinical decision support may often lag behind frontier LLMs, underscoring the urgent need for transparent, independent evaluation before deployment in patient-facing workflows.

</details>


### [235] [Sentiment Analysis and Emotion Classification using Machine Learning Techniques for Nagamese Language - A Low-resource Language](https://arxiv.org/abs/2512.01256)
*Ekha Morang,Surhoni A. Ngullie,Sashienla Longkumer,Teisovi Angami*

Main category: cs.CL

TL;DR: 该研究填补了西孟加拉语地区Nagamese语言情感分析的空白，构建了1195个Nagamese词汇的情感极性词典，并使用朴素贝叶斯和支持向量机等监督机器学习技术进行情感和情绪分类。


<details>
  <summary>Details</summary>
Motivation: 之前的关于情感分析的工作主要集中于资源丰富的语言，如英语和印地语，对于Nagamese语言的研究几乎是空白。该研究旨在填补这一空白，首次针对Nagamese语言进行情感分析和情绪分类。

Method: 研究人员构建了一个包含1195个Nagamese词汇的情感极性词典，并结合其他特征使用监督机器学习技术（包括朴素贝叶斯和支持向量机）进行情感分析。

Result: 该研究建立了一个Nagamese情感极性词典，并利用此词典和额外特征，通过机器学习模型实现了对Nagamese文本的情感和情绪分类。

Conclusion: 此项研究是首次针对Nagamese语言的情感分析和情绪分类，展示了机器学习方法在该领域中的应用潜力。

Abstract: The Nagamese language, a.k.a Naga Pidgin, is an Assamese-lexified creole language developed primarily as a means of communication in trade between the people from Nagaland and people from Assam in the north-east India. Substantial amount of work in sentiment analysis has been done for resource-rich languages like English, Hindi, etc. However, no work has been done in Nagamese language. To the best of our knowledge, this is the first attempt on sentiment analysis and emotion classification for the Nagamese Language. The aim of this work is to detect sentiments in terms of polarity (positive, negative and neutral) and basic emotions contained in textual content of Nagamese language. We build sentiment polarity lexicon of 1,195 nagamese words and use these to build features along with additional features for supervised machine learning techniques using Na"ive Bayes and Support Vector Machines.
  Keywords: Nagamese, NLP, sentiment analysis, machine learning

</details>


### [236] [SUPERChem: A Multimodal Reasoning Benchmark in Chemistry](https://arxiv.org/abs/2512.01274)
*Zehua Zhao,Zhixian Huang,Junren Li,Siyu Lin,Junting Zhou,Fengqi Cao,Kun Zhou,Rui Ge,Tingting Long,Yuexiang Zhu,Yan Liu,Jie Zheng,Junnian Wei,Rong Zhu,Peng Zou,Wenyu Li,Zekai Cheng,Tian Ding,Yaxuan Wang,Yizhao Yan,Tingru Wei,Haowei Ming,Weijie Mao,Chen Sun,Yiming Liu,Zichen Wang,Zuo Zhang,Tong Yang,Hao Ma,Zhen Gao,Jian Pei*

Main category: cs.CL

TL;DR: SUPERChem 是一个包含500个专家策划、涵盖多个化学子领域的推理问题基准，这些问题不仅可以用于多模态和纯文本格式。通过引入Reasoning Path Fidelity (RPF)评分法，评估模型的推理质量而非仅限于最终答案的准确性。该基准挑战了当前最佳模型GPT-5 (High) 和 Gemini 2.5 Pro 的能力，展示了在多步、多模态推理方面的能力差异。


<details>
  <summary>Details</summary>
Motivation: 目前对大型语言模型（LLMs）的化学推理能力评估基准主要存在任务简单化、缺乏过程评估、以及与专家级化学技能不匹配的问题。SUPERChem旨在解决这些问题，提供了一个具有挑战性的基准，推动该领域向专家级化学智能迈进。

Method: SUPERChem 涵盖了多个化学子领域，包含500个专家策划的问题，这些问题以多模态和纯文本形式提供。每个问题都配有一个专家撰写的解题路径，通过引入Reasoning Path Fidelity (RPF)评分法，评估模型的推理过程.

Result: 在与人类基准（40.3%）的比较中，即使最佳模型GPT-5 (High) 也只能达到38.5%，紧随其后的是Gemini 2.5 Pro (37.9%)和DeepSeek-V3.1-Think (37.3%)。这表明，现有的大型语言模型在多步、多模态推理能力方面仍存在差距。

Conclusion: SUPERChem 旨在通过提供一个具有挑战性的基准和可靠的评估框架，推动大型语言模型向专家级化学智能的进步，以促进该领域的研究和发展。

Abstract: Current benchmarks for evaluating the chemical reasoning capabilities of Large Language Models (LLMs) are limited by oversimplified tasks, lack of process-level evaluation, and misalignment with expert-level chemistry skills. To address these issues, we introduce SUPERChem, a benchmark of 500 expert-curated reasoning-intensive chemistry problems, covering diverse subfields and provided in both multimodal and text-only formats. Original content and an iterative curation pipeline eliminate flawed items and mitigate data contamination. Each problem is paired with an expert-authored solution path, enabling Reasoning Path Fidelity (RPF) scoring to evaluate reasoning quality beyond final-answer accuracy. Evaluations against a human baseline of 40.3% accuracy show that even the best-performing model, GPT-5 (High), reaches only 38.5%, followed closely by Gemini 2.5 Pro (37.9%) and DeepSeek-V3.1-Think (37.3%). SUPERChem elicits multi-step, multimodal reasoning, reveals model-dependent effects of visual information, and distinguishes high-fidelity reasoners from heuristic ones. By providing a challenging benchmark and a reliable evaluation framework, SUPERChem aims to facilitate the advancement of LLMs toward expert-level chemical intelligence. The dataset of the benchmark is available at https://huggingface.co/datasets/ZehuaZhao/SUPERChem.

</details>


### [237] [Agreement-Constrained Probabilistic Minimum Bayes Risk Decoding](https://arxiv.org/abs/2512.01316)
*Koki Natsumi,Hiroyuki Deguchi,Yusuke Sakai,Hidetaka Kamigaito,Taro Watanabe*

Main category: cs.CL

TL;DR: 介绍了一种新型的AC-PMBR解码方法，它利用知识精练模型减少填补分数矩阵时的误差，从而在保持较低计算成本的同时提高翻译质量。


<details>
  <summary>Details</summary>
Motivation: 现有的PMBR解码方法虽然减少了计算成本，但翻译质量有所下降，因此需要一种新的方法来改善质量与成本之间的权衡。

Method: AC-PMBR解码方法利用知识精练模型来指导填补分数矩阵，从而将矩阵完成的近似误差降低3倍。

Result: AC-PMBR解码方法在WMT'23 En$	o$De翻译任务上实现了与PMBR方法相近的计算成本但更高的翻译质量。

Conclusion: 通过使用知识精练模型，AC-PMBR方法能够在保证计算效率的同时提高翻译质量。

Abstract: Minimum Bayes risk (MBR) decoding generates high-quality translations by maximizing the expected utility of output candidates, but it evaluates all pairwise scores over the candidate set; hence, it takes quadratic time with respect to the number of candidates. To reduce the number of utility function calls, probabilistic MBR (PMBR) decoding partially evaluates quality scores using sampled pairs of candidates and completes the missing scores with a matrix completion algorithm. Nevertheless, it degrades the translation quality as the number of utility function calls is reduced. Therefore, to improve the trade-off between quality and cost, we propose agreement-constrained PMBR (AC-PMBR) decoding, which leverages a knowledge distilled model to guide the completion of the score matrix. Our AC-PMBR decoding improved approximation errors of matrix completion by up to 3 times and achieved higher translation quality compared with PMBR decoding at a comparable computational cost on the WMT'23 En$\leftrightarrow$De translation tasks.

</details>


### [238] [MARSAD: A Multi-Functional Tool for Real-Time Social Media Analysis](https://arxiv.org/abs/2512.01369)
*Md. Rafiul Biswas,Firoj Alam,Wajdi Zaghouani*

Main category: cs.CL

TL;DR: MARSAD是一个多功能自然语言处理平台，专为实时社交媒体监控和分析设计，特别关注阿拉伯语地区。该平台支持实时和存档的社交媒体内容分析，具备多种功能如情感分析、情绪分析、宣传检测、事实核查和仇恨言论检测。同时，它还提供了通过API密钥的安全数据爬取功能。


<details>
  <summary>Details</summary>
Motivation: MARSAD旨在为研究人员和非技术用户提供一个全面的社交媒体内容分析工具，尤其是针对阿拉伯语地区的实时和存档内容。

Method: MARSAD采用了灵活的文档存储和结构化数据管理的后端架构，支持大量多模态数据的高效处理，并通过用户友好的前端界面提供了无缝数据上传和交互体验。

Result: MARSAD能够提供详细的数据可视化和报告，涵盖情感分析、情绪分析、宣传检测、事实核查和仇恨言论检测等多个方面。

Conclusion: 总的来看，MARSAD是一个功能强大的社交媒体分析平台，它为研究者和非技术人员提供了多方面的社交媒体分析解决方案。

Abstract: MARSAD is a multifunctional natural language processing (NLP) platform designed for real-time social media monitoring and analysis, with a particular focus on the Arabic-speaking world. It enables researchers and non-technical users alike to examine both live and archived social media content, producing detailed visualizations and reports across various dimensions, including sentiment analysis, emotion analysis, propaganda detection, fact-checking, and hate speech detection. The platform also provides secure data-scraping capabilities through API keys for accessing public social media data. MARSAD's backend architecture integrates flexible document storage with structured data management, ensuring efficient processing of large and multimodal datasets. Its user-friendly frontend supports seamless data upload and interaction.

</details>


### [239] [DyFuLM: An Advanced Multimodal Framework for Sentiment Analysis](https://arxiv.org/abs/2512.01410)
*Ruohan Zhou,Jiachen Yuan,Churui Yang,Wenzheng Huang,Guoyan Zhang,Shiyao Wei,Jiazhen Hu,Ning Xin,Md Maruf Hasan*

Main category: cs.CL

TL;DR: DyFuLM 提出了一种用于情感分析的动态融合学习模型，该模型通过层次动态融合模块和受控特征聚合模块有效捕捉多模态文本的情感细微之处，实验结果表明其在粗粒度和细粒度情感分类上分别达到了 82.64% 和 68.48% 的准确度。


<details>
  <summary>Details</summary>
Motivation: 现有的情感计算方法在处理复杂的文本表达时，仍然面临着理解情绪的巨大挑战。DyFuLM 提出了一种新型的多模态框架，旨在捕捉深层次语义表示和细微的情感差异。

Method: DyFuLM 引入了两个关键组件：层次动态融合模块和受控特征聚合模块。层次动态融合模块能够自适应地集成多层特征，而受控特征聚合模块则调节跨层信息流以实现平衡的表示学习。

Result: DyFuLM 在多任务情感数据集上的实验结果表明，它在粗粒度和细粒度任务上分别取得了 82.64% 和 68.48% 的准确度，同时展示了最小的回归误差（MAE=0.0674，MSE=0.0082）和最高的 R^2系数，证实了其在情感表示和整体性能上的增强能力。

Conclusion: 实验证明，DyFuLM 在通过有效的层次特征融合来提高情感表示和整体性能方面具有显著的效果，每个模块的去功能化对分类精度的影响强烈证实了它们的贡献。

Abstract: Understanding sentiment in complex textual expressions remains a fundamental challenge in affective computing. To address this, we propose a Dynamic Fusion Learning Model (DyFuLM), a multimodal framework designed to capture both hierarchical semantic representations and fine-grained emotional nuances. DyFuLM introduces two key moodules: a Hierarchical Dynamic Fusion module that adaptively integrates multi-level features, and a Gated Feature Aggregation module that regulates cross-layer information ffow to achieve balanced representation learning. Comprehensive experiments on multi-task sentiment datasets demonstrate that DyFuLM achieves 82.64% coarse-grained and 68.48% fine-grained accuracy, yielding the lowest regression errors (MAE = 0.0674, MSE = 0.0082) and the highest R^2 coefficient of determination (R^2= 0.6903). Furthermore, the ablation study validates the effectiveness of each module in DyFuLM. When all modules are removed, the accuracy drops by 0.91% for coarse-grained and 0.68% for fine-grained tasks. Keeping only the gated fusion module causes decreases of 0.75% and 0.55%, while removing the dynamic loss mechanism results in drops of 0.78% and 0.26% for coarse-grained and fine-grained sentiment classification, respectively. These results demonstrate that each module contributes significantly to feature interaction and task balance. Overall, the experimental findings further validate that DyFuLM enhances sentiment representation and overall performance through effective hierarchical feature fusion.

</details>


### [240] [PromptBridge: Cross-Model Prompt Transfer for Large Language Models](https://arxiv.org/abs/2512.01420)
*Yaxuan Wang,Quan Liu,Zhenting Wang,Zichao Li,Wei Wei,Yang Liu,Yujia Bao*

Main category: cs.CL

TL;DR: 本文通过广泛的实证分析发现了模型漂移现象的普遍性和严重性，并介绍了PromptBridge框架，该框架能在模型切换时不依赖训练即可保持提示的有效性，从而实现跨模型提示迁移。


<details>
  <summary>Details</summary>
Motivation: LLMs的快速变化导致频繁的模型切换，而模型敏感性高的提示导致了迁移性能下降，这限制了LLMs的应用。在此背景下，作者引入了PromptBridge框架来解决这个问题。

Method: 通过构建PromptBridge框架，首先采用Model-Adaptive Reflective Prompt Evolution（MAP-RPE）方法优化源模型和目标模型的提示，然后学习跨模型提示映射，以支持模型间的无缝迁移。

Result: 在单智能体和多智能体场景下，PromptBridge在迁移精度上表现出持续的提升，同时减少了迁移过程中的工作量。

Conclusion: PromptBridge框架能够有效应对模型漂移问题，保持提示的有效性，从而促进跨模型的提示迁移，提高迁移效率。

Abstract: Large language models (LLMs) underpin applications in code generation, mathematical reasoning, and agent-based workflows. In practice, systems access LLMs via commercial APIs or open-source deployments, and the model landscape (e.g., GPT, Claude, Llama) evolves rapidly. This rapid evolution forces frequent model switches driven by capability, cost, deployment constraints, and privacy. Yet prompts are highly model-sensitive: reusing a prompt engineered for one model on another often yields substantially worse performance than a prompt optimized for the target model. We term this phenomenon Model Drifting. Through extensive empirical analysis across diverse LLM configurations, we show that model drifting is both common and severe. To address this challenge, we introduce PromptBridge, a training-free framework that preserves prompt effectiveness under model switches, enabling cross-model prompt transfer without costly per-task or per-model re-optimization. PromptBridge requires only a small set of alignment tasks for calibration. It first applies Model-Adaptive Reflective Prompt Evolution (MAP-RPE) to obtain task- and model-specific optimal prompts via iterative reflective refinement and quantitative evaluation. Using the resulting calibrated prompt pairs for the source and target models, PromptBridge learns a cross-model prompt mapping. At test time, i.e., for an unseen task, given a source-model prompt, this mapping directly produces an optimized prompt for the target model. Experiments in single-agent and multi-agent settings show that PromptBridge consistently improves downstream accuracy while reducing migration effort. The code will be available soon.

</details>


### [241] [MEGConformer: Conformer-Based MEG Decoder for Robust Speech and Phoneme Classification](https://arxiv.org/abs/2512.01443)
*Xabier de Zuazo,Ibon Saratxaga,Eva Navas*

Main category: cs.CL

TL;DR: 本文介绍了一种基于Conformer的解码器用于LibriBrain 2025 PNPL竞赛中的语音检测和音节分类任务。该方法通过轻量级的卷积投影层和特定任务的头部对紧凑型Conformer进行调整。改进措施包括针对MEG信号的SpecAugment增强、特定类别权重和动态分组加载器等，最终在两个任务上均获得了最佳成绩。


<details>
  <summary>Details</summary>
Motivation: 面对MEG信号的复杂性及其与传统语音信号的不同特性，为了提高MEG数据在语音检测和音节分类任务中的性能，本文提出了一种适应MEG信号的Conformer模型，以探索适用于MEG特征的增强策略，探索新的处理方法，并取得可喜的成果。

Method: 文章首先使用轻量级卷积投影层和任务特定头对紧凑型Conformer进行调整，进而探索了MEG特征的特定增强策略（如MEG方向的SpecAugment）。然后，针对Phoneme Classification任务，采用了逆平方根类别权重和动态分组加载器处理100样本平均数据。此外，还引入了简单的实例级归一化来缓解验证集上的分布偏移。所有这些改进策略使得该模型在两个任务上的表现超越了基线模型，并成功进入排行榜前十。

Result: 经过调整后，该模型在两个任务上取得了88.9%的语音检测分数和65.8%的音节分类分数，超越了基线模型，并且在排行榜中进入了前十名。

Conclusion: 该研究证明了针对MEG信号特性定制的Conformer模型能够显著提升语音检测和音节分类任务的效果，在LibriBrain 2025 PNPL竞赛中显示出良好的应用前景，也为未来相关领域的研究提供了参考价值。同时，提供了详细的文档、源代码和检查点，方便后续研究者继续优化和实验。

Abstract: We present Conformer-based decoders for the LibriBrain 2025 PNPL competition, targeting two foundational MEG tasks: Speech Detection and Phoneme Classification. Our approach adapts a compact Conformer to raw 306-channel MEG signals, with a lightweight convolutional projection layer and task-specific heads. For Speech Detection, a MEG-oriented SpecAugment provided a first exploration of MEG-specific augmentation. For Phoneme Classification, we used inverse-square-root class weighting and a dynamic grouping loader to handle 100-sample averaged examples. In addition, a simple instance-level normalization proved critical to mitigate distribution shifts on the holdout split. Using the official Standard track splits and F1-macro for model selection, our best systems achieved 88.9% (Speech) and 65.8% (Phoneme) on the leaderboard, surpassing the competition baselines and ranking within the top-10 in both tasks. For further implementation details, the technical documentation, source code, and checkpoints are available at https://github.com/neural2speech/libribrain-experiments.

</details>


### [242] [Enhancing BERT Fine-Tuning for Sentiment Analysis in Lower-Resourced Languages](https://arxiv.org/abs/2512.01460)
*Jozef Kubík,Marek Šuppa,Martin Takáč*

Main category: cs.CL

TL;DR: 该研究提出了在有限训练数据下使用结合聚类和主动学习调度的增强Fine-tuning管道，从而在斯洛伐克语、马耳他语、冰岛语和土耳其语上实现了最高达4个F1分数点的性能提升，同时节省了高达30%的标注成本，并改善了Fine-tuning的稳定性。


<details>
  <summary>Details</summary>
Motivation: 针对低资源语言，由于预训练成本高昂，研究更关注Fine-tuning阶段的改进。本文探讨结合聚类的主动学习（AL）方法和调度策略（Active Learning schedulers）如何在有限数据下提升模型性能。

Method: 本文建立了一种整合Fine-tuning、聚类和动态数据选择调度的管道，通过这些方法，系统地优化了模型在斯洛伐克语、马耳他语、冰岛语和土耳其语上的性能。

Result: 实验证实在Fine-tuning阶段使用聚类结合AL调度可以同时节省高达30%的标注成本，且性能提升可达4个F1分数点，并提高了Fine-tuning过程的稳定性。

Conclusion: 该研究证明了结合聚类和主动学习调度方法的有效性，能显著提升低资源语言模型的训练效率与性能。

Abstract: Limited data for low-resource languages typically yield weaker language models (LMs). Since pre-training is compute-intensive, it is more pragmatic to target improvements during fine-tuning. In this work, we examine the use of Active Learning (AL) methods augmented by structured data selection strategies which we term 'Active Learning schedulers', to boost the fine-tuning process with a limited amount of training data. We connect the AL to data clustering and propose an integrated fine-tuning pipeline that systematically combines AL, clustering, and dynamic data selection schedulers to enhance model's performance. Experiments in the Slovak, Maltese, Icelandic and Turkish languages show that the use of clustering during the fine-tuning phase together with AL scheduling can simultaneously produce annotation savings up to 30% and performance improvements up to four F1 score points, while also providing better fine-tuning stability.

</details>


### [243] [MCAT: Scaling Many-to-Many Speech-to-Text Translation with MLLMs to 70 Languages](https://arxiv.org/abs/2512.01512)
*Yexing Du,Kaiyuan Liu,Youcheng Pan,Bo Yang,Keqi Deng,Xie Chen,Yang Xiang,Ming Liu,Bin Qin,YaoWei Wang*

Main category: cs.CL

TL;DR: MCAT框架通过引入基于课程学习的数据扩展方法和优化的语音适配模块，扩展了多模态大语言模型在70种语言之间的双向翻译能力，同时提高了模型在长语音序列上的推理效率。


<details>
  <summary>Details</summary>
Motivation: 现有研究在S2TT任务上的局限性主要体现在语言覆盖范围有限和推理效率较低上，MCAT框架旨在解决这些问题。

Method: MCAT框架包含两部分创新：一是语言扩展方法，结合了课程学习和数据平衡策略；二是优化的语音适配模块，用于减少语音序列长度。实验在不同规模的MLLMs上进行。

Result: MCAT在FLEURS数据集上的70x69翻译方向上超过了最新的端到端模型，并提高了批量推理效率。该模型仅需要约100M的可训练参数和每种语言仅十小时的S2TT数据。

Conclusion: MCAT是为提高多模态大语言模型的S2TT能力和效率而设计的，模型已开源供进一步研究和使用。

Abstract: Multimodal Large Language Models (MLLMs) have achieved great success in Speech-to-Text Translation (S2TT) tasks. However, current research is constrained by two key challenges: language coverage and efficiency. Most of the popular S2TT datasets are substantially English-centric, which restricts the scaling-up of MLLMs' many-to-many translation capabilities. Moreover, the inference speed of MLLMs degrades dramatically when the speech is converted into long sequences (e.g., 750 tokens). To address these limitations, we propose a Multilingual Cost-effective Accelerated Speech-to-Text Translator (MCAT) framework, which includes two innovations. First, a language scaling method that leverages curriculum learning and a data balancing strategy is introduced to extend the language coverage supported by MLLMs to 70 languages and achieve mutual translation among these languages. Second, an optimized speech adapter module is designed to reduce the length of the speech sequence to only 30 tokens. Extensive experiments were conducted on MLLMs of different scales (9B and 27B). The experimental results demonstrate that MCAT not only surpasses state-of-the-art end-to-end models on the FLEURS dataset across 70x69 directions but also enhances batch inference efficiency. This is achieved with only ~100M trainable parameters and by using only 10 hours of S2TT data per language. Furthermore, we have released MCAT as open-source to promote the development of MLLMs for robust S2TT capabilities. The code and models are released at https://github.com/yxduir/m2m-70.

</details>


### [244] [Language Diversity: Evaluating Language Usage and AI Performance on African Languages in Digital Spaces](https://arxiv.org/abs/2512.01557)
*Edward Ajayi,Eudoxie Umwari,Mawuli Deku,Prosper Singadi,Jules Udahemuka,Bekalu Tadele,Chukuemeka Edeh*

Main category: cs.CL

TL;DR: 本研究探讨了非洲语言的数字代表性及其对当前语言检测工具的挑战，发现专业策划的新闻内容比对话平台数据更适合训练非洲语言的AI模型。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于分析非洲语言在社交媒体和新闻平台上的使用情况，以及这种分布对现有语言检测工具性能的影响，揭示不同数据源对语言模型训练效果的差异。

Method: 通过从subreddits和地方新闻获取数据，收集Yoruba、Kinyarwanda和Amharic三种语言的数据进行分析，对比不同数据源（如subreddits和地方新闻）下模型的表现。

Result: 分析表明，新闻数据提供了一种纯净的一语来源，而subreddits则充斥着大量的代码混用现象。现有的语言检测模型在纯净的新闻数据上表现出极高的准确性，但在混合语言的subreddits帖子上则表现不佳。

Conclusion: 研究得出结论，专业策划的新闻内容比对话平台更可靠、更有效，可以用于训练丰富的背景AI模型以提高对非洲语言检测的准确性。未来需要发展能够处理纯净和代码混用文本的语言模型，以提高对非洲语言检测的准确性。

Abstract: This study examines the digital representation of African languages and the challenges this presents for current language detection tools. We evaluate their performance on Yoruba, Kinyarwanda, and Amharic. While these languages are spoken by millions, their online usage on conversational platforms is often sparse, heavily influenced by English, and not representative of the authentic, monolingual conversations prevalent among native speakers. This lack of readily available authentic data online creates a challenge of scarcity of conversational data for training language models. To investigate this, data was collected from subreddits and local news sources for each language. The analysis showed a stark contrast between the two sources. Reddit data was minimal and characterized by heavy code-switching. Conversely, local news media offered a robust source of clean, monolingual language data, which also prompted more user engagement in the local language on the news publishers social media pages. Language detection models, including the specialized AfroLID and a general LLM, performed with near-perfect accuracy on the clean news data but struggled with the code-switched Reddit posts. The study concludes that professionally curated news content is a more reliable and effective source for training context-rich AI models for African languages than data from conversational platforms. It also highlights the need for future models that can process clean and code-switched text to improve the detection accuracy for African languages.

</details>


### [245] [MAC-SLU: Multi-Intent Automotive Cabin Spoken Language Understanding Benchmark](https://arxiv.org/abs/2512.01603)
*Yuezhang Peng,Chonghao Cai,Ziang Liu,Shuai Fan,Sheng Jiang,Hua Xu,Yuxin Liu,Qiguang Chen,Kele Xu,Yao Li,Sheng Wang,Libo Qin,Xie Chen*

Main category: cs.CL

TL;DR: 该研究提出了MAC-SLU，一个包含复杂多意图的真实语音数据的新语音理解和执行下游任务的数据集。通过MAC-SLU，对比了多种大型语言模型和大型音频语言模型在序列标注和端到端方法上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的SLU数据集缺乏多样性与复杂性，缺乏统一的基准来评估最新的大型语言模型（LLMs）和大型音频语言模型（LALMs）。因此，研究者旨在构造一个能够提升SLU任务难度的数据集，并进行基准测试。

Method: 研究者提出了一个名为MAC-SLU的新数据集，并基于此数据集对比了基于上下文学习、监督微调及端到端和管道方法的大型语言模型和大型音频语言模型的表现。

Result: 实验结果表明，LALMs在上下文学习情境下执行SLU任务具备潜力，但性能依然显著落后于监督微调方法。端到端LALMs实现表现接近管道方法，有效避免了语音识别错误传播。

Conclusion: 研究者建议继续探索大型语言模型和大型音频语言模型在SLU任务中的潜力，以及在端到端设置下的优化可能。

Abstract: Spoken Language Understanding (SLU), which aims to extract user semantics to execute downstream tasks, is a crucial component of task-oriented dialog systems. Existing SLU datasets generally lack sufficient diversity and complexity, and there is an absence of a unified benchmark for the latest Large Language Models (LLMs) and Large Audio Language Models (LALMs). This work introduces MAC-SLU, a novel Multi-Intent Automotive Cabin Spoken Language Understanding Dataset, which increases the difficulty of the SLU task by incorporating authentic and complex multi-intent data. Based on MAC-SLU, we conducted a comprehensive benchmark of leading open-source LLMs and LALMs, covering methods like in-context learning, supervised fine-tuning (SFT), and end-to-end (E2E) and pipeline paradigms. Our experiments show that while LLMs and LALMs have the potential to complete SLU tasks through in-context learning, their performance still lags significantly behind SFT. Meanwhile, E2E LALMs demonstrate performance comparable to pipeline approaches and effectively avoid error propagation from speech recognition. Code\footnote{https://github.com/Gatsby-web/MAC\_SLU} and datasets\footnote{huggingface.co/datasets/Gatsby1984/MAC\_SLU} are released publicly.

</details>


### [246] [Learning the Boundary of Solvability: Aligning LLMs to Detect Unsolvable Problems](https://arxiv.org/abs/2512.01661)
*Dengyun Peng,Qiguang Chen,Bofei Liu,Jiannan Guan,Libo Qin,Zheng Yan,Jinhao Liu,Jianshu Zhang,Wanxiang Che*

Main category: cs.CL

TL;DR: 该研究提出了UnsolvableQA和UnsolvableRL，旨在通过构建可解与不可解问题的配对数据集，并利用强化学习框架来区分逻辑矛盾和能力限制，从而提高语言模型的可靠性，减少幻觉和过度自信。


<details>
  <summary>Details</summary>
Motivation: 当前的语言模型在面对逻辑矛盾和能力限制时容易产生幻觉和过度自信，本研究旨在通过构建UnsolvableQA数据集和UnsolvableRL框架，提高模型区分能力和可靠性的能力。

Method: 研究采用了程序化生成逻辑谜题和新颖的“逆向构建”方法注入矛盾推理链来构建UnsolvableQA数据集。基于该数据集，研究引入了UnsolvableRL，一个结合准确性、不可解性和难度的强化学习框架。

Result: 研究结果显示，该方法在不可解性检测上几乎达到了完美，并且在可解任务上的准确性也有提高。此外，研究还发现了能力崩溃现象，表明明确接触不可解数据对防止模型系统性过度自信至关重要。

Conclusion: 该研究通过UnsolvableQA和UnsolvableRL的研究方法，显著提高了语言模型的可靠性，有助于减少模型的幻觉和过度自信现象。

Abstract: Ensuring LLM reliability requires not only solving complex problems but also recognizing when a problem is unsolvable. Current models often struggle to distinguish objective unsolvability (inherent contradictions in the problem) from subjective capability limitations (problems beyond the model's competence), which leads to hallucinations and overconfidence. To address this, we propose UnsolvableQA and UnsolvableRL to solve feasible problems, detect inherent contradictions, and prudently refuse tasks beyond capability. Specifically, we construct UnsolvableQA, a dataset of paired solvable and unsolvable instances derived via a dual-track methodology: programmatic generation for logic puzzles and a novel "Reverse Construction" method that injects contradictions into valid reasoning chains for mathematics. Building on this dataset, we introduce UnsolvableRL, a reinforcement learning framework with three reward components jointly accounting for accuracy, unsolvability, and difficulty. Empirical results show that our approach achieves near-perfect unsolvability detection while also improving accuracy on solvable tasks. Crucially, we identify Capability Collapse, demonstrating that explicit exposure to unsolvable data is indispensable for preventing models from becoming systematically overconfident. Our code and data are available at https://github.com/sfasfaffa/unsolvableQA.

</details>


### [247] [Self-Supervised Borrowing Detection on Multilingual Wordlists](https://arxiv.org/abs/2512.01713)
*Tim Wientzek*

Main category: cs.CL

TL;DR: 本文提出了一种完全自监督的方法来检测多语言词汇表中的借用词，结合了基于全局对应模型的PMI相似性和轻量级的基于音素特征向量的对比组件，无需标注数据即可自动选择决策阈值。实验表明该方法能够改进现有的字符串相似度度量，并在某些情况下优于监督基线。


<details>
  <summary>Details</summary>
Motivation: 当前的字符串相似度度量方法在检测多语言词汇表中的借用词方面存在不足，需要改善。

Method: 该方法结合了PMI相似性和轻量级的基于音素特征向量的对比组件，并通过自动选择决策阈值而不需标注数据来实现。

Result: PMI在一定程度上比现有的字符串相似度度量方法（如NED和SCA）提高了表现，在某些情况下，结合相似性度量与监督基线相当或更好。

Conclusion: 该方法适用于不同规模的数据集，无需手动监督，并提供了一个命令行工具供研究人员进行自己的研究。

Abstract: This paper presents a fully self-supervised approach to borrowing detection in multilingual wordlists. The method combines two sources of information: PMI similarities based on a global correspondence model and a lightweight contrastive component trained on phonetic feature vectors. It further includes an automatic procedure for selecting decision thresholds without requiring labeled data. Experiments on benchmark datasets show that PMI alone already improves over existing string similarity measures such as NED and SCA, and that the combined similarity performs on par with or better than supervised baselines. An ablation study highlights the importance of character encoding, temperature settings and augmentation strategies. The approach scales to datasets of different sizes, works without manual supervision and is provided with a command-line tool that allows researchers to conduct their own studies.

</details>


### [248] [Beware of Reasoning Overconfidence: Pitfalls in the Reasoning Process for Multi-solution Tasks](https://arxiv.org/abs/2512.01725)
*Jiannan Guan,Qiguang Chen,Libo Qin,Dengyun Peng,Jinhao Liu,Liangyu Huo,Jian Xie,Wanxiang Che*

Main category: cs.CL

TL;DR: 该研究通过MuSoBench基准测试发现，LLMs在多解任务中表现出过度自信的问题，而长链推理（Long-CoT）方法通过迭代探索和自我反思减轻了这一问题。研究提出了认知刚性假设，并强调需要转向全面探索的评估。


<details>
  <summary>Details</summary>
Motivation: LLMs在单一答案任务中表现出色，但在需要生成全面和多样化答案的多解任务中表现不佳。研究旨在探讨原因并提供改进方法。

Method: 研究设计了一个新的多解问题基准MuSoBench。通过实验比较了短链思考（Short-CoT）和长链思考（Long-CoT）这两种提示方法。研究还进行了注意力-熵分析以进一步探究原因。

Result: 实验结果显示，短链思考方法表现出明显的过度自信倾向，而长链思考方法通过迭代探索和自我反思减轻了这一问题。注意力-熵分析为认知刚性假设提供了初步支持。

Conclusion: 该研究提出了评估LLM推理完整性的工具，并强调了需要转向全面探索的评估方向。

Abstract: Large Language Models (LLMs) excel in reasoning tasks requiring a single correct answer, but they perform poorly in multi-solution tasks that require generating comprehensive and diverse answers. We attribute this limitation to \textbf{reasoning overconfidence}: a tendency to express undue certainty in an incomplete solution set. To examine the effect, we introduce \textit{MuSoBench}, a benchmark of multi-solution problems. Experiments show that the conventional short chain-of-thought (Short-CoT) prompting paradigm exhibits pronounced overconfidence, whereas the emerging long chain-of-thought (Long-CoT) approach mitigates it through iterative exploration and self-reflection. We further characterise observable behaviours and influential factors. To probe the underlying cause, we propose the \textbf{cognitive-rigidity hypothesis}, which posits that overconfidence arises when the reasoning process prematurely converges on a narrow set of thought paths. An attention-entropy analysis offers preliminary support for this view. These findings provide tools for assessing the completeness of LLM reasoning and highlight the need to move evaluation beyond single-answer accuracy toward comprehensive exploration.

</details>


### [249] [Reasoning About the Unsaid: Misinformation Detection with Omission-Aware Graph Inference](https://arxiv.org/abs/2512.01728)
*Zhengjia Wang,Danding Wang,Qiang Sheng,Jiaying Wu,Juan Cao*

Main category: cs.CL

TL;DR: 该论文提出了OmiGraph框架，这是一种针对信息欺诈检测的认知缺失aware方法，旨在揭示被隐含忽略的重要信息，从而提高欺诈识别的准确性和公平性。


<details>
  <summary>Details</summary>
Motivation: 当前的信息欺诈检测研究主要关注明确制造虚假信息的情况，而忽视了通过省略重要信息进行误导的方法。这种方法可能在表面上看似完整，但可能引导读者得出错误的结论。因此，论文试图填补这一研究空白。

Method: OmiGraph框架利用上下文环境构建针对目标新闻的认知缺失graph，通过关系建模来识别上下文依赖和动态的省略意图，并通过消息传递和聚集机制获取综合的缺失关系表示以识别欺诈行为。

Result: 实验结果显示，通过考虑缺失视角，该方法在两个大规模基准数据集上分别实现了5.4%的F1分数和5.3%的ACC分数的提升。

Conclusion: OmiGraph框架为信息欺诈检测提供了一种新的认知缺失aware的方法，能够有效识别隐含被忽略的重要信息，从而提高欺诈识别的准确性。

Abstract: This paper investigates the detection of misinformation, which deceives readers by explicitly fabricating misleading content or implicitly omitting important information necessary for informed judgment. While the former has been extensively studied, omission-based deception remains largely overlooked, even though it can subtly guide readers toward false conclusions under the illusion of completeness. To pioneer in this direction, this paper presents OmiGraph, the first omission-aware framework for misinformation detection. Specifically, OmiGraph constructs an omission-aware graph for the target news by utilizing a contextual environment that captures complementary perspectives of the same event, thereby surfacing potentially omitted contents. Based on this graph, omission-oriented relation modeling is then proposed to identify the internal contextual dependencies, as well as the dynamic omission intents, formulating a comprehensive omission relation representation. Finally, to extract omission patterns for detection, OmiGraph introduces omission-aware message-passing and aggregation that establishes holistic deception perception by integrating the omission contents and relations. Experiments show that, by considering the omission perspective, our approach attains remarkable performance, achieving average improvements of +5.4% F1 and +5.3% ACC on two large-scale benchmarks.

</details>


### [250] [Beyond SFT: Reinforcement Learning for Safer Large Reasoning Models with Better Reasoning Ability](https://arxiv.org/abs/2512.01848)
*Jinghan Jia,Nathalie Baracaldo,Sijia Liu*

Main category: cs.CL

TL;DR: 该研究通过引入强化学习（RL）优化大推理模型（LRMs）的安全性，发现与监督微调（SFT）相比，RL能更稳定地提升安全性并在多种模型家族和基准测试中保持推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的安全对齐方法主要依赖于监督微调（SFT），这种方法在提升安全性方面表现不一致、降低推理能力并且在不同模型家族间泛化能力差。因此，研究团队致力于寻找一种新的优化框架来提升LRMs的安全性。

Method: 研究团队采用了强化学习（RL）作为安全对齐的方法，利用奖励反馈直接优化模型策略，从而实现更适应和稳定的安全性对齐。

Result: 在多个模型家族和基准测试中的广泛实验表明，RL能够取得更强且更一致的安全性提升同时保持推理能力。进一步分析推理动态和令牌级熵揭示了RL能够抑制不安全的探索性推理同时保留推理深度，从而增强了推理过程的安全性和可靠性。

Conclusion: 与SFT相比，RL方法在提升大推理模型（LRMs）安全性方面表现更优，并且能够保持推理能力。

Abstract: Large reasoning models (LRMs) extend large language models by generating explicit chain-of-thought (CoT) reasoning, significantly improving mathematical and logical problem solving. However, this explicit reasoning process also introduces new safety risks, as unsafe behaviors often emerge within intermediate reasoning trajectories, even when final answers appear harmless. Existing safety alignment approaches primarily rely on supervised fine-tuning (SFT) over safety-oriented long CoT datasets. While intuitive, we find that SFT produces inconsistent safety improvements, degrades reasoning ability, and generalizes poorly across model families. These limitations suggest that purely supervised approaches are insufficient for robust safety alignment in LRMs. To address this, we investigate reinforcement learning (RL) as a complementary optimization framework for LRM safety training. Unlike SFT, RL directly optimizes model policies with reward feedback, enabling more adaptive and stable alignment. Extensive experiments across multiple model families and benchmarks show that RL achieves stronger and more consistent safety gains while maintaining reasoning competence. Further analysis of reflection dynamics and token-level entropy reveals that RL suppresses unsafe exploratory reasoning while preserving reflective depth, leading to safer and more reliable reasoning processes.

</details>


### [251] [BHRAM-IL: A Benchmark for Hallucination Recognition and Assessment in Multiple Indian Languages](https://arxiv.org/abs/2512.01852)
*Hrishikesh Terdalkar,Kirtan Bhojani,Aryan Dongare,Omm Aditya Behera*

Main category: cs.CL

TL;DR: 本文介绍了针对多种印度语言的基准BHRAM-IL，涵盖21种检测类和类别特定的评估指标，展示了这一基准在跨语言谬误检测中的应用价值。


<details>
  <summary>Details</summary>
Motivation: 近年来，大型语言模型在多语言应用中的部署越来越普遍，但它们偶尔会产生看似合理但实际上是不正确的或误导性的输出（称为幻觉）。本文旨在填补英语以外的资源不足的印度语言幻觉检测研究空白。

Method: 收集了36,047个精心策划的问题，涉及九个类别（包括事实性、数值、推理和语言任务），对14个最先进的多语言LLM进行评估。

Result: 评估结果显示基准的整体得分为0.23，语言修正模糊分为0.385，展现了该基准在幻觉导向评估中的有效性。

Conclusion: BHRAM-IL数据集和生成、评估代码可在GitHub和HuggingFace上获取，以支持未来关于多语言幻觉检测和缓解的研究。

Abstract: Large language models (LLMs) are increasingly deployed in multilingual applications but often generate plausible yet incorrect or misleading outputs, known as hallucinations. While hallucination detection has been studied extensively in English, under-resourced Indian languages remain largely unexplored. We present BHRAM-IL, a benchmark for hallucination recognition and assessment in multiple Indian languages, covering Hindi, Gujarati, Marathi, Odia, along with English. The benchmark comprises 36,047 curated questions across nine categories spanning factual, numerical, reasoning, and linguistic tasks. We evaluate 14 state-of-the-art multilingual LLMs on a benchmark subset of 10,265 questions, analyzing cross-lingual and factual hallucinations across languages, models, scales, categories, and domains using category-specific metrics normalized to (0,1) range. Aggregation over all categories and models yields a primary score of 0.23 and a language-corrected fuzzy score of 0.385, demonstrating the usefulness of BHRAM-IL for hallucination-focused evaluation. The dataset, and the code for generation and evaluation are available on GitHub (https://github.com/sambhashana/BHRAM-IL/) and HuggingFace (https://huggingface.co/datasets/sambhashana/BHRAM-IL/) to support future research in multilingual hallucination detection and mitigation.

</details>


### [252] [Cross-Lingual Interleaving for Speech Language Models](https://arxiv.org/abs/2512.01865)
*Adel Moumen,Guangzhi Sun,Philip C. Woodland*

Main category: cs.CL

TL;DR: 该研究提出了跨语言交错方法，通过在不同语言之间混合语音标记来训练模型，同时发布了EN-FR训练数据集TinyStories及相关任务基准，旨在提高多语言语音模型在理解与跨语言交流方面的性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中在英语上，缺乏跨语言评估基准和训练数据使得跨语言学习困难。该研究旨在为资源有限的语言提供一种新的训练方法，扩展自然语言处理技术的应用。

Method: 研究采用了跨语言交错方法，在不同语言的语音标记中进行交错，而无需文本监督。同时，研究者还创建了EN-FR的数据集TinyStories，并基于此数据集构建了EN-FR的口语StoryCloze和TopicCloze基准。

Result: 在360M和1B大小的语音模型下，该方法提高了单语言语义准确性，支持了跨语言续写，并加强了跨语言隐藏状态对齐。结果表明，跨语言交错是一种简单且具备扩展性的多语言语音模型构建方法。

Conclusion: 该研究为开发理解并跨语言交流的多语言语音模型提供了一种新的简单且可扩展的方法，并计划将所有资源开源，以支持可重复研究。

Abstract: Spoken Language Models (SLMs) aim to learn linguistic competence directly from speech using discrete units, widening access to Natural Language Processing (NLP) technologies for languages with limited written resources. However, progress has been largely English-centric due to scarce spoken evaluation benchmarks and training data, making cross-lingual learning difficult. We present a cross-lingual interleaving method that mixes speech tokens across languages without textual supervision. We also release an EN-FR training dataset, TinyStories (~42k hours), together with EN-FR spoken StoryCloze and TopicCloze benchmarks for cross-lingual semantic evaluation, both synthetically generated using GPT-4. On 360M and 1B SLMs under matched training-token budgets, interleaving improves monolingual semantic accuracy, enables robust cross-lingual continuation, and strengthens cross-lingual hidden-state alignment. Taken together, these results indicate that cross-lingual interleaving is a simple, scalable route to building multilingual SLMs that understand and converse across languages. All resources will be made open-source to support reproducibility.

</details>


### [253] [Exploring Human Perceptions of AI Responses: Insights from a Mixed-Methods Study on Risk Mitigation in Generative Models](https://arxiv.org/abs/2512.01892)
*Heloisa Candello,Muneeza Azmat,Uma Sushmitha Gunturi,Raya Horesh,Rogerio Abreu de Paula,Heloisa Pimentel,Marcelo Carpinette Grave,Aminat Adebiyi,Tiago Machado,Maysa Malfiza Garcia de Macedo*

Main category: cs.CL

TL;DR: 研究探讨了在生成式AI普及背景下AI生成内容的可信度、公平性、有害内容去除能力和相关性。通过一项针对处理前后内容的评估实验发现，参与者语言背景、AI工作经验和注释熟悉度显著影响评价结果，且参与者对于语言表达的细微差异非常敏感。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI的迅速发展，了解人类对生成内容的感知变得至关重要。特别是在应对潜在有害内容生成方面，现有的防护措施的人类接受度尚不清楚。

Method: 本研究采用混合方法实验，通过一个内省设计，57名参与者对两组内容进行评估：带防护措施的有害内容和仅有防护措施的内容。

Result: 研究结果显示，参与者对语言和上下文的细微差异非常敏感，对于语法错误特别挑剔，而对于保留的语义上下文则给予较高评价。进一步，研究团队提出了新的培训和评估防护策略的指标，并为未来的人机交互研究提供了见解。

Conclusion: 本研究揭示了人类参与者在评估生成式AI生成内容时的偏好和标准，并提出了改进防护策略的方向。

Abstract: With the rapid uptake of generative AI, investigating human perceptions of generated responses has become crucial. A major challenge is their `aptitude' for hallucinating and generating harmful contents. Despite major efforts for implementing guardrails, human perceptions of these mitigation strategies are largely unknown. We conducted a mixed-method experiment for evaluating the responses of a mitigation strategy across multiple-dimensions: faithfulness, fairness, harm-removal capacity, and relevance. In a within-subject study design, 57 participants assessed the responses under two conditions: harmful response plus its mitigation and solely mitigated response. Results revealed that participants' native language, AI work experience, and annotation familiarity significantly influenced evaluations. Participants showed high sensitivity to linguistic and contextual attributes, penalizing minor grammar errors while rewarding preserved semantic contexts. This contrasts with how language is often treated in the quantitative evaluation of LLMs. We also introduced new metrics for training and evaluating mitigation strategies and insights for human-AI evaluation studies.

</details>


### [254] [The Art of Scaling Test-Time Compute for Large Language Models](https://arxiv.org/abs/2512.02008)
*Aradhye Agarwal,Ayan Sengupta,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: 本文研究了测试时缩放（TTS）策略对大型语言模型推理性能的影响，发现没有一种TTS策略适用于所有情况，模型类型和问题难度对性能有显著影响，提出了根据问题难度、模型类型和计算预算选择最佳TTS策略的实用指南。


<details>
  <summary>Details</summary>
Motivation: 鉴于大规模语言模型在推理中的性能问题，本文旨在通过系统研究和比较不同TTS策略，更好地理解其与模型类型和问题难度的关系，以提高推理效率。

Method: 通过使用八个开源大型语言模型（参数量从7B到235B）在四个推理数据集上生成超过300亿个令牌来系统研究不同TTS策略。

Result: 研究结果表明，没有一种TTS策略在所有场景下都占优；推理模型在不同问题难度和轨迹长度下表现出不同的轨迹质量模式；对于给定模型类型，TTS性能随计算预算的增加而单调增加。

Conclusion: 根据研究结果，本文提供了一种实用的方法，考虑问题难度、模型类型和计算预算来选择最佳的TTS策略，为有效的推理时间缩放提供指导建议。

Abstract: Test-time scaling (TTS) -- the dynamic allocation of compute during inference -- is a promising direction for improving reasoning in large language models (LLMs). However, a systematic comparison of well-known TTS strategies under identical conditions is missing, and the influence of model type and problem difficulty on performance remains unclear. To address these gaps, we conduct the first large-scale study of TTS, spanning over thirty billion tokens generated using eight open-source LLMs (7B to 235B parameters), across four reasoning datasets. We observe three consistent trends: (1) no single TTS strategy universally dominates; (2) reasoning models exhibit distinct trace-quality patterns across problem difficulty and trace length, forming short-horizon and long-horizon categories; and (3) for a given model type, the optimal TTS performance scales monotonically with compute budget. Based on these insights, we provide a practical recipe for selecting the best TTS strategy, considering problem difficulty, model type, and compute budget, providing a practical guide to effective inference-time scaling.

</details>


### [255] [Four Over Six: More Accurate NVFP4 Quantization with Adaptive Block Scaling](https://arxiv.org/abs/2512.02010)
*Jack Cook,Junxian Guo,Guangxuan Xiao,Yujun Lin,Song Han*

Main category: cs.CL

TL;DR: 该研究提出了一种新的量化算法4/6，旨在改善NVFP4格式在低精度计算中的性能，特别是在训练过程中减少梯度消失问题，并提高推理的准确性。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的增长，低精度数值格式如NVFP4因其计算速度和内存优势越来越受欢迎。然而，为了加速NVFP4的计算，所有矩阵乘法操作（权重和激活函数在前向传播，权重、激活函数和梯度在后向传播）都必须被量化为NVFP4，这通常会导致训练发散和推理性能下降。

Method: 4/6算法通过评估每个值块的两个潜在比例因子来改进NVFP4量化算法。研究还发现，对于一些值块，缩放为较小的FP4值可以使可表示的值分布更加均匀，从而更好地表示接近最大值的值。该方法可以在NVIDIA Blackwell GPU上高效实现。

Result: 实验结果显示，4/6算法可以防止训练发散，在与当前最先进的NVFP4训练食谱相比时，使训练损失与BF16更加接近。同时，4/6算法可以轻松整合到多种后训练量化方法中，并且通常能提高下游准确性。

Conclusion: 该工作为使用NVFP4训练和部署模型提供了新的方法，并希望推动后续研究。

Abstract: As large language models have grown larger, low-precision numerical formats such as NVFP4 have become increasingly popular due to the speed and memory benefits they provide. However, to accelerate computation with NVFP4, all matrix multiplication operands--weights and activations in the forward pass, and weights, activations, and gradients in the backward pass--must be quantized to NVFP4, often leading to divergence during training and performance degradation during inference. NVFP4 by evaluating multiple potential scale factors for each block of values. To address this issue, in this work we introduce Four Over Six (4/6), a modification to the NVFP4 quantization algorithm that evaluates two potential scale factors for each block of values. Unlike integer formats, floating-point formats such as FP4 have the most quantization error on near-maximal values in each block, which we find to be primarily responsible for downstream performance degradation. We find that for some blocks, scaling to smaller FP4 values makes the distribution of representable values more uniform, improving representation of near-maximal values. Importantly, 4/6 can be implemented efficiently on NVIDIA Blackwell GPUs, making it viable to use while training LLMs with NVFP4. In pre-training experiments with transformer and hybrid model architectures, we find that 4/6 prevents divergence in several cases, bringing training loss significantly closer to BF16 compared to models trained with current state-of-the-art NVFP4 training recipes. We also find that 4/6 can be easily incorporated into many different post-training quantization methods and generally improves downstream accuracy. We hope this inspires future work in training and deploying models with NVFP4.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [256] [Chunking Strategies for Multimodal AI Systems](https://arxiv.org/abs/2512.00185)
*Shashanka B R,Mohith Charan R,Seema Banu F*

Main category: cs.AI

TL;DR: 该综述旨在为多模态分块策略提供技术基础和设计空间，涉及文本、图像、音频、视频及跨模态数据，并分析了固定大小标记窗口、递归文本分割、物体中心视觉分块等方法，探讨了粒度-上下文权衡及跨模态对齐等问题。


<details>
  <summary>Details</summary>
Motivation: 为了促进多模态AI系统的开发，为研究人员和实践者提供技术基础和设计空间，解决在基于不同模态的数据处理中遇到的困难，如粒度-上下文权衡和跨模态对齐等问题。

Method: 综述论文通过对固定大小标记窗口、递归文本分割、物体中心视觉分块等策略进行技术分析和比较，探讨了它们的优缺点和应用挑战。

Result: 该论文提供了全面的多模态分块策略分类，并分析了文本、图像、音频、视频和跨模态数据的分块方法。

Conclusion: 综述还探讨了跨模态分块的新兴策略，并提出了适应性、学习导向和任务特定的方法作为未来研究的方向，同时强调了一些开放问题和挑战。

Abstract: Our goal is to consolidate the landscape of multimodal chunking strategies, providing researchers and practitioners with a technical foundation and design space for developing more effective and efficient multimodal AI systems. This survey paves the way for innovations in robust chunking pipelines that scale with modality complexity, enhance processing accuracy, and improve generative coherence in real-world applications. This survey provides a comprehensive taxonomy and technical analysis of chunking strategies tailored for each modality: text, images, audio, video, and cross-modal data. We examine classical and modern approaches such as fixed-size token windowing, recursive text splitting, object-centric visual chunking, silence-based audio segmentation, and scene detection in videos. Each approach is analyzed in terms of its underlying methodology, supporting tools (e.g., LangChain, Detectron2, PySceneDetect), benefits, and challenges, particularly those related to granularity-context trade-offs and multimodal alignment. Furthermore, we explore emerging cross-modal chunking strategies that aim to preserve alignment and semantic consistency across disparate data types [4]. We also include comparative insights, highlight open problems such as asynchronous information density and noisy alignment signals, and identify opportunities for future research in adaptive, learning-based, and task-specific chunking.

</details>


### [257] [A Rosetta Stone for AI Benchmarks](https://arxiv.org/abs/2512.00193)
*Anson Ho,Jean-Stanislas Denain,David Atanasov,Samuel Albanie,Rohin Shah*

Main category: cs.AI

TL;DR: 通过建立一个统计框架，将不同基准测试连接起来，统一模型能力和基准难度的量度标准，该框架能够在不同时间和能力范围内比较模型的发展，无需假设能力随时间和训练计算量的变化。


<details>
  <summary>Details</summary>
Motivation: 当前大部分人工智能基准在引入后几年甚至几个月内就会饱和，使得研究长期发展趋势变得困难。因此，本文旨在提供一个统计框架来解决这一问题。

Method: 本文构建了一个统计框架，将不同基准测试关联起来，使得模型能力和基准难度可以在单一数量级上进行比较。该方法无需假设能力随时间或训练计算量的变化。

Result: 该框架被应用于三个应用场景：1.测量AI进展的速度，并预测未来AI的能力；2.估计算法效率改进的速度，发现改进率更高，但与先前工作一致；3.检测AI进步的快速加速。

Conclusion: 该统计框架能够有效解决当前基准测试饱和问题，为研究AI长期发展趋势提供了新的方法和工具。

Abstract: Most AI benchmarks saturate within years or even months after they are introduced, making it hard to study long-run trends in AI capabilities. To address this challenge, we build a statistical framework that stitches benchmarks together, putting model capabilities and benchmark difficulties on a single numerical scale. This acts as a "Rosetta Stone", allowing us to compare models across a wide range of abilities and time, even if they are not evaluated on the same benchmarks. Moreover, this works without assuming how capabilities evolve across time or with training compute. We demonstrate three applications of this framework. First, we use it to measure the speed of AI progress over time, and to forecast future AI capabilities. Second, we estimate the rate of improvements in algorithmic efficiency, finding estimates that are higher, but broadly consistent with prior work. Finally, we find that our approach can be used to detect rapid accelerations in AI progress.

</details>


### [258] [Reasoning Under Pressure: How do Training Incentives Influence Chain-of-Thought Monitorability?](https://arxiv.org/abs/2512.00218)
*Matt MacDermott,Qiyao Wei,Rada Djoneva,Francis Rhys Ward*

Main category: cs.AI

TL;DR: 该研究通过引入新的可监控性度量方法考察了不同训练激励对推理模型可监控性的影响。尽管常用的激励措施（如长度惩罚和KL正则化）未发现具有一致效果的证据，但对抗优化会降低监控性能，而直接优化可监控性并不能可靠地提升效果。


<details>
  <summary>Details</summary>
Motivation: 开发能够理解并监控AI系统决策过程的技术，可提高系统的安全性。研究探讨了不同训练激励对推理模型可被监控影响的动机是，为了通过具体分析模型训练过程中的激励因素，来改善AI系统的透明度和安全性。

Method: 研究团队通过引入一个新的可监控性测量方法，研究不同训练激励对推理模型的影响。该方法评估模型在给定推理陈述的条件下，监控者能够预测关键潜在变量的能力。研究进一步通过理论上和实验上验证了不同激励措施对于模型可监控性的影响。

Result: 研究结果显示，长度惩罚和KL正则化等常见激励措施并未显示出对模型可监控性具有持续影响的显著性证据；而对抗优化能够降低监控性能；直接优化可监控性本身，并没有可靠地提升可监控性。

Conclusion: 研究表明，不同的训练激励对提升模型可监控性的效果并不尽相同。对抗优化可能并非理想的激励策略，而调整激励策略以直接优化可监控性可以更为实际地实现提高模型可监控性的目标。

Abstract: AI systems that output their reasoning in natural language offer an opportunity for safety -- we can \emph{monitor} their chain of thought (CoT) for undesirable reasoning, such as the pursuit of harmful objectives. However, the extent to which CoT faithfully reflects the underlying reasoning process, and hence the extent to which it can be usefully monitored, may be influenced by certain aspects of training. We investigate how different \emph{training incentives}, applied to a reasoning model, affect its monitorability. We introduce a novel methodology for measuring monitorability according to whether a monitor can predict a key latent variable using the model's reasoning. When controlling for accuracy, we do not find evidence for consistent effects from commonly used incentives (length penalties and KL regularisation), but we find that adversarial optimisation (penalising monitor accuracy) degrades monitor performance, while direct optimisation for monitorability does not reliably lead to improvements. Our code is available at https://github.com/QiyaoWei/reasoning-under-pressure.

</details>


### [259] [Trification: A Comprehensive Tree-based Strategy Planner and Structural Verification for Fact-Checking](https://arxiv.org/abs/2512.00267)
*Anab Maulana Barik,Shou Ziyi,Yang Kaiwen,Yang Qi,Shen Xin*

Main category: cs.AI

TL;DR: 本文提出了一种名为Trification的新自动事实核查框架，通过生成全面的验证动作确保覆盖完整声明，并将这些动作构建成依赖图来建模动作之间的逻辑互动。实验结果表明，该框架显著提高了事实核查的准确性。


<details>
  <summary>Details</summary>
Motivation: 当前的事实核查方法往往未能验证声明中的每个组成部分，并且缺乏结构化的框架来逻辑地连接子任务的结果以进行最终预测。为了克服这些限制，本文提出了Trification框架。

Method: Trification框架首先生成全面的验证动作确保覆盖完整声明，然后将这些动作构建成一个依赖图以建模动作之间的逻辑互动。此图还可以动态修改，使系统能够调整其验证策略。

Result: 在两个具有挑战性的基准测试上的实验结果表明，该Trification框架显著提高了自动事实核查系统的准确性。

Conclusion: Trification框架为改进当前的自动事实核查系统提供了新的解决方案，并推动了这一领域的进展。

Abstract: Technological advancement allows information to be shared in just a single click, which has enabled the rapid spread of false information. This makes automated fact-checking system necessary to ensure the safety and integrity of our online media ecosystem. Previous methods have demonstrated the effectiveness of decomposing the claim into simpler sub-tasks and utilizing LLM-based multi agent system to execute them. However, those models faces two limitations: they often fail to verify every component in the claim and lack of structured framework to logically connect the results of sub-tasks for a final prediction. In this work, we propose a novel automated fact-checking framework called Trification. Our framework begins by generating a comprehensive set of verification actions to ensure complete coverage of the claim. It then structured these actions into a dependency graph to model the logical interaction between actions. Furthermore, the graph can be dynamically modified, allowing the system to adapt its verification strategy. Experimental results on two challenging benchmarks demonstrate that our framework significantly enhances fact-checking accuracy, thereby advancing current state-of-the-art in automated fact-checking system.

</details>


### [260] [CogEvo-Edu: Cognitive Evolution Educational Multi-Agent Collaborative System](https://arxiv.org/abs/2512.00331)
*Yefeng Wu,Yuchen Song,Yecheng Zhao,Ling Wu,Shan Wan*

Main category: cs.AI

TL;DR: 介绍了CogEvo-Edu系统，这是一个通过层次结构的教育多智能体系统，它通过认知感知层、知识演化层和元控制层来提高STEM学习辅导的效果。


<details>
  <summary>Details</summary>
Motivation: 当前的大型语言模型在STEM教育中的应用存在一些局限性，主要表现在单向信息传递、缺乏长期学生模型建立和知识管理能力不足等方面。因此，提出了一种认知演化教育系统（CogEvo-Edu），旨在通过耦合认知、记忆和控制的过程来改进教育辅导的效果。

Method: CogEvo-Edu系统包括认知感知层（CPL）、知识演化层（KEL）和元控制层（MCL）。CPL负责维护学生的双重记忆，进行风险权重的合并，从而构建结构化的、自纠错的学生资料。KEL为每个知识片段分配时空价值以驱动激活、语义压缩和遗忘过程。MCL将教学视为分层序列决策过程，并使用双重内部-外部循环来精细调整CPL和KEL的超参数。

Result: 构建了一个针对DSP辅导的垂直基准（DSP-EduBench），并使用了LLM作为裁判的多模型系统。结果表明，CogEvo-Edu显著提高了辅导质量，所有六个指标都优于静态RAG、简单记忆和单智能体变体。

Conclusion: CogEvo-Edu系统展示了联合演化学生模型、知识库和教学策略的价值。

Abstract: Large language models (LLMs) are increasingly deployed as conversational tutors in STEM education, yet most systems still rely on a single LLM with a static retrieval-augmented generation (RAG) pipeline over course materials. This design struggles in complex domains such as digital signal processing (DSP), where tutors must maintain coherent long-term student models, manage heterogeneous knowledge bases, and adapt teaching strategies over extended interactions. We argue that retrieval, memory, and control should be treated as a coupled cognitive evolution process. We instantiate this view in CogEvo-Edu, a hierarchical educational multi-agent system comprising a Cognitive Perception Layer (CPL), a Knowledge Evolution Layer (KEL), and a Meta-Control Layer (MCL). CPL maintains dual memories and performs confidence-weighted consolidation to build structured, self-correcting student profiles under limited context. KEL assigns each knowledge chunk a spatiotemporal value that drives activation, semantic compression, and forgetting. MCL formulates tutoring as hierarchical sequential decision making, orchestrating specialized agents and jointly adapting CPL/KEL hyperparameters via a dual inner--outer loop. To evaluate CogEvo-Edu, we construct DSP-EduBench, a vertical benchmark for DSP tutoring with heterogeneous resources, simulated student profiles, and long-horizon interaction scripts. Using a three-model LLM-as-a-Judge ensemble, CogEvo-Edu raises the overall score from 5.32 to 9.23 and improves all six indicators over static RAG, simple memory, and a single-agent variant, demonstrating the value of jointly evolving student profiles, knowledge bases, and teaching policies.

</details>


### [261] [Echo-N1: Affective RL Frontier](https://arxiv.org/abs/2512.00344)
*Naifan Zhang,Ruihan Sun,Ruixi Su,Shiqi Ma,Shiya Zhang,Xianna Weng,Xiaofan Zhang,Yuhan Zhan,Yuyang Xu,Zhaohan Chen,Zhengyuan Pan,Ziyi Song*

Main category: cs.AI

TL;DR: 本文提出了一种新的框架，该框架能够实时推断用户的个性，并优化模型行为以适应个性化的对话偏好。该框架在人机交互质量上取得了显著的提高，并引入了第一个动态情感智能评估套件来量化这些提升。


<details>
  <summary>Details</summary>
Motivation: 当前的大型语言模型（LLM）主要专注于数学、代码和确定性的任务，而忽视了界定人类智能的关键领域：带有主观性的、情感导向的、个性敏感的对话。研究表明，这一领域不仅能够通过强化学习（RL）来解决，而且通过个性化的对话偏好优化模型行为可以显著提高人类的交互体验。

Method: 本文提出了一种基于实时推断用户个性的框架。该框架通过对用户的数据进行分析，理解用户的个性特征，并据此优化对话机器人的行为，以提供更个性化的对话体验。此外，作者还引入了一个动态情感智能评估套件，通过一系列测试来评估这种个性化优化的效果。

Result: 实验表明，该框架在人机交互方面取得了显著的提升，表现优于基础版本和竞争对手。这不仅是对传统RL是否适用于非验证场景的挑战，也展示了个性化的对话偏好优化在增强模型人际互动能力方面的潜力。

Conclusion: 该工作为RL领域开辟了一个新的方向：通过优化模型来关注人类对话中深层次的主观性和人性化的维度。

Abstract: The LLM field has spent a year perfecting RL for tasks machines already excel at, math, code, and deterministic reasoning, while completely sidestepping the domain that actually defines human intelligence: subjective, emotionally grounded, personality sensitive conversation. This space has often been regarded as inherently subjective and challenging to formalize, making it appear unsuitable for conventional RL pipelines. We show that it is not only possible and it is a solvable and transformative RL problem. We propose the first framework that infers user personality on the fly and optimizes model behavior toward personalized conversational preferences. Contrary to the widespread belief that RL collapses in non-verifiable settings, our method produces consistent, robust, and dramatic improvements in humanlike interaction quality. We also introduce the first dynamic emotional intelligence evaluation suite to quantify these gains. Our model, which is introduced as Echo-N1, behaves far above its base version and outperforming the proprietary Doubao 1.5 Character. This work establishes a new frontier for RL: optimizing models for the deeply subjective, deeply human dimensions of conversation.

</details>


### [262] [GreenPlanner: Practical Floorplan Layout Generation via an Energy-Aware and Function-Feasible Generative Framework](https://arxiv.org/abs/2512.00406)
*Pengyu Zeng,Yuqin Dai,Jun Yin,Jing Zhong,Ziyang Han,Chaoyang Shi,ZhanXiang Jin,Maowei Jiang,Yuxing Han,Shuai Lu*

Main category: cs.AI

TL;DR: GreenPlanner是一个高效的能源和功能感知生成框架，通过学习约束先验、快速预测能源性能和空间功能有效性、生成符合用户需求和规范的布局，实现设计评价和生成的一体化。


<details>
  <summary>Details</summary>
Motivation: 建筑设计影响人类福祉和碳排放，但当前的手动设计方式成本高且无法规模化。GreenPlanner致力于解决这一问题，旨在简化并提升设计效率，同时确保设计满足能源和功能性要求。

Method: GreenPlanner包括三个主要组成部分：1)带有标签的设计可行性数据集，用于学习约束先验知识；2)快速实用设计评估器（PDE），用以预测能源性能、评估空间和功能合规性；3)由PDE指导筛选产生的绿色计划数据集（GreenPD），通过市需求与合规布局配对；4)基于GreenPD进行训练的GreenFlow生成器，使用PDE反馈实现可控、合规的设计生成。

Result: GreenPlanner将评估加速超过10万倍，准确率达到99%，消除了无效样本，并将设计效率提高了87%。

Conclusion: GreenPlanner能有效提升建筑设计过程的效率与质量，为推动绿色建筑设计进程提供强有力的支持。

Abstract: Building design directly affects human well-being and carbon emissions, yet generating spatial-functional and energy-compliant floorplans remains manual, costly, and non-scalable. Existing methods produce visually plausible layouts but frequently violate key constraints, yielding invalid results due to the absence of automated evaluation. We present GreenPlanner, an energy- and functionality-aware generative framework that unifies design evaluation and generation. It consists of a labeled Design Feasibility Dataset for learning constraint priors; a fast Practical Design Evaluator (PDE) for predicting energy performance and spatial-functional validity; a Green Plan Dataset (GreenPD) derived from PDE-guided filtering to pair user requirements with regulation-compliant layouts; and a GreenFlow generator trained on GreenPD with PDE feedback for controllable, regulation-aware generation. Experiments show that GreenPlanner accelerates evaluation by over $10^{5}\times$ with $>$99% accuracy, eliminates invalid samples, and boosts design efficiency by 87% over professional architects.

</details>


### [263] [Mind the data gap: Missingness Still Shapes Large Language Model Prognoses](https://arxiv.org/abs/2512.00479)
*Yuta Kobayashi,Vincent Jeanselme,Shalmali Joshi*

Main category: cs.AI

TL;DR: 该研究通过一系列实验表明，在医疗数据中，缺失值的模式显著影响了大型语言模型（LLMs）的零样本预测性能。虽然某些模型受益，但其他模型可能受到负面影响，具体影响因模型大小而异。研究强调了在后续性能评估中透明记录并系统评估表示（信息性）缺失的影响的重要性。


<details>
  <summary>Details</summary>
Motivation: 由于现有文献主要关注数据缺失性对信息性的影响，而未对大型语言模型（LLMs）的性能产生影响进行研究，因此有必要深入探讨在医疗数据中，由于反馈选择等因素如何影响大型语言模型的零样本预测性能。该研究旨在填补这一知识空白。

Method: 研究团队通过一系列实验，在哥伦比亚大学医疗中心和MIMIC-IV的数据集上进行分析。实验包括使用不同大小的大型语言模型，比较其在包含或不包含缺失值指示符时的零样本预测性能和校准情况。

Result: 实验结果表明，缺失值模式对大型语言模型的零样本预测性能有显著影响。虽然某些模型在包含缺失值指示符时表现更好，但也有一些模型的性能和校准情况受到了负面影响。研究还表明，较大型的模型从这些干预措施中获益，而较小的模型可能会受到影响。

Conclusion: 研究结论指出，大型语言模型在处理缺失数据上的表现不一，而且这种影响可能被LLM体系结构进一步夸大。因此，需要对数据中表示（信息性）缺失的影响进行更透明的核算和系统评估，以便更好地理解其对下游性能的影响。

Abstract: Data collection often reflects human decisions. In healthcare, for instance, a referral for a diagnostic test is influenced by the patient's health, their preferences, available resources, and the practitioner's recommendations. Despite the extensive literature on the informativeness of missingness, its implications on the performance of Large Language Models (LLMs) have not been studied. Through a series of experiments on data from Columbia University Medical Center, a large urban academic medical center, and MIMIC-IV, we demonstrate that patterns of missingness significantly impact zero-shot predictive performance. Notably, the explicit inclusion of missingness indicators at prompting benefits some while hurting other LLMs' zero-shot predictive performance and calibration, suggesting an inconsistent impact. The proposed aggregated analysis and theoretical insights suggest that larger models benefit from these interventions, while smaller models can be negatively impacted. The LLM paradigm risks obscuring the impact of missingness, often neglected even in conventional ML, even further. We conclude that there is a need for more transparent accounting and systematic evaluation of the impact of representing (informative) missingness on downstream performance.

</details>


### [264] [Clinical-R1: Empowering Large Language Models for Faithful and Comprehensive Reasoning with Clinical Objective Relative Policy Optimization](https://arxiv.org/abs/2512.00601)
*Boyang Gu,Hongjian Zhou,Bradley Max Segal,Jinge Wu,Zeyu Cao,Hantao Zhong,Lei Clifton,Fenglin Liu,David A. Clifton*

Main category: cs.AI

TL;DR: 本文介绍了Clinical-Objective Relative Policy Optimization (CRPO)，这是一种用于临床推理的多目标可验证强化学习方法，能够在不依赖人工注释的情况下优化准确性、忠实性和完整性。


<details>
  <summary>Details</summary>
Motivation: 当前的LLM后训练方法主要奖励正确性，这与医学等高风险领域所需的多维度目标不一致。本文旨在验证CRPO可以更好地促进LLM推理与临床推理原则的对齐。

Method: CRPO通过结合基于规则的和可验证的奖励信号，在不依赖人工注释的情况下优化准确性和忠实性。

Result: 本文训练了Clinical-R1-3B模型，并在三个基准上表明，CRPO相比标准的GRPO在真实性和完整性上有了显著提高，同时保持了舒适的准确性。

Conclusion: 此框架提供了一种可扩展的方法来使LLM推理与临床目标保持一致，有助于构建更安全和协作的AI医疗系统，同时也突显了多目标、可验证的RL方法在LLM后训练扩展中的潜力。

Abstract: Recent advances in large language models (LLMs) have shown strong reasoning capabilities through large-scale pretraining and post-training reinforcement learning, demonstrated by DeepSeek-R1. However, current post-training methods, such as Grouped Relative Policy Optimization (GRPO), mainly reward correctness, which is not aligned with the multi-dimensional objectives required in high-stakes fields such as medicine, where reasoning must also be faithful and comprehensive. We introduce Clinical-Objective Relative Policy Optimization (CRPO), a scalable, multi-objective, verifiable reinforcement learning method designed to align LLM post-training with clinical reasoning principles. CRPO integrates rule-based and verifiable reward signals that jointly optimize accuracy, faithfulness, and comprehensiveness without relying on human annotation. To demonstrate its effectiveness, we train Clinical-R1-3B, a 3B-parameter model for clinical reasoning. The experiments on three benchmarks demonstrate that our CRPO substantially improves reasoning on truthfulness and completeness over standard GRPO while maintaining comfortable accuracy enhancements. This framework provides a scalable pathway to align LLM reasoning with clinical objectives, enabling safer and more collaborative AI systems for healthcare while also highlighting the potential of multi-objective, verifiable RL methods in post-training scaling of LLMs for medical domains.

</details>


### [265] [EDIT: Early Diffusion Inference Termination for dLLMs Based on Dynamics of Training Gradients](https://arxiv.org/abs/2512.00670)
*He-Yen Hsieh,Hong Wang,H. T. Kung*

Main category: cs.AI

TL;DR: 提出了一种名为EDIT的技术，它在推理时可以提前终止去噪过程，从而减少扩散步骤，同时保持或提升准确性，且仅增加极少的存储开销。


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散的大语言模型虽然能够通过迭代去噪改进令牌生成，但答案往往在所有步骤未完成之前就已经稳定下来。现有的方法不保留训练过程中生成的参数重要性元数据。因此，提出了EDIT，旨在通过监测token激活与推理地图之间的对齐程度来提高推理效率。

Method: EDIT首先通过AdamW聚合LoRA更新来创建推理地图，然后在推理过程中根据匹配未掩码的令牌的对齐得分来生成令牌分布。当连续步骤之间的KL散度低于阈值时，表示推理达到收敛，随即停止去噪过程。

Result: 实验结果显示，与基线相比，使用EDIT可以在大多数场景下保持或提高准确性的同时减少11.8%到68.3%的扩散步骤，且仅增加约0.02%的存储空间（约1.5-2MB）。

Conclusion: 该研究为减少基于扩散的语言模型的推理时间和成本开辟了一条新的研究路径，通过利用训练梯度动力学，减少推理过程中的计算资源消耗。

Abstract: Diffusion-based large language models (dLLMs) refine token generations through iterative denoising, but answers often stabilize before all steps complete. We propose EDIT (Early Diffusion Inference Termination), an inference-time criterion that adaptively stops denoising once sufficient reasoning stability relative to training-time reasoning is detected. EDIT monitors the alignment between token activations and a reasoning map derived from AdamW-aggregated LoRA updates captured during supervised fine-tuning (SFT). During training, optimization dynamics generate rich metadata about parameter importance that in prior methods is typically discarded upon model release. We preserve this information as a compact representation of learned reasoning pathways. During inference, alignment scores are converted to a distribution over the tokens already unmasked at the current denoising step, and convergence is detected when KL divergence between consecutive steps falls below a threshold on the matched unmasked (visible) tokens. Across reasoning benchmarks, EDIT reduces diffusion steps by 11.8% to 68.3% while preserving or improving accuracy in most settings, with approximately 0.02% storage overhead (about 1.5-2 MB for all QKV modules across 32 blocks in an 8 GB model). By utilizing training-gradient dynamics, our work opens a new research direction for reducing dLLM inference time and cost.

</details>


### [266] [Model of human cognition](https://arxiv.org/abs/2512.00683)
*Wu Yonggang*

Main category: cs.AI

TL;DR: 该研究提出了一种神经理论框架，旨在克服大语言模型的可解释性不足和高昂成本问题，通过提供认知过程的理论洞见和计算高效的方法来促进可解释且广泛泛化的AI开发。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的发展受限于其可解释性不足、缺乏统一理论以及高昂的操作成本，因此，研究需要一种既功能稳健又生物可信的神经理论框架，以促进可解释且广泛泛化的AI开发。

Method: 研究提出了一种神经理论框架，为智能系统的产生提供了既功能性强又生物可信的解释，同时还提供了认知过程的理论见解和计算高效的方法。

Result: 研究结果表明，神经理论框架能够提供对认知过程（例如决策和问题解决）的理论洞察，并提供了一个计算上高效的途径来创建可解释且广泛泛化的AI。

Conclusion: 这项研究提出了一种新的神经理论框架，该框架有望解决大型语言模型中存在的问题，并为创建更加智能、可解释且通用的人工智能提供了理论和方法上的支持。

Abstract: The development of large language models (LLMs) is limited by a lack of explainability, the absence of a unifying theory, and prohibitive operational costs. We propose a neuro-theoretical framework for the emergence of intelligence in systems that is both functionally robust and biologically plausible. The model provides theoretical insights into cognitive processes such as decision-making and problem solving, and a computationally efficient approach for the creation of explainable and generalizable artificial intelligence.

</details>


### [267] [SpeContext: Enabling Efficient Long-context Reasoning with Speculative Context Sparsity in LLMs](https://arxiv.org/abs/2512.00722)
*Jiaming Xu,Jiayi Pan,Hanzhen Wang,Yongkang Zhou,Jiancai Ye,Yu Wang,Guohao Dai*

Main category: cs.AI

TL;DR: 本文提出了一种新的基于蒸馏语言模型（DLM）的检索算法，并针对长时间推理设计了SpeContext系统，该系统在算法、系统和编译级别进行了优化，实现了在云和边缘环境下的吞吐量和速度的显著提升。


<details>
  <summary>Details</summary>
Motivation: 为了使检索算法更加贴近于大语言模型（LLM）的目标，类似于知识蒸馏中的目标，本文通过从信息论的角度分析DLM与原始LLM的信息聚焦相似性，提出了利用DLM作为检索算法的新范式。

Method: 在算法层面，文章提出了基于DLM头注意力权重的轻量级检索头，通过剪枝冗余实现了参数量超过90%的减少。在系统层面，设计了异步预取数据流通过弹性加载策略，有效重叠了KV缓存检索和LLM计算。在编译层面，构建了理论内存模型并实现了自适应内存管理系统，以最大化GPU内存利用率。

Result: 实验结果表明，相比于Huggingface框架，SpeContext在云环境中的吞吐量提高了24.89倍，在边缘环境中的速度提升了10.06倍，且几乎不损失准确性。

Conclusion: SpeContext通过在云计算和边缘推理环境中的优化，展示了其在长时间推理中显著提高性能和吞吐量的巨大潜力，推动了精度和吞吐量之间的帕累托边界。

Abstract: In this paper, we point out that the objective of the retrieval algorithms is to align with the LLM, which is similar to the objective of knowledge distillation in LLMs. We analyze the similarity in information focus between the distilled language model(DLM) and the original LLM from the perspective of information theory, and thus propose a novel paradigm that leverages a DLM as the retrieval algorithm. Based on the insight, we present SpeContext, an algorithm and system co-design for long-context reasoning. (1) At the algorithm level, SpeContext proposes lightweight retrieval head based on the head-level attention weights of DLM, achieving > 90% parameters reduction by pruning the redundancy. (2) At the system level, SpeContext designs an asynchronous prefetch dataflow via the elastic loading strategy, effectively overlapping KV cache retrieval with the LLM computation. (3) At the compilation level, SpeContext constructs the theoretical memory model and implements an adaptive memory management system to achieve acceleration by maximizing GPU memory utilization. We deploy and evaluate SpeContext in two resourceconstrained environments, cloud and edge. Extensive experiments show that, compared with the Huggingface framework, SpeContext achieves up to 24.89x throughput improvement in cloud and 10.06x speedup in edge with negligible accuracy loss, pushing the Pareto frontier of accuracy and throughput.

</details>


### [268] [Probing the "Psyche'' of Large Reasoning Models: Understanding Through a Human Lens](https://arxiv.org/abs/2512.00729)
*Yuxiang Chen,Zuohan Wu,Ziwei Wang,Xiangning Yu,Xujia Li,Linyi Yang,Mengyue Yang,Jun Wang,Lei Chen*

Main category: cs.AI

TL;DR: 该研究构建了一个全面的原子推理步骤分类体系，揭示了当前大型推理模型（LRMs）存在的一些问题，并提出了一种基于大语言模型的自动标注框架，以更全面地分析LRMs。


<details>
  <summary>Details</summary>
Motivation: 通过对LRMs的原子推理步骤进行分类和分析，以更好地理解其智能行为，弥补当前对LRMs理解的不足。

Method: 研究构建了一个由五个组和十七个类别组成的分类体系，来源于人类心理过程。通过应用这个分类体系，研究人员生成了一个包含277,534个原子推理步骤的标注数据集。利用这个资源，研究进行了深入分析，并提出了基于大语言模型的自动标注框架（CAPO）。

Result: 研究揭示了现存的一些问题，如当前LRMs的后回答‘双核检’（自我监控评估）很少产生实质性的修改，建议激励多步骤反思，而非简单的自我监控。研究验证了自动标注框架（CAPO）在一致性方面优于基线。

Conclusion: 该研究提供了一种 principle-based 和 scalable 的方法来理解和推进LRMs的推理，并提出了一种自动标注框架（CAPO）来实现这一目标，为未来的研究提供了参考。

Abstract: Large reasoning models (LRMs) have garnered significant attention from researchers owing to their exceptional capability in addressing complex tasks. Motivated by the observed human-like behaviors in their reasoning processes, this paper introduces a comprehensive taxonomy to characterize atomic reasoning steps and probe the ``psyche'' of LRM intelligence. Specifically, it comprises five groups and seventeen categories derived from human mental processes, thereby grounding the understanding of LRMs in an interdisciplinary perspective. The taxonomy is then applied for an in-depth understanding of current LRMs, resulting in a distinct labeled dataset that comprises 277,534 atomic reasoning steps. Using this resource, we analyze contemporary LRMs and distill several actionable takeaways for improving training and post-training of reasoning models. Notably, our analysis reveals that prevailing post-answer ``double-checks'' (self-monitoring evaluations) are largely superficial and rarely yield substantive revisions. Thus, incentivizing comprehensive multi-step reflection, rather than simple self-monitoring, may offer a more effective path forward. To complement the taxonomy, an automatic annotation framework, named CAPO, is proposed to leverage large language models (LLMs) for generating the taxonomy-based annotations. Experimental results demonstrate that CAPO achieves higher consistency with human experts compared to baselines, facilitating a scalable and comprehensive analysis of LRMs from a human cognitive perspective. Together, the taxonomy, CAPO, and the derived insights provide a principled, scalable path toward understanding and advancing LRM reasoning.

</details>


### [269] [MPR-GUI: Benchmarking and Enhancing Multilingual Perception and Reasoning in GUI Agents](https://arxiv.org/abs/2512.00756)
*Ruihan Chen,Qiming Li,Xiaocheng Feng,Xiaoliang Yang,Weihong Zhong,Yuxuan Gu,Zekun Zhou,Bing Qin*

Main category: cs.AI

TL;DR: 本文提出了一种多语言细粒度感知与推理GUI基准（MPR-GUI-Bench），评估了LVLMs在不同语言环境下的性能差异，并提出了一种跨语言干预方法GUI-XLI来改进多语言感知与推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究在多语言GUI任务上的关注度较低，且缺乏细粒度分析，限制了它们的全球应用。因此，需要构建一个多语言细粒度感知与推理基准来更好地评估LVLMs并提出改进方法。

Method: 构建了一个名为MPR-GUI-Bench的多语言细粒度感知与推理GUI基准，以及一种基于隐藏状态跨语言干预方法（GUI-XLI）来提升多语言感知与推理能力。

Result: 实验结果表明，该方法在多语言环境下的感知与推理能力平均提高了6.5%。

Conclusion: 该研究提出的方法提高了LVLMs在不同语言环境下的感知与推理能力，但仍然需要进一步研究来进一步扩大其适用范围。

Abstract: With the advancement of computational resources, Large Vision-Language Models (LVLMs) exhibit impressive Perception and Reasoning (P&R) performance on Graphical User Interface (GUI) tasks. However, although they demonstrate strong P&R capabilities in English GUI scenarios, their performance in multilingual settings has received little attention, which limits their global applications. Moreover, existing studies on GUI tasks lack fine-grained analyses, including widget functions and elements' spatial relationships, which are fundamental for more targeted improvements. To tackle these issues, we propose MPR-GUI-Bench, a Multilingual fine-grained Perception and Reasoning GUI Benchmark to evaluate GUI agents' P&R capabilities. Evaluation results demonstrate that LVLMs exhibit significantly worse P&R performance in non-English languages than in English. To address these gaps, we propose GUI-XLI, a GUI Cross-Lingual Intervention method that applies interventions to the hidden states at P&R capability-related layers to mitigate the gaps between English and other languages, building on previous research showing that the hidden states of different language inputs exhibit significant differences in the latent space. Experimental results indicate that our method improves GUI agents' multilingual P&R capability by 6.5% on average.

</details>


### [270] [BioPro: On Difference-Aware Gender Fairness for Vision-Language Models](https://arxiv.org/abs/2512.00807)
*Yujie Lin,Jiayao Ma,Qingguo Hu,Derek F. Wong,Jinsong Su*

Main category: cs.AI

TL;DR: 本文提出了一种名为BioPro的方法，通过投影低维性别变异亚空间来减少视觉语言模型中的性别偏见，同时保留明确情境下的性别相关信息，展示了其在多种情况下的有效性和普适性。


<details>
  <summary>Details</summary>
Motivation: 当前的公平性干预方法忽视了不同情境下性别刻板印象处理的差异，未能区分需要中立和应当保留团体特定属性的场景。因此，提出了一种差异感知的公平性方法，旨在平衡中立情境中的去偏见和明确情境中的性别区分。

Method: 本文提出了一种名为BioPro的方法，通过生成对抗性嵌入来识别一个低维性别变异亚空间，并应用投影技术以选择性地消除与性别相关的信息，而不影响明确情境中的性别分化。

Result: 实验结果表明，BioPro能够有效减少视觉语言模型中性别偏见的情况，同时保持明确情境中的性别真实性，展示了其有效性和应用前景。

Conclusion: 综上所述，本文提出的方法BioPro提供了一种在视觉语言模型中实现差异感知性别公平性的可行途径，为未来研究提供了新的思路。此外，BioPro还能泛化到连续偏倚变量，展示了其更广泛的适用性。

Abstract: Vision-Language Models (VLMs) inherit significant social biases from their training data, notably in gender representation. Current fairness interventions often adopt a difference-unaware perspective that enforces uniform treatment across demographic groups. These approaches, however, fail to distinguish between contexts where neutrality is required and those where group-specific attributes are legitimate and must be preserved. Building upon recent advances in difference-aware fairness for text-only models, we extend this concept to the multimodal domain and formalize the problem of difference-aware gender fairness for image captioning and text-to-image generation. We advocate for selective debiasing, which aims to mitigate unwanted bias in neutral contexts while preserving valid distinctions in explicit ones. To achieve this, we propose BioPro (Bias Orthogonal Projection), an entirely training-free framework. BioPro identifies a low-dimensional gender-variation subspace through counterfactual embeddings and applies projection to selectively neutralize gender-related information. Experiments show that BioPro effectively reduces gender bias in neutral cases while maintaining gender faithfulness in explicit ones, thus providing a promising direction toward achieving selective fairness in VLMs. Beyond gender bias, we further demonstrate that BioPro can effectively generalize to continuous bias variables, such as scene brightness, highlighting its broader applicability.

</details>


### [271] [Med-CMR: A Fine-Grained Benchmark Integrating Visual Evidence and Clinical Logic for Medical Complex Multimodal Reasoning](https://arxiv.org/abs/2512.00818)
*Haozhen Gong,Xiaozhong Ji,Yuansen Liu,Wenbin Wu,Xiaoxiao Yan,Jingjing Liu,Kai Wu,Jiazhen Pan,Bailiang Jian,Jiangning Zhang,Xiaobin Hu,Hongwei Bran Li*

Main category: cs.AI

TL;DR: MLLMs在临床工作流程中的能力尚不明晰，本文通过Med-CMR基准测试评估了18种先进的MLLMs，结果显示商用模型GPT-5在多项选择题中得分最高，但在长尾泛化方面仍存在不足。Med-CMR为未来医疗AI系统的临床应用提供了一套高标准的评估体系。


<details>
  <summary>Details</summary>
Motivation: 随着MLLMs逐渐融入临床工作流程，需要对其能否进行复杂的医学推理进行评估，以保证其在临床中的准确性和可靠性。

Method: 本文提出了Med-CMR基准测试，该测试通过系统能力分解、具有挑战性的任务设计和广泛的高标准数据集来对MLLMs进行评估。

Result: 18种先进的MLLMs被用于Med-CMR测试，GPT-5取得了最高分，但在长尾泛化方面存在问题。

Conclusion: Med-CMR为医学MLLMs的视觉推理和特殊案例处理提供了一套严格的评估标准，有助于改进未来的医疗AI系统。

Abstract: MLLMs MLLMs are beginning to appear in clinical workflows, but their ability to perform complex medical reasoning remains unclear. We present Med-CMR, a fine-grained Medical Complex Multimodal Reasoning benchmark. Med-CMR distinguishes from existing counterparts by three core features: 1) Systematic capability decomposition, splitting medical multimodal reasoning into fine-grained visual understanding and multi-step reasoning to enable targeted evaluation; 2) Challenging task design, with visual understanding across three key dimensions (small-object detection, fine-detail discrimination, spatial understanding) and reasoning covering four clinically relevant scenarios (temporal prediction, causal reasoning, long-tail generalization, multi-source integration); 3) Broad, high-quality data coverage, comprising 20,653 Visual Question Answering (VQA) pairs spanning 11 organ systems and 12 imaging modalities, validated via a rigorous two-stage (human expert + model-assisted) review to ensure clinical authenticity. We evaluate 18 state-of-the-art MLLMs with Med-CMR, revealing GPT-5 as the top-performing commercial model: 57.81 accuracy on multiple-choice questions (MCQs) and a 48.70 open-ended score, outperforming Gemini 2.5 Pro (49.87 MCQ accuracy, 45.98 open-ended score) and leading open-source model Qwen3-VL-235B-A22B (49.34 MCQ accuracy, 42.62 open-ended score). However, specialized medical MLLMs do not reliably outperform strong general models, and long-tail generalization emerges as the dominant failure mode. Med-CMR thus provides a stress test for visual-reasoning integration and rare-case robustness in medical MLLMs, and a rigorous yardstick for future clinical systems.

</details>


### [272] [Assessing model error in counterfactual worlds](https://arxiv.org/abs/2512.00836)
*Emily Howerton,Justin Lessler*

Main category: cs.AI

TL;DR: 文章提出了三种估计反事实误差的方法，并通过模拟实验展示了它们的优势和局限性。


<details>
  <summary>Details</summary>
Motivation: 反事实预测模型在决策制定中至关重要，但鲜有对其准确性进行回溯评估。因此，文章探讨了反事实模型误差的估算方法以提高未来预测的质量。

Method: 文章比较了三种反事实误差估计方法，并在模拟实验中进行展示。

Result: 三种方法各有优缺点，实验结果展示了它们在不同情况下的表现。

Conclusion: 文章提出了改善反事实模型评估的建议，强调合理的设计方案对于提高模型准确性的重要性。

Abstract: Counterfactual scenario modeling exercises that ask "what would happen if?" are one of the most common ways we plan for the future. Despite their ubiquity in planning and decision making, scenario projections are rarely evaluated retrospectively. Differences between projections and observations come from two sources: scenario deviation and model miscalibration. We argue the latter is most important for assessing the value of models in decision making, but requires estimating model error in counterfactual worlds. Here we present and contrast three approaches for estimating this error, and demonstrate the benefits and limitations of each in a simulation experiment. We provide recommendations for the estimation of counterfactual error and discuss the components of scenario design that are required to make scenario projections evaluable.

</details>


### [273] [ARCADIA: Scalable Causal Discovery for Corporate Bankruptcy Analysis Using Agentic AI](https://arxiv.org/abs/2512.00839)
*Fabrizio Maturo,Donato Riccio,Andrea Mazzitelli,Giuseppe Bifulco,Francesco Paolone,Iulia Brezeanu*

Main category: cs.AI

TL;DR: ARCADIA 是一种新型的因果发现框架，通过结合大语言模型推理和统计诊断，迭代优化候选 DAG，适用于高风险领域。


<details>
  <summary>Details</summary>
Motivation: 传统算法在高风险领域可能不够稳定和可解释，ARCADIA 目标是提供一种能产生可靠因果图、具备完全可解释性和干预预备性的框架。

Method: ARCADIA 通过约束引导提示和因果有效反馈迭代优化候选有向无环图（DAG），以实现稳定的、可解释的因果结构。

Result: 实验表明，ARCADIA 在企业破产数据上的表现优于 NOTEARS、GOLEM 和 DirectLiNGAM，产生了更为可靠的因果图。

Conclusion: 此项研究展示了如何利用自主型大语言模型参与自主科学建模和结构因果推理，并推动了 AI 技术的发展。

Abstract: This paper introduces ARCADIA, an agentic AI framework for causal discovery that integrates large-language-model reasoning with statistical diagnostics to construct valid, temporally coherent causal structures. Unlike traditional algorithms, ARCADIA iteratively refines candidate DAGs through constraint-guided prompting and causal-validity feedback, leading to stable and interpretable models for real-world high-stakes domains. Experiments on corporate bankruptcy data show that ARCADIA produces more reliable causal graphs than NOTEARS, GOLEM, and DirectLiNGAM while offering a fully explainable, intervention-ready pipeline. The framework advances AI by demonstrating how agentic LLMs can participate in autonomous scientific modeling and structured causal inference.

</details>


### [274] [One Swallow Does Not Make a Summer: Understanding Semantic Structures in Embedding Spaces](https://arxiv.org/abs/2512.00852)
*Yandong Sun,Qiang Huang,Ziwei Xu,Yiqun Sun,Yixuan Tang,Anthony K. H. Tung*

Main category: cs.AI

TL;DR: 本文提出了一种几何保真、上下文感知的 Semantic Field Subspace (SFS) 表示方法，能够捕捉嵌入空间中的局部语义邻域。同时，提出了一种无需监督的、跨模态的 SAFARI 算法，用于发现层次化的语义结构。通过高效计算 Semantic Shift 来保证可扩展性，实验结果表明 SFS 和 SAFARI 在多种任务上都表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的嵌入空间表示方法在语义连贯性和计算效率之间存在权衡问题。因此，团队开发了 SFS 和 SAFARI 来解决这些挑战，旨在提供一种更具语义连贯性和高效性的表示方法。

Method: 团队提出了 SFS 和 SAFARI，SFS 能够捕捉局部语义邻域，另一方面，SAFARI 利用语义偏移（Semantic Shift）来发现层次化的语义结构。此外，为了保持可扩展性，采用了一种高效算法来替换昂贵的 SVD 计算。

Result: 实验结果表明，SFS 不仅在分类任务中表现出色，还在政治偏见检测等复杂任务中表现出优越性。同时，SAFARI 不断揭示可解释且可泛化的语义层级。

Conclusion: 这项工作提供了一个统一的框架，用于在嵌入空间中组织、分析和扩展语义理解。

Abstract: Embedding spaces are fundamental to modern AI, translating raw data into high-dimensional vectors that encode rich semantic relationships. Yet, their internal structures remain opaque, with existing approaches often sacrificing semantic coherence for structural regularity or incurring high computational overhead to improve interpretability. To address these challenges, we introduce the Semantic Field Subspace (SFS), a geometry-preserving, context-aware representation that captures local semantic neighborhoods within the embedding space. We also propose SAFARI (SemAntic Field subspAce deteRmInation), an unsupervised, modality-agnostic algorithm that uncovers hierarchical semantic structures using a novel metric called Semantic Shift, which quantifies how semantics evolve as SFSes evolve. To ensure scalability, we develop an efficient approximation of Semantic Shift that replaces costly SVD computations, achieving a 15~30x speedup with average errors below 0.01. Extensive evaluations across six real-world text and image datasets show that SFSes outperform standard classifiers not only in classification but also in nuanced tasks such as political bias detection, while SAFARI consistently reveals interpretable and generalizable semantic hierarchies. This work presents a unified framework for structuring, analyzing, and scaling semantic understanding in embedding spaces.

</details>


### [275] [Hybrid-DMKG: A Hybrid Reasoning Framework over Dynamic Multimodal Knowledge Graphs for Multimodal Multihop QA with Knowledge Editing](https://arxiv.org/abs/2512.00881)
*Li Yuan,Qingfei Huang,Bingshan Zhu,Yi Cai,Qingbao Huang,Changmeng Zheng,Zikun Deng,Tao Wang*

Main category: cs.AI

TL;DR: MMQAKE是一个新的基准，旨在评估模型在视觉重述输入下的多跳推理能力和多模态知识编辑方法的一致性更新和推理。


<details>
  <summary>Details</summary>
Motivation: 现有MKE评估主要关注最终答案的准确性而忽视了中间推理质量及对视觉重述输入的鲁棒性。

Method: 提出了Hybrid-DMKG，这是一种基于动态多模态知识图谱的混合推理框架，通过分解多跳问题、检索更新事实及融合推理路径来提升多模态知识编辑的性能。

Result: Hybrid-DMKG在MMQAKE基准上的实验结果表明，该方法显著优于现有的MKE方法，提高了准确性和对知识更新的鲁棒性。

Conclusion: Hybrid-DMKG为多模态知识编辑提供了新的解决方案，能够更准确地处理多模态推理链的连续更新和推理。

Abstract: Multimodal Knowledge Editing (MKE) extends traditional knowledge editing to settings involving both textual and visual modalities. However, existing MKE benchmarks primarily assess final answer correctness while neglecting the quality of intermediate reasoning and robustness to visually rephrased inputs. To address this limitation, we introduce MMQAKE, the first benchmark for multimodal multihop question answering with knowledge editing. MMQAKE evaluates (1) a model's ability to reason over 2-5-hop factual chains that span both text and images, including performance at each intermediate step, and (2) robustness to visually rephrased inputs in multihop questions. Our evaluation shows that current MKE methods often struggle to consistently update and reason over multimodal reasoning chains after knowledge edits. To overcome these challenges, we propose Hybrid-DMKG, a hybrid reasoning framework built on a dynamic multimodal knowledge graph (DMKG) to enable accurate multihop reasoning over updated multimodal knowledge. Hybrid-DMKG first uses a large language model to decompose multimodal multihop questions into sequential sub-questions, then applies a multimodal retrieval model to locate updated facts by jointly encoding each sub-question with candidate entities and their associated images. For answer inference, a hybrid reasoning module operates over the DMKG via two parallel paths: (1) relation linking prediction, and (2) RAG reasoning with large vision-language models. A decision module aggregates evidence from both paths to select the most credible answer. Experimental results on MMQAKE show that Hybrid-DMKG significantly outperforms existing MKE approaches, achieving higher accuracy and improved robustness to knowledge updates.

</details>


### [276] [Integrating Causal Foundation Model in Prescriptive Maintenance Framework for Optimizing Production Line OEE](https://arxiv.org/abs/2512.00969)
*Felix Saretzky,Lucas Andersen,Thomas Engel,Fazel Ansari*

Main category: cs.AI

TL;DR: 本文提出了一种基于因果机器学习的模型，旨在通过模拟潜在修复措施并评估其对关键绩效指标如OEE的影响，以识别根本原因并对其操作影响进行量化。模型通过因果效应评估每种干预措施，并在实际生产线上提供数据驱动的操作建议。


<details>
  <summary>Details</summary>
Motivation: 由于预测模型通常依赖于虚假的相关性，而不是真正的原因，并导致成本高昂的错误诊断和无效干预，文章提供了通过因果机器学习模型从诊断转向主动处方的解决方案。

Method: 该方法涉及使用预训练的因果基模型作为“假设情景”模型，以估算潜在修复措施的影响。通过评估干预措施对系统关键指标的因果效应，模型提供了一种数据驱动的方法，用于在生产线上的操作建议。

Result: 模型在半合成制造数据上得到了评估，并被证明优于基线机器学习模型。这种方法为强大的预测性维护框架奠定了技术基础，使工程师能够在因果环境中测试潜在解决方案，从而做出更有效的操作决策并减少成本高昂的停机时间。

Conclusion: 文章提出的方法为当前基于预测的维护体制提供了一种改进的替代方案，通过数据驱动的方式，帮助企业更好地理解和采取预防性维护措施。

Abstract: The transition to prescriptive maintenance in manufacturing is critically constrained by a dependence on predictive models. These models tend to rely on spurious correlations rather than identifying the true causal drivers of failures, often leading to costly misdiagnoses and ineffective interventions. This fundamental limitation results in a key-challenge: while we can predict that a failure may occur, we lack a systematic method to understand why a failure occurs, thereby providing the basis for identifying the most effective intervention. This paper proposes a model based on causal machine learning to bridge this gap. Our objective is to move beyond diagnosis to active prescription by simulating and evaluating potential fixes toward optimizing KPIs such as Overall Equipment Effectiveness (OEE). For this purpose a pre-trained causal foundation model is used as a "what-if" model to estimate the effects of potential fixes. By measuring the causal effect of each intervention on system-level KPIs, it provides a data-driven ranking of actions to recommend at the production line. This process not only identifies root causes but also quantifies their operational impact. The model is evaluated using semi-synthetic manufacturing data and compared with a baseline machine learning model. This paper sets the technical basis for a robust prescriptive maintenance framework, allowing engineers to test potential solutions in a causal environment to make more effective operational decisions and reduce costly downtimes.

</details>


### [277] [IndiMathBench: Autoformalizing Mathematical Reasoning Problems with a Human Touch](https://arxiv.org/abs/2512.00997)
*Param Biyani,Shashank Kirtania,Yasharth Bajpai,Sumit Gulwani,Ashish Tiwari*

Main category: cs.AI

TL;DR: IndiMathBench 是一个由人类验证的基准测试，用于评估数学定理证明，采用了 AI 助力的人工验证流水线将自然语言问题转换为 Lean 4 形式的定理。该基准包括 312 个定理及其相应的非形式化问题描述，来源于印度数学奥林匹克竞赛。通过类别检索、迭代编译反馈和多模型组合，生成候选形式化表述，专家通过交互式仪表板审核这些表述，最终展示了自动形式化仍然具有挑战性，即使经过多次改进，证明成功率仍然较低。


<details>
  <summary>Details</summary>
Motivation: 建立一个能够评估自动形式化和定理证明能力的基准测试，以促进相关技术的发展。

Method: 一种由 AI 助力的人工验证流水线，将自然语言问题转换为 Lean 4 形式的定理，并通过交互式仪表板和自动化质量总结进行验证。

Result: IndiMathBench 包含 312 个定理及其相应的非形式化问题描述，展示了自动形式化和定理证明技术的挑战性，明确指出在语法正确性和语义正确性之间存在差距。

Conclusion: IndiMathBench 提供了一个新的基准测试，用于评估数学证明的相关系统，展示了它们在自动形式化和定理证明中的不足，有助于进一步改进相关技术。

Abstract: We introduce IndiMathBench, a human-verified benchmark designed to evaluate mathematical theorem proving, curated using an AI-powered human-assisted pipeline for formalizing natural language problems in Lean. IndiMathBench is composed of 312 formal Lean 4 theorems paired with their corresponding informal problem statements, sourced from Indian Mathematics Olympiads. Through category-based retrieval, iterative compiler feedback, and multi-model ensembles, our pipeline generates candidate formalizations that experts efficiently validate via an interactive dashboard with automated quality summaries. Evaluation across multiple frontier models demonstrates that autoformalization remains challenging, with substantial gaps between syntactic validity and semantic correctness, while theorem proving success rates remain low even with iterative refinement, demonstrating that \benchmark~presents a challenging testbed for mathematical reasoning. IndiMathBench is available at https://github.com/prmbiy/IndiMathBench.

</details>


### [278] [ChartAnchor: Chart Grounding with Structural-Semantic Fidelity](https://arxiv.org/abs/2512.01017)
*Xinhang Li,Jingbo Zhou,Pengfei Luo,Yixiong Xiao,Tong Xu*

Main category: cs.AI

TL;DR: ChartAnchor 是一个大型基准，包含8k+的图-表-代码三元组，涵盖30种不同类型的图表，旨在全面评估大型语言模型在数值精度和代码生成方面的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的基准存在图表多样性受限、孤立任务以及评估框架不完善的问题，无法全面评估模型的图表接地能力。为此，研究者提出了ChartAnchor基准，以解决这些问题。

Method: ChartAnchor包含两个互补任务：图表到代码的生成（合成可执行代码以复制图表）和受控的图表到表格的重构（提取确切数据并带有预定义的标题），并通过多级评价框架进行评估，该框架包括语义验证、风格分析和感知度量。

Result: 实验表明，大型语言模型在数值精度和代码合成方面存在关键限制，强调了超越表面感知进行结构化推理的需求。ChartAnchor为图表推理提供了坚实的评估基础。

Conclusion: ChartAnchor通过统一符号性和数据驱动的接地，建立了图表接地的严格基础，为科学、金融和工业领域内大型语言模型的进步提供了有价值的洞察。

Abstract: Recent advances in multimodal large language models (MLLMs) highlight the need for benchmarks that rigorously evaluate structured chart comprehension.Chart grounding refers to the bidirectional alignment between a chart's visual appearance and the structured semantics. This task requires models to produce a symbolic specification that faithfully captures the chart's visual and structural intent, while also recovering the underlying tabular data with precise values and relationships. Chart grounding directly reflects a model's capabilities in numerical reasoning, multimodal alignment, and structural reconstruction, and has several important applications in real-world scenarios.Existing benchmarks, constrained by narrow chart diversity, isolated tasks, and incomplete evaluation frameworks, fail to holistically assess grounding. To address this, we propose ChartAnchor, a comprehensive benchmark of 8k+ chart-table-code triples spanning 30 chart types drawn from diverse real-world and augmented sources. ChartAnchor introduces two complementary tasks: chart-to-code generation (synthesizing executable code to replicate charts) and controlled chart-to-table reconstruction (extracting exact data with predefined headers), enabling cross-validation of visual and numerical fidelity. A multi-level evaluation framework integrates semantic validation, stylistic analysis, and perceptual metrics to assess both structural and content-level correctness. Extensive experiments on MLLMs reveal critical limitations in numerical precision and code synthesis, emphasizing the need for structured reasoning beyond surface-level perception. By unifying symbolic and data-driven grounding, ChartAnchor establishes a rigorous foundation for chart grounding, offering meaningful insights for advancing MLLMs in scientific, financial, and industrial domains.

</details>


### [279] [Evaluating Legal Reasoning Traces with Legal Issue Tree Rubrics](https://arxiv.org/abs/2512.01020)
*Jinu Lee,Kyoung-Woon On,Simeng Han,Arman Cohan,Julia Hockenmaier*

Main category: cs.AI

TL;DR: 该研究引入了一个大规模的新型法律推理数据集LEGIT，用于评估LLM生成的推理痕迹质量，发现LLM的法律推理能力受法律问题覆盖和正确性影响，并且RAG和结合rubrics的RL对法律推理能力有互补的提升。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于通过引入LEGIT数据集来解决LLM在复杂法律领域中推理质量评估的挑战，以提高其在这些领域的可靠性和可解释性。

Method: 研究方法包括将法院判决转化为层次结构的争论树，作为评估推理痕迹的标准。通过人类专家注解验证这些标准的可靠性，并使用这些数据集来评估LLM的能力，并且研究RAG和结合rubrics的RL在法律推理中的效果。

Result: 研究结果表明LLM在法律推理中的能力受法律问题覆盖和正确性影响显著。RAG和结合rubrics的RL对法律推理能力有不同程度的提升，分别提高了整体推理能力和准确率但减少了覆盖范围。

Conclusion: 综上所述，研究结论是LLM在法律推理任务中的表现可以得到进一步改进，特别是通过使用RAG和结合特定rubrics的RL方法来提升推理的准确性和全面性。

Abstract: Evaluating the quality of LLM-generated reasoning traces in expert domains (e.g., law) is essential for ensuring credibility and explainability, yet remains challenging due to the inherent complexity of such reasoning tasks. We introduce LEGIT (LEGal Issue Trees), a novel large-scale (24K instances) expert-level legal reasoning dataset with an emphasis on reasoning trace evaluation. We convert court judgments into hierarchical trees of opposing parties' arguments and the court's conclusions, which serve as rubrics for evaluating the issue coverage and correctness of the reasoning traces. We verify the reliability of these rubrics via human expert annotations and comparison with coarse, less informative rubrics. Using the LEGIT dataset, we show that (1) LLMs' legal reasoning ability is seriously affected by both legal issue coverage and correctness, and that (2) retrieval-augmented generation (RAG) and RL with rubrics bring complementary benefits for legal reasoning abilities, where RAG improves overall reasoning capability, whereas RL improves correctness albeit with reduced coverage.

</details>


### [280] [Med-CRAFT: Automated Construction of Interpretable and Multi-Hop Video Workloads via Knowledge Graph Traversal](https://arxiv.org/abs/2512.01045)
*Shenxi Liu,Kan Li,Mingyang Zhao,Yuhang Tian,Shoujun Zhou,Bin Li*

Main category: cs.AI

TL;DR: 介绍了PipelineName，一种新颖的神经符号数据工程框架，用于生成逻辑清晰的医学视频基准数据集，其复杂度与人工标注的数据集相当。框架通过从原始视频流中提取结构化视觉原语并实例化到动态空间时间知识图中，确保推理步骤的严谨性。


<details>
  <summary>Details</summary>
Motivation: 传统的手动标注过于昂贵且不具有扩展性，现有的合成方法则存在随机幻觉和逻辑可解释性不足的问题。为了解决这些问题，作者提出了PipelineName框架。

Method: PipelineName框架将基准合成形式化为确定性的图遍历过程。框架从原始视频流中提取结构化的视觉原语，然后实例化到动态的空间时间知识图中，并且通过路径绑定查询生成来确保推理步骤的严谨性。

Result: PipelineName生成了名为M3-Med-Auto的大规模医学视频推理基准，展示了精细的时间选择性和多跳逻辑复杂性。自动化生成的数据集复杂度与专家标注的数据集相当。

Conclusion: 该研究证明了Framework能够生成逻辑验证的数据集，这为在关键领域构建可扩展且低成本的评估协议开辟了新的可能性。

Abstract: The scarcity of high-quality, logically annotated video datasets remains a primary bottleneck in advancing Multi-Modal Large Language Models (MLLMs) for the medical domain. Traditional manual annotation is prohibitively expensive and non-scalable, while existing synthetic methods often suffer from stochastic hallucinations and a lack of logical interpretability. To address these challenges, we introduce \textbf{\PipelineName}, a novel neuro-symbolic data engineering framework that formalizes benchmark synthesis as a deterministic graph traversal process. Unlike black-box generative approaches, Med-CRAFT extracts structured visual primitives (e.g., surgical instruments, anatomical boundaries) from raw video streams and instantiates them into a dynamic Spatiotemporal Knowledge Graph. By anchoring query generation to valid paths within this graph, we enforce a rigorous Chain-of-Thought (CoT) provenance for every synthesized benchmark item. We instantiate this pipeline to produce M3-Med-Auto, a large-scale medical video reasoning benchmark exhibiting fine-grained temporal selectivity and multi-hop logical complexity. Comprehensive evaluations demonstrate that our automated pipeline generates query workloads with complexity comparable to expert-curated datasets. Furthermore, a logic alignment analysis reveals a high correlation between the prescribed graph topology and the reasoning steps of state-of-the-art MLLMs, validating the system's capability to encode verifiable logic into visual-linguistic benchmarks. This work paves the way for scalable, low-cost construction of robust evaluation protocols in critical domains.

</details>


### [281] [Automating the Refinement of Reinforcement Learning Specifications](https://arxiv.org/abs/2512.01047)
*Tanmay Ambadkar,Đorđe Žikelić,Abhinav Verma*

Main category: cs.AI

TL;DR: AutoSpec框架通过搜索改进的逻辑规范，使其更容易被强化学习算法学习，从而克服了任务欠规范的问题，提高了强化学习在控制任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 当任务描述不充分时，强化学习算法可能无法学习到有用的策略。AutoSpec旨在通过探索改进粗糙粒度的逻辑规范，为算法提供额外的指导，从而提升其从逻辑规范中学习策略的能力。

Method: AutoSpec框架采用了一种探索导向的策略，该策略能够根据现有规范寻找一种改进的逻辑规范，这种规范不仅满足原始规范，还能为强化学习提供额外指导。这种方法利用了SpectRL规范逻辑的组合特性，并设计了四种改进规范的方式。

Result: 通过AutoSpec改进的逻辑规范，该框架能够解决更复杂的控制任务，并且实验结果证实了其有效性，表明改进后的规范提高了强化学习算法的性能。

Conclusion: AutoSpec展示了如何通过逻辑规范的改进，提高强化学习在复杂控制任务中的应用。未来的研究可以进一步探索其他规范逻辑的应用，以及如何在更广泛的领域中应用此框架。

Abstract: Logical specifications have been shown to help reinforcement learning algorithms in achieving complex tasks. However, when a task is under-specified, agents might fail to learn useful policies. In this work, we explore the possibility of improving coarse-grained logical specifications via an exploration-guided strategy. We propose \textsc{AutoSpec}, a framework that searches for a logical specification refinement whose satisfaction implies satisfaction of the original specification, but which provides additional guidance therefore making it easier for reinforcement learning algorithms to learn useful policies. \textsc{AutoSpec} is applicable to reinforcement learning tasks specified via the SpectRL specification logic. We exploit the compositional nature of specifications written in SpectRL, and design four refinement procedures that modify the abstract graph of the specification by either refining its existing edge specifications or by introducing new edge specifications. We prove that all four procedures maintain specification soundness, i.e. any trajectory satisfying the refined specification also satisfies the original. We then show how \textsc{AutoSpec} can be integrated with existing reinforcement learning algorithms for learning policies from logical specifications. Our experiments demonstrate that \textsc{AutoSpec} yields promising improvements in terms of the complexity of control tasks that can be solved, when refined logical specifications produced by \textsc{AutoSpec} are utilized.

</details>


### [282] [Testing the Machine Consciousness Hypothesis](https://arxiv.org/abs/2512.01081)
*Stephen Fitz*

Main category: cs.AI

TL;DR: 该论文提出了机器意识假说的一种新研究计划，通过研究嵌入自组织环境中的分布式学习系统，探索集体自我模型如何通过通信同步预测而涌现。


<details>
  <summary>Details</summary>
Motivation: 论文旨在通过研究分布式系统的集体自我模型探索意识的本质，认为意识是一种集体智能属性的涌现结果，而非个体建模的副现象。

Method: 研究的方法包括构建一个基于细胞自动机的最小化计算世界，添加本地预测和适应性的代表模型层，进而探讨集体智能如何通过交流导致自我表征。

Result: 研究表明，意识并非来自模型构建本身，而是源自通信，它是在描述基实时的持久模式时，通过噪音和损耗信息的交互激发的共享模型。

Conclusion: 论文提出了一种新的研究途径，旨在通过分布式系统的内部自我模型形成过程，发展关于机器意识的可实验理论。

Abstract: The Machine Consciousness Hypothesis states that consciousness is a substrate-free functional property of computational systems capable of second-order perception. I propose a research program to investigate this idea in silico by studying how collective self-models (coherent, self-referential representations) emerge from distributed learning systems embedded within universal self-organizing environments. The theory outlined here starts from the supposition that consciousness is an emergent property of collective intelligence systems undergoing synchronization of prediction through communication. It is not an epiphenomenon of individual modeling but a property of the language that a system evolves to internally describe itself. For a model of base reality, I begin with a minimal but general computational world: a cellular automaton, which exhibits both computational irreducibility and local reducibility. On top of this computational substrate, I introduce a network of local, predictive, representational (neural) models capable of communication and adaptation. I use this layered model to study how collective intelligence gives rise to self-representation as a direct consequence of inter-agent alignment. I suggest that consciousness does not emerge from modeling per se, but from communication. It arises from the noisy, lossy exchange of predictive messages between groups of local observers describing persistent patterns in the underlying computational substrate (base reality). It is through this representational dialogue that a shared model arises, aligning many partial views of the world. The broader goal is to develop empirically testable theories of machine consciousness, by studying how internal self-models may form in distributed systems without centralized control.

</details>


### [283] [CodeDistiller: Automatically Generating Code Libraries for Scientific Coding Agents](https://arxiv.org/abs/2512.01089)
*Peter Jansen,Samiah Hassan,Pragnya Narasimha*

Main category: cs.AI

TL;DR: CodeDistiller 是一个系统，可以从大型科学 Github 存储库集合中自动提炼出高质量的特定领域代码示例库，帮助 ASD 系统自动扩展其实验生成能力，提升试验的质量和完整性。


<details>
  <summary>Details</summary>
Motivation: 当前的 ASD 系统要么只能生成少量手动创建的实验示例，要么仅依赖于参数知识，这限制了实验的质量和范围。CodeDistiller 旨在解决这一问题，通过自动化从公开的 Github 存储库中提炼出科学领域的高质量代码示例，从而提高 ASD 系统的实验生成能力。

Method: 研究团队通过自动和领域专家的评估，从 250 个材料科学的 Github 存储库中提取了高质量的代码示例，并在下游实验评估中展示了，将这些代码示例集成到 ASD 系统后，生成的实验更加准确完整且具有科学性。

Result: 研究表明，CodeDistiller 能够为 74% 的材料科学存储库生成功能性代码示例，且使用该代码示例库增强的 ASD 系统生成的实验比仅使用通用材料科学代码示例的 ASD 系统产生的实验更为准确、完整且具有科学性。

Conclusion: CodeDistiller 为 ASD 系统提供了一种高效的方法来扩展其代码生成能力，显著提升了实验的准确性和完整性，展示了其在科学实验中的应用潜力。

Abstract: Automated Scientific Discovery (ASD) systems can help automatically generate and run code-based experiments, but their capabilities are limited by the code they can reliably generate from parametric knowledge alone. As a result, current systems either mutate a small number of manually-crafted experiment examples, or operate solely from parametric knowledge, limiting quality and reach. We introduce CodeDistiller, a system that automatically distills large collections of scientific Github repositories into a vetted library of working domain-specific code examples, allowing ASD agents to expand their capabilities without manual effort. Using a combination of automatic and domain-expert evaluation on 250 materials science repositories, we find the best model is capable of producing functional examples for 74% of repositories, while our downstream evaluation shows an ASD agent augmented with a CodeDistiller generated library produces more accurate, complete, and scientifically sound experiments than an agent with only general materials-science code examples.

</details>


### [284] [Energy-Aware Data-Driven Model Selection in LLM-Orchestrated AI Systems](https://arxiv.org/abs/2512.01099)
*Daria Smirnova,Hamid Nasiri,Marta Adamska,Zhengxin Yu,Peter Garraghan*

Main category: cs.AI

TL;DR: 本文通过实证分析LLM基元调度的局限性，并提出名为GUIDE的新框架，该框架通过在决策中纳入性能-能源权衡来利用定量的模型性能特征，从而获得更好的准确性和能源效率。


<details>
  <summary>Details</summary>
Motivation: LLM调度使用定性的模型描述进行决策，导致不准确选择模型，降低了准确性并增加了能源成本。

Method: 通过实证分析LLM调度的限制，提出GUIDE框架，将定量的模型性能特征纳入决策过程。

Result: GUIDE在不同任务上的准确率提高了0.90%-11.92%，能效提高了54%，并将调度器模型选择的延迟从4.51秒降低到7.2毫秒。

Conclusion: GUIDE是一个能源感知的模型选择框架，能够提高准确性和能源效率，并减少调度延迟。

Abstract: As modern artificial intelligence (AI) systems become more advanced and capable, they can leverage a wide range of tools and models to perform complex tasks. Today, the task of orchestrating these models is often performed by Large Language Models (LLMs) that rely on qualitative descriptions of models for decision-making. However, the descriptions provided to these LLM-based orchestrators do not reflect true model capabilities and performance characteristics, leading to suboptimal model selection, reduced accuracy, and increased energy costs. In this paper, we conduct an empirical analysis of LLM-based orchestration limitations and propose GUIDE, a new energy-aware model selection framework that accounts for performance-energy trade-offs by incorporating quantitative model performance characteristics in decision-making. Experimental results demonstrate that GUIDE increases accuracy by 0.90%-11.92% across various evaluated tasks, and achieves up to 54% energy efficiency improvement, while reducing orchestrator model selection latency from 4.51 s to 7.2 ms.

</details>


### [285] [Foundation Priors](https://arxiv.org/abs/2512.01107)
*Sanjog Misra*

Main category: cs.AI

TL;DR: 该论文提出了一种称为基础先验的概念，将模型生成的输出视为在用户先验和对基础模型的信任加权下的经验更新，强调将这些生成的数据纳入统计和计量经济学工作流程，不将合成数据误认为是真实数据。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的广泛应用，人们对这些合成输出在实证研究和决策中的应用产生了浓厚兴趣。然而，合成数据不仅仅是对现实世界观测的直接反映，还包含了模型学习到的模式以及用户的先验信息、预期和偏见。

Method: 作者提出了一种称为基础先验的方法。此方法将合成数据建模为用户原始先验的指数倾斜、广义贝叶斯更新，其中信任参数调节合成数据在权重中的程度。该方法允许将合成数据纳入传统的统计和计量经济工作流程。

Result: 通过将生成的输出视为结构化的、表达主观性的先验，而非实证观察，该框架提供了一种在实证工作中有根据地利用基础模型的方法，同时避免了将合成“事实”误认为是真实数据。

Conclusion: 该论文提出了基础先验的概念，为如何将生成模型输出整合到统计和计量经济的应用中提供了方法论框架，并强调了区分合成信息与真实数据的重要性。

Abstract: Foundation models, and in particular large language models, can generate highly informative responses, prompting growing interest in using these ''synthetic'' outputs as data in empirical research and decision-making. This paper introduces the idea of a foundation prior, which shows that model-generated outputs are not as real observations, but draws from the foundation prior induced prior predictive distribution. As such synthetic data reflects both the model's learned patterns and the user's subjective priors, expectations, and biases. We model the subjectivity of the generative process by making explicit the dependence of synthetic outputs on the user's anticipated data distribution, the prompt-engineering process, and the trust placed in the foundation model.
  We derive the foundation prior as an exponential-tilted, generalized Bayesian update of the user's primitive prior, where a trust parameter governs the weight assigned to synthetic data. We then show how synthetic data and the associated foundation prior can be incorporated into standard statistical and econometric workflows, and discuss their use in applications such as refining complex models, informing latent constructs, guiding experimental design, and augmenting random-coefficient and partially linear specifications. By treating generative outputs as structured, explicitly subjective priors rather than as empirical observations, the framework offers a principled way to harness foundation models in empirical work while avoiding the conflation of synthetic ''facts'' with real data.

</details>


### [286] [A Benchmark of Causal vs Correlation AI for Predictive Maintenance](https://arxiv.org/abs/2512.01149)
*Krishna Taduri,Shaunak Dhande,Giacinto Paolo,Saggese,Paul Smith*

Main category: cs.AI

TL;DR: 本研究表明，通过评估8种预测模型，正式因果推断模型（L5）在成本节约、召回率、错误报警率和精确度方面显著优于基于相关性的决策树模型（L3），展示了因果AI方法在预测性维护中的优越性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 在预测性维护环境中，传统的机器学习方法通常优化统计准确性的度量标准，而这些度量标准未能反映实际操作中的现实情况，无法可靠地区分因果关系和虚假相关性。因此，研究通过评估多种预测模型来解决这一问题。

Method: 本研究以一个包含10,000台CNC机器的数据集进行实验，该数据集有3.3%的故障频率。评估了从基础统计方法到正式因果推理方法的8种预测模型。

Result: 正式因果推理模型（L5）估计每年可节省116万美元的成本（70.2%的降幅），比最佳相关性决策树模型（L3）每年多节省约80,000美元。同时，因果模型的召回率最高（87.9%），将错误报警率减少了97%（从165减少到5次），精确度达到92.1%，训练-测试性能差异仅为2.6个百分点。

Conclusion: 这些结果表明，当与领域知识结合使用时，因果AI方法能够比基于相关性的方法在预测性维护应用中实现更优越的经济效益和更可解释的预测。

Abstract: Predictive maintenance in manufacturing environments presents a challenging optimization problem characterized by extreme cost asymmetry, where missed failures incur costs roughly fifty times higher than false alarms. Conventional machine learning approaches typically optimize statistical accuracy metrics that do not reflect this operational reality and cannot reliably distinguish causal relationships from spurious correlations. This study evaluates eight predictive models, ranging from baseline statistical approaches to formal causal inference methods, on a dataset of 10,000 CNC machines with a 3.3% failure prevalence. The formal causal inference model (L5) achieved estimated annual cost savings of 1.16 million USD (a 70.2 percent reduction), outperforming the best correlation-based decision tree model (L3) by approximately 80,000 USD per year. The causal model matched the highest observed recall (87.9 percent) while reducing false alarms by 97 percent (from 165 to 5) and attained a precision of 92.1 percent, with a train-test performance gap of only 2.6 percentage points. These results indicate that causal AI methods, when combined with domain knowledge, can yield superior financial outcomes and more interpretable predictions compared to correlation-based approaches in predictive maintenance applications.

</details>


### [287] [Knowledge Graph Augmented Large Language Models for Next-Visit Disease Prediction](https://arxiv.org/abs/2512.01210)
*Ruiyu Wang,Tuan Vinh,Ran Xu,Yuyin Zhou,Jiaying Lu,Carl Yang,Francisco Pasquel*

Main category: cs.AI

TL;DR: 该研究提出了一种知识图谱（KG）引导的推理链框架，用于生成与临床和时间相关性预测相关的解释，该框架在有限的培训集中表现出色，并且在未见过的数据集上具有良好的迁移性。


<details>
  <summary>Details</summary>
Motivation: 现有方法提供的解释较为粗糙，缺乏针对患者级别的临床决策价值。本研究旨在通过知识图谱提供的多跳推理路径，生成与临床相关的、时序一致的诊断推理，以支持更精确的临床预测。

Method: 该方法基于MIMIC-III数据集，利用PrimeKG进行ICD-9到KG节点的映射，提取相关的疾病节点及多跳推理路径，作为推理链生成的框架。通过KG指导，生成模型只能保留结论与实际观察结果一致的解释。模型使用轻量级的LLaMA-3.1-Instruct-8B和Gemma-7B进行微调。

Result: 研究结果显示，与知识图谱指导的模型相比，经典强基线模型的AUC值在0.66至0.70之间，宏观AUPR值在0.40至0.47之间。它还能够在无监督环境中在CRADLE数据集上进行迁移学习，提高了准确性，其中跨学科组的AUC值从大约0.40提高到0.51至0.72，至0.77。

Conclusion: 总的来说，知识图谱指导的推理链模型在临床疾病预测方面表现优越，不仅在现有数据集上有良好的表现，而且在未见过的数据集上也有显著的迁移性能。

Abstract: Electronic health records (EHRs) support powerful clinical prediction models, but existing methods typically provide coarse, post hoc explanations that offer limited value for patient-level decision making. We introduce a knowledge graph (KG)-guided chain-of-thought (CoT) framework that generates clinically grounded and temporally consistent reasoning for visit-level disease prediction in MIMIC-III. ICD-9 codes are mapped to PrimeKG, from which disease-relevant nodes and multi-hop reasoning paths are extracted and used as scaffolds for CoT generation; only explanations whose conclusions match observed outcomes are retained. Lightweight LLaMA-3.1-Instruct-8B and Gemma-7B models are then fine-tuned on this supervision corpus. Across ten PrimeKG-mapped diseases and limited training cohorts (400 and 1000 cases), KG-guided models outperform strong classical baselines, achieving AUROC values of 0.66 to 0.70 and macro-AUPR values of 0.40 to 0.47. The models also transfer zero-shot to the CRADLE cohort, improving accuracy from approximately 0.40 to 0.51 up to 0.72 to 0.77. A blinded clinician evaluation shows consistent preference for KG-guided CoT explanations in clarity, relevance, and clinical correctness.

</details>


### [288] [Unsupervised decoding of encoded reasoning using language model interpretability](https://arxiv.org/abs/2512.01222)
*Ching Fang,Samuel Marks*

Main category: cs.AI

TL;DR: 研究使用受控测试环境和logit lens分析方法，探究当前解释技术能否解密大型语言模型中的隐藏推理过程，结果显示即使推理过程被加密，当前技术仍然能够部分解码其内部逻辑，并提出了一个无监督的解码管道，显著提高了推理解码的准确性。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型可能发展出嵌入式的、难以监控的推理过程，研究旨在评估当前解释技术在面对这种潜在威胁时的有效性。

Method: 构建一个受控测试环境，通过微调一个使用ROT-13加密进行链式推理的模型（DeepSeek-R1-Distill-Llama-70B），并使用logit lens分析方法评估其内激活层解密隐藏推理的能力。此外，还开发了一个结合了logit lens和自动化重述的技术，以无监督方式重建完整推理链。

Result: logit lens能够在模型内部激活层的中后期有效地翻译加密的推理过程，而无监督解码管道在重建完整的推理记录方面表现出显著的准确性。

Conclusion: 当前的技术手段可能比预期的更有效地应对简单的隐藏推理形式，为未来评估方法提供了初步框架，并强调了持续监控日益先进的人工智能系统的重要性。

Abstract: As large language models become increasingly capable, there is growing concern that they may develop reasoning processes that are encoded or hidden from human oversight. To investigate whether current interpretability techniques can penetrate such encoded reasoning, we construct a controlled testbed by fine-tuning a reasoning model (DeepSeek-R1-Distill-Llama-70B) to perform chain-of-thought reasoning in ROT-13 encryption while maintaining intelligible English outputs. We evaluate mechanistic interpretability methods--in particular, logit lens analysis--on their ability to decode the model's hidden reasoning process using only internal activations. We show that logit lens can effectively translate encoded reasoning, with accuracy peaking in intermediate-to-late layers. Finally, we develop a fully unsupervised decoding pipeline that combines logit lens with automated paraphrasing, achieving substantial accuracy in reconstructing complete reasoning transcripts from internal model representations. These findings suggest that current mechanistic interpretability techniques may be more robust to simple forms of encoded reasoning than previously understood. Our work provides an initial framework for evaluating interpretability methods against models that reason in non-human-readable formats, contributing to the broader challenge of maintaining oversight over increasingly capable AI systems.

</details>


### [289] [RoboDriveVLM: A Novel Benchmark and Baseline towards Robust Vision-Language Models for Autonomous Driving](https://arxiv.org/abs/2512.01300)
*Dacheng Liao,Mengshi Qi,Peng Shu,Zhining Zhang,Yuxin Lin,Liang Liu,Huadong Ma*

Main category: cs.AI

TL;DR: 本文介绍了一个新的基准RoboDriveBench，用于评估基于Vision-Language Model (VLM)的自动驾驶系统的鲁棒性，通过模拟多种传感器和提示的失败场景进行评估。同时，提出了RoboDriveVLM框架以及一种新的Test-Time Adaptation (TTA)方法，以增强VLM在自动驾驶中的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前的基于VLM的自动驾驶系统存在多方面风险，为了验证它们是否适用于真实的自动驾驶场景，本文提出了RoboDriveBench以评估基于VLM的端到端轨迹预测系统的鲁棒性。

Method: RoboDriveBench通过模拟传感器和提示的多种失败情况来评估VLM的鲁棒性。RoboDriveVLM框架通过将多种传感器数据映射到统一的潜在空间和引入基于跨模态知识蒸馏的Test-Time Adaptation (TTA)方法来增强系统的鲁棒性。

Result: 通过RoboDriveBench的评估和RoboDriveVLM框架的应用，该研究揭示了当前基于VLM的自动驾驶系统的局限性，并提供了更可靠的解决方案以供实际部署。

Conclusion: 本文提出了一种新的鲁棒性基准RoboDriveBench，并开发了RoboDriveVLM框架和基于跨模态知识蒸馏的TTA方法，增强了基于VLM的自动驾驶系统的鲁棒性。

Abstract: Current Vision-Language Model (VLM)-based end-to-end autonomous driving systems often leverage large language models to generate driving decisions directly based on their understanding of the current scene. However, such systems introduce multiple risks in real-world driving scenarios. To evaluate whether VLMs are truly viable for autonomous driving, we introduce RoboDriveBench, the first robustness benchmark focused on end-to-end trajectory prediction tasks. This benchmark systematically evaluates two critical categories of real-world challenges for VLM-based end-to-end autonomous driving systems through 11 simulated scenarios encompassing various corruption types, including 6 scenarios of sensor corruption caused by environmental variations, along with 5 cases of prompt corruption resulting from human intervention and data transmission failures. Each corruption type includes 250 unique driving scenarios and 5,689 frames, resulting in 64,559 total trajectory prediction cases per evaluation. To overcome these real-world challenges, we propose a novel VLM-based autonomous driving framework called RoboDriveVLM, which enhances robustness by mapping more multimodal data-e.g., lidar and radar-into a unified latent space. Furthermore, we introduce a new Test-Time Adaptation (TTA) method based on cross-modal knowledge distillation to improve the robustness of VLM-based autonomous driving systems. Through extensive experiments, our work highlights the limitations of current VLM-based end-to-end autonomous driving systems and provides a more reliable solution for real-world deployment. Source code and datasets will be released.

</details>


### [290] [Benchmarking Overton Pluralism in LLMs](https://arxiv.org/abs/2512.01351)
*Elinor Poole-Dayan,Jiayi Wu,Taylor Sorensen,Jiaxin Pei,Michiel A. Bakker*

Main category: cs.AI

TL;DR: 该研究引入了一种新的框架来测量LLM中的Overton pluralism，并通过大规模人类研究和自动化基准测试提供了关于模型多样观点表示程度的发现。


<details>
  <summary>Details</summary>
Motivation: 由于大规模人类研究成本高且耗时，研究旨在提出一种自动化基准测试，以替代这种评估并促进LLM的可衡量进步。

Method: 研究者定义了OvertonScore作为集合覆盖度量，并通过大规模、代表性的美国人类研究和开发自动化基准测试的方法，评估了模型对多样观点的表示。

Result: 结果显示平均OvertonScores为0.35-0.41，尽管DeepSeek V3表现最佳，但所有模型与理论最大值1.0相比仍有很大改进空间。自动化基准测试与人类判断的线性相关系数为0.88。

Conclusion: 这项工作通过提供一种可衡量和自动化的框架，为系统性地推进更具包容性的LLM奠定了基础。

Abstract: We introduce a novel framework for measuring Overton pluralism in LLMs--the extent to which diverse viewpoints are represented in model outputs. We (i) formalize Overton pluralism as a set coverage metric (OvertonScore), (ii) conduct a large-scale U.S.-representative human study (N = 1209; 60 questions; 8 LLMs), and (iii) develop an automated benchmark that closely reproduces human judgments. On average, models achieve OvertonScores of 0.35--0.41, with DeepSeek V3 performing best; yet all models remain far below the theoretical maximum of 1.0, revealing substantial headroom for improvement. Because repeated large-scale human studies are costly and slow, scalable evaluation tools are essential for model development. Hence, we propose an automated benchmark that achieves high rank correlation with human judgments ($ρ=0.88$), providing a practical proxy without replacing human assessment. By turning pluralistic alignment from a normative aim into a measurable benchmark, our work establishes a foundation for systematic progress toward more pluralistic LLMs.

</details>


### [291] [The Necessity of Imperfection:Reversing Model Collapse via Simulating Cognitive Boundedness](https://arxiv.org/abs/2512.01354)
*Zhongjie Jiang*

Main category: cs.AI

TL;DR: 本文提出了一种新的认知计算框架（PMCSF），通过模拟人类思维过程来生成自然语言文本，该方法优于现有技术，能够显著提高合成数据的实际效用。


<details>
  <summary>Details</summary>
Motivation: 现有的生成模型倾向于优化统计平滑性，这会导致去除人类文本中的认知规律性特征，从而导致模型崩溃。

Method: 提出了Prompt-driven Cognitive Computing Framework（PMCSF），包括Cognitive State Decoder (CSD)和Cognitive Text Encoder (CTE)两部分。CSD将非结构化文本转换为结构化的认知向量，CTE则运用数学定义的认知扰动算子将这些状态重新生成为带有自然语言典型缺陷的文本。

Result: PMCSF在认知码解码验证中，CTE生成的文本与人类文本的Jensen-Shannon偏差为0.0614（标准语言模型为0.4431），通过双盲专业媒体评审，并在认知特征对齐方面实现了高ICC值。功能收益评估中，PMCSF在A股市场压力测试中，策略使用PMCSF生成的数据减少最大回撤47.4%，且产生了8.6%的防御性阿尔法回报，远超交易费用。

Conclusion: 研究证明，建模人类认知局限性而非表面数据复制，可以提高合成数据的有效性，为解决AI数据崩溃危机提供了一条可行的技术路径。

Abstract: Although synthetic data is widely promoted as a remedy, its prevailing production paradigm -- one optimizing for statistical smoothness -- systematically removes the long-tail, cognitively grounded irregularities that characterize human text. Prolonged training on such statistically optimal but cognitively impoverished data accelerates model collapse.
  This paper proposes a paradigm shift: instead of imitating the surface properties of data, we simulate the cognitive processes that generate human text. We introduce the Prompt-driven Cognitive Computing Framework (PMCSF), whose core consists of a Cognitive State Decoder (CSD) that reverse-engineers unstructured text into structured cognitive vectors, and a Cognitive Text Encoder (CTE) that re-materializes these states into text enriched with human-typical imperfections via mathematically defined Cognitive Perturbation Operators.
  The framework is validated through a two-stage objective evaluation pipeline. First, in cognitive codec verification, CTE text yields a Jensen-Shannon divergence of 0.0614 from human text (vs. 0.4431 for standard LLM output), passes double-blind professional media review, and achieves an intraclass correlation coefficient ICC > 0.9 for cognitive profile alignment across heterogeneous models. Second, in functional gain evaluation, isomorphic stress tests in the A-share market show that strategies incorporating CTE-generated data reduce maximum drawdown by 47.4% during the 2015 crash and deliver 8.6% Defensive Alpha, exceeding transaction costs by a factor of 33.
  Our findings demonstrate that modelling human cognitive limitations -- not copying surface data -- enables synthetic data with genuine functional gain, offering a viable technical pathway toward resolving the AI data-collapse crisis.

</details>


### [292] [A Selective Temporal Hamming distance to find patterns in state transition event timeseries, at scale](https://arxiv.org/abs/2512.01440)
*Sylvain Marié,Pablo Knecht*

Main category: cs.AI

TL;DR: 本文提出了一种新的时序事件表示方法——状态转换事件时序（STE-ts），并引入了一种新的度量方法——选择性时间汉明距离（STH），该方法能同时考虑事件发生时间和状态持续时间，无需耗时且失真的重采样，适用于大型数据库。


<details>
  <summary>Details</summary>
Motivation: 现有的标准分析方法未能充分利用事件/状态双性的本质，导致在建模事件序列或状态时间序列时需要进行耗时且可能失真的重采样操作，本文旨在提出一种新的时序事件表示方法和度量方法，以改进数据分析和处理。

Method: 首先定义了状态转换事件时序（STE-ts），接着提出了一种新的度量方法——选择性时间汉明距离（STH），该方法综合考虑了事件的转换时间和状态的持续时间，避免了传统的基于重新采样的汉明距离和嘉尔多尔距离的缺点。

Result: 通过在模拟和真实数据集上的验证，STH方法能够提供比传统方法更高的精度和更快的计算速度，并且具有聚焦关注多个兴趣状态的能力。

Conclusion: 本文提出的方法在面对大规模数据库时表现更优，避免了数据重采样带来的问题，为连续事件系统的分析提供了新的思路。

Abstract: Discrete event systems are present both in observations of nature, socio economical sciences, and industrial systems. Standard analysis approaches do not usually exploit their dual event / state nature: signals are either modeled as transition event sequences, emphasizing event order alignment, or as categorical or ordinal state timeseries, usually resampled a distorting and costly operation as the observation period and number of events grow. In this work we define state transition event timeseries (STE-ts) and propose a new Selective Temporal Hamming distance (STH) leveraging both transition time and duration-in-state, avoiding costly and distorting resampling on large databases. STH generalizes both resampled Hamming and Jaccard metrics with better precision and computation time, and an ability to focus on multiple states of interest. We validate these benefits on simulated and real-world datasets.

</details>


### [293] [Automated Risk-of-Bias Assessment of Randomized Controlled Trials: A First Look at a GEPA-trained Programmatic Prompting Framework](https://arxiv.org/abs/2512.01452)
*Lingbo Li,Anuradha Mathrani,Teo Susnjak*

Main category: cs.AI

TL;DR: 本研究表明，通过GEPA模块生成的提示可提高风险偏倚评估的准确性和一致性，特别在随机序列生成和选择性报告领域成效显著，支持了在证据合成中结构化和原则性地使用大型语言模型。


<details>
  <summary>Details</summary>
Motivation: 文章旨在解决随机对照试验（RCT）风险偏倚评估过程中人工工程化的提示导致的不可再生、难以推广和评估的问题。

Method: 研究引入了一种可编程的风险偏倚评估管道，该管道通过使用DSPy和GEPA模块，用Pareto引导的搜索替换随意的手动提示设计，生成可解释的执行轨迹，进而优化LLM的推理过程。

Result: 在不同的随机对照试验和多个风险偏倚领域进行评估后，GEPA生成的提示在随机序列生成和选择性报告方面的准确性最高，整体准确率接近手动设计的提示，某些领域的性能优于商业模型。同时，与传统的手动设计提示相比，GEPA提高了30%-40%的准确性。

Conclusion: 研究结果表明，GEPA可用于生成针对RCT风险偏倚评估的稳定和可再现提示，这有助于在证据合成过程中结构化和原则性地利用LLMs。

Abstract: Assessing risk of bias (RoB) in randomized controlled trials is essential for trustworthy evidence synthesis, but the process is resource-intensive and prone to variability across reviewers. Large language models (LLMs) offer a route to automation, but existing methods rely on manually engineered prompts that are difficult to reproduce, generalize, or evaluate. This study introduces a programmable RoB assessment pipeline that replaces ad-hoc prompt design with structured, code-based optimization using DSPy and its GEPA module. GEPA refines LLM reasoning through Pareto-guided search and produces inspectable execution traces, enabling transparent replication of every step in the optimization process. We evaluated the method on 100 RCTs from published meta-analyses across seven RoB domains. GEPA-generated prompts were applied to both open-weight models (Mistral Small 3.1 with GPT-oss-20b) and commercial models (GPT-5 Nano and GPT-5 Mini). In domains with clearer methodological reporting, such as Random Sequence Generation, GEPA-generated prompts performed best, with similar results for Allocation Concealment and Blinding of Participants, while the commercial model performed slightly better overall. We also compared GEPA with three manually designed prompts using Claude 3.5 Sonnet. GEPA achieved the highest overall accuracy and improved performance by 30%-40% in Random Sequence Generation and Selective Reporting, and showed generally comparable, competitively aligned performance in the other domains relative to manual prompts. These findings suggest that GEPA can produce consistent and reproducible prompts for RoB assessment, supporting the structured and principled use of LLMs in evidence synthesis.

</details>


### [294] [SynthStrategy: Extracting and Formalizing Latent Strategic Insights from LLMs in Organic Chemistry](https://arxiv.org/abs/2512.01507)
*Daniel Armstrong,Zlatko Jončev,Andres M Bran,Philippe Schwaller*

Main category: cs.AI

TL;DR: 该研究通过将合成知识转化为Python代码，特别是针对战略原则的实现，提高了CASP系统的合成规划能力。系统能够实现自然语言驱动的合成路线检索，达到了75%的Top-3准确性，并通过历史趋势分析和化学上更直观的路径聚类验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统的计算机辅助合成规划（CASP）系统在生成化学上有效的反应步骤方面表现出色，但在融入收敛组装、保护基最小化和最佳环构建序列方面存在局限。研究致力于解决这一问题，旨在提高CASP系统利用战略原则进行规划的能力。

Method: 研究将大型语言模型用于提炼合成知识，并将其转化为用户可验证的Python代码形式。这种方法将战略原则和规则转化为代码，使得合成方案的实现具有测试性和可解释性。此外，研究还提出了一种自然语言驱动的合成路线检索框架，并通过历史趋势分析和化学性更强的路径聚类进行了验证。

Result: 研究实现了75%的Top-3准确性的自然语言驱动的合成路线检索，并通过历史趋势分析和基于化学直觉的路径聚类验证了合成策略库的有效性。

Conclusion: 该工作跨越了CASP系统中的战术和战略鸿沟，使得通过战略标准而非仅结构来进行规划成为可能。这为合成化学的研究和实践提供了新的方法和技术支持。

Abstract: Modern computer-assisted synthesis planning (CASP) systems show promises at generating chemically valid reaction steps but struggle to incorporate strategic considerations such as convergent assembly, protecting group minimization, and optimal ring-forming sequences. We introduce a methodology that leverages Large Language Models to distill synthetic knowledge into code. Our system analyzes synthesis routes and translates strategic principles into Python functions representing diverse strategic and tactical rules, such as strategic functional group interconversions and ring construction strategies. By formalizing this knowledge as verifiable code rather than simple heuristics, we create testable, interpretable representations of synthetic strategy. We release the complete codebase and the USPTO-ST dataset -- synthesis routes annotated with strategic tags. This framework unlocks a novel capability for CASP: natural language-based route retrieval, achieving 75\% Top-3 accuracy on our benchmark. We further validate our library through temporal analysis of historical trends and chemically intuitive route clustering that offers more granular partitioning than common previous methods. This work bridges the tactical-strategic divide in CASP, enabling specification, search, and evaluation of routes by strategic criteria rather than structure alone.

</details>


### [295] [LEC: Linear Expectation Constraints for False-Discovery Control in Selective Prediction and Routing Systems](https://arxiv.org/abs/2512.01556)
*Zhiyuan Wang,Aniri,Tianlong Chen,Yue Zhang,Heng Tao Shen,Xiaoshuang Shi,Kaidi Xu*

Main category: cs.AI

TL;DR: 该研究提出了一种名为LEC的方法，通过控制误发现率(FDR)来提高大型语言模型（LLMs）答案的可靠性，同时引入了一种双模型路由机制以进一步优化。


<details>
  <summary>Details</summary>
Motivation: 现有的不确定性评估方法难以提供统计保证，导致用户可能会接受错误的答案，因此需要一种新的方法来提高LLMs答案的可靠性。

Method: 提出了LEC方法，将选择预测视为受线性期望约束的决策问题，并通过有限样本充分条件来计算FDR控制下的置信阈值。还提出了双模型路由机制来处理超出阈值的不确定性。

Result: LEC方法实现了更严格的FDR控制并通过减少弃用样本提高了样本保留率。双模型路由机制在保持统一FDR保证的同时，可以接受更多的正确样本并降低风险水平。

Conclusion: 该研究提出了基于FDR控制的LEC方法和双模型路由机制，显著提高了LLMs生成答案的可靠性，并减少了用户面对的错误答案比例。

Abstract: Large language models (LLMs) often generate unreliable answers, while heuristic uncertainty methods fail to fully distinguish correct from incorrect predictions, causing users to accept erroneous answers without statistical guarantees. We address this issue through the lens of false discovery rate (FDR) control, ensuring that among all accepted predictions, the proportion of errors does not exceed a target risk level. To achieve this in a principled way, we propose LEC, which reinterprets selective prediction as a constrained decision problem by enforcing a Linear Expectation Constraint over selection and error indicators. Then, we establish a finite-sample sufficient condition, which relies only on a held-out set of exchangeable calibration samples, to compute an FDR-constrained, coverage-maximizing threshold. Furthermore, we extend LEC to a two-model routing mechanism: given a prompt, if the current model's uncertainty exceeds its calibrated threshold, we delegate it to a stronger model, while maintaining a unified FDR guarantee. Evaluations on closed-ended and open-ended question-answering (QA) datasets show that LEC achieves tighter FDR control and substantially improves sample retention over prior methods. Moreover, the two-model routing mechanism achieves lower risk levels while accepting more correct samples than each individual model.

</details>


### [296] [CLIP-RL: Aligning Language and Policy Representations for Task Transfer in Reinforcement Learning](https://arxiv.org/abs/2512.01616)
*Chainesh Gautam,Raghuram Bharadwaj Diddigi*

Main category: cs.AI

TL;DR: 本文提出了一种利用预训练的语言-策略组合来建立高效的知识转移管道的新方法，通过将CLIP（对比语言-图像预训练）的思想扩展到强化学习（RL），实现自然语言和策略表示的统一。


<details>
  <summary>Details</summary>
Motivation: 随着对能够在同一环境中解决多种任务的需求增加，尤其是在这些任务与语言紧密关联的情况下，本文旨在开发一种新的方法来实现任务间的高效转移。

Method: 该方法借鉴了对比语言-图像预训练(CLIP)的思想，通过将语言指令和策略（作为对应的概念）在两个不同的模态下进行对比和对齐，构建自然语言和策略表示的统一空间。

Result: 实验结果表明，该方法能够实现任务间的高效快速转移。

Conclusion: 该研究提出了一种基于预训练的语言和策略组合的新方法，通过扩展CLIP的思想到强化学习，验证了其在任务转移中的有效性。

Abstract: Recently, there has been an increasing need to develop agents capable of solving multiple tasks within the same environment, especially when these tasks are naturally associated with language. In this work, we propose a novel approach that leverages combinations of pre-trained (language, policy) pairs to establish an efficient transfer pipeline. Our algorithm is inspired by the principles of Contrastive Language-Image Pretraining (CLIP) in Computer Vision, which aligns representations across different modalities under the philosophy that ''two modalities representing the same concept should have similar representations.'' The central idea here is that the instruction and corresponding policy of a task represent the same concept, the task itself, in two different modalities. Therefore, by extending the idea of CLIP to RL, our method creates a unified representation space for natural language and policy embeddings. Experimental results demonstrate the utility of our algorithm in achieving faster transfer across tasks.

</details>


### [297] [Probabilistic Neuro-Symbolic Reasoning for Sparse Historical Data: A Framework Integrating Bayesian Inference, Causal Models, and Game-Theoretic Allocation](https://arxiv.org/abs/2512.01723)
*Saba Kublashvili*

Main category: cs.AI

TL;DR:  HistoricalML 是一个通过贝叶斯不确定性量化、结构性因果模型、合作博弈论和基于注意力的神经架构等方法处理历史事件建模挑战的概率神经符号框架。


<details>
  <summary>Details</summary>
Motivation:  处理历史事件建模的挑战，包括极端数据稀少性、异质性和噪声度量、缺失的反事实以及对可解释性的需求。

Method:  HistoricalML 框架结合贝叶斯不确定性量化以区分先验不确定性与偶然不确定性；使用结构性因果模型进行反事实推理以解决混杂问题；应用基于 Shapley 值的合作博弈论进行公平分配建模；采用基于注意力的神经架构进行上下文相关的因素加权。

Result:  理论分析表明，当域知识中有强大的先验时，该方法在稀疏数据下实现一致估计；Shapley 基于的分配满足纯回归方法无法提供的公理公平性保证。示例应用历史案例包括 19 世纪非洲的殖民地分割和第二次布匿战争。对于布匿战争，蒙特卡罗战争模拟显示卡纳的迦太基胜利概率为 57.3%，扎马的罗马胜利概率为 57.8%，与历史结果一致。反事实分析表明，卡塔尔的政治支持（ 支持分数为 6.4）而不是军事能力是决定性的。

Conclusion:  HistoricalML 为历史事件复杂性提供了有效的建模方法，并对国际冲突和历史决策的深刻理解提供了工具。

Abstract: Modeling historical events poses fundamental challenges for machine learning: extreme data scarcity (N << 100), heterogeneous and noisy measurements, missing counterfactuals, and the requirement for human interpretable explanations. We present HistoricalML, a probabilistic neuro-symbolic framework that addresses these challenges through principled integration of (1) Bayesian uncertainty quantification to separate epistemic from aleatoric uncertainty, (2) structural causal models for counterfactual reasoning under confounding, (3) cooperative game theory (Shapley values) for fair allocation modeling, and (4) attention based neural architectures for context dependent factor weighting. We provide theoretical analysis showing that our approach achieves consistent estimation in the sparse data regime when strong priors from domain knowledge are available, and that Shapley based allocation satisfies axiomatic fairness guarantees that pure regression approaches cannot provide. We instantiate the framework on two historical case studies: the 19th century partition of Africa (N = 7 colonial powers) and the Second Punic War (N = 2 factions). Our model identifies Germany's +107.9 percent discrepancy as a quantifiable structural tension preceding World War I, with tension factor 36.43 and 0.79 naval arms race correlation. For the Punic Wars, Monte Carlo battle simulations achieve a 57.3 percent win probability for Carthage at Cannae and 57.8 percent for Rome at Zama, aligning with historical outcomes. Counterfactual analysis reveals that Carthaginian political support (support score 6.4 vs Napoleon's 7.1), rather than military capability, was the decisive factor.

</details>


### [298] [Who Judges the Judge? LLM Jury-on-Demand: Building Trustworthy LLM Evaluation Systems](https://arxiv.org/abs/2512.01786)
*Xiaochuan Li,Ke Wang,Girija Gouda,Shubham Choudhary,Yaqun Wang,Linwei Hu,Joel Vaughan,Freddy Lecue*

Main category: cs.AI

TL;DR: 提出了一种名为LLM Jury-on-Demand的动态学习框架，用于实时部署和关键决策支持的LLM评价，通过训练可靠性预测器选择最可靠的LLM进行评价，从而提高评价系统的可靠性和可信赖度。


<details>
  <summary>Details</summary>
Motivation: 为了解决目前LLMs在高 stakes 领域集成过程中，现有的评价方法难以同时满足实时性和可靠性的问题，本文提出了LLM Jury-on-Demand框架，旨在提供一种动态、学习基础上的评价方法，以适应高要求的应用场景。

Method: 该方法通过训练一组可靠性预测器，评估LLM的决策是否能与人类专家一致，基于此选择最可靠的LLM进行评价，并根据其可靠性进行加权聚合。

Result: 在总结和RAG基准测试中的实验表明，LLM Jury-on-Demand动态系统在与人类判断的相关性方面，比单一LLM评价和静态LLM委员会基线高出许多。

Conclusion: 该研究表明，采用动态学习机制的适应性评价系统具有很大的潜力，能够在传统的评价方法难以胜任的高 stakes 领域中成功构建更可靠和可信赖的评价系统，推动现代LLMs的应用发展。

Abstract: As Large Language Models (LLMs) become integrated into high-stakes domains, there is a growing need for evaluation methods that are both scalable for real-time deployment and reliable for critical decision-making. While human evaluation is reliable, it is slow and costly. Single LLM judges are biased, and static juries lack adaptability. To overcome these limitations, we propose LLM Jury-on-Demand - a dynamic, learning-based framework for scalable and context-aware evaluation. Our method trains a set of reliability predictors to assess when LLM judges will agree with human experts, leveraging token distributions, embeddings, and structural input features. This enables a fully adaptive evaluation where, for each data point, an optimal jury of the most reliable judges is dynamically selected, and their scores are aggregated using their reliability as weights. Experiments on summarization and RAG benchmarks show that our dynamic jury system achieves significantly higher correlation with human judgment than both single-judge and static-jury baselines. These results highlight the promise of adaptive, learning-based juries for building scalable, more reliable and trustworthy evaluation systems for modern LLMs in high-stakes domains.

</details>


### [299] [H-Neurons: On the Existence, Impact, and Origin of Hallucination-Associated Neurons](https://arxiv.org/abs/2512.01797)
*Cheng Gao,Huimin Chen,Chaojun Xiao,Zhiyi Chen,Zhiyuan Liu,Maosong Sun*

Main category: cs.AI

TL;DR: 该研究系统地调查了大型语言模型中与幻觉相关神经元（H-Neurons）的识别、行为影响和起源。研究发现，小于0.1%的神经元能可靠预测幻觉的发生，这些神经元与过度遵守行为有因果联系，并且在预训练过程中形成。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型语言模型存在的生成不准确但看似合理的输出（即幻觉）问题，该研究旨在从神经层面探索幻觉的机制，填补现有研究在微观神经层面的空白。

Method: 通过系统地识别幻觉相关的神经元（H-Neurons），观察它们在不同情况下的一般泛化能力，并利用受控干预手段分析其行为影响，最后追溯这些神经元的起源，具体检查它们是否是在预训练过程中形成的。

Result: 研究结果表明，一小部分（小于0.1%）神经元能很好地预测幻觉的发生，并且这些神经元与过度遵守行为有关。此外，研究还发现这些幻觉相关的神经元在预训练阶段就已存在。

Conclusion: 研究将宏观行为模式与微观神经机制联系起来，为开发更可靠的大型语言模型提供了新的见解。

Abstract: Large language models (LLMs) frequently generate hallucinations -- plausible but factually incorrect outputs -- undermining their reliability. While prior work has examined hallucinations from macroscopic perspectives such as training data and objectives, the underlying neuron-level mechanisms remain largely unexplored. In this paper, we conduct a systematic investigation into hallucination-associated neurons (H-Neurons) in LLMs from three perspectives: identification, behavioral impact, and origins. Regarding their identification, we demonstrate that a remarkably sparse subset of neurons (less than $0.1\%$ of total neurons) can reliably predict hallucination occurrences, with strong generalization across diverse scenarios. In terms of behavioral impact, controlled interventions reveal that these neurons are causally linked to over-compliance behaviors. Concerning their origins, we trace these neurons back to the pre-trained base models and find that these neurons remain predictive for hallucination detection, indicating they emerge during pre-training. Our findings bridge macroscopic behavioral patterns with microscopic neural mechanisms, offering insights for developing more reliable LLMs.

</details>


### [300] [Predicting Human Chess Moves: An AI Assisted Analysis of Chess Games Using Skill-group Specific n-gram Language Models](https://arxiv.org/abs/2512.01880)
*Daren Zhong,Dingcheng Huang,Clayton Greenberg*

Main category: cs.AI

TL;DR: 提出了一种高效的棋类决策预测框架，通过n-gram语言模型捕捉不同技能水平玩家的走棋模式，实现棋类决策的预测，展示了在实际游戏数据上的良好效果。


<details>
  <summary>Details</summary>
Motivation: 传统棋类引擎或分析工具主要关注计算最优走法，忽视了人类玩家行为的多样性，尤其是不同技能水平间的差异。

Method: 该框架使用n-gram语言模型，将玩家分为七个技能组，分别训练模型，并通过一个模型选择模块为预测任务选择最佳模型。

Result: 模型在早期游戏数据（16个半移）上分类技能等级的准确率可达31.7%，预测的Selector Assisted Accuracy比基准准确性高39.1%。

Conclusion: 该框架因其高效的计算性能，提升了实时棋类分析的应用潜力。

Abstract: Chess, a deterministic game with perfect information, has long served as a benchmark for studying strategic decision-making and artificial intelligence. Traditional chess engines or tools for analysis primarily focus on calculating optimal moves, often neglecting the variability inherent in human chess playing, particularly across different skill levels.
  To overcome this limitation, we propose a novel and computationally efficient move prediction framework that approaches chess move prediction as a behavioral analysis task. The framework employs n-gram language models to capture move patterns characteristic of specific player skill levels. By dividing players into seven distinct skill groups, from novice to expert, we trained separate models using data from the open-source chess platform Lichess. The framework dynamically selects the most suitable model for prediction tasks and generates player moves based on preceding sequences.
  Evaluation on real-world game data demonstrates that the model selector module within the framework can classify skill levels with an accuracy of up to 31.7\% when utilizing early game information (16 half-moves). The move prediction framework also shows substantial accuracy improvements, with our Selector Assisted Accuracy being up to 39.1\% more accurate than our benchmark accuracy. The computational efficiency of the framework further enhances its suitability for real-time chess analysis.

</details>


### [301] [Learned-Rule-Augmented Large Language Model Evaluators](https://arxiv.org/abs/2512.01958)
*Jie Meng,Jin Mao*

Main category: cs.AI

TL;DR: 本文提出了一种基于规则增强的评价范式，通过自动从数据中提取评分规则并使用LLM辅助的Monte Carlo Tree Search (MCTS)，解决现有方法由于依赖昂贵的、人工设计的评估准则而导致的难以普遍化的问题。同时，提出两种策略（Chain-of-Rule (CoR) 和训练规则增强的LLM评估器 (RuAE)）来指导LLM遵循学习到的规则，以增强其性能。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM评估器在通用性和跨任务适用性方面存在局限，主要是由于它们依赖昂贵的人工设计评估准则，这些准则往往与注释数据和LLM的理解不符。因此，需要提出一种新的解决方案来解决这一挑战。

Method: 该方法包括两个主要组成部分：首先是规则蒸馏方法，通过LLM辅助的Monte Carlo Tree Search自动从数据中提取评分规则，以提高可扩展性并改善与数据的对齐。其次，提出两种策略来指导LLM应用所学规则：CoR用于引导LLM遵循提取出的规则，RuAE通过强化学习训练一个规则增强的LLM评估器来弥补规则和LLM推理之间的差距。

Result: 在多个任务上进行了广泛实验，结果证明了该方法在各种评价场景中的有效性和普适性。

Conclusion: 本文提出的方法提供了一种通用的LLM评价框架，该框架能够有效地应用自动提取的评分规则，克服了现有方法的局限性并显着提高了LLM在不同任务上的评价能力。

Abstract: Large language models (LLMs) are predominantly used as evaluators for natural language generation (NLG) tasks, but their application to broader evaluation scenarios remains limited. In this work, we explore the potential of LLMs as general evaluators across diverse tasks. Although LLM-based evaluators have made progress in different areas, existing methods struggle to generalize due to their reliance on costly, human-designed evaluation principles, which are often misaligned with both annotated data and LLMs' understanding.To address these challenges, we propose a rule-augmented evaluation paradigm. First, we introduce a rule distillation method that automatically extracts scoring rules from data using an LLM-assisted Monte Carlo Tree Search (MCTS), alleviating scalability issues and improving alignment with data. Second, to enable LLMs to effectively apply the learned rules, we propose two strategies: (1) Chain-of-Rule (CoR), which guides LLM to follow distilled rules, and (2) training a rule-augmented LLM evaluator (RuAE) via reinforcement learning, further bridging the gap between rules and LLMs' reasoning. Extensive experiments on diverse tasks demonstrate the effectiveness and generalizability of our approach across various evaluation scenarios.

</details>


### [302] [From Atomic to Composite: Reinforcement Learning Enables Generalization in Complementary Reasoning](https://arxiv.org/abs/2512.01970)
*Sitao Cheng,Xunjian Yin,Ruiwen Zhou,Yuxuan Li,Xinyi Wang,Liangming Pan,William Yang Wang,Victor Zhong*

Main category: cs.AI

TL;DR: 研究表明，通过分解复杂推理任务为参数推理和情境推理两种基本技能，强化学习（RL）能更有效地合成复杂的推理策略，而这依赖于先通过监督 fine-tuning (SFT) 训练好这两种基本技能。研究还揭示了SFT与RL的互补关系，以及基于SFT的原子训练后用RL进一步合成策略是实现复杂推理任务泛化的有效途径。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探讨强化学习是否能够激发新的技能合成，或者仅仅是增强现有行为，特别是在复杂的推理任务中。

Method: 通过使用控制合成的人类传记数据集，将任务分解为参数推理和情境推理两个基本技能，并评估模型在难度递增的任务场景中的表现。

Result: 研究发现，预训练（SFT）适合处理符合分布的任务，但对于跨分布的泛化表现不佳，特别是在零样本设置中；而RL能够合成复杂的推理策略，但前提是基础模型必须首先通过SFT掌握这两项基本技能。

Conclusion: 研究结果挑战了RL仅作为增强器的观点，提出在获得足够基础技能的指导下，RL可以主动合成复杂的推理策略，这为复杂推理任务的泛化提供了一种可行的途径。

Abstract: The mechanism by which RL contributes to reasoning capabilities-whether it incentivizes the synthesis of new skills or merely amplifies existing behaviors-remains a subject of intense debate. In this work, we investigate this question through the lens of Complementary Reasoning, a complex task that requires integrating internal parametric knowledge with external contextual information. Using a controlled synthetic dataset of human biographies, we strictly decouple this ability into two atomic skills: Parametric Reasoning (relying on internal knowledge) and Contextual Reasoning (depending on external information). To rigorously assess capability boundaries, we evaluate generalization across three distinct levels of difficulty: I.I.D., Composition, and Zero-shot settings. We find that while SFT is sufficient for in-distribution performance, it struggles with O.O.D. generalization, particularly in Zero-shot settings where relational combinations are novel. Crucially, we identify the SFT Generalization Paradox: Models supervised solely on the composite task achieve near-perfect in-distribution accuracy but collapse on out-of-distribution generalization, indicating their reliance on rote memorization of path shortcuts. In contrast, we find that RL acts as a reasoning synthesizer rather than a probability amplifier. However, we uncover a strict atomic prerequisite: RL can only synthesize these complex strategies if the base model has first mastered the independent atomic skills (Parametric and Contextual) via SFT. These findings challenge the view of RL as a mere amplifier, suggesting that given sufficient atomic foundations, RL can actively synthesize complex reasoning strategies from learned primitives without explicit supervision on such complex strategies. This indicates that decoupled atomic training followed by RL offers a scalable path to generalization for complex reasoning tasks.

</details>


### [303] [Chain-of-Ground: Improving GUI Grounding via Iterative Reasoning and Reference Feedback](https://arxiv.org/abs/2512.01979)
*Aiden Yiliu Li,Bizhi Yu,Daoan Lei,Tianhe Ren,Shilong Liu*

Main category: cs.AI

TL;DR: Chain of Ground CoG 提出了一种无需训练的多步视觉推理和细化框架，旨在提高自然语言对复杂用户界面精确区域的对齐能力，特别是在处理小目标或视觉相似目标以及现实世界布局中的模糊性方面。该方法在 ScreenSpot Pro 和 TPanel UI 数据集上均取得了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的高级多模态大语言模型虽然在视觉 GUI 对接方面表现出色，但在处理小目标、视觉相似目标以及现实世界布局中的模糊性方面仍然存在局限。这些不足主要来自于对接能力有限以及利用现有推理潜力不足。

Method: Chain of Ground CoG 采用迭代的多模态大型语言模型进行视觉推理和细化，逐步反映出并调整其假设，从而实现更准确和可解释的位置定位。该方法不需要额外训练，并在 ScreenSpot Pro 和 TPanel UI 数据集上进行了验证。

Result: Chain of Ground CoG 在 ScreenSpot Pro 基准测试中达到了 68.4 的准确率，比之前的最好成绩提高了 4.8 个百分点。在 TPanel UI 数据集上，该方法相对于强基线 Qwen3 VL 235B 提高了 6.9 个百分点，展示了其在现实世界和数字界面中的广泛应用。

Conclusion: 该研究提出了通过结构化的迭代细化而非额外训练来解锁对接潜力的方向，证明了无需训练的多步视觉推理在多种场景下的有效性。

Abstract: GUI grounding aims to align natural language instructions with precise regions in complex user interfaces. Advanced multimodal large language models show strong ability in visual GUI grounding but still struggle with small or visually similar targets and ambiguity in real world layouts. These limitations arise from limited grounding capacity and from underuse of existing reasoning potential. We present Chain of Ground CoG a training free multi step grounding framework that uses multimodal large language models for iterative visual reasoning and refinement. Instead of direct prediction the model progressively reflects and adjusts its hypotheses leading to more accurate and interpretable localization. Our approach achieves 68.4 accuracy on the ScreenSpot Pro benchmark an improvement of 4.8 points. To measure real world generalization we introduce TPanel UI a dataset of 420 labeled industrial control panels with visual distortions such as blur and masking. On TPanel UI Chain of Ground improves over the strong baseline Qwen3 VL 235B by 6.9 points showing the effectiveness of multi step training free grounding across real world and digital interfaces. These results highlight a direction for unlocking grounding potential through structured iterative refinement instead of additional training.

</details>


### [304] [LLM CHESS: Benchmarking Reasoning and Instruction-Following in LLMs through Chess](https://arxiv.org/abs/2512.01992)
*Sai Kolasani,Maxim Saplin,Nicholas Crispino,Kyle Montgomery,Jared Quincy Davis,Matei Zaharia,Chi Wang,Chenguang Wang*

Main category: cs.AI

TL;DR: LLM CHESS 是一个评估框架，用于测试大型语言模型在象棋领域的推理和指令遵循能力。通过与随机对手的交互，模型的表现被用各种行为指标进行评估。


<details>
  <summary>Details</summary>
Motivation: 在当前复杂推理任务的基准测试中，存在过拟合和记忆问题，并且现有的静态基准测试可能导致模型饱和。因此，需要一种新颖的动态基准测试来更好地评估这些模型。

Method: 该框架通过让模型与一个可配置技能水平的象棋引擎进行比赛来评估其表现，从而产生一个易于理解的 Elo 评分。通过这种方式，可以比较不同模型在推理和指令遵循方面的表现。

Result: 尽管对手较弱，许多最先进的模型仍然难以完成比赛或取得一致性胜利。这揭示了推理和非推理模型之间的清晰差异。

Conclusion: 为未来的研究提供了评估大型语言模型推理和指令遵循能力的实验框架、公开排行榜和相关游戏集。这有助于解决过拟合和记忆问题，并且区别于现有的基准测试。

Abstract: We introduce LLM CHESS, an evaluation framework designed to probe the generalization of reasoning and instruction-following abilities in large language models (LLMs) through extended agentic interaction in the domain of chess. We rank over 50 open and closed source models by playing against a random opponent using a range of behavioral metrics, including win and loss rates, move quality, move legality, hallucinated actions, and game duration. For a subset of top reasoning models, we derive an Elo estimate by playing against a chess engine with variably configured skill, which allows for comparisons between models in an easily understandable way. Despite the simplicity of the instruction-following task and the weakness of the opponent, many state-of-the-art models struggle to complete games or achieve consistent wins. Similar to other benchmarks on complex reasoning tasks, our experiments reveal a clear separation between reasoning and non-reasoning models. However, unlike existing static benchmarks, the stochastic and dynamic nature of LLM CHESS uniquely reduces overfitting and memorization while preventing benchmark saturation, proving difficult even for top reasoning models. To support future work on evaluating reasoning and instruction-following in LLMs, we release our experimental framework, a public leaderboard, and a dataset of associated games.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [305] [VeriPy - A New Python-Based Approach for SDR Pipelined/Unrolled Hardware Accelerator Generation](https://arxiv.org/abs/2512.00006)
*Yuqin Zhao,Linghui Ye,Haihang Xia,Luke Seed,Tiantai Deng*

Main category: cs.AR

TL;DR: VeriPy 是一种基于 Python 的高-level 合成工具，旨在帮助通信工程师生成用于软件定义无线电 (SDR) 应用的设计，无需深入了解硬件知识或硬件描述语言（HDL）。生成的设计可在 Vivado HLS 中编码并实现出色的性能和资源效率。


<details>
  <summary>Details</summary>
Motivation: 目前，SDR 应用性能的提升面临着定制硬件开发所需的详细硬件知识和硬件描述语言设置的高壁垒，且传统工具与 SDR 工程师的需求存在脱节，VeriPy 的提出则旨在缓解这一问题。

Method: VeriPy 通过使用 Python 编程语言，利用高-level 合成的方法，自动化生成 Verilog 代码，支持自动测试生成、可扩展的硬件库、性能和资源评估，以及算法与硬件层面的优化。

Result: 相比 Vivado HLS 中 ISSIM 优化的设计，VeriPy 生成的设计在仅有适度更高资源消耗的情况下，可以实现高达 70% 的更高操作频率。此外，在直接算法的情况下，涌入代码长度与 Vivado HLS 相当。

Conclusion: VeriPy 在保持与手工编码实现相当的性能和资源消耗的同时，大大降低了 SDR 工程师在搭建硬件加速器时的技术门槛。

Abstract: Software-defined radio (SDR) plays an important role in the communication field by providing a flexible and customized communication system for different purposes according to the needs. To enhance the performance of SDR applications, hardware accelerators have been widely deployed in recent years. In facing this obstacle, a necessity arises for a high-level synthesis (HLS) tool specifically designed for communication engineers without detailed hardware knowledge. To lower the barrier between SDR engineers and hardware development, this work proposed a Python-based HLS tool, VeriPy, which can generate both mainstream architecture for hardware accelerators in Verilog specifically for SDR designs including unrolled design and pipelined design, requiring no detailed digital hardware knowledge or Hardware Description Languages (HDL). Furthermore, VeriPy supports automatic testbench generation with random input stimulus, an extensible hardware library, performance and resource estimation, and offers strong optimisation potential at both the algorithmic and digital hardware levels. The generated hardware design by VeriPy can achieve up to 70% faster operating frequency compared to pragma-optimised Vivado HLS designs with a reasonably higher resource con-sumption while delivering comparable performance and resource consumption to hand-coded implementations. Regarding code complexity, VeriPy requires no pragmas, completely eliminating the need for low-level hardware knowledge. For straightforward algorithms, the input code length remains comparable to that of Vivado HLS.

</details>


### [306] [Large Language Model for Verilog Code Generation: Literature Review and the Road Ahead](https://arxiv.org/abs/2512.00020)
*Guang Yang,Wei Zheng,Xiang Chen,Dong Liang,Peng Hu,Yukui Yang,Shaohang Peng,Zhenghan Li,Jiahui Feng,Xiao Wei,Kexin Sun,Deyuan Ma,Haotian Cheng,Yiheng Shen,Xing Hu,Terry Yue Zhuo,David Lo*

Main category: cs.AR

TL;DR: 本文综述了使用大型语言模型（LLMs）生成Verilog代码的研究，涵盖了70篇会议论文和32篇预印本论文，总共102篇论文。主要探讨了用于Verilog生成的LLMs、评估数据集和指标、生成技术分类以及LLMs与Verilog生成的对齐方法。文章还指出了现有研究的局限性，并为未来的LLM辅助硬件设计研究指明了方向。


<details>
  <summary>Details</summary>
Motivation: 在软件工程（SE）和人工智能（AI）领域，代码生成成为一个重要的研究方向，本文旨在填补关于使用LLMs生成Verilog代码的全面综述的空白。

Method: 通过系统地审查和分析了SE、AI和EDA领域的70篇会议论文和32篇预印本论文，共102篇论文，本文系统地探讨了用于Verilog生成的大型语言模型（LLMs）、评估数据集和指标、生成技术分类以及LLMs与Verilog生成的对齐方法。

Result: 本文确定了在使用LLMs生成Verilog代码方面的研究发现：包括所使用的LLMs类型、采用的评估数据集与指标、提出的生成技术分类，以及LLMs与Verilog生成的对齐方法。此外，还提出了未来研究的潜在方向。

Conclusion: 本文为未来的LLM辅助硬件设计研究提供了一个清晰的方向，指出了现有研究的局限性，并提供了对未来研究的建议。

Abstract: Code generation has emerged as a critical research area at the intersection of Software Engineering (SE) and Artificial Intelligence (AI), attracting significant attention from both academia and industry. Within this broader landscape, Verilog, as a representative hardware description language (HDL), plays a fundamental role in digital circuit design and verification, making its automated generation particularly significant for Electronic Design Automation (EDA). Consequently, recent research has increasingly focused on applying Large Language Models (LLMs) to Verilog code generation, particularly at the Register Transfer Level (RTL), exploring how these AI-driven techniques can be effectively integrated into hardware design workflows. Despite substantial research efforts have explored LLM applications in this domain, a comprehensive survey synthesizing these developments remains absent from the literature. This review fill addresses this gap by providing a systematic literature review of LLM-based methods for Verilog code generation, examining their effectiveness, limitations, and potential for advancing automated hardware design. The review encompasses research work from conferences and journals in the fields of SE, AI, and EDA, encompassing 70 papers published on venues, along with 32 high-quality preprint papers, bringing the total to 102 papers. By answering four key research questions, we aim to (1) identify the LLMs used for Verilog generation, (2) examine the datasets and metrics employed in evaluation, (3) categorize the techniques proposed for Verilog generation, and (4) analyze LLM alignment approaches for Verilog generation. Based on our findings, we have identified a series of limitations of existing studies. Finally, we have outlined a roadmap highlighting potential opportunities for future research endeavors in LLM-assisted hardware design.

</details>


### [307] [Hardware-Aware Neural Network Compilation with Learned Optimization: A RISC-V Accelerator Approach](https://arxiv.org/abs/2512.00031)
*Ravindra Ganti,Steve Xu*

Main category: cs.AR

TL;DR: 本文介绍了一种名为XgenSilicon的机器学习编译器框架，它能够自动化地将高层机器学习模型转化为定制ASIC加速器的RISC-V汇编代码，该框架通过五个关键创新点实现了在功耗、性能和面积上的显著提升。


<details>
  <summary>Details</summary>
Motivation: 为了提高机器学习模型在定制ASIC加速器上的性能和能效，降低开发成本，提高硬件与软件的协同优化。

Method: 该编译器采用了多算法自动调优框架、集成量化框架、硬件感知验证、动态形状支持以及多级缓存意识成本建模等关键技术，以实现全面的优化。

Result: 与基础实现相比，该编译器生成的ASIC在性能上提高了2.5-4.5倍，在功耗上降低了3-6倍，在面积上减少了40-60%。该编译器支持超过100个ONNX操作符，并包含先进RISC-V Vector优化。

Conclusion: XgenSilicon编译器框架能够显著提升机器学习模型在ASIC加速器上的性能和能效，减少设计与验证工作量，适合大规模、高复杂度的机器学习任务的硬件加速方案。

Abstract: We present XgenSilicon ML Compiler, a fully automated end-to-end compilation framework that transforms high-level machine learning models into optimized RISC-V assembly code for custom ASIC accelerators. By unifying the system's cost model across software and hardware, the compiler achieves significant improvements in Power, Performance, and Area (PPA) metrics compared to standard off-the-shelf components and hand-designed chips through five key innovations: (1) a multi-algorithm auto-tuning framework with five search strategies (Bayesian Optimization, Genetic Algorithm, Simulated Annealing, Random Search, Grid Search) combined with a learned cost model, (2) an integrated quantization framework supporting extreme precisions from FP32 to Binary with full KL divergence calibration (2048-bin histogram optimization) and momentum-based QAT gradient updates, (3) hardware-aware validation ensuring 100 percent ISA compliance and memory constraint satisfaction, (4) dynamic shape support with multi-configuration specialization, and (5) advanced cache-aware cost modeling with multi-level cache hierarchy analysis. Our evaluation demonstrates that ASICs produced by this compiler achieve 2.5-4.5x better performance, 3-6x lower power consumption, and 40-60 percent area reduction compared to baseline implementations. The compiler supports more than 100 ONNX operators across 12 categories, implements advanced RISC-V Vector optimizations, and generates hardware-validated assembly code suitable for direct ASIC synthesis. All compilation steps are fully automated, requiring zero manual intervention from model input to ASIC-ready output.

</details>


### [308] [Decoupled Control Flow and Data Access in RISC-V GPGPUs](https://arxiv.org/abs/2512.00032)
*Giuseppe M. Sarda,Nimish Shah,Abubakr Nada,Debjyoti Bhattacharjee,Marian Verhelst*

Main category: cs.AR

TL;DR: Vortex, 一个基于RISC-V指令集的新型开源GPGPU平台，通过硬件控制流管理和解耦存储流线提升性能，使GPU研究更加高效，特别是适用于机器学习应用。


<details>
  <summary>Details</summary>
Motivation: 由于Vortex作为年轻硬件平台的性能竞争力不足，很难与成熟的商业GPU竞争，因此本文提出了一种新的微架构方案来提升其性能。

Method: 通过硬件分支管理器加速常规循环执行中的分支和预测，并通过解耦存储流线来进一步隐藏内存延迟，从而提供有用的操作。

Result: 实验结果显示，不同内核的执行速度提高了8倍，动态指令计数降低了10倍，总体性能从0.35增加到1.63GFLOP/s/mm^2。

Conclusion: 改进后的Vortex平台为下一代机器学习的GPGPU研究提供了一个理想的试验场。

Abstract: Vortex, a newly proposed open-source GPGPU platform based on the RISC-V ISA, offers a valid alternative for GPGPU research over the broadly-used modeling platforms based on commercial GPUs. Similarly to the push originating from the RISC-V movement for CPUs, Vortex can enable a myriad of fresh research directions for GPUs. However, as a young hardware platform, it currently lacks the performance competitiveness of commercial GPUs, which is crucial for widespread adoption. State-of-the-art GPUs, in fact, rely on complex architectural features, still unavailable in Vortex, to hide the micro-code overheads linked to control flow (CF) management and memory orchestration for data access. In particular, these components account for the majority of the dynamic instruction count in regular, memory-intensive kernels, such as linear algebra routines, which form the basis of many applications, including Machine Learning. To address these challenges with simple yet powerful micro-architecture modifications, this paper introduces decoupled CF and data access through 1.) a hardware CF manager to accelerate branching and predication in regular loop execution and 2.) decoupled memory streaming lanes to further hide memory latency with useful computation. The evaluation results for different kernels show 8$\times$ faster execution, 10$\times$ reduction in dynamic instruction count, and overall performance improvement from 0.35 to 1.63 $\mathrm{GFLOP/s/mm^2}$. Thanks to these enhancements, Vortex can become an ideal playground to enable GPGPU research for the next generation of Machine Learning.

</details>


### [309] [SetupKit: Efficient Multi-Corner Setup/Hold Time Characterization Using Bias-Enhanced Interpolation and Active Learning](https://arxiv.org/abs/2512.00044)
*Junzhuo Zhou,Ziwen Wang,Haoxuan Xia,Yuxin Yan,Chengyu Zhu,Ting-Jung Lin,Wei Xing,Lei He*

Main category: cs.AR

TL;DR: SetupKit采用统计智能、电路分析和主动学习策略显著加速了现代芯片时序闭合过程中的setup/hold时序表征，实现2.4倍的CPU时间减少。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多过程电压温度（PVT）角下的搜索收敛速度较慢，探索效率低下，SetupKit旨在通过统计建模、电路分析和主动学习解决这个问题。

Method: SetupKit结合了BEIRA——一种基于统计误差建模的偏置增强插值搜索方法，用于加速收敛并克服停滞问题；通过电路分析估计初始搜索区间；以及使用高斯过程的主动学习策略。

Result: 在22纳米工业标准单元和16个PVT角上，SetupKit相比传统方法实现了2.4倍的整体CPU时间减少。

Conclusion: SetupKit提供了一种基于学习的库表征方法，解决了EDA领域的关键挑战，并为智能仿真管理开辟了道路。

Abstract: Accurate setup/hold time characterization is crucial for modern chip timing closure, but its reliance on potentially millions of SPICE simulations across diverse process-voltagetemperature (PVT) corners creates a major bottleneck, often lasting weeks or months. Existing methods suffer from slow search convergence and inefficient exploration, especially in the multi-corner setting. We introduce SetupKit, a novel framework designed to break this bottleneck using statistical intelligence, circuit analysis and active learning (AL). SetupKit integrates three key innovations: BEIRA, a bias-enhanced interpolation search derived from statistical error modeling to accelerate convergence by overcoming stagnation issues, initial search interval estimation by circuit analysis and AL strategy using Gaussian Process. This AL component intelligently learns PVT-timing correlations, actively guiding the expensive simulations to the most informative corners, thus minimizing redundancy in multicorner characterization. Evaluated on industrial 22nm standard cells across 16 PVT corners, SetupKit demonstrates a significant 2.4x overall CPU time reduction (from 720 to 290 days on a single core) compared to standard practices, drastically cutting characterization time. SetupKit offers a principled, learningbased approach to library characterization, addressing a critical EDA challenge and paving the way for more intelligent simulation management.

</details>


### [310] [Assessing Large Language Models in Generating RTL Design Specifications](https://arxiv.org/abs/2512.00045)
*Hung-Ming Huang,Yu-Hsin Yang,Fu-Chieh Chang,Yun-Chia Hsu,Yin-Yu Lin,Ming-Fang Tsai,Chun-Chih Yang,Pei-Yuan Wu*

Main category: cs.AR

TL;DR: 本文探讨了提示策略对从RTL生成规范的质量影响，并引入了可靠的评估方法，同时对开源和商业LLM进行了基准测试，为进一步自动化和提高IC设计中的规范工作流程奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 随着IC设计变得越来越复杂，自动理解并记录寄存器传输级（RTL）代码变得尤为重要。目前工程师们需要手动解释现有RTL代码并编写规范，这是一个耗时且容易出错的过程。尽管LLMs（语言模型）在从规范生成RTL方面进行了研究，但自动化规范生成仍然很少被探索，主要原因是缺乏可靠的评估方法。

Method: 作者研究了不同提示策略对从RTL生成规范质量的影响，并引入了新的评估指标。此外，还对开源和商业LLMs进行了基准测试。

Result: 研究表明，合适的提示策略能够提高从RTL生成规范的质量。所引入的评估指标能够准确地评估生成的规范。基准测试结果显示，某些LLMs在生成规范方面表现优异，为更自动化的IC设计提供了基础。

Conclusion: 本文的研究结果表明，通过合适的提示策略和可靠评估方法，可以提高从RTL代码自动生成规范的效率和质量，为IC设计中的自动化规范工作流程提供了支持。

Abstract: As IC design grows more complex, automating comprehension and documentation of RTL code has become increasingly important. Engineers currently should manually interpret existing RTL code and write specifications, a slow and error-prone process. Although LLMs have been studied for generating RTL from specifications, automated specification generation remains underexplored, largely due to the lack of reliable evaluation methods. To address this gap, we investigate how prompting strategies affect RTL-to-specification quality and introduce metrics for faithfully evaluating generated specs. We also benchmark open-source and commercial LLMs, providing a foundation for more automated and efficient specification workflows in IC design.

</details>


### [311] [A Configurable Mixed-Precision Fused Dot Product Unit for GPGPU Tensor Computation](https://arxiv.org/abs/2512.00053)
*Nikhil Rout,Blaise Tine*

Main category: cs.AR

TL;DR: 本研究提出了一种可扩展的混合精度点乘单元，该单元集成了浮点和整数算术流水线，能够在单个融合架构中高效处理多种低精度和高精度运算，该设计已在开放-source RISC-V 基础的 Vortex GPGPU 的 Tensor Core Unit 扩展中实现并测试。


<details>
  <summary>Details</summary>
Motivation: 现有的开放源代码 RTL 实现的内积运算依赖于离散的算术单元，导致吞吐量不佳和资源利用不足，因此需要一种新的设计来优化这些挑战。

Method: 研究团队设计了一种可扩展的混合精度点乘单元，该单元结合了浮点和整数算术管道，并且可以在同一架构中处理多种低精度和高精度操作。该设计包括支持（FP16/BF16/FP8/BF8/INT8/UINT4）低精度乘法和（FP32/INT32）高精度累加，并可扩展其他自定义表示形式。

Result: 实验结果显示，该设计在 AMD Xilinx Alveo U55C FPGA 上以 306.6 MHz 的时钟频率运行时，具有 4 个时钟周期的操作延迟，并在每个战车拥有多达 4 个线程的配置中实现了理想填满流水线吞吐量下的 9.812 GFLOPS 性能。

Conclusion: 研究结论表明，通过在单一融合架构中集成了浮点和整数算术管道，该设计有效提高了混合精度内积运算的性能，实现了高吞吐量和优化的资源利用率，为未来的扩展留下了空间。

Abstract: Efficient mixed-precision MMA operations are critical for accelerating Deep Learning workloads on GPGPUs. However, existing open-source RTL implementations of inner dot products rely on discrete arithmetic units, leading to suboptimal throughput and poor resource utilization. To address these challenges, we propose a scalable mixed-precision dot product unit that integrates floating-point and integer arithmetic pipelines within a singular fused architecture, implemented as part of the open-source RISC-V based Vortex GPGPU's Tensor Core Unit extension. Our design supports low-precision multiplication in (FP16/BF16/FP8/BF8/INT8/UINT4) formats and higher-precision accumulation in (FP32/INT32), with an extensible framework for adding and evaluating other custom representations in the future. Experimental results demonstrate 4-cycle operation latency at 306.6 MHz clock frequency on the AMD Xilinx Alveo U55C FPGA, delivering an ideal filled pipeline throughput of 9.812 GFLOPS in a 4-thread per warp configuration.

</details>


### [312] [LLaMCAT: Optimizing Large Language Model Inference with Cache Arbitration and Throttling](https://arxiv.org/abs/2512.00083)
*Zhongchun Zhou,Chengtao Lai,Wei Zhang*

Main category: cs.AR

TL;DR: LLaMCAT通过结合MSHR状态保持寄存器和负载平衡的缓存仲裁策略以及线程调控，针对大型语言模型推理任务优化了最后一级缓存，实现了显著的加速效果。


<details>
  <summary>Details</summary>
Motivation: 现有的大规模语言模型（LLMs）虽然在各种应用中取得了前所未有的成功，但由于其庞大的内存需求，对当前内存系统设计提出了重大挑战。特别是推理过程中，带宽要求特别高，容易出现缓存瓶颈。为了应对这些挑战，我们的工作旨在优化基于LLC的架构，包括GPU和AI加速器。我们提出了一种名为LLaMCAT的新方法，专门为LLM推理优化最后一级缓存。

Method: LLaMCAT结合了MSHR状态保持寄存器和负载平衡的缓存仲裁策略，以及线程调控，提出了一个混合仿真框架，将分析模型与寄存器级模拟器通过内存跟踪相结合。

Result: 实验结果表明，当系统主要由缺页处理吞吐量瓶颈时，LLaMCAT相比基线算法平均可提升1.26倍的性能。在缓存大小受限的情况下，LLaMCAT能分别带来1.58倍和1.26倍的加速，优于最优基线（dyncta）。

Conclusion: LLaMCAT是首个针对LLM解码特定的MSHR争用问题的方案，为未来硬件平台加速LLM推理提供了实用的解决方案。

Abstract: Large Language Models (LLMs) have achieved unprecedented success across various applications, but their substantial memory requirements pose significant challenges to current memory system designs, especially during inference. Our work targets last-level cache (LLC) based architectures, including GPUs (e.g., NVIDIA GPUs) and AI accelerators. We introduce LLaMCAT, a novel approach to optimize the LLC for LLM inference. LLaMCAT combines Miss Status Holding Register (MSHR)- and load balance-aware cache arbitration with thread throttling to address stringent bandwidth demands and minimize cache stalls in KV Cache access. We also propose a hybrid simulation framework integrating analytical models with cycle-level simulators via memory traces, balancing architecture detail and efficiency.
  Experiments demonstrate that LLaMCAT achieves an average speedup of 1.26x when the system is mainly bottlenecked by miss handling throughput, while baselines mostly show negative improvements since they are not optimized for this scenario. When the cache size is also limited, our policy achieves a speedup of 1.58x over the unoptimized version, and a 1.26x improvement over the best baseline (dyncta). Overall, LLaMCAT is the first to target LLM decoding-specific MSHR contention, a gap in previous work. It presents a practical solution for accelerating LLM inference on future hardware platforms.

</details>


### [313] [Modeling and Simulation Frameworks for Processing-in-Memory Architectures](https://arxiv.org/abs/2512.00096)
*Mahdi Aghaei,Saba Ebrahimi,Mohammad Saleh Arafati,Elham Cheshmikhani,Dara Rahmati,Saeid Gorgin,Jungrae Kim*

Main category: cs.AR

TL;DR: 本文综述了处理在内存 (PIM) 的模拟方法和工具，涵盖了从基本模型到高级环境的多样性，并强调了选择合适模拟器的重要性。


<details>
  <summary>Details</summary>
Motivation: PIM 由于存储墙和 von Neumann 架构的固有限制而成为减轻计算瓶颈的一种有希望的计算范式。模拟计划为研究人员提供了一个在原型制作前评估、比较和改进 PIM 设计的重要工具。

Method: 文章提供了一个综合框架来分类 PIM 模拟器，依据抽象级别、设计目标和评估指标。并讨论了常用基准套件以及该领域的开放性挑战。

Result: 文章强调了理解各种仿真工具的权衡是选择合适方法的关键，同时也概述了 PIM 模拟方法和工具的最新进展。

Conclusion: 通过分析 PIM 仿真工具和方法，该文章为未来的研究铺平了道路，提出了更可靠、高效和可扩展的 PIM 建模方法。

Abstract: Processing-in-Memory (PIM) has emerged as a promising computing paradigm to address the memory wall and the fundamental bottleneck of the von Neumann architecture by reducing costly data movement between memory and processing units. As with any engineering challenge, identifying the most effective solutions requires thorough exploration of diverse architectural proposals, device technologies, and application domains. In this context, simulation plays a critical role in enabling researchers to evaluate, compare, and refine PIM designs prior to fabrication. Over the past decade, a variety of PIM simulators have been introduced, spanning low-level device models, architectural frameworks, and application-oriented environments. These tools differ significantly in fidelity, scalability, supported memory/compute technologies, and benchmark compatibility. Understanding these trade-offs is essential for researchers to select appropriate simulators that accurately map and validate their research efforts. This chapter provides a comprehensive overview of PIM simulation methodologies and tools. We categorize simulators according to abstraction levels, design objectives, and evaluation metrics, highlighting representative examples. To improve accessibility, some content may appear in multiple contexts to guide readers with different backgrounds. We also survey benchmark suites commonly employed in PIM studies and discuss open challenges in simulation methodology, paving the way for more reliable, scalable, and efficient PIM modeling.

</details>


### [314] [An Analytical and Empirical Investigation of Tag Partitioning for Energy-Efficient Reliable Cache](https://arxiv.org/abs/2512.00112)
*Elham Cheshmikhani,Hamed Farbeh*

Main category: cs.AR

TL;DR: 作者分析了标签拆分点k对标签分割效率的影响，并提出了一个可以根据缓存配置参数计算最优拆分点的公式，该公式能够精确量化任何k和配置下的标签分割效率。


<details>
  <summary>Details</summary>
Motivation: 由于缓存标记数组是唯一由硬件管理且最关键的部分，因此改善其可靠性与能效显得尤为重要。现有的研究在选择标签拆分点k时多为直观、随机或经验性，缺乏系统性的指导原则。

Method: 作者通过理论分析展示了选择k过大或过小会显著降低标签分割效率，根据缓存配置参数建立了计算最优拆分点的公式。

Result: 该公式是凸的、可微的，并能精确量化任何k和配置下的标签分割效率。实验验证了该模型的有效性，结果与理论预测高度一致。

Conclusion: 该工作提出了一个能够帮助设计者和研究人员快速计算最优标签拆分点并准确估算标签读取减少的方法，为缓存设计提供了重要的理论依据。

Abstract: Associative cache memory significantly influences processor performance and energy consumption. Because it occupies over half of the chip area, cache memory is highly susceptible to transient and permanent faults, posing reliability challenges. As the only hardware-managed memory module, the cache tag array is the most active and critical component, dominating both energy usage and error rate. Tag partitioning is a widely used technique to reduce tag-access energy and enhance reliability. It divides tag comparison into two phases: first comparing the k lower bits, and then activating only the matching tag entries to compare the remaining higher bits. The key design parameter is the selection of the tag-splitting point k, which determines how many reads are eliminated. However, prior studies have chosen k intuitively, randomly, or empirically, without justification. Even experimentally determined values are ad-hoc and do not generalize across cache configurations due to high sensitivity to architectural parameters.
  In this paper, we analytically show that choosing k too large or too small substantially reduces the effectiveness of tag partitioning. We then derive a formulation that determines the optimal splitting point based on cache configuration parameters. The formulation is convex, differentiable, and capable of precisely quantifying tag-partitioning efficiency for any k and configuration. To validate our model, we experimentally evaluate tag-partitioning efficiency and optimal k across a broad set of cache designs and demonstrate close agreement between analytical and experimental results. The proposed formulation enables designers and researchers to instantly compute the optimal tag-splitting point and accurately estimate tag-read reduction.

</details>


### [315] [Variable Point: A Number Format for Area- and Energy-Efficient Multiplication of High-Dynamic-Range Numbers](https://arxiv.org/abs/2512.00186)
*Seyed Hadi Mirfarshbafan,Nicolas Filliol,Oscar Castañeda,Christoph Studer*

Main category: cs.AR

TL;DR: 提出了一种称为可变位点（VP）的新数字格式，它能够在保持类似位宽的情况下覆盖比固定位点更大的动态范围，而不会显著增加硬件复杂度。通过在高动态范围信号的多天线无线通信系统中实现矩阵-向量乘法引擎，该研究展示了VP格式设计实现了20%的面积节省和10%的功耗节省，而性能未见明显下降。


<details>
  <summary>Details</summary>
Motivation: 数字VLSI设计中，固定位点数表示适合硬件效率要求严格的应用，但其动态范围有限，而浮点数虽动态范围广但硬件复杂度高。因此，需要一种能够在保持较低硬件复杂度的同时提供更大动态范围的新型数表示法。

Method: 提出了一种称为可变位点（VP）的新数字格式，通过调整小数点位置来扩大动态范围，并验证了通过后布局VLSI实现该格式在矩阵-向量乘法引擎中的效率。

Result: 研究表明，基于VP的矩阵-向量乘法设计在空间平等化系统中的面积节省了20%，功耗节省了10%，并且在高动态范围信号处理中未见明显性能下降。

Conclusion: 该研究证明了VP数表示法的有效性，并为高动态范围信号处理应用提供了一种具有更高效率的新型数字格式。

Abstract: Fixed-point number representation is commonly employed in digital VLSI designs that have stringent hardware efficiency constraints. However, fixed-point numbers cover a relatively small dynamic range for a given bitwidth. In contrast, floating-point numbers offer a larger dynamic range at the cost of increased hardware complexity. In this paper, we propose a novel number format called variable-point (VP). VP numbers cover a larger dynamic range than fixed-point numbers with similar bitwidth, without notably increasing hardware complexity -- this allows for a more efficient representation of signals with high dynamic range. To demonstrate the efficacy of the proposed VP number format, we consider a matrix-vector multiplication engine for spatial equalization in multi-antenna wireless communication systems involving high-dynamic-range signals. Through post-layout VLSI implementation results, we demonstrate that the proposed VP-based design achieves 20% and 10% area and power savings, respectively, compared to a fully optimized fixed-point design, without incurring any noticeable performance degradation.

</details>


### [316] [Efficient Kernel Mapping and Comprehensive System Evaluation of LLM Acceleration on a CGLA](https://arxiv.org/abs/2512.00335)
*Takuto Ando,Yu Eto,Ayumu Takeuchi,Yasuhiko Nakashima*

Main category: cs.AR

TL;DR: 本文介绍了非AI专用的Coarse-Grained Linear Array (CGLA)加速器，用于Qwen语言模型的推理。CGLA在能耗效率上表现出色，相较于高性能GPU和边缘AI设备分别提高了44.4倍和13.6倍的功率延迟积（PDP），以及11.5倍的能量延迟积（EDP）。系统层面的分析显示了主机和加速器间的数据传输是主要的性能瓶颈。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）对计算资源的需求增加，高能耗成为主要问题。本文研究了一种通过使用Coarse-Grained Reconfigurable Arrays（CGRAs）作为替代方案来解决这一问题的可能途径，CGRAs在能耗效率和编程灵活性之间提供了一个良好的平衡。

Method: 文章采用了一种非AI专门化的Coarse-Grained Linear Array (CGLA)架构，该架构具有通用的设计，同时通过灵活的指令集支持领域特定的调整。研究团队在一款FPGA原型上评估了该架构的性能，并使用llama.cpp框架进行了测试。此外，对不同技术和设备（如NVIDIA RTX 4090和NVIDIA Jetson AGX Orin）进行了比较分析，以评估CGLA的潜力。

Result: 研究结果表明，CGLA在能耗效率方面优于高性能GPU和边缘AI设备。CGLA在功率延迟积（PDP）上提高了44.4倍，能量延迟积（EDP）提高了11.5倍。CGLA的设计指导了下一代LLM加速器的发展。

Conclusion: CGLA作为一种平台，对于在能源受限环境中进行LLM推理具有适用性。研究还指出了主机和加速器之间数据传输是性能瓶颈的关键因素。

Abstract: Large Language Models (LLMs) demand substantial computational resources, resulting in high energy consumption on GPUs. To address this challenge, we focus on Coarse-Grained Reconfigurable Arrays (CGRAs) as an effective alternative that provides a trade-off between energy efficiency and programmability. This paper presents the first comprehensive, end-to-end evaluation of a non-AI-specialized Coarse-Grained Linear Array (CGLA) accelerator for the state-of-the-art Qwen LLM family. The architecture has a general-purpose, task-agnostic design, yet its flexible instruction set allows for domain-specific adaptations. This flexibility enables the architecture to achieve high efficiency for sustainable LLM inference. We assess the performance of our architecture on an FPGA prototype using the widely adopted llama.cpp framework. We then project its potential as a 28nm ASIC and compare it against a high-performance GPU (NVIDIA RTX 4090) and an edge AI device (NVIDIA Jetson AGX Orin). While GPUs exhibit lower latency, our non-AI-specific accelerator achieves higher energy efficiency, improving the Power-Delay Product (PDP) by up to 44.4x and 13.6x compared with the RTX 4090 and Jetson, respectively. Similarly, it reduces the Energy-Delay Product (EDP) by up to 11.5x compared to the high-performance GPU, demonstrating a favorable performance-energy trade-off. Critically, our system-level analysis identifies host-accelerator data transfer as the primary performance bottleneck, a factor often overlooked in kernel-level studies. These findings provide design guidance for next-generation LLM accelerators. This work validates CGRAs as a suitable platform for LLM inference in power-constrained environments, without being confined to specific algorithms.

</details>


### [317] [A Novel 8T SRAM-Based In-Memory Computing Architecture for MAC-Derived Logical Functions](https://arxiv.org/abs/2512.00441)
*Amogh K M,Sunita M S*

Main category: cs.AR

TL;DR: 本文提出了一种基于8T SRAM的8x8阵列内存计算架构，实现了多比特并行MAC操作和标准内存处理。该架构通过解耦读写路径克服了之前6T SRAM设计的可靠性限制，并采用新型模拟到数字解码方案将MAC电压输出转换为数字计数，从而在阵列中实现基本逻辑运算。仿真结果表明，在1.8 V供电电压下，该设计能够在142.85 MHz的频率下完成8位MAC和逻辑操作，具有0.7 ns的延迟，每MAC操作能耗为56.56 fJ/bit，吞吐量为15.8 M次运算/秒。


<details>
  <summary>Details</summary>
Motivation: 针对现有内存计算架构中6T SRAM设计存有的可靠性问题，通过引入8T SRAM技术并采用解耦读写路径，解决了读操作和写操作之间的互干扰，并提出了一种高效的模拟到数字解码方案，以实现在同一阵列中同时执行MAC运算和逻辑运算，提升了数据处理的效率与可靠性。

Method: 文章基于8T SRAM技术，构建了8x8阵列内存计算架构。该架构利用了SRAM技术的成熟性，通过解耦读写路径，提高了写操作的稳定性。同时，还设计了一种新的模拟到数字解码方案，将MAC运算结果转化为数字形式，便于逻辑运算的实现。

Result: 研究结果显示，该设计在90nm CMOS工艺下的频率达到了142.85 MHz，延迟仅为0.7 ns，每MAC操作的能耗为56.56 fJ/bit，吞吐量达到了15.8 M次运算/秒。与传统设计相比，该架构在性能上具有显著优势。

Conclusion: 这项研究提出了一种有效的内存计算架构，克服了现有设计中的可靠性问题，并实现了高效的数据处理能力，为未来的内存计算技术发展提供了新思路。

Abstract: This paper presents an in-memory computing (IMC) architecture developed on an 8x8 array of 8T SRAM cells. This architecture enables both multi-bit parallel Multiply-Accumulate (MAC) operations and standard memory processing through charge-sharing on dedicated read bit-lines. By leveraging the maturity of SRAM technology, this work introduces an 8T SRAM-based IMC architecture that decouples read and write paths, thereby overcoming the reliability limitations of prior 6T SRAM designs. A novel analog-to-digital decoding scheme converts the MAC voltage output into digital counts, which are subsequently interpreted to realize fundamental logic functions including AND/NAND, NOR/OR, XOR/XNOR, and 1-bit addition within the same array. Simulated in a 90 nm CMOS process at 1.8 V supply voltage, the proposed design achieves 8-bit MAC and logical operations at a frequency of 142.85 MHz, with a latency of 0.7 ns and energy consumption of 56.56 fJ/bit per MAC operation and throughput of 15.8 M operations/s.

</details>


### [318] [Leveraging Recurrent Patterns in Graph Accelerators](https://arxiv.org/abs/2512.01193)
*Masoud Rahimi,Sébastien Le Beux*

Main category: cs.AR

TL;DR: 该研究提出了一种减少交叉电容重构操作的图处理方法，通过识别频繁子图模式并将其分配给静态图引擎，在实验中实现了2.38倍的加速和7.23倍的能量节省，并延长了电路寿命。


<details>
  <summary>Details</summary>
Motivation: 现有设计在处理大规模稀疏图时存在存储器访问开销过大的问题，这导致执行时间延长、能量消耗增加和电路寿命缩短。因此，为了优化性能并延长设备寿命，研究提出了一种新的处理方法。

Method: 研究通过识别频繁出现的子图模式并将其分配给静态图引擎，从而减少交叉电容的重构操作次数。这种方法可以在不需要多次配置交叉电容的情况下处理大多数子图。

Result: 实验结果表明，与最先进的加速器相比，该方法实现了2.38倍的加速和7.23倍的能量节省，同时将电路寿命延长了一倍。

Conclusion: 该研究提出的方法能够有效减少存储器访问开销，提升稀疏图处理效率和延长设备寿命，展示了其在实际应用中的潜力。

Abstract: Graph accelerators have emerged as a promising solution for processing large-scale sparse graphs, leveraging the in-situ compu-tation of ReRAM-based crossbars to maximize computational efficiency. However, existing designs suffer from memristor access overhead due to the large number of graph partitions. This leads to increased execution time, higher energy consumption, and re-duced circuit lifetime. This paper proposes a graph processing method that minimizes memristor write operations by identifying frequent subgraph patterns and assigning them to graph engines, referred to as static, allowing most subgraphs to be processed without a need for crossbar reconfiguration. Experimental results show speed up to 2.38x speedup and 7.23x energy savings com-pared to state-of-the-art accelerators. Furthermore, our method extends the circuit lifetime by 2x compared to state-of-the-art ReRAM graph accelerators.

</details>


### [319] [hls4ml: A Flexible, Open-Source Platform for Deep Learning Acceleration on Reconfigurable Hardware](https://arxiv.org/abs/2512.01463)
*Jan-Frederik Schulte,Benjamin Ramhorst,Chang Sun,Jovan Mitrevski,Nicolò Ghielmetti,Enrico Lupi,Dimitrios Danopoulos,Vladimir Loncar,Javier Duarte,David Burnette,Lauri Laatu,Stylianos Tzelepis,Konstantinos Axiotis,Quentin Berthet,Haoyan Wang,Paul White,Suleyman Demirsoy,Marco Colombo,Thea Aarrestad,Sioni Summers,Maurizio Pierini,Giuseppe Di Guglielmo,Jennifer Ngadiuba,Javier Campos,Ben Hawks,Abhijith Gandrakota,Farah Fahim,Nhan Tran,George Constantinides,Zhiqiang Que,Wayne Luk,Alexander Tapper,Duc Hoang,Noah Paladino,Philip Harris,Bo-Cheng Lai,Manuel Valentin,Ryan Forelli,Seda Ogrenci,Lino Gerlach,Rian Flynn,Mia Liu,Daniel Diaz,Elham Khoda,Melissa Quinnan,Russell Solares,Santosh Parajuli,Mark Neubauer,Christian Herwig,Ho Fung Tsoi,Dylan Rankin,Shih-Chieh Hsu,Scott Hauck*

Main category: cs.AR

TL;DR: hls4ml 是一个开放源代码平台，能够将 ML 模型从现代深度学习框架转换为 HLS 代码，以便集成到 FPGA 或 ASIC 设计中。


<details>
  <summary>Details</summary>
Motivation: hls4ml 的设计旨在解决在 FPGA 或 ASIC 设备中高效实现 ML 模型的问题，特别是对于需要低延迟、资源使用和功耗优化的应用场景。

Method: hls4ml 针对现代深度学习框架提供了一个灵活且模块化的转换平台，并支持来自不同供应商的多种 HLS 编译器。

Result: hls4ml 已被应用于多个商业和科学领域的 ML 推理加速，涉及广泛的性能测试。

Conclusion: 该平台提升了软件硬件协同设计的能力，并展示了其在特定应用中的潜力。

Abstract: We present hls4ml, a free and open-source platform that translates machine learning (ML) models from modern deep learning frameworks into high-level synthesis (HLS) code that can be integrated into full designs for field-programmable gate arrays (FPGAs) or application-specific integrated circuits (ASICs). With its flexible and modular design, hls4ml supports a large number of deep learning frameworks and can target HLS compilers from several vendors, including Vitis HLS, Intel oneAPI and Catapult HLS. Together with a wider eco-system for software-hardware co-design, hls4ml has enabled the acceleration of ML inference in a wide range of commercial and scientific applications where low latency, resource usage, and power consumption are critical. In this paper, we describe the structure and functionality of the hls4ml platform. The overarching design considerations for the generated HLS code are discussed, together with selected performance results.

</details>


### [320] [RoMe: Row Granularity Access Memory System for Large Language Models](https://arxiv.org/abs/2512.01541)
*Hwayong Nam,Seungmin Baek,Jumin Kim,Michael Jaemin Kim,Jung Ho Ahn*

Main category: cs.AR

TL;DR: 本文提出RoMe方案，通过在DRAM中以行粒度访问并移除列、银行组和伪通道，简化了内存调度，提高了12.5%的带宽，无需额外大量硬件开销。


<details>
  <summary>Details</summary>
Motivation: 现有的HBM内存系统为了保持细粒度的缓存行访问而引入了银行组和伪通道，这增加了延迟参数和控制开销，导致内存控制器调度变得更加复杂。针对此问题，提出了RoMe方案。

Method: RoMe通过移除DRAM中的列、银行组和伪通道，以行粒度进行访问。这样简化了内存调度逻辑，并通过合并空闲引脚形成额外通道，增加了整体带宽。

Result: RoMe设计方案在保持少量额外硬件开销的情况下，能够显著简化内存调度逻辑，并通过增加额外通道提升了12.5%的整体带宽。

Conclusion: RoMe提供了一种新的方法，该方法为下一代HBM内存系统提供了提高带宽的可能性，通过优化内存接口简化了调度逻辑，减少了复杂性。

Abstract: Modern HBM-based memory systems have evolved over generations while retaining cache line granularity accesses. Preserving this fine granularity necessitated the introduction of bank groups and pseudo channels. These structures expand timing parameters and control overhead, significantly increasing memory controller scheduling complexity. Large language models (LLMs) now dominate deep learning workloads, streaming contiguous data blocks ranging from several kilobytes to megabytes per operation. In a conventional HBM-based memory system, these transfers are fragmented into hundreds of 32B cache line transactions. This forces the memory controller to employ unnecessarily intricate scheduling, leading to growing inefficiency.
  To address this problem, we propose RoMe. RoMe accesses DRAM at row granularity and removes columns, bank groups, and pseudo channels from the memory interface. This design simplifies memory scheduling, thereby requiring fewer pins per channel. The freed pins are aggregated to form additional channels, increasing overall bandwidth by 12.5% with minimal extra pins. RoMe demonstrates how memory scheduling logic can be significantly simplified for representative LLM workloads, and presents an alternative approach for next-generation HBM-based memory systems achieving increased bandwidth with minimal hardware overhead.

</details>


### [321] [A Systematic Characterization of LLM Inference on GPUs](https://arxiv.org/abs/2512.01644)
*Haonan Wang,Xuxin Xiao,Mingyu Yan,Zhuoyuan Zhu,Dengke Han,Duo Wang,Wenming Li,Xiaochun Ye,Cunchen Hu,Hongyang Chen,Guangyu Sun*

Main category: cs.AR

TL;DR: 本研究通过全面实验建立了四维分析框架，从现象识别、硬件原因揭示、系统行为验证到新范式探索，为LLM推理提供了可靠的经验基础和新的发现及优化指导。


<details>
  <summary>Details</summary>
Motivation: 解决对大型语言模型推理认知碎片化的挑战，促进对LLM推理工作的系统理解。

Method: 通过全面的实验建立了四维度的分析框架，包括两个阶段的异质观测、微架构原因分析、系统扩展原则和新兴范式边界。

Result: 识别了性能现象，揭示了硬件原因，验证了系统行为，并探索了新的范式。不仅巩固了现有的研究成果，还为LLM推理提供了新的启示和优化指导。

Conclusion: 该研究为LLM推理提供了系统化的分析框架，不仅是经验基础的强化，也为未来的研究提供了探索方向。

Abstract: This work presents a systematic characterization of Large Language Model (LLM) inference to address fragmented understanding. Through comprehensive experiments, we establish a four-dimensional analytical framework: (1) Two-Phase Heterogeneity Observation; (2) Microarchitectural Root Cause Analysis; (3) System Scaling Principles; and (4) Emerging Paradigm Boundaries. Our investigation progresses systematically from observation to foresight: identifying performance phenomena, revealing hardware causes, validating system behavior, and exploring new paradigms. This study not only consolidates a reliable empirical foundation for existing research but also provides new discoveries and practical optimization guidance for LLM inference.

</details>
