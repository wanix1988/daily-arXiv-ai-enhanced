<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 50]
- [cs.CL](#cs.CL) [Total: 52]
- [cs.AR](#cs.AR) [Total: 16]
- [cs.AI](#cs.AI) [Total: 14]
- [cs.PF](#cs.PF) [Total: 2]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Size Matters: Reconstructing Real-Scale 3D Models from Monocular Images for Food Portion Estimation](https://arxiv.org/abs/2601.20051)
*Gautham Vinod,Bruce Coburn,Siddeshwar Raghavan,Jiangpeng He,Fengqing Zhu*

Main category: cs.CV

TL;DR: 本文提出了一种从单一视角图像中恢复真实比例的3D重建方法，利用模型从大规模数据集提取的丰富视觉特征来估计重建物体的规模，从而将单视角3D重建转化为真实生活中具有物理意义的模型。实验结果显示，该方法在两个公开数据集上的表现优于现有技术，尤其是在体积估计误差方面。


<details>
  <summary>Details</summary>
Motivation: 饮食相关的慢性疾病如肥胖和糖尿病的增加突显了准确监控食品摄入的重要性。然而，从单一视角图像中恢复食物的真实尺寸信息仍然是一个挑战。现有技术要么重建几何结构表现不佳，要么无法恢复真实世界的物体尺度，这限制了它们在精准营养领域的应用。

Method: 本文提出了一种结合3D计算机视觉和数字健康的解决方案，通过训练在大规模数据集上的模型来提取丰富的视觉特征，估计重建物体的真实尺度，从而实现单视角3D重建的真实生活模型。

Result: 在两个公开数据集上的实验表明，该方法在体积估计误差方面取得了显著的改进，相较于现有技术，平均绝对体积估计误差减少了近30%，展示了其在精准营养领域的潜力。

Conclusion: 本文提出的方法能够从单一视角图像中恢复真实比例的3D重建，并且在体积估计任务上表现优异，为精准营养领域提供了新的可能性。

Abstract: The rise of chronic diseases related to diet, such as obesity and diabetes, emphasizes the need for accurate monitoring of food intake. While AI-driven dietary assessment has made strides in recent years, the ill-posed nature of recovering size (portion) information from monocular images for accurate estimation of ``how much did you eat?'' is a pressing challenge. Some 3D reconstruction methods have achieved impressive geometric reconstruction but fail to recover the crucial real-world scale of the reconstructed object, limiting its usage in precision nutrition. In this paper, we bridge the gap between 3D computer vision and digital health by proposing a method that recovers a true-to-scale 3D reconstructed object from a monocular image. Our approach leverages rich visual features extracted from models trained on large-scale datasets to estimate the scale of the reconstructed object. This learned scale enables us to convert single-view 3D reconstructions into true-to-life, physically meaningful models. Extensive experiments and ablation studies on two publicly available datasets show that our method consistently outperforms existing techniques, achieving nearly a 30% reduction in mean absolute volume-estimation error, showcasing its potential to enhance the domain of precision nutrition. Code: https://gitlab.com/viper-purdue/size-matters

</details>


### [2] [DiSa: Saliency-Aware Foreground-Background Disentangled Framework for Open-Vocabulary Semantic Segmentation](https://arxiv.org/abs/2601.20064)
*Zhen Yao,Xin Li,Taotao Jing,Shuai Zhang,Mooi Choo Chuah*

Main category: cs.CV

TL;DR: DiSa 通过引入 Saliency-aware Disentanglement Module 和 Hierarchical Refinement Module，解决传统 VLM 模型的前景偏置和稀疏空间定位问题，实验结果表明 DiSa 在六个基准测试上优于当前最先进的方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于 VLM 方法在前景注意力上存在偏置，忽视了背景区域，同时在空间定位上表现不佳，边界模糊。

Method: DiSa 引入 Saliency-aware Disentanglement Module 和 Hierarchical Refinement Module，从前景和背景中分离特征，同时通过多级更新提供像素级别的空间上下文来细化通道特征。

Result: DiSa 在六个基准测试中表现优异，整体性能优于当前最先进的方法。

Conclusion: 研究提出了一种新颖的、注重稀疏的前背景分离框架 DiSa，通过引入新的模块解决了 VLM 在细分特征和空间定位上的不足，实验验证了其优越性。

Abstract: Open-vocabulary semantic segmentation aims to assign labels to every pixel in an image based on text labels. Existing approaches typically utilize vision-language models (VLMs), such as CLIP, for dense prediction. However, VLMs, pre-trained on image-text pairs, are biased toward salient, object-centric regions and exhibit two critical limitations when adapted to segmentation: (i) Foreground Bias, which tends to ignore background regions, and (ii) Limited Spatial Localization, resulting in blurred object boundaries. To address these limitations, we introduce DiSa, a novel saliency-aware foreground-background disentangled framework. By explicitly incorporating saliency cues in our designed Saliency-aware Disentanglement Module (SDM), DiSa separately models foreground and background ensemble features in a divide-and-conquer manner. Additionally, we propose a Hierarchical Refinement Module (HRM) that leverages pixel-wise spatial contexts and enables channel-wise feature refinement through multi-level updates. Extensive experiments on six benchmarks demonstrate that DiSa consistently outperforms state-of-the-art methods.

</details>


### [3] [Sparse CLIP: Co-Optimizing Interpretability and Performance in Contrastive Learning](https://arxiv.org/abs/2601.20075)
*Chuan Qin,Constantin Venhoff,Sonia Joseph,Fanyi Xiao,Stefan Scherer*

Main category: cs.CV

TL;DR: 该研究提出了一种将稀疏性直接融入CLIP训练的方法，该方法产生的表示既能提高可解释性，又不会牺牲性能，实现了稀疏CLIP在下游任务上的强性能和更好的可解释性。


<details>
  <summary>Details</summary>
Motivation: CLIP具有密集且不透明的潜在表示，这使得其解释性较差。该研究旨在解决解释性与性能之间的权衡，通过直接在训练中引入稀疏性，同时提高解释性和保持性能。

Method: 研究提出了一种新的稀疏CLIP训练方法，通过在训练过程中直接嵌入稀疏性，以生成同时具备解释性和高性能的表示。

Result: 与基于稀疏自编码器（SAEs）的后处理方法相比，稀疏CLIP保持了强劲的下游任务性能，实现了更好的解释性，并保留了多模态能力。稀疏的多模态特征使语义概念对齐更加直观，揭示了跨模态知识如何涌现的训练动态。

Conclusion: 该研究挑战了解释性需要牺牲性能的传统观点，证明了解释性和性能可以同时优化，为未来模型的设计提供了有价值的指导原则。

Abstract: Contrastive Language-Image Pre-training (CLIP) has become a cornerstone in vision-language representation learning, powering diverse downstream tasks and serving as the default vision backbone in multimodal large language models (MLLMs). Despite its success, CLIP's dense and opaque latent representations pose significant interpretability challenges. A common assumption is that interpretability and performance are in tension: enforcing sparsity during training degrades accuracy, motivating recent post-hoc approaches such as Sparse Autoencoders (SAEs). However, these post-hoc approaches often suffer from degraded downstream performance and loss of CLIP's inherent multimodal capabilities, with most learned features remaining unimodal.
  We propose a simple yet effective approach that integrates sparsity directly into CLIP training, yielding representations that are both interpretable and performant. Compared to SAEs, our Sparse CLIP representations preserve strong downstream task performance, achieve superior interpretability, and retain multimodal capabilities. We show that multimodal sparse features enable straightforward semantic concept alignment and reveal training dynamics of how cross-modal knowledge emerges. Finally, as a proof of concept, we train a vision-language model on sparse CLIP representations that enables interpretable, vision-based steering capabilities. Our findings challenge conventional wisdom that interpretability requires sacrificing accuracy and demonstrate that interpretability and performance can be co-optimized, offering a promising design principle for future models.

</details>


### [4] [Look in the Middle: Structural Anchor Pruning for Scalable Visual RAG Indexing](https://arxiv.org/abs/2601.20107)
*Zhuchenyang Liu,Ziyu Hu,Yao Zhang,Yu Xiao*

Main category: cs.CV

TL;DR: 本文提出了一种名为结构锚点剪枝(SAP)的方法，它通过识别中间层的关键视觉补丁，实现高性能压缩。此外，通过引入Oracle Score Retention (OSR)协议，证明了中间层中的语义结构锚点补丁能够保持效果，从而提供了高性能且可扩展的视觉拉取检索解决方案。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有训练无监督剪枝方法在高压缩比下性能不佳的问题，本文提出了结构锚点剪枝(SAP)方法，通过使用中间层的关键视觉补丁，实现了高性能的压缩，同时解决了结构信息在更高层逐渐消失的问题。

Method: SAP方法首先通过分析中间层的视觉补丁，识别出最重要的一部分作为锚点。采用Oracle Score Retention (OSR)协议来评估每一层的信息如何影响压缩效率。

Result: 在ViDoRe基准测试上的评估结果显示，SAP方法能够将索引向量压缩超过90%，同时保持了高度的检索准确性，提供了一种高效的可视化拉取检索解决方案。

Conclusion: 本文提出的SAP方法通过使用中间层语义结构锚点补丁，显著提高了压缩效率，解决了传统剪枝方法在高层结构信息消失的问题，为大规模视觉检索提供了新的可能性。

Abstract: Recent Vision-Language Models (e.g., ColPali) enable fine-grained Visual Document Retrieval (VDR) but incur prohibitive index vector size overheads. Training-free pruning solutions (e.g., EOS-attention based methods) can reduce index vector size by approximately 60% without model adaptation, but often underperform random selection in high-compression scenarios (> 80%). Prior research (e.g., Light-ColPali) attributes this to the conclusion that visual token importance is inherently query-dependent, thereby questioning the feasibility of training-free pruning. In this work, we propose Structural Anchor Pruning (SAP), a training-free pruning method that identifies key visual patches from middle layers to achieve high performance compression. We also introduce Oracle Score Retention (OSR) protocol to evaluate how layer-wise information affects compression efficiency. Evaluations on the ViDoRe benchmark demonstrate that SAP reduces index vectors by over 90% while maintaining robust retrieval fidelity, providing a highly scalable solution for Visual RAG. Furthermore, our OSR-based analysis reveals that semantic structural anchor patches persist in the middle layers, unlike traditional pruning solutions that focus on the final layer where structural signals dissipate.

</details>


### [5] [Efficient Token Pruning for LLaDA-V](https://arxiv.org/abs/2601.20168)
*Zhewen Wan,Tianchen Song,Chen Lin,Zhiyong Zhao,Xianpeng Lang*

Main category: cs.CV

TL;DR: 本文提出了一种针对LLaDA-V这种基于扩散的大规模多模态模型的结构化 token 剪枝策略，通过在中间到晚期的层上剪枝视觉 token，降低了计算开销，同时保持了任务性能。


<details>
  <summary>Details</summary>
Motivation: 研究发现，LLaDA-V 在中间到晚期层主要聚合跨模式信息，导致语义对齐延迟。因此，提出了基于 FastV 的结构化 token 剪枝策略，在第一阶段剪枝以降低后续步骤的计算量。

Method: 该方法 inspired by FastV，通过在 LLaDA-V 的第一个去噪步骤中的中间到晚期层选择性地移除一定比例的视觉 token。这种方法专注于与 LLaDA-V 的延迟注意力聚合对齐，从而维持输出质量。

Result: 实验结果表明，最佳配置可以降低高达 65% 的计算成本，同时保持平均 95% 的任务性能。这为 LLaDA-V 的高效推理提供了实证基础，并展示了扩散型多模态模型中感知剪枝的潜力。

Conclusion: 本文提出的结构化 token 剪枝策略在保证任务性能的前提下显著降低了计算成本，为多模态模型的高效推理提供了新的思路。

Abstract: Diffusion-based large multimodal models, such as LLaDA-V, have demonstrated impressive capabilities in vision-language understanding and generation. However, their bidirectional attention mechanism and diffusion-style iterative denoising paradigm introduce significant computational overhead, as visual tokens are repeatedly processed across all layers and denoising steps. In this work, we conduct an in-depth attention analysis and reveal that, unlike autoregressive decoders, LLaDA-V aggregates cross-modal information predominantly in middle-to-late layers, leading to delayed semantic alignment. Motivated by this observation, we propose a structured token pruning strategy inspired by FastV, selectively removing a proportion of visual tokens at designated layers to reduce FLOPs while preserving critical semantic information. To the best of our knowledge, this is the first work to investigate structured token pruning in diffusion-based large multimodal models. Unlike FastV, which focuses on shallow-layer pruning, our method targets the middle-to-late layers of the first denoising step to align with LLaDA-V's delayed attention aggregation to maintain output quality, and the first-step pruning strategy reduces the computation across all subsequent steps. Our framework provides an empirical basis for efficient LLaDA-V inference and highlights the potential of vision-aware pruning in diffusion-based multimodal models. Across multiple benchmarks, our best configuration reduces computational cost by up to 65% while preserving an average of 95% task performance.

</details>


### [6] [TeleStyle: Content-Preserving Style Transfer in Images and Videos](https://arxiv.org/abs/2601.20175)
*Shiwen Zhang,Xiaoyan Yang,Bojia Zi,Haibin Huang,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: TeleStyle 是一种轻量级且有效的图像和视频风格转换模型，通过结合高质量风格数据集和 Curriculum Continual Learning 训练方法，实现了较好的风格相似性、内容一致性和美学质量。


<details>
  <summary>Details</summary>
Motivation: Diffusion Transformers (DiTs) 在内容和风格特征的内部分离方面存在挑战，因此需要一种轻量级且有效的模型来同时处理图像和视频风格转换。

Method: TeleStyle 基于 Qwen-Image-Edit，采用 Curriculum Continual Learning 训练框架，并结合高质数据集和合成三元组，以提高模型的泛化能力并在不损害内容保真度的情况下实现风格转换。此外，还开发了一个视频到视频的风格化模块以提高视觉质量和时间一致性。

Result: TeleStyle 在风格相似性、内容一致性和美学质量三个方面实现了最优基准性能。

Conclusion: TeleStyle 是一种轻量级且有效的图像和视频风格转换模型，适用于各种应用场合并在多个关键评价指标上表现出色。

Abstract: Content-preserving style transfer, generating stylized outputs based on content and style references, remains a significant challenge for Diffusion Transformers (DiTs) due to the inherent entanglement of content and style features in their internal representations. In this technical report, we present TeleStyle, a lightweight yet effective model for both image and video stylization. Built upon Qwen-Image-Edit, TeleStyle leverages the base model's robust capabilities in content preservation and style customization. To facilitate effective training, we curated a high-quality dataset of distinct specific styles and further synthesized triplets using thousands of diverse, in-the-wild style categories. We introduce a Curriculum Continual Learning framework to train TeleStyle on this hybrid dataset of clean (curated) and noisy (synthetic) triplets. This approach enables the model to generalize to unseen styles without compromising precise content fidelity. Additionally, we introduce a video-to-video stylization module to enhance temporal consistency and visual quality. TeleStyle achieves state-of-the-art performance across three core evaluation metrics: style similarity, content consistency, and aesthetic quality. Code and pre-trained models are available at https://github.com/Tele-AI/TeleStyle

</details>


### [7] [DenseGRPO: From Sparse to Dense Reward for Flow Matching Model Alignment](https://arxiv.org/abs/2601.20218)
*Haoyou Deng,Keyu Yan,Chaojie Mao,Xiang Wang,Yu Liu,Changxin Gao,Nong Sang*

Main category: cs.CV

TL;DR: DenseGRPO 提出了一种新颖的框架，通过预测每个去噪步骤的逐步奖励增加作为密集奖励，解决基于流匹配模型的 GRPO 方法面临的稀疏奖励问题，并通过奖励感知的策略来校准探索空间，确保所有时间步长的合适探索空间。


<details>
  <summary>Details</summary>
Motivation: 现有基于 GRPO 的方法在人类偏好对齐方面取得了显著的改进，但这仍然受到稀疏奖励问题的困扰。DenseGRPO 提出了一种新的框架，通过为其每个去噪步骤提供详细的反馈信号，解决这一问题。

Method: DenseGRPO 的方法包括两个关键组件：一是提出预测每个去噪步骤的逐步奖励增加作为密集奖励；二是基于估计的密集奖励，提出一种奖励感知的方案来校准探索空间。

Result: 在多个标准基准上的广泛实验表明，DenseGRPO 是有效的，突显了在流匹配模型对齐中，有效的密集奖励的作用至关重要。

Conclusion: DenseGRPO 通过改进的密集奖励和探索空间校准，有效地解决了基于流匹配模型的 GRPO 方法的稀疏奖励问题，提升了人类偏好对齐的效果。

Abstract: Recent GRPO-based approaches built on flow matching models have shown remarkable improvements in human preference alignment for text-to-image generation. Nevertheless, they still suffer from the sparse reward problem: the terminal reward of the entire denoising trajectory is applied to all intermediate steps, resulting in a mismatch between the global feedback signals and the exact fine-grained contributions at intermediate denoising steps. To address this issue, we introduce \textbf{DenseGRPO}, a novel framework that aligns human preference with dense rewards, which evaluates the fine-grained contribution of each denoising step. Specifically, our approach includes two key components: (1) we propose to predict the step-wise reward gain as dense reward of each denoising step, which applies a reward model on the intermediate clean images via an ODE-based approach. This manner ensures an alignment between feedback signals and the contributions of individual steps, facilitating effective training; and (2) based on the estimated dense rewards, a mismatch drawback between the uniform exploration setting and the time-varying noise intensity in existing GRPO-based methods is revealed, leading to an inappropriate exploration space. Thus, we propose a reward-aware scheme to calibrate the exploration space by adaptively adjusting a timestep-specific stochasticity injection in the SDE sampler, ensuring a suitable exploration space at all timesteps. Extensive experiments on multiple standard benchmarks demonstrate the effectiveness of the proposed DenseGRPO and highlight the critical role of the valid dense rewards in flow matching model alignment.

</details>


### [8] [Feature Projection Learning for Better Vision-Language Reasoning](https://arxiv.org/abs/2601.20224)
*Yi Zhang,Weicheng Lin,Liang-Jie Zhang*

Main category: cs.CV

TL;DR: 本文介绍了一种名为FPL的方法，该方法通过将类原型特征投影到查询图像特征空间并重构查询图像特征图来解决现有方法的问题。这种方法将分类问题转换为特征投影问题，并通过投影模型的预测和原始预训练的CLIP的组合实现了显著的准确率提升。


<details>
  <summary>Details</summary>
Motivation: 现有方法在适应CLIP模型到下游任务时存在性能有限、可学习参数过多或训练时间过长的问题。本文提出了一种简单有效的方法，以解决这些问题。

Method: FPL方法通过开发一个投影模型，将类原型特征投影到查询图像特征空间并重构查询图像特征图来工作。使用负平均平方重构误差作为类得分。这种方法将分类问题转换为特征投影问题。

Result: FPL方法在综合实验评估中表现出色，准确率超过当前最先进的方法。

Conclusion: FPL提供了一种简单有效的方法，用于解决CLIP模型适应下游任务时的常见问题，并通过实验验证了其优越性。

Abstract: Vision-Language Pre-Trained models, notably CLIP, that utilize contrastive learning have proven highly adept at extracting generalizable visual features. To inherit the well-learned knowledge of VLP models for downstream tasks, several approaches aim to adapt them efficiently with limited supervision. However, these methods either suffer from limited performance, excessive learnable parameters, or extended training times, all of which hinder their effectiveness in adapting the CLIP model to downstream tasks. In this work, we propose a simple yet efficient and effective method called \textit{\textbf{F}eature \textbf{P}rojection \textbf{L}earning(FPL)} to address these problems. Specifically, we develop a projection model that projects class prototype features into the query image feature space and reconstructs the query image feature map. The negative average squared reconstruction error is used as the class score. In this way, we transform the classification problem into a feature projection problem. The final output of this method is a combination of the prediction from the projection model and the original pre-trained CLIP. Comprehensive empirical evaluations confirm that FPL delivers superior accuracy, surpassing the current state-of-the-art methods by a substantial margin.

</details>


### [9] [Visual Prompt-Agnostic Evolution](https://arxiv.org/abs/2601.20232)
*Junze Wang,Lei Fan,Dezheng Zhang,Weipeng Jing,Donglin Di,Yang Song,Sidong Liu,Cong Cong*

Main category: cs.CV

TL;DR: 本文提出了一种名为Prompt-Agnostic Evolution (PAE)的新方法，旨在改善视觉提示调整（VPT）中的训练动态，实现更稳定和快速的收敛。PAE通过频率域初始化提示，并采用共享Koopman算子确保不同层之间的协调更新。此外，PAE引入了Lyapunov稳定性理论的正则化器来控制演化过程中的误差放大。


<details>
  <summary>Details</summary>
Motivation: 现有视觉提示调整（VPT）方法常常存在不稳定的训练动态，不适应深层和浅层提示的挑战。

Method: PAE方法通过任务感知的频率初始化提示，使用共享Koopman算子确保不同层的同步更新，并引入基于Lyapunov稳定性的正则化器来控制误差放大。

Result: 实验表明，PAE方法相比现有方法平均提速1.41倍，并提高了1-3%的准确率。该方法具有提示无关和轻量级的特点，并能与多种VPT变体无缝结合。

Conclusion: PAE方法为提高VPT性能提供了一种新的思路，通过增强提示演化的稳定性，优化视觉任务的训练过程。

Abstract: Visual Prompt Tuning (VPT) adapts a frozen Vision Transformer (ViT) to downstream tasks by inserting a small number of learnable prompt tokens into the token sequence at each layer. However, we observe that existing VPT variants often suffer from unstable training dynamics, characterized by gradient oscillations. A layer-wise analysis reveals that shallow-layer prompts tend to stagnate early, while deeper-layer prompts exhibit high-variance oscillations, leading to cross-layer mismatch. These issues slow convergence and degrade final performance. To address these challenges, we propose Prompt-Agnostic Evolution ($\mathtt{PAE}$), which strengthens vision prompt tuning by explicitly modeling prompt dynamics. From a frequency-domain perspective, we initialize prompts in a task-aware direction by uncovering and propagating frequency shortcut patterns that the backbone inherently exploits for recognition. To ensure coherent evolution across layers, we employ a shared Koopman operator that imposes a global linear transformation instead of uncoordinated, layer-specific updates. Finally, inspired by Lyapunov stability theory, we introduce a regularizer that constrains error amplification during evolution. Extensive experiments show that $\mathtt{PAE}$ accelerates convergence with an average $1.41\times$ speedup and improves accuracy by 1--3% on 25 datasets across multiple downstream tasks. Beyond performance, $\mathtt{PAE}$ is prompt-agnostic and lightweight, and it integrates seamlessly with diverse VPT variants without backbone modification or inference-time changes.

</details>


### [10] [Reversible Efficient Diffusion for Image Fusion](https://arxiv.org/abs/2601.20260)
*Xingxin Xu,Bing Cao,DongDong Li,Qinghua Hu,Pengfei Zhu*

Main category: cs.CV

TL;DR: 本文提出了一种名为RED的可逆高效扩散模型，旨在通过显式监督克服传统扩散模型在多模态图像融合中的细节损失问题。


<details>
  <summary>Details</summary>
Motivation: 传统的扩散模型在图像生成方面表现出色，但在应用于图像融合时往往会出现细节丢失的问题，这主要是由于马尔可夫过程中的累积噪声误差导致的不一致性。为解决此问题，本文提出了RED模型。

Method: RED模型采用了显式监督的端到端训练框架，旨在保持扩散模型的强大生成能力，同时避免分布估计问题。

Result: 该研究证明了RED模型在多模态图像融合方面的优势。

Conclusion: RED模型提供了一种新的方法来有效地进行多模态图像融合，平衡了生成质量和计算效率。

Abstract: Multi-modal image fusion aims to consolidate complementary information from diverse source images into a unified representation. The fused image is expected to preserve fine details and maintain high visual fidelity. While diffusion models have demonstrated impressive generative capabilities in image generation, they often suffer from detail loss when applied to image fusion tasks. This issue arises from the accumulation of noise errors inherent in the Markov process, leading to inconsistency and degradation in the fused results. However, incorporating explicit supervision into end-to-end training of diffusion-based image fusion introduces challenges related to computational efficiency. To address these limitations, we propose the Reversible Efficient Diffusion (RED) model - an explicitly supervised training framework that inherits the powerful generative capability of diffusion models while avoiding the distribution estimation.

</details>


### [11] [Hallucination Begins Where Saliency Drops](https://arxiv.org/abs/2601.20279)
*Xiaofeng Zhang,Yuanchao Zhu,Chaochen Gu,Xiaosong Yuan,Qiyan Zhao,Jiawei Cao,Feilong Tang,Sinan Fan,Yaomin Shen,Chen Shen,Hao Tang*

Main category: cs.CV

TL;DR: 该研究提出了一种新的框架LVLMs-Saliency，通过结合注意力权重和输入梯度来量化每个输出标记的视觉关联强度。研究发现，幻觉经常出现在先前的输出标记对下一个标记的预测缺乏重要性时，提出了基于重要性的拒绝采样和局部一致性增强两大机制来减少幻觉，实验表明该方法在保持流畅性和任务性能的同时显著降低了幻觉率。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅依赖前向注意力模式来识别幻觉，忽略了梯度信号，导致难以区分幻觉和事实依据的输出。为了填补这一空白，提出了LVLMs-Saliency框架。

Method: 结合了注意力权重和输入梯度，LVLMs-Saliency框架通过量化每个输出标记的视觉关联强度来进行检测和减少幻觉。此外，还设计了基于重要性的拒绝采样（SGRS）和局部一致性增强（LocoRE）两大机制来实际减少幻觉。

Result: 通过广泛的实验验证了SGLRS和LocoRE在多个大型视觉语言模型中的有效性，显著降低了幻觉率，同时保持了流畅性和任务性能。

Conclusion: 该研究提供了一种新的方法LVLMs-Saliency，有效减少了大型视觉语言模型中的幻觉，提升了模型的可靠性和可解释性。

Abstract: Recent studies have examined attention dynamics in large vision-language models (LVLMs) to detect hallucinations. However, existing approaches remain limited in reliably distinguishing hallucinated from factually grounded outputs, as they rely solely on forward-pass attention patterns and neglect gradient-based signals that reveal how token influence propagates through the network. To bridge this gap, we introduce LVLMs-Saliency, a gradient-aware diagnostic framework that quantifies the visual grounding strength of each output token by fusing attention weights with their input gradients. Our analysis uncovers a decisive pattern: hallucinations frequently arise when preceding output tokens exhibit low saliency toward the prediction of the next token, signaling a breakdown in contextual memory retention. Leveraging this insight, we propose a dual-mechanism inference-time framework to mitigate hallucinations: (1) Saliency-Guided Rejection Sampling (SGRS), which dynamically filters candidate tokens during autoregressive decoding by rejecting those whose saliency falls below a context-adaptive threshold, thereby preventing coherence-breaking tokens from entering the output sequence; and (2) Local Coherence Reinforcement (LocoRE), a lightweight, plug-and-play module that strengthens attention from the current token to its most recent predecessors, actively counteracting the contextual forgetting behavior identified by LVLMs-Saliency. Extensive experiments across multiple LVLMs demonstrate that our method significantly reduces hallucination rates while preserving fluency and task performance, offering a robust and interpretable solution for enhancing model reliability. Code is available at: https://github.com/zhangbaijin/LVLMs-Saliency

</details>


### [12] [A Source-Free Approach for Domain Adaptation via Multiview Image Transformation and Latent Space Consistency](https://arxiv.org/abs/2601.20284)
*Debopom Sutradhar,Md. Abdur Rahman,Mohaimenul Azam Khan Raiaan,Reem E. Mohamed,Sami Azam*

Main category: cs.CV

TL;DR: 本文提出了一种无需源域数据的领域自适应方法，通过多视图增强和潜在空间一致性技术直接从目标域学习领域不变特征。


<details>
  <summary>Details</summary>
Motivation: 现有的领域自适应方法通常需要访问源域数据或使用复杂的伪标签技术，这很耗计算资源。本文旨在提出一种新的方法来解决这些挑战。

Method: 该方法使用多视图增强和潜在空间一致性技术，仅通过目标域的数据学习可迁移的表示，通过在潜在空间中强制多个增强视图的一致性来确保所学特征的一致性。

Result: 在Office-31、Office-Home和Office-Caltech数据集中，本文的方法分别实现了90.72%、84%和97.12%的分类精度，比现有方法平均提高了1.23%、7.26%和1.77%。

Conclusion: 该研究提出了一种新型的无需源域数据的领域自适应方法，有效提高了目标域的分类性能。

Abstract: Domain adaptation (DA) addresses the challenge of transferring knowledge from a source domain to a target domain where image data distributions may differ. Existing DA methods often require access to source domain data, adversarial training, or complex pseudo-labeling techniques, which are computationally expensive. To address these challenges, this paper introduces a novel source-free domain adaptation method. It is the first approach to use multiview augmentation and latent space consistency techniques to learn domain-invariant features directly from the target domain. Our method eliminates the need for source-target alignment or pseudo-label refinement by learning transferable representations solely from the target domain by enforcing consistency between multiple augmented views in the latent space. Additionally, the method ensures consistency in the learned features by generating multiple augmented views of target domain data and minimizing the distance between their feature representations in the latent space. We also introduce a ConvNeXt-based encoder and design a loss function that combines classification and consistency objectives to drive effective adaptation directly from the target domain. The proposed model achieves an average classification accuracy of 90. 72\%, 84\%, and 97. 12\% in Office-31, Office-Home and Office-Caltech datasets, respectively. Further evaluations confirm that our study improves existing methods by an average classification accuracy increment of +1.23\%, +7.26\%, and +1.77\% on the respective datasets.

</details>


### [13] [Artifact-Aware Evaluation for High-Quality Video Generation](https://arxiv.org/abs/2601.20297)
*Chen Zhu,Jiashu Zhu,Yanxun Li,Meiqi Wu,Bingze Song,Chubin Chen,Jiahong Wu,Xiangxiang Chu,Yangang Wang*

Main category: cs.CV

TL;DR: 该研究提出了一种综合评价协议，专注于影响人类感知的三个方面：外观、运动和摄像机。通过一个包含10种常见生成失败的分类税本来定义这些轴，并引入了一个大规模的视频生成数据集GenVID，用于进行精细的生成缺陷识别和分类。基于GenVID，开发了DVAR框架，实验表明该方法显著提高了缺陷检测的准确性。


<details>
  <summary>Details</summary>
Motivation: 随着视频生成技术的快速发展，对生成视频的评估和审计变得日益重要。现有的方法通常只能提供粗略的视频质量评分，缺乏对特定缺陷的详细定位和分类。因此，本文提出了一个综合评价协议，重点关注人类感知的三个关键方面：外观、运动和摄像机，以提供更详细的评价。

Method: 本文通过引入一个包含10种常见生成失败的分类税本来定义了影响人类感知的三个轴，并构建了一个大规模的视频生成数据集GenVID，用于对生成缺陷进行精细的识别和分类。在此基础上，开发了一个密集视频缺陷识别框架DVAR。

Result: 实验表明，基于GenVID和DVAR框架的方法能够显著提高生成缺陷的检测准确性，并有效过滤低质量内容。

Conclusion: 本文提出了一种综合评价协议及相关的方法，能够更精细地识别和分类生成视频中的缺陷，从而提供更准确的评价结果。

Abstract: With the rapid advancement of video generation techniques, evaluating and auditing generated videos has become increasingly crucial. Existing approaches typically offer coarse video quality scores, lacking detailed localization and categorization of specific artifacts. In this work, we introduce a comprehensive evaluation protocol focusing on three key aspects affecting human perception: Appearance, Motion, and Camera. We define these axes through a taxonomy of 10 prevalent artifact categories reflecting common generative failures observed in video generation. To enable robust artifact detection and categorization, we introduce GenVID, a large-scale dataset of 80k videos generated by various state-of-the-art video generation models, each carefully annotated for the defined artifact categories. Leveraging GenVID, we develop DVAR, a Dense Video Artifact Recognition framework for fine-grained identification and classification of generative artifacts. Extensive experiments show that our approach significantly improves artifact detection accuracy and enables effective filtering of low-quality content.

</details>


### [14] [Bridging the Applicator Gap with Data-Doping:Dual-Domain Learning for Precise Bladder Segmentation in CT-Guided Brachytherapy](https://arxiv.org/abs/2601.20302)
*Suresh Das,Siladittya Manna,Sayantari Ghosh*

Main category: cs.CV

TL;DR: 通过将无植入器(NA)CT数据和有植入器(WA)CT数据结合，研究提出了一种双域学习策略，以提高在CT导向妇科放疗中通过CT引导下膀胱分割的鲁棒性和泛化能力，结果表明少量的WA数据可以显著提升分割性能。


<details>
  <summary>Details</summary>
Motivation: 研究的动机在于解决医学图像分割中由于分布偏移导致的性能下降问题，特别是在缺乏目标领域大量数据的情况下，希望通过集成不同分布的数据来提高模型的鲁棒性和泛化能力，使其在存在显著解剖变形和成像伪影的情况下仍能有效学习。

Method: 研究采用了一种称为双域学习的策略，该策略结合了无植入器(NA)CT数据和有植入器(WA)CT数据。通过系统地在多个深度学习架构和不同切面（轴向、冠状和矢状面）上进行实验，逐步验证了少量WA数据能否显著提高分割性能。

Result: 研究结果显示，通过增加10-30%的有植入器(WA)数据到主要由无植入器(NA)数据组成的训练集中，显著提高了膀胱分割的 Dice 相似性系数（最高达到0.94）和交集并集比（最高达到0.92）。这一结果表明，双域策略在解决因分布偏移而导致的数据稀缺问题方面具有重要价值。

Conclusion: 研究结论是，双域学习策略在充分通过与目标领域样本相似但分布偏移的数据集进行训练方面表现出色，提升了医学影像分割模型在特定应用场景中的有效性和临床可靠性。

Abstract: Performance degradation due to covariate shift remains a major challenge for deep learning models in medical image segmentation. An open question is whether samples from a shifted distribution can effectively support learning when combined with limited target domain data. We investigate this problem in the context of bladder segmentation in CT guided gynecological brachytherapy, a critical task for accurate dose optimization and organ at risk sparing. While CT scans without brachytherapy applicators (no applicator: NA) are widely available, scans with applicators inserted (with applicator: WA) are scarce and exhibit substantial anatomical deformation and imaging artifacts, making automated segmentation particularly difficult.
  We propose a dual domain learning strategy that integrates NA and WA CT data to improve robustness and generalizability under covariate shift. Using a curated assorted dataset, we show that NA data alone fail to capture the anatomical and artifact related characteristics of WA images. However, introducing a modest proportion of WA data into a predominantly NA training set leads to significant performance improvements. Through systematic experiments across axial, coronal, and sagittal planes using multiple deep learning architectures, we demonstrate that doping only 10 to 30 percent WA data achieves segmentation performance comparable to models trained exclusively on WA data.
  The proposed approach attains Dice similarity coefficients of up to 0.94 and Intersection over Union scores of up to 0.92, indicating effective domain adaptation and improved clinical reliability. This study highlights the value of integrating anatomically similar but distribution shifted datasets to overcome data scarcity and enhance deep learning based segmentation for brachytherapy treatment planning.

</details>


### [15] [Physically Guided Visual Mass Estimation from a Single RGB Image](https://arxiv.org/abs/2601.20303)
*Sungjae Lee,Junhan Jeong,Yeonjoo Hong,Kwang In Kim*

Main category: cs.CV

TL;DR: 本文提出了一种用于单幅图像物体质量估计的物理结构框架，通过融合几何、语义和外观特征，并预测体积和密度相关的潜在因素，改进了物体质量估计的准确性。


<details>
  <summary>Details</summary>
Motivation: 物体质量从视觉输入中估计具有挑战性，因为质量与几何体积和材料密度有关，后者不能直接从单张RGB图像中观察到。因此，像素级别的质量预测问题缺乏明确性，需要用物理上合理的表示来限制可能的解空间。

Method: 该框架首先通过单目深度估计从单张RGB图像中恢复以物体为中心的三维几何形状，随后使用视觉-语言模型提取粗略的语义信息，以此指导密度相关的推理。几何、语义和外观特征通过实例自适应门控机制融合，预测体积和密度相关的两个物理指导潜在因素。

Result: 通过在image2mass和ABO-500数据集上的实验，该方法在物体质量估计上显著优于现有最先进的方法。

Conclusion: 本文的工作展示了通过物理结构框架可以有效提高单幅图像中物体质量估计的准确性。

Abstract: Estimating object mass from visual input is challenging because mass depends jointly on geometric volume and material-dependent density, neither of which is directly observable from RGB appearance. Consequently, mass prediction from pixels is ill-posed and therefore benefits from physically meaningful representations to constrain the space of plausible solutions. We propose a physically structured framework for single-image mass estimation that addresses this ambiguity by aligning visual cues with the physical factors governing mass. From a single RGB image, we recover object-centric three-dimensional geometry via monocular depth estimation to inform volume and extract coarse material semantics using a vision-language model to guide density-related reasoning. These geometry, semantic, and appearance representations are fused through an instance-adaptive gating mechanism, and two physically guided latent factors (volume- and density-related) are predicted through separate regression heads under mass-only supervision. Experiments on image2mass and ABO-500 show that the proposed method consistently outperforms state-of-the-art methods.

</details>


### [16] [Structure-constrained Language-informed Diffusion Model for Unpaired Low-dose Computed Tomography Angiography Reconstruction](https://arxiv.org/abs/2601.20304)
*Genyuan Zhang,Zihao Wang,Zhifan Gao,Lei Xu,Zhen Zhou,Haijun Yu,Jianjia Zhang,Xiujian Liu,Weiwei Zhang,Shaoyu Wang,Huazhu Fu,Fenglin Liu,Weiwen Wu*

Main category: cs.CV

TL;DR: 研究提出了一种名为结构约束语言导向扩散模型（SLDM）的方法，该方法通过结构先验信息约束和空间智能指导，有效提升低剂量对比剂CT血管造影图像的质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法在低剂量对比剂图像增强上存在精确增强困难的问题，主要是由于模型识别特定结构能力有限。

Method: SLDM模型结合了结构先验信息约束和空间智能指导，分为三个步骤：提取结构先验信息以约束模型推理过程，引入语义监督策略结合视觉感知和空间推理，最后应用减影血管造影增强模块以提高对比剂区域的对比度。

Result: 通过视觉比较和多种度量的定量结果，该研究验证了SLDM方法在低剂量对比剂CT血管造影重建中的有效性。

Conclusion: SLDM方法能够有效提升低剂量对比剂CT血管造影图像的质量，确保重建过程中的结构一致性，并实现准确的增强。

Abstract: The application of iodinated contrast media (ICM) improves the sensitivity and specificity of computed tomography (CT) for a wide range of clinical indications. However, overdose of ICM can cause problems such as kidney damage and life-threatening allergic reactions. Deep learning methods can generate CT images of normal-dose ICM from low-dose ICM, reducing the required dose while maintaining diagnostic power. However, existing methods are difficult to realize accurate enhancement with incompletely paired images, mainly because of the limited ability of the model to recognize specific structures. To overcome this limitation, we propose a Structure-constrained Language-informed Diffusion Model (SLDM), a unified medical generation model that integrates structural synergy and spatial intelligence. First, the structural prior information of the image is effectively extracted to constrain the model inference process, thus ensuring structural consistency in the enhancement process. Subsequently, semantic supervision strategy with spatial intelligence is introduced, which integrates the functions of visual perception and spatial reasoning, thus prompting the model to achieve accurate enhancement. Finally, the subtraction angiography enhancement module is applied, which serves to improve the contrast of the ICM agent region to suitable interval for observation. Qualitative analysis of visual comparison and quantitative results of several metrics demonstrate the effectiveness of our method in angiographic reconstruction for low-dose contrast medium CT angiography.

</details>


### [17] [OSDEnhancer: Taming Real-World Space-Time Video Super-Resolution with One-Step Diffusion](https://arxiv.org/abs/2601.20308)
*Shuoyan Wei,Feng Li,Chen Zhou,Runmin Cong,Yao Zhao,Huihui Bai*

Main category: cs.CV

TL;DR: 提出了一种新颖的OSDEnhancer框架，通过高效的一步扩散过程实现了一种新的时空视频超分辨率方法，显著提升了帧间一致性和跨帧重建精度。


<details>
  <summary>Details</summary>
Motivation: 鉴于现有STVSR方法在处理复杂未知降质假设方面的能力有限，特别是面对高准确性和时间内在一致性的高需求，本文旨在提出一种全面的方法来解决时空视频超分辨率的不足。

Method: OSDEnhancer框架利用线性预插值策略初始化时空结构，并采用训练时序细化和空间增强混合专家（TR-SE MoE），允许不同专家路径逐步学习对时序连贯性和空间细节的鲁棒、专业化表示，进一步在推理过程中相互加强。引入双向可变形VAE解码器进行时空聚合和传播，增强跨帧重建精度。

Result: 实验证明，所提方法在基准数据集上达到了最先进的性能，同时保持了在实际应用中的优越泛化能力。

Conclusion: 本文提出的OSDEnhancer为时空视频超分辨率领域的进一步研究提供了新的思路和方法。

Abstract: Diffusion models (DMs) have demonstrated exceptional success in video super-resolution (VSR), showcasing a powerful capacity for generating fine-grained details. However, their potential for space-time video super-resolution (STVSR), which necessitates not only recovering realistic visual content from low-resolution to high-resolution but also improving the frame rate with coherent temporal dynamics, remains largely underexplored. Moreover, existing STVSR methods predominantly address spatiotemporal upsampling under simplified degradation assumptions, which often struggle in real-world scenarios with complex unknown degradations. Such a high demand for reconstruction fidelity and temporal consistency makes the development of a robust STVSR framework particularly non-trivial. To address these challenges, we propose OSDEnhancer, a novel framework that, to the best of our knowledge, represents the first method to achieve real-world STVSR through an efficient one-step diffusion process. OSDEnhancer initializes essential spatiotemporal structures through a linear pre-interpolation strategy and pivots on training temporal refinement and spatial enhancement mixture of experts (TR-SE MoE), which allows distinct expert pathways to progressively learn robust, specialized representations for temporal coherence and spatial detail, further collaboratively reinforcing each other during inference. A bidirectional deformable variational autoencoder (VAE) decoder is further introduced to perform recurrent spatiotemporal aggregation and propagation, enhancing cross-frame reconstruction fidelity. Experiments demonstrate that the proposed method achieves state-of-the-art performance while maintaining superior generalization capability in real-world scenarios.

</details>


### [18] [CPiRi: Channel Permutation-Invariant Relational Interaction for Multivariate Time Series Forecasting](https://arxiv.org/abs/2601.20318)
*Jiyuan Xu,Wenyu Zhang,Xin Jing,Shuai Chen,Shuai Zhang,Jiahao Nie*

Main category: cs.CV

TL;DR: CPiRi 通过提出一种通道不变（CPI）框架，解决了多变量时间序列预测中通道依赖性和通道独立性模型的局限性。该框架利用数据推断跨通道结构，而不是记忆固定的渠道顺序。CPiRi 在多种基准测试上表现出优越的性能，并且在不重新训练的情况下也能保持对未见过通道的推广性能。


<details>
  <summary>Details</summary>
Motivation: 当前的方法在多变量时间序列预测中存在不足，如通道依赖模型容易过拟合通道顺序，而通道独立模型则忽略了跨通道的依赖关系。CPiRi 旨在克服这些难题，提供一种新的框架来更好地理解和预测多变量时间序列。

Method: CPiRi 采用了时空分离架构和通道不变规训策略。首先，使用冻结的预训练时间编码器提取高质量的时间特性；其次，轻量级的空间模块学习内容驱动的跨通道关系；最后，通过通道洗牌策略在训练期间实施通道不变性。

Result: 该研究在多个基准测试上取得了最先进的结果。CPiRi 在调整通道顺序后依然表现稳定，即使仅用一半的通道进行训练也能展现出对未见过通道的强归纳泛化能力；同时保持了在大规模数据集上的实用性。

Conclusion: 总而言之，CPiRi 有望成为提高多变量时间序列预测性能和适应性的有效解决方案。

Abstract: Current methods for multivariate time series forecasting can be classified into channel-dependent and channel-independent models. Channel-dependent models learn cross-channel features but often overfit the channel ordering, which hampers adaptation when channels are added or reordered. Channel-independent models treat each channel in isolation to increase flexibility, yet this neglects inter-channel dependencies and limits performance. To address these limitations, we propose \textbf{CPiRi}, a \textbf{channel permutation invariant (CPI)} framework that infers cross-channel structure from data rather than memorizing a fixed ordering, enabling deployment in settings with structural and distributional co-drift without retraining. CPiRi couples \textbf{spatio-temporal decoupling architecture} with \textbf{permutation-invariant regularization training strategy}: a frozen pretrained temporal encoder extracts high-quality temporal features, a lightweight spatial module learns content-driven inter-channel relations, while a channel shuffling strategy enforces CPI during training. We further \textbf{ground CPiRi in theory} by analyzing permutation equivariance in multivariate time series forecasting. Experiments on multiple benchmarks show state-of-the-art results. CPiRi remains stable when channel orders are shuffled and exhibits strong \textbf{inductive generalization} to unseen channels even when trained on \textbf{only half} of the channels, while maintaining \textbf{practical efficiency} on large-scale datasets. The source code is released at https://github.com/JasonStraka/CPiRi.

</details>


### [19] [GVGS: Gaussian Visibility-Aware Multi-View Geometry for Accurate Surface Reconstruction](https://arxiv.org/abs/2601.20331)
*Mai Su,Qihan Yu,Zhongtao Wang,Yilong Li,Chengwei Pan,Yisong Chen,Guoping Wang*

Main category: cs.CV

TL;DR: 本文提出了一种新的Gaussian可见性感知多视角几何一致性约束和分级单目深度约束，从而改进了Gaussian深度估计，提高了几何准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于Gaussian的方法在表面重建时面临几何不一致性问题，而基于单目深度先验的方法则受到尺度不确定性的影响。

Method: 文中引入了Gaussian可见性感知多视角几何一致性约束以及分级单目深度约束。

Result: 实验结果表明，该方法在DTU和TNT数据集上的几何准确性比之前的基于Gaussian的方法和隐式曲面重建方法有持续改进。

Conclusion: 该工作提出的方法在3D表面重建方面有显著的改进，为后续研究提供了新的思路。

Abstract: 3D Gaussian Splatting enables efficient optimization and high-quality rendering, yet accurate surface reconstruction remains challenging. Prior methods improve surface reconstruction by refining Gaussian depth estimates, either via multi-view geometric consistency or through monocular depth priors. However, multi-view constraints become unreliable under large geometric discrepancies, while monocular priors suffer from scale ambiguity and local inconsistency, ultimately leading to inaccurate Gaussian depth supervision. To address these limitations, we introduce a Gaussian visibility-aware multi-view geometric consistency constraint that aggregates the visibility of shared Gaussian primitives across views, enabling more accurate and stable geometric supervision. In addition, we propose a progressive quadtree-calibrated Monocular depth constraint that performs block-wise affine calibration from coarse to fine spatial scales, mitigating the scale ambiguity of depth priors while preserving fine-grained surface details. Extensive experiments on DTU and TNT datasets demonstrate consistent improvements in geometric accuracy over prior Gaussian-based and implicit surface reconstruction methods. Codes are available at an anonymous repository: https://github.com/GVGScode/GVGS.

</details>


### [20] [Test-Time Adaptation for Anomaly Segmentation via Topology-Aware Optimal Transport Chaining](https://arxiv.org/abs/2601.20333)
*Ali Zia,Usman Ali,Umer Ramzan,Abdul Rehman,Abdelwahed Khamis,Wei Xiang*

Main category: cs.CV

TL;DR: TopoOT 是一种基于拓扑的数据分析方法，它利用最优传输在多级过滤持久性图上进行建模，能够更稳健地处理领域变化，从而在多种标准的2D和3D异常检测基准上获得最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法如阈值二值化对分布偏移敏感，而基于拓扑的方法能够捕捉结构不变量，更适合作为异常分割的任务。

Method: TopoOT 框架结合了多尺度过滤和测验时间适应，通过最优传输链进行持久性图对齐，生成地标稳定性评分，监督一个轻量级头部模型。

Result: TopoOT 在包括2D和3D异检测在内的标准基准测试中表现出色，特别是在2D数据集上平均F1提高了24.1%，在3D异常分割上提高了10.2%。

Conclusion: TopoOT 成为一种强大的工具，能够在分布偏移的环境下实现稳定的异常检测。

Abstract: Deep topological data analysis (TDA) offers a principled framework for capturing structural invariants such as connectivity and cycles that persist across scales, making it a natural fit for anomaly segmentation (AS). Unlike thresholdbased binarisation, which produces brittle masks under distribution shift, TDA allows anomalies to be characterised as disruptions to global structure rather than local fluctuations. We introduce TopoOT, a topology-aware optimal transport (OT) framework that integrates multi-filtration persistence diagrams (PDs) with test-time adaptation (TTA). Our key innovation is Optimal Transport Chaining, which sequentially aligns PDs across thresholds and filtrations, yielding geodesic stability scores that identify features consistently preserved across scales. These stabilityaware pseudo-labels supervise a lightweight head trained online with OT-consistency and contrastive objectives, ensuring robust adaptation under domain shift. Across standard 2D and 3D anomaly detection benchmarks, TopoOT achieves state-of-the-art performance, outperforming the most competitive methods by up to +24.1% mean F1 on 2D datasets and +10.2% on 3D AS benchmarks.

</details>


### [21] [Everything in Its Place: Benchmarking Spatial Intelligence of Text-to-Image Models](https://arxiv.org/abs/2601.20354)
*Zengbin Wang,Xuecai Hu,Yong Wang,Feng Xiong,Man Zhang,Xiangxiang Chu*

Main category: cs.CV

TL;DR: SpatialGenEval 提出了一个新的基准，旨在系统评估 T2I 模型的时空智能，通过使用大量复杂且信息密集的提示来挑战模型的高阶空间推理能力。研究还展示了如何通过丰富的数据集进一步提升时空智能。


<details>
  <summary>Details</summary>
Motivation: 当前 T2I 模型因为简单的提示设计而忽视了复杂的空间关系处理，新的基准 SpatialGenEval 旨在填补这一空白。

Method: 构建了 1,230 个复杂且信息密集的提示，每个提示包含10个空间亚域及相对应的10个选择题，同时创建了一个包含15,400个图文对的 SpatialT2I 数据集，用于训练和评估模型。

Result: 21个最先进的模型在 SpatialGenEval 上的评估结果显示，高阶空间推理能力仍是主要瓶颈。同时，利用 SpatialT2I 数据集进行微调的模型在当前基础模型上表现出 +4.2% 至 +5.7% 的性能提升，并在空间关系上呈现出更真实的效果。

Conclusion: 此研究通过新的基准和数据集展示了提升 T2I 模型时空智能的有效方法，并揭示了高阶空间推理仍是当前 T2I 技术的痛点。

Abstract: Text-to-image (T2I) models have achieved remarkable success in generating high-fidelity images, but they often fail in handling complex spatial relationships, e.g., spatial perception, reasoning, or interaction. These critical aspects are largely overlooked by current benchmarks due to their short or information-sparse prompt design. In this paper, we introduce SpatialGenEval, a new benchmark designed to systematically evaluate the spatial intelligence of T2I models, covering two key aspects: (1) SpatialGenEval involves 1,230 long, information-dense prompts across 25 real-world scenes. Each prompt integrates 10 spatial sub-domains and corresponding 10 multi-choice question-answer pairs, ranging from object position and layout to occlusion and causality. Our extensive evaluation of 21 state-of-the-art models reveals that higher-order spatial reasoning remains a primary bottleneck. (2) To demonstrate that the utility of our information-dense design goes beyond simple evaluation, we also construct the SpatialT2I dataset. It contains 15,400 text-image pairs with rewritten prompts to ensure image consistency while preserving information density. Fine-tuned results on current foundation models (i.e., Stable Diffusion-XL, Uniworld-V1, OmniGen2) yield consistent performance gains (+4.2%, +5.7%, +4.4%) and more realistic effects in spatial relations, highlighting a data-centric paradigm to achieve spatial intelligence in T2I models.

</details>


### [22] [CURVE: Learning Causality-Inspired Invariant Representations for Robust Scene Understanding via Uncertainty-Guided Regularization](https://arxiv.org/abs/2601.20355)
*Yue Liang,Jiatong Du,Ziyi Yang,Yanjun Huang,Hong Chen*

Main category: cs.CV

TL;DR: CURVE 基于因果推理框架，通过结合变异性建模与结构正则化来减少环境特异性关系，从而提高场景理解的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有场景图方法容易过度拟合，导致分布外泛化能力差。

Method: CURVE 使用因果启发的方法，结合变异性建模和结构正则化，通过原型条件下的去偏差处理，将不变的互动动态与环境依赖变化分离，促进稀疏且领域稳定的拓扑结构。

Result: 在零-shot 转移任务和低数据模拟到现实的适应中，CURVE 演示了构建领域稳定稀疏拓扑和提供可靠的不确定性估计的能力，以支持分布转移下的风险预测。

Conclusion: CURVE 提供了一种新的方法来增强场景图表示的方法，提高其在变化环境下的可靠性和适应性。

Abstract: Scene graphs provide structured abstractions for scene understanding, yet they often overfit to spurious correlations, severely hindering out-of-distribution generalization. To address this limitation, we propose CURVE, a causality-inspired framework that integrates variational uncertainty modeling with uncertainty-guided structural regularization to suppress high-variance, environment-specific relations. Specifically, we apply prototype-conditioned debiasing to disentangle invariant interaction dynamics from environment-dependent variations, promoting a sparse and domain-stable topology. Empirically, we evaluate CURVE in zero-shot transfer and low-data sim-to-real adaptation, verifying its ability to learn domain-stable sparse topologies and provide reliable uncertainty estimates to support risk prediction under distribution shifts.

</details>


### [23] [RAW-Flow: Advancing RGB-to-RAW Image Reconstruction with Deterministic Latent Flow Matching](https://arxiv.org/abs/2601.20364)
*Zhen Liu,Diedong Feng,Hai Jiang,Liaoyuan Zeng,Hao Wang,Chaoyu Feng,Lei Lei,Bing Zeng,Shuaicheng Liu*

Main category: cs.CV

TL;DR: RAW-Flow通过将RGB-to-RAW重建问题重新表述为确定性的潜空间传输问题，引入了新颖的流动匹配方法来学习潜空间中的确定性向量场，增强了跨尺度上下文指导模块，并设计了一个双域潜空间自编码器以促进稳定的训练和高质量的重建。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的方法在RGB-to-RAW重建任务中通常直接将其视为直接回归目标，难以解决细节不一致和颜色偏差问题。RAW-Flow通过革新方法旨在解决这些问题。

Method: RAW-Flow通过将问题重新表述为确定性的潜空间传输问题，使用流动匹配来学习潜空间中的确定性向量场。此外，还引入了一种跨尺度上下文指导模块，将层次RGB特征注入到流动估计过程中，并设计了一个双域潜空间自编码器以促进稳定的训练和高质量的重建。

Result: 实验结果表明，与现有的先进方法相比，RAW-Flow在定量和视觉上都表现出更好的性能。

Conclusion: RAW-Flow为RGB-to-RAW重建提出了一个新的框架，通过上述方法有效地连接RGB和RAW表示之间，实现结构细节和颜色信息的准确重建。

Abstract: RGB-to-RAW reconstruction, or the reverse modeling of a camera Image Signal Processing (ISP) pipeline, aims to recover high-fidelity RAW data from RGB images. Despite notable progress, existing learning-based methods typically treat this task as a direct regression objective and struggle with detail inconsistency and color deviation, due to the ill-posed nature of inverse ISP and the inherent information loss in quantized RGB images. To address these limitations, we pioneer a generative perspective by reformulating RGB-to-RAW reconstruction as a deterministic latent transport problem and introduce a novel framework named RAW-Flow, which leverages flow matching to learn a deterministic vector field in latent space, to effectively bridge the gap between RGB and RAW representations and enable accurate reconstruction of structural details and color information. To further enhance latent transport, we introduce a cross-scale context guidance module that injects hierarchical RGB features into the flow estimation process. Moreover, we design a dual-domain latent autoencoder with a feature alignment constraint to support the proposed latent transport framework, which jointly encodes RGB and RAW inputs while promoting stable training and high-fidelity reconstruction. Extensive experiments demonstrate that RAW-Flow outperforms state-of-the-art approaches both quantitatively and visually.

</details>


### [24] [HINT: Hierarchical Interaction Modeling for Autoregressive Multi-Human Motion Generation](https://arxiv.org/abs/2601.20383)
*Mengge Liu,Yan Di,Gu Wang,Yun Qu,Dekai Zhu,Yanyan Li,Xiangyang Ji*

Main category: cs.CV

TL;DR: HINT通过利用分解的运动表示和分层的交互建模，在生成多人体运动过程中实现了对变化数量的人数和不同文本指导的适应，并且在保持长序列一致性的同时捕捉到过去的人类历史和人际依赖。


<details>
  <summary>Details</summary>
Motivation: 现有的固定长度运动生成方法无法处理长文本或可变人数情况，HINT框架通过滑动窗口策略和层次交互建模解决了这些问题。

Method: HINT采用了一种滑动窗口的方法以支持在线生成，集成了局部和全局的信息来捕捉过去的人类历史、人际依赖关系及文本指导，并通过分解的运动表示来减少互动间的依赖。

Result: HINT框架在公共基准测试中的表现与强静态模型相当，并且超过了自回归基线。特别是在InterHuman基准测试中，HINT取得了3.100的FID分数，显著提高了之前最佳状态的5.154的FID分数。

Conclusion: HINT是一种创新的多人体交互生成框架，能够处理变化的人数和复杂的文本指导，展示了在保持序列长期一致性和捕捉历史交互方面的能力。

Abstract: Text-driven multi-human motion generation with complex interactions remains a challenging problem. Despite progress in performance, existing offline methods that generate fixed-length motions with a fixed number of agents, are inherently limited in handling long or variable text, and varying agent counts. These limitations naturally encourage autoregressive formulations, which predict future motions step by step conditioned on all past trajectories and current text guidance. In this work, we introduce HINT, the first autoregressive framework for multi-human motion generation with Hierarchical INTeraction modeling in diffusion. First, HINT leverages a disentangled motion representation within a canonicalized latent space, decoupling local motion semantics from inter-person interactions. This design facilitates direct adaptation to varying numbers of human participants without requiring additional refinement. Second, HINT adopts a sliding-window strategy for efficient online generation, and aggregates local within-window and global cross-window conditions to capture past human history, inter-person dependencies, and align with text guidance. This strategy not only enables fine-grained interaction modeling within each window but also preserves long-horizon coherence across all the long sequence. Extensive experiments on public benchmarks demonstrate that HINT matches the performance of strong offline models and surpasses autoregressive baselines. Notably, on InterHuman, HINT achieves an FID of 3.100, significantly improving over the previous state-of-the-art score of 5.154.

</details>


### [25] [Let's Roll a BiFTA: Bi-refinement for Fine-grained Text-visual Alignment in Vision-Language Models](https://arxiv.org/abs/2601.20419)
*Yuhao Sun,Chengyi Cai,Jiacheng Zhang,Zesheng Ye,Xingliang Yuan,Feng Liu*

Main category: cs.CV

TL;DR: 本文提出了一种名为BiFTA的方法，通过去除冗余的图像片段和文本描述来改进细粒度的图文对齐，从而提高零样本性能。


<details>
  <summary>Details</summary>
Motivation: 当前的零样本性能可以通过精细的文本描述与局部图像片段对齐来提升，但两方面都存在冗余信息，降低了对齐效果。因此，作者提出BiFTA方法进行视图精炼（去除高IoU的冗余图像片段）和描述精炼（去除高余弦相似度的冗余文本描述），以提高零样本性能。

Method: 该方法首先根据图像片段间的IoU去除冗余片段，然后根据描述间的余弦相似度去除冗余描述，确保剩余部分既有差异性又能表示好特定的类别。该方法在6个基准数据集上进行了验证。

Result: 该方法在ViT和ResNet架构下的CLIP模型上达到了优越的零样本性能。

Conclusion: 去除冗余信息是提升视觉-文本对齐零样本性能的关键，BiFTA方法对细粒度的图文对齐有显著促进作用。

Abstract: Recent research has shown that aligning fine-grained text descriptions with localized image patches can significantly improve the zero-shot performance of pre-trained vision-language models (e.g., CLIP). However, we find that both fine-grained text descriptions and localized image patches often contain redundant information, making text-visual alignment less effective. In this paper, we tackle this issue from two perspectives: \emph{View Refinement} and \emph{Description refinement}, termed as \textit{\textbf{Bi}-refinement for \textbf{F}ine-grained \textbf{T}ext-visual \textbf{A}lignment} (BiFTA). \emph{View refinement} removes redundant image patches with high \emph{Intersection over Union} (IoU) ratios, resulting in more distinctive visual samples. \emph{Description refinement} removes redundant text descriptions with high pairwise cosine similarity, ensuring greater diversity in the remaining descriptions. BiFTA achieves superior zero-shot performance on 6 benchmark datasets for both ViT-based and ResNet-based CLIP, justifying the necessity to remove redundant information in visual-text alignment.

</details>


### [26] [Quartet of Diffusions: Structure-Aware Point Cloud Generation through Part and Symmetry Guidance](https://arxiv.org/abs/2601.20425)
*Chenliang Zhou,Fangcheng Zhong,Weihao Xia,Albert Miao,Canberk Baykal,Cengiz Oztireli*

Main category: cs.CV

TL;DR: Quartet of Diffusions 是一种新颖的点云生成框架，通过四个协调的扩散模型明确建模部分组成和对称性，实现了结构保证、部分共现性和高质多样性的输出。


<details>
  <summary>Details</summary>
Motivation: 现有的点云生成方法通常将形状生成视为整体过程，或仅支持部分组合。Quartet of Diffusions 旨在通过明确建模部分组成和对称性，提供对形状属性的细粒度控制，同时确保全局一致性。

Method: Quartet of Diffusions 利用四个协调的扩散模型，学习全局形状隐变量、对称性、语义部分及其空间组装的分布。这种方法分离了生成过程，使每个组件都有可解释性，便于精细控制形状属性。

Result: 实验结果表明，Quartet of Diffusions 达到了最先进的性能，是首个在生成过程中全面整合并强制执行对称性和部分先验的 3D 点云生成框架。

Conclusion: Quartet of Diffusions 提供了一种创新的方法，通过明确建模部分组成和对称性，实现了高质量、高多样性的 3D 点云生成，同时支持细粒度的形状属性控制。

Abstract: We introduce the Quartet of Diffusions, a structure-aware point cloud generation framework that explicitly models part composition and symmetry. Unlike prior methods that treat shape generation as a holistic process or only support part composition, our approach leverages four coordinated diffusion models to learn distributions of global shape latents, symmetries, semantic parts, and their spatial assembly. This structured pipeline ensures guaranteed symmetry, coherent part placement, and diverse, high-quality outputs. By disentangling the generative process into interpretable components, our method supports fine-grained control over shape attributes, enabling targeted manipulation of individual parts while preserving global consistency. A central global latent further reinforces structural coherence across assembled parts. Our experiments show that the Quartet achieves state-of-the-art performance. To our best knowledge, this is the first 3D point cloud generation framework that fully integrates and enforces both symmetry and part priors throughout the generative process.

</details>


### [27] [Youtu-Parsing: Perception, Structuring and Recognition via High-Parallelism Decoding](https://arxiv.org/abs/2601.20430)
*Kun Yin,Yunfei Wu,Bing Liu,Zhongpeng Cai,Xiaotian Li,Huang Chen,Xin Li,Haoyu Cao,Yinsong Liu,Deqiang Jiang,Xing Sun,Yunsheng Wu,Qianyu Li,Antai Guo,Yanzhen Liao,Yanqiu Qu,Haodong Lin,Chengxu He,Shuangyin Liu*

Main category: cs.CV

TL;DR: Yuut-Parsing 是一种高效的文档解析模型，通过使用动态分辨率视觉变换器和提示引导的语言模型，结合 token 并行性和查询并行性解码策略，实现快速高效的内容提取。


<details>
  <summary>Details</summary>
Motivation: 随着文档智能化应用的需求增加，传统的文档解析方法在性能和灵活性上存在限制。为了适应不同类型和结构文档并提供更好的性能，Yuut-Parsing被设计开发出来。

Method: Yuut-Parsing 使用了自注意力机制的 Vision Transformer 作为视觉编码器，学习文档的全局与局部特征。它还结合了提示引导的大规模语言模型进行布局分析和区域提示解码。此外，该模型通过引入解码过程中的 token 并行性和查询并行性策略来利用高并行性的优势。

Result: Yuut-Parsing 在标准测试集 OmniDocBench 和 olmOCR-bench 上达到了最先进的性能，尤其是在高度结构化的场景（如表识别）中，执行速度比传统自回归解码快 5-11 倍。此外，模型展示了处理罕见字符、多语言文本和手写内容的强大鲁棒性。

Conclusion: Yuut-Parsing 证明了在大规模文档智能应用中的实验价值和实用价值，可以广泛应用于多种文档解析任务。

Abstract: This paper presents Youtu-Parsing, an efficient and versatile document parsing model designed for high-performance content extraction. The architecture employs a native Vision Transformer (ViT) featuring a dynamic-resolution visual encoder to extract shared document features, coupled with a prompt-guided Youtu-LLM-2B language model for layout analysis and region-prompted decoding. Leveraging this decoupled and feature-reusable framework, we introduce a high-parallelism decoding strategy comprising two core components: token parallelism and query parallelism. The token parallelism strategy concurrently generates up to 64 candidate tokens per inference step, which are subsequently validated through a verification mechanism. This approach yields a 5--11x speedup over traditional autoregressive decoding and is particularly well-suited for highly structured scenarios, such as table recognition. To further exploit the advantages of region-prompted decoding, the query parallelism strategy enables simultaneous content prediction for multiple bounding boxes (up to five), providing an additional 2x acceleration while maintaining output quality equivalent to standard decoding. Youtu-Parsing encompasses a diverse range of document elements, including text, formulas, tables, charts, seals, and hierarchical structures. Furthermore, the model exhibits strong robustness when handling rare characters, multilingual text, and handwritten content. Extensive evaluations demonstrate that Youtu-Parsing achieves state-of-the-art (SOTA) performance on both the OmniDocBench and olmOCR-bench benchmarks. Overall, Youtu-Parsing demonstrates significant experimental value and practical utility for large-scale document intelligence applications.

</details>


### [28] [MARE: Multimodal Alignment and Reinforcement for Explainable Deepfake Detection via Vision-Language Models](https://arxiv.org/abs/2601.20433)
*Wenbo Xu,Wei Lu,Xiangyang Luo,Jiantao Zhou*

Main category: cs.CV

TL;DR: MARE 提出一种结合多模态对齐和强化学习的检测方法，通过视语言模型提升 Deepfake 的检测和解释能力。


<details>
  <summary>Details</summary>
Motivation: 现有 Deepfake 检测方法主要依赖分类和空间定位，但随着生成模型的发展，需要新的方法来增强检测准确性与可靠性。

Method: MARE 通过优化视语言模型，使用强化学习从人类反馈中学习奖励函数，创建文本与空间对齐的推理内容，同时引入伪造解纠缠模块捕捉面部高阶语义特征。

Result: MARE 在生成的推理内容评估中表现优秀，定量和定性实验结果表明，其在准确性和可靠性方面达到最佳水平。

Conclusion: MARE 为 Deepfake 检测提供了一种新的框架，通过增强算法来改进模型性能，并将模型的解释性提升至新高度。

Abstract: Deepfake detection is a widely researched topic that is crucial for combating the spread of malicious content, with existing methods mainly modeling the problem as classification or spatial localization. The rapid advancements in generative models impose new demands on Deepfake detection. In this paper, we propose multimodal alignment and reinforcement for explainable Deepfake detection via vision-language models, termed MARE, which aims to enhance the accuracy and reliability of Vision-Language Models (VLMs) in Deepfake detection and reasoning. Specifically, MARE designs comprehensive reward functions, incorporating reinforcement learning from human feedback (RLHF), to incentivize the generation of text-spatially aligned reasoning content that adheres to human preferences. Besides, MARE introduces a forgery disentanglement module to capture intrinsic forgery traces from high-level facial semantics, thereby improving its authenticity detection capability. We conduct thorough evaluations on the reasoning content generated by MARE. Both quantitative and qualitative experimental results demonstrate that MARE achieves state-of-the-art performance in terms of accuracy and reliability.

</details>


### [29] [Exploiting the Final Component of Generator Architectures for AI-Generated Image Detection](https://arxiv.org/abs/2601.20461)
*Yanzhu Liu,Xiao Liu,Yuexuan Wang,Mondal Soumik*

Main category: cs.CV

TL;DR: 该研究利用图像生成器的最终组件对真实图像进行污染，并以此训练检测器区分污染后的真实图像与原始图像，同时构建了一个基于生成器最终组件的分类体系，利用100样本在22个未见过的生成器测试集中达到了98.83%的平均准确率。


<details>
  <summary>Details</summary>
Motivation: 面对日益增多的AI生成图像，需要一个能准确检测的解决方案来保持在线环境的可信度，而现有技术通常不能很好地泛化到未见过的生成器上。

Method: 研究通过让真实图像与特定生成器的最终组件‘污染’，即利用此组件将中间表示转换为图像；然后训练检测器以区分这些被污染的真实图像与原始真实图像，进而研究其在各类生成器上的泛化性能。

Result: 采用这一方法，在DINOv3的支撑下，仅使用每个代表类别100个样本，开发出的检测器在22个未见过的生成器测试集上达到了98.83%的平均准确率。

Conclusion: 该研究通过构建一个基于生成器最终组件的新分类体系，提升了检测器的有效性和通用性，并验证了其强大的泛化能力。

Abstract: With the rapid proliferation of powerful image generators, accurate detection of AI-generated images has become essential for maintaining a trustworthy online environment. However, existing deepfake detectors often generalize poorly to images produced by unseen generators. Notably, despite being trained under vastly different paradigms, such as diffusion or autoregressive modeling, many modern image generators share common final architectural components that serve as the last stage for converting intermediate representations into images. Motivated by this insight, we propose to "contaminate" real images using the generator's final component and train a detector to distinguish them from the original real images. We further introduce a taxonomy based on generators' final components and categorize 21 widely used generators accordingly, enabling a comprehensive investigation of our method's generalization capability. Using only 100 samples from each of three representative categories, our detector-fine-tuned on the DINOv3 backbone-achieves an average accuracy of 98.83% across 22 testing sets from unseen generators.

</details>


### [30] [Efficient Autoregressive Video Diffusion with Dummy Head](https://arxiv.org/abs/2601.20499)
*Hang Guo,Zhaoyang Jia,Jiahao Li,Bin Li,Yuanhao Cai,Jiangshan Wang,Yawei Li,Yan Lu*

Main category: cs.CV

TL;DR: 通过提出 Dummy Forcing 方法，减少多头自注意力对最近帧的过度依赖，同时通过异质内存分配和动态头编程减少头间的上下文冗余，以及采用上下文打包技术使缓存压缩更激进，本文提高了视频自回归扩散模型的速度，实现24.3 FPS的生成速度。


<details>
  <summary>Details</summary>
Motivation: 现有的自回归视频扩散模型在处理历史帧时，部分多头自注意力机制的效用被低估，特别是在处理仅关注当前帧的‘dummy’头部时。本文通过优化这些头部的作用，提出了一种简单但有效的加速方法。

Method: 本文提出了 Dummy Forcing 方法，通过以下步骤进行优化：1) 异质内存分配减少了各个多头间上下文的冗余；2) 动态头编程允许多头根据需要灵活分类；3) 上下文打包技术实现更激进的缓存压缩，确保在不增加额外训练成本的情况下提高视频生成速度。

Result: 实验结果显示，应用 Dummy Forcing 方法后，该模型能够在仅0.5%的质量下降的情况下，实现2.0倍的速度提升，达到24.3 FPS的视频生成帧率。

Conclusion: 该研究提出了一个新的方法来优化自回归视频扩散模型的上下文访问，显著加速了视频生成过程。该方法展示了其在提高效率的同时保持高质量结果的潜力，并提供了一个使用更少计算资源产生视频的途径。

Abstract: The autoregressive video diffusion model has recently gained considerable research interest due to its causal modeling and iterative denoising. In this work, we identify that the multi-head self-attention in these models under-utilizes historical frames: approximately 25% heads attend almost exclusively to the current frame, and discarding their KV caches incurs only minor performance degradation. Building upon this, we propose Dummy Forcing, a simple yet effective method to control context accessibility across different heads. Specifically, the proposed heterogeneous memory allocation reduces head-wise context redundancy, accompanied by dynamic head programming to adaptively classify head types. Moreover, we develop a context packing technique to achieve more aggressive cache compression. Without additional training, our Dummy Forcing delivers up to 2.0x speedup over the baseline, supporting video generation at 24.3 FPS with less than 0.5% quality drop. Project page is available at https://csguoh.github.io/project/DummyForcing/.

</details>


### [31] [Comparative evaluation of training strategies using partially labelled datasets for segmentation of white matter hyperintensities and stroke lesions in FLAIR MRI](https://arxiv.org/abs/2601.20503)
*Jesse Phitidis,Alison Q. Smithard,William N. Whiteley,Joanna M. Wardlaw,Miguel O. Bernabeu,Maria Valdés Hernández*

Main category: cs.CV

TL;DR: 研究通过混合私人和公共部分标注的数据集，开发了一种同时分割白质高信号（WMH）和缺血性卒中病变（ISL）的深度学习模型。使用伪标签的方法表现最佳。


<details>
  <summary>Details</summary>
Motivation: WMH和ISL是脑小血管疾病（SVD）的影像学标志，会在FLAIR序列中混淆导致难以区分，在同一受试者中经常同时出现。因此，迫切需要开发准确分割这两种病变的深度学习模型。

Method: 研究者通过混合私人和公共的部分标注数据集，训练了一个结合WMH和ISL分割的模型。使用了包括预训练、伪标签、迁移学习等多种方法。

Result: 研究发现，多种方法能够有效利用部分标注数据提高模型性能，其中使用伪标签方法取得了最佳效果。

Conclusion: 研究证明了通过有效利用部分标注数据可以改进分割模型性能，并指出了伪标签在医学影像分割任务中的应用潜力。

Abstract: White matter hyperintensities (WMH) and ischaemic stroke lesions (ISL) are imaging features associated with cerebral small vessel disease (SVD) that are visible on brain magnetic resonance imaging (MRI) scans. The development and validation of deep learning models to segment and differentiate these features is difficult because they visually confound each other in the fluid-attenuated inversion recovery (FLAIR) sequence and often appear in the same subject. We investigated six strategies for training a combined WMH and ISL segmentation model using partially labelled data. We combined privately held fully and partially labelled datasets with publicly available partially labelled datasets to yield a total of 2052 MRI volumes, with 1341 and 1152 containing ground truth annotations for WMH and ISL respectively. We found that several methods were able to effectively leverage the partially labelled data to improve model performance, with the use of pseudolabels yielding the best result.

</details>


### [32] [Latent Temporal Discrepancy as Motion Prior: A Loss-Weighting Strategy for Dynamic Fidelity in T2V](https://arxiv.org/abs/2601.20504)
*Meiqi Wu,Bingze Song,Ruimin Lin,Chen Zhu,Xiaokun Feng,Jiahong Wu,Xiangxiang Chu,Kaiqi Huang*

Main category: cs.CV

TL;DR: 该研究提出了一种名为Latent Temporal Discrepancy (LTD)的方法来指导损失加权，在视频生成中引入运动先验，通过衡量帧间在潜在空间中的变化并为高差异区域施加大处罚，从而提高模型对高频动态的重建能力，实验表明在通用基准VBench和运动专注的VMBench上均取得显著改进。


<details>
  <summary>Details</summary>
Motivation: 当前视频生成模型在静态场景下取得了显著进展，但在动态视频生成方面表现受限，尤其是在处理剧烈动态变化时效果下降。这是由于噪声破坏了时间连贯性，使学习动态区域变得更加困难。此外，现有扩散模型依赖静态损失处理所有场景，限制了其捕捉复杂动态的能力。

Method: 引入了一种名为Latent Temporal Discrepancy (LTD)的方法，衡量帧与帧之间的差异，并在潜在空间中进行评估。方法根据差异程度对不同区域施加不同的权重，从而稳定训练并提高模型对高频动态的重建能力。

Result: 在通用基准VBench和运动专注的VMBench上的实验结果表明，与强大基线相比，在VBench上获得3.31%的改进，在VMBench上获得3.58%的改进，显著提高了运动质量。

Conclusion: 该研究通过引入Latent Temporal Discrepancy (LTD)来改进视频生成模型中的动态捕捉能力，展示了在多种基准上的一致性能提升，证明了该方法的有效性。

Abstract: Video generation models have achieved notable progress in static scenarios, yet their performance in motion video generation remains limited, with quality degrading under drastic dynamic changes. This is due to noise disrupting temporal coherence and increasing the difficulty of learning dynamic regions. {Unfortunately, existing diffusion models rely on static loss for all scenarios, constraining their ability to capture complex dynamics.} To address this issue, we introduce Latent Temporal Discrepancy (LTD) as a motion prior to guide loss weighting. LTD measures frame-to-frame variation in the latent space, assigning larger penalties to regions with higher discrepancy while maintaining regular optimization for stable regions. This motion-aware strategy stabilizes training and enables the model to better reconstruct high-frequency dynamics. Extensive experiments on the general benchmark VBench and the motion-focused VMBench show consistent gains, with our method outperforming strong baselines by 3.31% on VBench and 3.58% on VMBench, achieving significant improvements in motion quality.

</details>


### [33] [Say Cheese! Detail-Preserving Portrait Collection Generation via Natural Language Edits](https://arxiv.org/abs/2601.20511)
*Zelong Sun,Jiahui Wu,Ying Ba,Dong Jing,Zhiwu Lu*

Main category: cs.CV

TL;DR: 本文介绍了一项新颖的任务——基于自然语言指令生成一致的肖像集合（PCG）。提出CHEESE数据集和SCheese框架，解决了复杂多属性修改和高保质细节保留的挑战。


<details>
  <summary>Details</summary>
Motivation: 随着社交媒体平台的普及，用户希望有直观的方法来生成多种高质量的肖像集合。现有的方法无法满足这些需求，因此需要研究新型的PCG任务。

Method: 提出了一种名为CHEESE的数据集，包含24K肖像集合和573K样本。还提出了SCheese框架，结合了文本指导生成和层次身份及细节保持。它使用自适应特征融合机制和ConsistencyNet注入细粒度特征，对一致性进行维护。

Result: 实验结果表明，SCheese在推进PCG领域上表现出色，达到了最先进的效果。

Conclusion: 本文通过提出PCG任务、CHEESE数据集和SCheese框架，解决了复杂多属性修改和高保质细节保留的挑战，为肖像集合生成领域做出了贡献。

Abstract: As social media platforms proliferate, users increasingly demand intuitive ways to create diverse, high-quality portrait collections. In this work, we introduce Portrait Collection Generation (PCG), a novel task that generates coherent portrait collections by editing a reference portrait image through natural language instructions. This task poses two unique challenges to existing methods: (1) complex multi-attribute modifications such as pose, spatial layout, and camera viewpoint; and (2) high-fidelity detail preservation including identity, clothing, and accessories. To address these challenges, we propose CHEESE, the first large-scale PCG dataset containing 24K portrait collections and 573K samples with high-quality modification text annotations, constructed through an Large Vison-Language Model-based pipeline with inversion-based verification. We further propose SCheese, a framework that combines text-guided generation with hierarchical identity and detail preservation. SCheese employs adaptive feature fusion mechanism to maintain identity consistency, and ConsistencyNet to inject fine-grained features for detail consistency. Comprehensive experiments validate the effectiveness of CHEESE in advancing PCG, with SCheese achieving state-of-the-art performance.

</details>


### [34] [IOTA: Corrective Knowledge-Guided Prompt Learning via Black-White Box Framework](https://arxiv.org/abs/2601.20526)
*Shaokun Wang,Yifan Yu,Yuhang He,Weili Guan,Yihong Gong*

Main category: cs.CV

TL;DR: 本文提出了一种新的黑白盒提示学习框架IOTA，通过结合数据驱动的黑盒模块和知识驱动的白盒模块来实现下游任务的高效适配。实验结果表明，与现有最佳方法相比，该框架在12个图像分类基准上的表现更优。


<details>
  <summary>Details</summary>
Motivation: 当前参数高效调优(PET)方法忽视了预训练模型的先验知识，仅依赖数据驱动优化，导致影响模型在下游任务适应性上的潜力。因此，提出了一种新的黑白盒提示学习框架IOTA以弥补这一不足。

Method: IOTA框架包括数据驱动的黑盒模块和知识驱动的白盒模块。不符合预测的知识通过对比错误预测与正确认知生成，并通过解释性的提示词指导黑盒模块，从而引导其生成更准确的预测。这种方法结合了知识驱动和数据驱动的学习信号。

Result: 在12个图像分类基准上进行了实验，结果显示IOTA的有效性及优于现有的最佳方法，特别是在少量样本和从简单到复杂的适应设置中。

Conclusion: 该研究提出的方法为基于预训练模型的下游任务适应性提供了新的视角和技术支持，证实了结合知识和数据驱动学习信号的重要性。

Abstract: Recently, adapting pre-trained models to downstream tasks has attracted increasing interest. Previous Parameter-Efficient-Tuning (PET) methods regard the pre-trained model as an opaque Black Box model, relying purely on data-driven optimization and underutilizing their inherent prior knowledge. This oversight limits the models' potential for effective downstream task adaptation. To address these issues, we propose a novel black-whIte bOx prompT leArning framework (IOTA), which integrates a data-driven Black Box module with a knowledge-driven White Box module for downstream task adaptation. Specifically, the White Box module derives corrective knowledge by contrasting the wrong predictions with the right cognition. This knowledge is verbalized into interpretable human prompts and leveraged through a corrective knowledge-guided prompt selection strategy to guide the Black Box module toward more accurate predictions. By jointly leveraging knowledge- and data-driven learning signals, IOTA achieves effective downstream task adaptation. Experimental results on 12 image classification benchmarks under few-shot and easy-to-hard adaptation settings demonstrate the effectiveness of corrective knowledge and the superiority of our method over state-of-the-art methods.

</details>


### [35] [Advancing Open-source World Models](https://arxiv.org/abs/2601.20540)
*Robbyant Team,Zelin Gao,Qiuyu Wang,Yanhong Zeng,Jiapeng Zhu,Ka Leong Cheng,Yixuan Li,Hanlin Wang,Yinghao Xu,Shuailei Ma,Yihang Chen,Jie Liu,Yansong Cheng,Yao Yao,Jiayi Zhu,Yihao Meng,Kecheng Zheng,Qingyan Bai,Jingye Chen,Zehong Shen,Yue Yu,Xing Zhu,Yujun Shen,Hao Ouyang*

Main category: cs.CV

TL;DR: LingBot-World 是一个开放源代码的世界模拟器，提供了高保真度和动态性、长时间记忆及实时交互等功能。


<details>
  <summary>Details</summary>
Motivation: 为了填充开源与封闭源代码技术之间的鸿沟，并为内容创作、游戏及机器人学习等领域提供实用应用。

Method: 文本未详细说明具体的构建方法，仅提及来自视频生成。

Result: 提供了广泛的环境支持，包括现实主义、科学环境、卡通风格等；具备分钟级的视野和时间一致性；支持实时互动，延迟低于1秒。

Conclusion: 公布了代码和模型供公众访问，试图推动社区发展相关技术应用。

Abstract: We present LingBot-World, an open-sourced world simulator stemming from video generation. Positioned as a top-tier world model, LingBot-World offers the following features. (1) It maintains high fidelity and robust dynamics in a broad spectrum of environments, including realism, scientific contexts, cartoon styles, and beyond. (2) It enables a minute-level horizon while preserving contextual consistency over time, which is also known as "long-term memory". (3) It supports real-time interactivity, achieving a latency of under 1 second when producing 16 frames per second. We provide public access to the code and model in an effort to narrow the divide between open-source and closed-source technologies. We believe our release will empower the community with practical applications across areas like content creation, gaming, and robot learning.

</details>


### [36] [DeepSeek-OCR 2: Visual Causal Flow](https://arxiv.org/abs/2601.20552)
*Haoran Wei,Yaofeng Sun,Yukun Li*

Main category: cs.CV

TL;DR: 该研究提出了一种名为DeepEncoder V2的新型视觉编码器，旨在动态调整视觉标记的排列顺序，以实现更接近人类视觉感知的因果推理。该工作探索了一种新的范式，通过两层一维因果推理结构进行二维图像理解，相比传统的按固定顺序处理视觉标记的方法，这可能实现真正的二维推理。


<details>
  <summary>Details</summary>
Motivation: 当前的视觉-语言模型在处理视觉信息时采用固定的顺序和位置编码，但这与人类视觉感知机制不符。DeepSeek-OCR 2的工作旨在引入了一种新的方法，通过动态调整视觉标记的顺序，增强视觉编码器的因果推理能力，以提高图像理解的准确性。

Method: DeepSeek-OCR 2提出了一种新型的视觉编码器DeepEncoder V2。该编码器能够根据图像的语义动态调整视觉标记的顺序。这是通过引入一种新机制来实现的，即利用因果推理结构对视觉标记进行重新排序，在传递给语言模型进行内容解释之前，更好地匹配自然视觉处理过程。

Result: 这项工作为图像理解提供了一种新的架构，通过两层因果推理结构，可能实现真正的二维推理。这种方法展示了比传统处理方式更有效的视觉信息处理能力，并且已经在 GitHub 上开源了代码和模型权重。

Conclusion: 该研究证明了通过因果推理结构动态调整视觉标记顺序的可行性，并提供了一个新的视角来实现复杂的图像理解任务。未来的研究将探索这一方法的实际应用效果及其与其他现有技术的对比。

Abstract: We present DeepSeek-OCR 2 to investigate the feasibility of a novel encoder-DeepEncoder V2-capable of dynamically reordering visual tokens upon image semantics. Conventional vision-language models (VLMs) invariably process visual tokens in a rigid raster-scan order (top-left to bottom-right) with fixed positional encoding when fed into LLMs. However, this contradicts human visual perception, which follows flexible yet semantically coherent scanning patterns driven by inherent logical structures. Particularly for images with complex layouts, human vision exhibits causally-informed sequential processing. Inspired by this cognitive mechanism, DeepEncoder V2 is designed to endow the encoder with causal reasoning capabilities, enabling it to intelligently reorder visual tokens prior to LLM-based content interpretation. This work explores a novel paradigm: whether 2D image understanding can be effectively achieved through two-cascaded 1D causal reasoning structures, thereby offering a new architectural approach with the potential to achieve genuine 2D reasoning. Codes and model weights are publicly accessible at http://github.com/deepseek-ai/DeepSeek-OCR-2.

</details>


### [37] [DiffVC-RT: Towards Practical Real-Time Diffusion-based Perceptual Neural Video Compression](https://arxiv.org/abs/2601.20564)
*Wenzhuo Ma,Zhenzhong Chen*

Main category: cs.CV

TL;DR: 提出了一种名为DiffVC-RT的新框架，旨在解决基于扩散的神经视频压缩(NVC)中的实时性问题，通过高效的信息模型架构、一致性和异步并行解码管道，实现80.1%的LPIPS比特率节省和实时编码与解码速度。


<details>
  <summary>Details</summary>
Motivation: 现有NVC技术面临严重的信息损失、推断延迟高以及时间一致性差的问题，这些挑战限制了其实际部署。

Method: DiffVC-RT框架包括三个关键技术：1) 一个高效且信息丰富的模型架构；2) 显式和隐式的时序一致性建模；3) 异步并行解码流水线。

Result: DiffVC-RT在HEVC数据集上实现了高达80.1%的LPIPS比特率节省，并在NVIDIA H800 GPU上达到了206/30 fps的实时编码和解码速度。

Conclusion: DiffVC-RT为基于扩散的神经视频压缩提供了一种实时解决方案，显著提高了时间一致性，减少了计算复杂度，并实现了比特率节省。

Abstract: The practical deployment of diffusion-based Neural Video Compression (NVC) faces critical challenges, including severe information loss, prohibitive inference latency, and poor temporal consistency. To bridge this gap, we propose DiffVC-RT, the first framework designed to achieve real-time diffusion-based perceptual NVC. First, we introduce an Efficient and Informative Model Architecture. Through strategic module replacements and pruning, this architecture significantly reduces computational complexity while mitigating structural information loss. Second, to address generative flickering artifacts, we propose Explicit and Implicit Consistency Modeling. We enhance temporal consistency by explicitly incorporating a zero-cost Online Temporal Shift Module within the U-Net, complemented by hybrid implicit consistency constraints. Finally, we present an Asynchronous and Parallel Decoding Pipeline incorporating Mixed Half Precision, which enables asynchronous latent decoding and parallel frame reconstruction via a Batch-dimension Temporal Shift design. Experiments show that DiffVC-RT achieves 80.1% bitrate savings in terms of LPIPS over VTM-17.0 on HEVC dataset with real-time encoding and decoding speeds of 206 / 30 fps for 720p videos on an NVIDIA H800 GPU, marking a significant milestone in diffusion-based video compression.

</details>


### [38] [StructAlign: Structured Cross-Modal Alignment for Continual Text-to-Video Retrieval](https://arxiv.org/abs/2601.20597)
*Shaokun Wang,Weili Guan,Jizhou Han,Jianlong Wu,Yupeng Hu,Liqiang Nie*

Main category: cs.CV

TL;DR: 本文提出了一种名为StructAlign的方法来解决连续文本-视频检索（CTVR）中的模态失准问题。该方法通过设计统一的几何先验和交叉模态几何对齐损失来减轻模态失准，并通过交叉模态关系保持损失抑制模内特征漂移，从而有效缓解CTVR中的灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: CTVR的连续学习设置使得模型在学习新语义类别时容易忘记之前学习的信息，因此需要提出一种方法来减轻灾难性遗忘。

Method: StructAlign方法引入了简单形等距紧框架（ETF）几何作为统一的几何先验，设计了交叉模态ETF对齐损失来对齐文本和视频特征，同时设计了交叉模态关系保持损失来保持跨模态的相似性关系。

Result: 实验结果表明，该方法在基准数据集上的表现优于现有最先进的连续检索方法。

Conclusion: 该研究提出的方法能够有效减轻CTVR中的模态失准和模内特征漂移，提升了模型对新语义类别的学习能力。

Abstract: Continual Text-to-Video Retrieval (CTVR) is a challenging multimodal continual learning setting, where models must incrementally learn new semantic categories while maintaining accurate text-video alignment for previously learned ones, thus making it particularly prone to catastrophic forgetting. A key challenge in CTVR is feature drift, which manifests in two forms: intra-modal feature drift caused by continual learning within each modality, and non-cooperative feature drift across modalities that leads to modality misalignment. To mitigate these issues, we propose StructAlign, a structured cross-modal alignment method for CTVR. First, StructAlign introduces a simplex Equiangular Tight Frame (ETF) geometry as a unified geometric prior to mitigate modality misalignment. Building upon this geometric prior, we design a cross-modal ETF alignment loss that aligns text and video features with category-level ETF prototypes, encouraging the learned representations to form an approximate simplex ETF geometry. In addition, to suppress intra-modal feature drift, we design a Cross-modal Relation Preserving loss, which leverages complementary modalities to preserve cross-modal similarity relations, providing stable relational supervision for feature updates. By jointly addressing non-cooperative feature drift across modalities and intra-modal feature drift, StructAlign effectively alleviates catastrophic forgetting in CTVR. Extensive experiments on benchmark datasets demonstrate that our method consistently outperforms state-of-the-art continual retrieval approaches.

</details>


### [39] [Person Re-ID in 2025: Supervised, Self-Supervised, and Language-Aligned. What Works?](https://arxiv.org/abs/2601.20598)
*Lakshman Balasubramanian*

Main category: cs.CV

TL;DR: 本研究对比了监督学习、自监督学习和语言对齐模型在跨领域行人重识别中的性能，发现监督模型在训练领域内表现优异但在跨领域数据集上效果不佳；而语言对齐模型表现出令人惊讶的跨领域鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索监督模型、自监督模型及语言对齐模型在行人重识别中的表现差异，以及这些模型在跨领域任务中的泛化能力。

Method: 研究通过比较三种不同的训练范式：监督式学习、自监督学习与语言对齐模型，并在11款模型和9个数据集上进行分析。

Result: 研究结果表明，监督模型在其训练领域内表现出色，但在跨领域数据集上表现较差；语言对齐模型则在跨领域行人重识别任务中显示出了意外的鲁棒性。

Conclusion: 研究结论指出了当前监督和基础模型在行人重识别中的局限性，并强调了语言对齐模型在跨领域应用中的潜力。

Abstract: Person Re-Identification (ReID) remains a challenging problem in computer vision. This work reviews various training paradigm and evaluates the robustness of state-of-the-art ReID models in cross-domain applications and examines the role of foundation models in improving generalization through richer, more transferable visual representations. We compare three training paradigms, supervised, self-supervised, and language-aligned models. Through the study the aim is to answer the following questions: Can supervised models generalize in cross-domain scenarios? How does foundation models like SigLIP2 perform for the ReID tasks? What are the weaknesses of current supervised and foundational models for ReID? We have conducted the analysis across 11 models and 9 datasets. Our results show a clear split: supervised models dominate their training domain but crumble on cross-domain data. Language-aligned models, however, show surprising robustness cross-domain for ReID tasks, even though they are not explicitly trained to do so. Code and data available at: https://github.com/moiiai-tech/object-reid-benchmark.

</details>


### [40] [GDCNet: Generative Discrepancy Comparison Network for Multimodal Sarcasm Detection](https://arxiv.org/abs/2601.20618)
*Shuguang Zhang,Junhong Lian,Guoxin Yu,Baoxun Xu,Xiang Ao*

Main category: cs.CV

TL;DR: 该研究提出了一种名为GDCNet的新框架，通过使用多模态大语言模型生成的事实性描述图像字幕作为稳定的语义锚点，来捕捉跨模态冲突。该方法通过融合视觉和文本特征来评估语义和情感差异，以及视觉和文本的一致性，从而提高了多模态讽刺检测的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态讽刺检测方法在处理视觉和文本内容松散关联或语义间接的情况时表现出色，但由于语言模型生成的讽刺线索存在多样性和主观性，导致质量和效果不一。

Method: GDCNet通过利用多模态大语言模型生成的事实性描述图像字幕作为稳定的语义锚点，来捕捉跨模态冲突。具体来说，该方法计算生成的客观描述和原始文本之间的语义和情感差异，同时也衡量视觉与文本的一致性。这些差异特征通过门控模块与视觉和文本表示融合，以自适应地平衡模态贡献。

Result: 在多模态讽刺检测基准上的广泛实验表明，GDCNet具有更高的准确性和鲁棒性，并在MMSD2.0基准测试中达到了最先进的性能。

Conclusion: GDCNet框架在识别跨模态讽刺方面表现出了优越的效果，特别是在处理视觉和文本内容松散关联或语义间接的情况下。

Abstract: Multimodal sarcasm detection (MSD) aims to identify sarcasm within image-text pairs by modeling semantic incongruities across modalities. Existing methods often exploit cross-modal embedding misalignment to detect inconsistency but struggle when visual and textual content are loosely related or semantically indirect. While recent approaches leverage large language models (LLMs) to generate sarcastic cues, the inherent diversity and subjectivity of these generations often introduce noise. To address these limitations, we propose the Generative Discrepancy Comparison Network (GDCNet). This framework captures cross-modal conflicts by utilizing descriptive, factually grounded image captions generated by Multimodal LLMs (MLLMs) as stable semantic anchors. Specifically, GDCNet computes semantic and sentiment discrepancies between the generated objective description and the original text, alongside measuring visual-textual fidelity. These discrepancy features are then fused with visual and textual representations via a gated module to adaptively balance modality contributions. Extensive experiments on MSD benchmarks demonstrate GDCNet's superior accuracy and robustness, establishing a new state-of-the-art on the MMSD2.0 benchmark.

</details>


### [41] [ProSkill: Segment-Level Skill Assessment in Procedural Videos](https://arxiv.org/abs/2601.20661)
*Michele Mazzamuto,Daniele Di Mauro,Gianpiero Francesca,Giovanni Maria Farinella,Antonino Furnari*

Main category: cs.CV

TL;DR: ProSkill 是首个用于程序任务操作级技能评估的大规模基准数据集，它提供了绝对评估标签和基于对弈的相对评估标签，通过瑞士锦标赛方案和ELO排名系统生成全局连续评分。


<details>
  <summary>Details</summary>
Motivation: 现有的技能评估研究主要集中在体育领域，缺乏针对复杂程序活动的大规模数据集，且以往研究多针对单一动作或仅提供简单的二元标签评价。

Method: ProSkill 采用了新的高效对弈协议，利用瑞士锦标赛方案进行对弈比较，并结合ELO排名系统整合成一致的、连续的全球评分。

Result: 在 ProSkill 数据集上对比了当前领先技能评估算法的表现，并指出现有的算法在此领域表现不佳，突显了 ProSkill 的价值。

Conclusion: ProSkill 为程序视频中的操作级技能评估提供了一个有价值的基准，有助于推动该领域的研究进步。

Abstract: Skill assessment in procedural videos is crucial for the objective evaluation of human performance in settings such as manufacturing and procedural daily tasks. Current research on skill assessment has predominantly focused on sports and lacks large-scale datasets for complex procedural activities. Existing studies typically involve only a limited number of actions, focus on either pairwise assessments (e.g., A is better than B) or on binary labels (e.g., good execution vs needs improvement). In response to these shortcomings, we introduce ProSkill, the first benchmark dataset for action-level skill assessment in procedural tasks. ProSkill provides absolute skill assessment annotations, along with pairwise ones. This is enabled by a novel and scalable annotation protocol that allows for the creation of an absolute skill assessment ranking starting from pairwise assessments. This protocol leverages a Swiss Tournament scheme for efficient pairwise comparisons, which are then aggregated into consistent, continuous global scores using an ELO-based rating system. We use our dataset to benchmark the main state-of-the-art skill assessment algorithms, including both ranking-based and pairwise paradigms. The suboptimal results achieved by the current state-of-the-art highlight the challenges and thus the value of ProSkill in the context of skill assessment for procedural videos. All data and code are available at https://fpv-iplab.github.io/ProSkill/

</details>


### [42] [bi-modal textual prompt learning for vision-language models in remote sensing](https://arxiv.org/abs/2601.20675)
*Pankhi Kashyap,Mainak Singha,Biplab Banerjee*

Main category: cs.CV

TL;DR: BiMoRS 提出了一种轻量级的双模态提示学习框架，专为遥感任务设计。通过结合冻结的图像字幕模型提取的文本语义摘要和高层次视觉特性，以及轻量级交叉注意力模块，BiMoRS 能够为 CLIP 编码器生成上下文化的提示，从而在四组遥感数据集的三大泛化任务中获得一致的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有提示学习方法在遥感图像上表现不佳，难以识别主导语义线索并泛化到未见过的类。BiMoRS 框架旨在解决这些问题，通过结合图像字幕模型提取的文本信息，增强提示学习方法的跨域适应性。

Method: BiMoRS 采用了一个冻结的图像字幕模型，用于从遥感图像中提取文本语义摘要。这些摘要随后通过 BERT 分词器进行分词，并与来自 CLIP 编码器的高级视觉特征融合。基于此融合的文本-视觉表示，再通过一个轻量级的交叉注意力模块对学习到的查询提示进行条件化，从而生成上下文化的提示。

Result: 在四项遥感数据集上的评估显示，BiMoRS 在三种域泛化任务中的表现优于强大基线，平均性能提升高达 2%。

Conclusion: BiMoRS 通过结合图像字幕模型和 CLIP，提供了一种有效的方法来针对具有挑战性的遥感任务进行预训练模型的提示学习。

Abstract: Prompt learning (PL) has emerged as an effective strategy to adapt vision-language models (VLMs), such as CLIP, for downstream tasks under limited supervision. While PL has demonstrated strong generalization on natural image datasets, its transferability to remote sensing (RS) imagery remains underexplored. RS data present unique challenges, including multi-label scenes, high intra-class variability, and diverse spatial resolutions, that hinder the direct applicability of existing PL methods. In particular, current prompt-based approaches often struggle to identify dominant semantic cues and fail to generalize to novel classes in RS scenarios. To address these challenges, we propose BiMoRS, a lightweight bi-modal prompt learning framework tailored for RS tasks. BiMoRS employs a frozen image captioning model (e.g., BLIP-2) to extract textual semantic summaries from RS images. These captions are tokenized using a BERT tokenizer and fused with high-level visual features from the CLIP encoder. A lightweight cross-attention module then conditions a learnable query prompt on the fused textual-visual representation, yielding contextualized prompts without altering the CLIP backbone. We evaluate BiMoRS on four RS datasets across three domain generalization (DG) tasks and observe consistent performance gains, outperforming strong baselines by up to 2% on average. Codes are available at https://github.com/ipankhi/BiMoRS.

</details>


### [43] [Decoupling Perception and Calibration: Label-Efficient Image Quality Assessment Framework](https://arxiv.org/abs/2601.20689)
*Xinyue Li,Zhichao Zhang,Zhiming Xu,Shubo Xu,Xiongkuo Min,Yitong Chen,Guangtao Zhai*

Main category: cs.CV

TL;DR: LEAF框架通过从大型语言模型（MLLM）教师中提炼感知质量先验知识并将其转移至轻量级学生回归模型，实现图像质量评估（IQA）中的MOS校准，显著减少对人类注释的需求。


<details>
  <summary>Details</summary>
Motivation: 最近的多模态大型语言模型在图像质量评估任务中表现出色，但适应这些大规模模型在计算上是昂贵的，并且仍然需要大量的人类评分。因此，提出LEAF框架以解决MOS尺度校准问题，而非质量感知能力。

Method: LEAF框架首先通过 dense supervision 和 pair-wise preferences 从MLLM教师模型中获取感知质量先验知识，然后通过联合蒸馏指导学生模型学习教师的质量感知模式，并仅在校准少量MOS子集时对其进行调整，以确保与人类注释的一致性。

Result: 在用户生成和AI生成的图像质量评估基准测试上，LEAF框架减少了对人类注释的需求，同时保持了MOS评分的强一致性。

Conclusion: LEAF框架提供了在有限注释预算下实现轻量级图像质量评估的可行性，表明在MOS校准方面，关键挑战在于人类评分的狭隘领域，而非模型的感知能力。

Abstract: Recent multimodal large language models (MLLMs) have demonstrated strong capabilities in image quality assessment (IQA) tasks. However, adapting such large-scale models is computationally expensive and still relies on substantial Mean Opinion Score (MOS) annotations. We argue that for MLLM-based IQA, the core bottleneck lies not in the quality perception capacity of MLLMs, but in MOS scale calibration. Therefore, we propose LEAF, a Label-Efficient Image Quality Assessment Framework that distills perceptual quality priors from an MLLM teacher into a lightweight student regressor, enabling MOS calibration with minimal human supervision. Specifically, the teacher conducts dense supervision through point-wise judgments and pair-wise preferences, with an estimate of decision reliability. Guided by these signals, the student learns the teacher's quality perception patterns through joint distillation and is calibrated on a small MOS subset to align with human annotations. Experiments on both user-generated and AI-generated IQA benchmarks demonstrate that our method significantly reduces the need for human annotations while maintaining strong MOS-aligned correlations, making lightweight IQA practical under limited annotation budgets.

</details>


### [44] [LEMON: How Well Do MLLMs Perform Temporal Multimodal Understanding on Instructional Videos?](https://arxiv.org/abs/2601.20705)
*Zhuang Yu,Lei Shen,Jing Zhao,Shiliang Sun*

Main category: cs.CV

TL;DR: LEMON 是一个聚焦于 STEM 讲授视频的多模态评价基准，涵盖了学科丰富度、时间连贯性和教学结构等特点，旨在评估大型语言模型在长形式、知识密集型教学内容上的性能。


<details>
  <summary>Details</summary>
Motivation: 当前的多模态大语言模型在视觉、音频和语言任务上取得了显著的进步，但在长篇幅、知识密集型和时间结构化的教育内容上的表现尚未得到充分探索。LEMON 的引入旨在填补这一空白，评估模型在这些领域的表现。

Method: LEMON 包含 2,277 个视频片段，涉及 5 个学科和 29 门课程，共产生 4,181 个高质量问答对。基准设计涵盖了六个主要任务和十二个子任务，全面评估模型在感知、推理和生成方面的表现。

Result: 实验结果表明，即使是最新的多模态大语言模型如 GPT-4o，在时间推理和教学预测方面也存在显著差距。这突显了 LEV-mon 在多模态感知、推理和生成能力上的潜在挑战。

Conclusion: LEMON 有望成为一个扩展性和挑战性的基准，促进长形式教学内容中的多模态感知、推理和生成技术的进步。

Abstract: Recent multimodal large language models (MLLMs) have shown remarkable progress across vision, audio, and language tasks, yet their performance on long-form, knowledge-intensive, and temporally structured educational content remains largely unexplored. To bridge this gap, we introduce LEMON, a Lecture-based Evaluation benchmark for MultimOdal uNderstanding, focusing on STEM lecture videos that require long-horizon reasoning and cross-modal integration. LEMON comprises 2,277 video segments spanning 5 disciplines and 29 courses, with an average duration of 196.1 seconds, yielding 4,181 high-quality QA pairs, including 3,413 multiple-choice and 768 open-ended questions. Distinct from existing video benchmarks, LEMON features: (1) semantic richness and disciplinary density, (2) tightly coupled video-audio-text modalities, (3) explicit temporal and pedagogical structure, and (4) contextually linked multi-turn questioning. It further encompasses six major tasks and twelve subtasks, covering the full cognitive spectrum from perception to reasoning and then to generation. Comprehensive experiments reveal substantial performance gaps across tasks, highlighting that even state-of-the-art MLLMs like GPT-4o struggle with temporal reasoning and instructional prediction. We expect LEMON to serve as an extensible and challenging benchmark for advancing multimodal perception, reasoning, and generation in long-form instructional contents.

</details>


### [45] [Li-ViP3D++: Query-Gated Deformable Camera-LiDAR Fusion for End-to-End Perception and Trajectory Prediction](https://arxiv.org/abs/2601.20720)
*Matej Halinkovic,Nina Masarykova,Alexey Vinel,Marek Galinski*

Main category: cs.CV

TL;DR: 本文提出了一种基于查询的多模态感知预测框架Li-ViP3D++，引入了Query-Gated Deformable Fusion (QGDF)机制，将多视角RGB和LiDAR信息融合到查询空间。该方法在nuScenes数据集上提高了感知准确性和预测质量，同时保持了高效的推理速度。


<details>
  <summary>Details</summary>
Motivation: 模块化管道会限制信息流并放大上游错误，而基于查询的感知和预测（PnP）模型能解决这些问题，但现有的图像和LiDAR融合方案往往依赖于引入他手校准和离散选择步骤的方法，这会导致信息利用不充分并将引入不必要的偏差。本文旨在提出一种完全可微分的相机和LiDAR融合框架，以提高感知和预测的准确性。

Method: Li-ViP3D++框架通过引入Query-Gated Deformable Fusion (QGDF)机制，将来自多视角RGB和LiDAR的数据融合到查询空间。QGDF同时通过掩码注意机制整合了来自不同相机和特征层的图像证据，通过完全可微的BEV采样方式从LiDAR中学习到可变偏移，并通过查询条件门控来适应性加权视觉线索和几何线索。这种方法在单个端到端模型中联合优化了检测、跟踪和多假设轨迹预测。

Result: 在nuScenes数据集上，Li-ViP3D++提高了端到端行为表现和检测质量，获得了更高的EPA (0.335)和mAP (0.502)，同时大幅减少了假阳性率（假阳性比0.147）。此外，该方法的推理速度比之前的Li-ViP3D变体更快（139.82 ms vs. 145.91 ms）。

Conclusion: Li-ViP3D++展示了相机和LiDAR在查询空间中完全可微分融合的潜力，提高了端到端感知预测的鲁棒性，同时保持了良好的可部署性。

Abstract: End-to-end perception and trajectory prediction from raw sensor data is one of the key capabilities for autonomous driving. Modular pipelines restrict information flow and can amplify upstream errors. Recent query-based, fully differentiable perception-and-prediction (PnP) models mitigate these issues, yet the complementarity of cameras and LiDAR in the query-space has not been sufficiently explored. Models often rely on fusion schemes that introduce heuristic alignment and discrete selection steps which prevent full utilization of available information and can introduce unwanted bias. We propose Li-ViP3D++, a query-based multimodal PnP framework that introduces Query-Gated Deformable Fusion (QGDF) to integrate multi-view RGB and LiDAR in query space. QGDF (i) aggregates image evidence via masked attention across cameras and feature levels, (ii) extracts LiDAR context through fully differentiable BEV sampling with learned per-query offsets, and (iii) applies query-conditioned gating to adaptively weight visual and geometric cues per agent. The resulting architecture jointly optimizes detection, tracking, and multi-hypothesis trajectory forecasting in a single end-to-end model. On nuScenes, Li-ViP3D++ improves end-to-end behavior and detection quality, achieving higher EPA (0.335) and mAP (0.502) while substantially reducing false positives (FP ratio 0.147), and it is faster than the prior Li-ViP3D variant (139.82 ms vs. 145.91 ms). These results indicate that query-space, fully differentiable camera-LiDAR fusion can increase robustness of end-to-end PnP without sacrificing deployability.

</details>


### [46] [Compression Tells Intelligence: Visual Coding, Visual Token Technology, and the Unification](https://arxiv.org/abs/2601.20742)
*Xin Jin,Jinming Liu,Yuntao Wei,Junyan Lin,Zhicheng Wang,Jianguo Huang,Xudong Yang,Yanxiao Liu,Wenjun Zeng*

Main category: cs.CV

TL;DR: 本文综述并统一了视觉编码和视觉标记技术，探讨了压缩效率与模型性能之间的trade-off，并展示了任务导向标记技术在多模态大语言模型等领域的潜力。


<details>
  <summary>Details</summary>
Motivation: 本文的主要动机是探讨视觉编码和视觉标记技术在多模态大语言模型等任务中的优化关系，通过统一这两种技术，旨在为未来的视觉编解码和标记技术提供新的见解，并探讨标准化一般标记技术的可能性。

Method: 本文的方法是首先对视觉编码技术和视觉标记技术进行了全面的回顾，并从优化的角度将两者统一，接着基于这种统一的建模框架综合两种技术的双向洞察，最后通过实际实验展示了在多模态大语言模型和AI生成内容等任务中自适应标记技术的潜力。

Result: 本文指出了视觉编码与视觉标记技术在保真度和计算成本最小化之间的关系，并展示了自适应标记技术在多模态大语言模型等实际任务中的潜力，提出了未来的视觉编解码器和技术标准的可能方向。

Conclusion: 总的来说，本文在理论和实践上为多模态大语言模型以及智能任务中的视觉编解码和标记技术提供了新的见解，并探讨了标准化自适应标记技术的可能性。

Abstract: "Compression Tells Intelligence", is supported by research in artificial intelligence, particularly concerning (multimodal) large language models (LLMs/MLLMs), where compression efficiency often correlates with improved model performance and capabilities. For compression, classical visual coding based on traditional information theory has developed over decades, achieving great success with numerous international industrial standards widely applied in multimedia (e.g., image/video) systems. Except that, the recent emergingvisual token technology of generative multi-modal large models also shares a similar fundamental objective like visual coding: maximizing semantic information fidelity during the representation learning while minimizing computational cost. Therefore, this paper provides a comprehensive overview of two dominant technique families first -- Visual Coding and Vision Token Technology -- then we further unify them from the aspect of optimization, discussing the essence of compression efficiency and model performance trade-off behind. Next, based on the proposed unified formulation bridging visual coding andvisual token technology, we synthesize bidirectional insights of themselves and forecast the next-gen visual codec and token techniques. Last but not least, we experimentally show a large potential of the task-oriented token developments in the more practical tasks like multimodal LLMs (MLLMs), AI-generated content (AIGC), and embodied AI, as well as shedding light on the future possibility of standardizing a general token technology like the traditional codecs (e.g., H.264/265) with high efficiency for a wide range of intelligent tasks in a unified and effective manner.

</details>


### [47] [FAIRT2V: Training-Free Debiasing for Text-to-Video Diffusion Models](https://arxiv.org/abs/2601.20791)
*Haonan Zhong,Wei Song,Tingxu Han,Maurice Pagnucco,Jingling Xue,Yang Song*

Main category: cs.CV

TL;DR: FairT2V 提出了一种无需微调的去偏见框架，通过锚点基于的球面测地变换来中和提示嵌入，从而减轻以预训练文本编码器为源头的性别偏见，同时保持语义的一致性，并通过动态去噪调度在早期身份形成步骤中应用去偏见。


<details>
  <summary>Details</summary>
Motivation: 由于现有的T2V模型主要依赖预训练文本编码器，这些编码器会对中性提示产生隐含的性别偏见，因此研究并减轻这种性别偏见对于提高生成视频的公平性非常重要。

Method: FairT2V 使用了基于锚点的球面测地变换方法来中和提示嵌入中的性别偏见，同时通过动态去噪调度仅在早期身份形成步骤中应用去偏见处理，以保持视频的时空一致性。

Result: 实验结果显示，FairT2V 能够显著降低不同职业的性别偏见，对视频质量的影响较小。

Conclusion: FairT2V 是一种有效的去偏见框架，能够在无需微调的情况下减轻 T2V 模型中的性别偏见，对公平性和生成质量的平衡具有重要意义。

Abstract: Text-to-video (T2V) diffusion models have achieved rapid progress, yet their demographic biases, particularly gender bias, remain largely unexplored. We present FairT2V, a training-free debiasing framework for text-to-video generation that mitigates encoder-induced bias without finetuning. We first analyze demographic bias in T2V models and show that it primarily originates from pretrained text encoders, which encode implicit gender associations even for neutral prompts. We quantify this effect with a gender-leaning score that correlates with bias in generated videos.
  Based on this insight, FairT2V mitigates demographic bias by neutralizing prompt embeddings via anchor-based spherical geodesic transformations while preserving semantics. To maintain temporal coherence, we apply debiasing only during early identity-forming steps through a dynamic denoising schedule. We further propose a video-level fairness evaluation protocol combining VideoLLM-based reasoning with human verification. Experiments on the modern T2V model Open-Sora show that FairT2V substantially reduces demographic bias across occupations with minimal impact on video quality.

</details>


### [48] [Open-Vocabulary Functional 3D Human-Scene Interaction Generation](https://arxiv.org/abs/2601.20835)
*Jie Liu,Yu Sun,Alpar Cseke,Yao Feng,Nicolas Heron,Michael J. Black,Yan Zhang*

Main category: cs.CV

TL;DR: FunHSI 是一个无需训练的功能驱动框架，能够从开放词汇的任务提示中生成功能正确的人景交互。


<details>
  <summary>Details</summary>
Motivation: 当前方法在理解场景功能元素及人类动作与场景接触方面存在不足，导致交互不现实或功能上错误。因此，本文提出了 FunHSI，旨在解决这一问题。

Method: FunHSI 通过功能感知接触推理识别场景功能元素，重新构建其 3D 几何，并通过接触图建模高阶交互。利用视觉语言模型合成执行此任务的人，并估计提出的身体和手部 3D 姿态。最后，通过逐步优化细化所提的 3D 人体配置。

Result: 实验证明，FunHSI 能在多种室内和室外场景中生成功能正确且物理上合乎逻辑的人景交互，不仅合成更现实的一般 3D 交互，还能支持精细的功能性人景交互。

Conclusion: FunHSI 为 3D 交互设计提供了一种新颖的方法，并在实际应用中展示了其价值。

Abstract: Generating 3D humans that functionally interact with 3D scenes remains an open problem with applications in embodied AI, robotics, and interactive content creation. The key challenge involves reasoning about both the semantics of functional elements in 3D scenes and the 3D human poses required to achieve functionality-aware interaction. Unfortunately, existing methods typically lack explicit reasoning over object functionality and the corresponding human-scene contact, resulting in implausible or functionally incorrect interactions. In this work, we propose FunHSI, a training-free, functionality-driven framework that enables functionally correct human-scene interactions from open-vocabulary task prompts. Given a task prompt, FunHSI performs functionality-aware contact reasoning to identify functional scene elements, reconstruct their 3D geometry, and model high-level interactions via a contact graph. We then leverage vision-language models to synthesize a human performing the task in the image and estimate proposed 3D body and hand poses. Finally, the proposed 3D body configuration is refined via stage-wise optimization to ensure physical plausibility and functional correctness. In contrast to existing methods, FunHSI not only synthesizes more plausible general 3D interactions, such as "sitting on a sofa'', while supporting fine-grained functional human-scene interactions, e.g., "increasing the room temperature''. Extensive experiments demonstrate that FunHSI consistently generates functionally correct and physically plausible human-scene interactions across diverse indoor and outdoor scenes.

</details>


### [49] [A New Dataset and Framework for Robust Road Surface Classification via Camera-IMU Fusion](https://arxiv.org/abs/2601.20847)
*Willams de Lima Costa,Thifany Ketuli Silva de Souza,Jonas Ferreira Silva,Carlos Gabriel Bezerra Pereira,Bruno Reis Vila Nova,Leonardo Silvino Brito,Rafael Raider Leoni,Juliano Silva,Valter Ferreira,Sibele Miguel Soares Neto,Samantha Uehara,Daniel Giacomo,João Marcelo Teixeira,Veronica Teichrieb,Cristiano Coelho de Araújo*

Main category: cs.CV

TL;DR: 本研究提出了一种针对道路表面分类的多模态框架，融合了图像和惯性测量，通过轻量级双向交叉注意力模块和自适应门控层，提高了在多变环境下的泛化能力。同时，还构建了一个新的道路数据集ROAD，以评估模型在各种条件下的鲁棒性。实验结果显示，该方法在多种环境下的F1分数表现优于先前的最佳方法。


<details>
  <summary>Details</summary>
Motivation: 现有道路表面分类技术在面对不同环境条件时泛化能力有限，本文旨在通过引入多模态融合方法来解决这一问题，以提高道路维护系统的环境感知能力。

Method: 本研究采用轻量级双向交叉注意力机制和自适应门控层，将图像和惯性测量数据进行融合，实现对道路表面的分类。同时，还构建了一个新的多模态数据集ROAD，该数据集包括了真实的多模态记录、大规模的仅基于视觉的子集以及合成的子集，用于评估模型在不同类型环境下的表现。

Result: 实验结果显示，该方法在PVS基准测试中提升了1.4个百分点，在多模态ROAD子集中提升了11.6个百分点，并且在夜间、大雨和混合路面条件下都表现出了一致的高F1分数。

Conclusion: 该研究成功地提出了一种多模态方法，该方法在环境多样性的道路上表现出了优异的分类能力，为低成本道路表面理解提供了新的可能性。

Abstract: Road surface classification (RSC) is a key enabler for environment-aware predictive maintenance systems. However, existing RSC techniques often fail to generalize beyond narrow operational conditions due to limited sensing modalities and datasets that lack environmental diversity. This work addresses these limitations by introducing a multimodal framework that fuses images and inertial measurements using a lightweight bidirectional cross-attention module followed by an adaptive gating layer that adjusts modality contributions under domain shifts. Given the limitations of current benchmarks, especially regarding lack of variability, we introduce ROAD, a new dataset composed of three complementary subsets: (i) real-world multimodal recordings with RGB-IMU streams synchronized using a gold-standard industry datalogger, captured across diverse lighting, weather, and surface conditions; (ii) a large vision-only subset designed to assess robustness under adverse illumination and heterogeneous capture setups; and (iii) a synthetic subset generated to study out-of-distribution generalization in scenarios difficult to obtain in practice. Experiments show that our method achieves a +1.4 pp improvement over the previous state-of-the-art on the PVS benchmark and an +11.6 pp improvement on our multimodal ROAD subset, with consistently higher F1-scores on minority classes. The framework also demonstrates stable performance across challenging visual conditions, including nighttime, heavy rain, and mixed-surface transitions. These findings indicate that combining affordable camera and IMU sensors with multimodal attention mechanisms provides a scalable, robust foundation for road surface understanding, particularly relevant for regions where environmental variability and cost constraints limit the adoption of high-end sensing suites.

</details>


### [50] [FreeFix: Boosting 3D Gaussian Splatting via Fine-Tuning-Free Diffusion Models](https://arxiv.org/abs/2601.20857)
*Hongyu Zhou,Zisen Shao,Sheng Miao,Pan Wang,Dongfeng Bai,Bingbing Liu,Yiyi Liao*

Main category: cs.CV

TL;DR: FreeFix 提出了一种无需微调的方法，通过预训练的图像扩散模型对插值渲染进行增强，实现了高一致性和强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前方法依赖密集输入，并在插值视图上退化。而利用生成模型如扩散模型提供额外监督，存在泛化能力和保真度之间的权衡。

Method: FreeFix 采用了一种交错的 2D-3D 技术策略，利用预训练的图像扩散模型进行细化，提出了一种像素级置信掩模来识别需要改进的不确定区域。

Result: 实验表明，FreeFix 在多帧一致性方面取得了更好的表现，性能与微调方法相当甚至更优，同时保持了强泛化能力。

Conclusion: FreeFix 提出的方法为渲染强化提供了一种新的解决方案。

Abstract: Neural Radiance Fields and 3D Gaussian Splatting have advanced novel view synthesis, yet still rely on dense inputs and often degrade at extrapolated views. Recent approaches leverage generative models, such as diffusion models, to provide additional supervision, but face a trade-off between generalization and fidelity: fine-tuning diffusion models for artifact removal improves fidelity but risks overfitting, while fine-tuning-free methods preserve generalization but often yield lower fidelity. We introduce FreeFix, a fine-tuning-free approach that pushes the boundary of this trade-off by enhancing extrapolated rendering with pretrained image diffusion models. We present an interleaved 2D-3D refinement strategy, showing that image diffusion models can be leveraged for consistent refinement without relying on costly video diffusion models. Furthermore, we take a closer look at the guidance signal for 2D refinement and propose a per-pixel confidence mask to identify uncertain regions for targeted improvement. Experiments across multiple datasets show that FreeFix improves multi-frame consistency and achieves performance comparable to or surpassing fine-tuning-based methods, while retaining strong generalization ability.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [51] [From Intuition to Expertise: Rubric-Based Cognitive Calibration for Human Detection of LLM-Generated Korean Text](https://arxiv.org/abs/2601.19913)
*Shinwoo Park,Yo-Sub Han*

Main category: cs.CL

TL;DR: 本研究介绍了一种名为LREAD的评分标准，通过三个阶段的纵向盲测，提高了对人类撰写韩文与流畅的LLM输出区别的检测能力。最终，通过评分标准校准的人类评委在细微的语文特征上表现出更强的判断能力。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决语言专业人员对LLM生成文本的误判问题，以及提出一种可行的校准方法提升专家检测水平。

Method: 研究方法包括三个阶段的纵向盲测，分别为直觉检测、分级评分并提供明确的依据、专项领域掌握评价。使用Fleiss' kappa度量者间一致性。

Result: 结果显示，经过校准的人类评委在三个阶段中的准确率从60%提升到100%，且度量者间一致性显著提高，从-0.09提升到0.82。相比最先进的LLM检测器，校准的人类评委更依赖于语言特异性微诊断，这些诊断不能被粗略的语篇先验所涵盖。

Conclusion: 研究结论认为，评分标准支撑下的专家判断可以作为解释性补充自动检测器，特别适用于非英语环境，同时发布时间格式化的评分标准和校准检测的分类标准。

Abstract: Distinguishing human-written Korean text from fluent LLM outputs remains difficult even for linguistically trained readers, who can over-trust surface well-formedness. We study whether expert detection can be treated as a learnable skill and improved through structured calibration. We introduce LREAD, a rubric derived from national Korean writing standards and adapted to target micro-level artifacts (e.g., punctuation optionality, spacing behavior, and register shifts). In a three-phase longitudinal blind protocol with Korean linguistics majors, Phase 1 measures intuition-only detection, Phase 2 enforces criterion-level scoring with explicit justifications, and Phase 3 evaluates domain-focused mastery on held-out elementary essays. Across phases, majority-vote accuracy increases from 60% to 100%, accompanied by stronger inter-annotator agreement (Fleiss' kappa: -0.09 --> 0.82). Compared to state-of-the-art LLM detectors, calibrated humans rely more on language-specific micro-diagnostics that are not well captured by coarse discourse priors. Our findings suggest that rubric-scaffolded expert judgment can serve as an interpretable complement to automated detectors for non-English settings, and we release the full rubric and a taxonomy of calibrated detection signatures.

</details>


### [52] [Simulating Complex Multi-Turn Tool Calling Interactions in Stateless Execution Environments](https://arxiv.org/abs/2601.19914)
*Maxwell Crouse,Ibrahim Abdelaziz,Kshitij Fadnis,Siva Sankalp Patel,Kinjal Basu,Chulaka Gunasekara,Sadhana Kumaravel,Asim Munawar,Pavan Kapanipathi*

Main category: cs.CL

TL;DR: 研究人员提出了DiGiT-TC方法，该方法可以在没有执行环境和状态的情况下生成具有类似状态环境特性的工具调用对话。通过一种新颖的生成模式，使得用户请求中隐式包含特定的工具调用，验证结果显示在有状态的问题设置中也能取得显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 当前的工具调用数据生成方法通常假设存在维护状态的执行环境，这在某些现实中难以实现的情形下存在局限性。因此，研究人员开发了DiGiT-TC方法，以填补这一空白并在更广泛的场景中生成有效的工具调用数据。

Method: DiGiT-TC方法通过一种新的生成模式，隐式地在用户请求中表示特定的工具调用。这种方法能够在没有执行环境和状态的情况下生成具有类似状态环境特性的工具调用对话。

Result: 研究人员在标准的工具调用基准上验证了DiGiT-TC方法的有效性，结果显示即使在有状态的问题设置中，这种方法也能获得显著的性能提升。

Conclusion: DiGiT-TC方法为生成适用于不同类型工具调用对话的数据提供了一种新模式，尤其在没有执行环境和状态的情况下也能有效生成高质量的数据。这种方法在实际应用中具有广泛的前景。

Abstract: Synthetic data has proven itself to be a valuable resource for tuning smaller, cost-effective language models to handle the complexities of multi-turn tool calling conversations. While many frameworks and systems for producing synthetic multi-turn tool calling data have been proposed, prior works have frequently assumed that any tool calling interactions will take place in an execution environment that maintains state. When such an environment is available, this is advantageous as it allows for the validity of an interaction to be determined by whether or not the state of the execution environment matches to some prespecified objective. Unfortunately, this does not hold in many real-world tool use settings, e.g., in enterprise settings where data security is of the utmost importance or in cases where tool specifications are synthesized from multiple sources. In this work, we address this gap by introducing a data generation method, DiGiT-TC, that is designed to produce tool calling conversations that have the characteristics of conversations generated through search in a stateful environment. The key to our technique lies in a novel generation pattern that allows our approach to implicitly represent certain tool calls in the user request. We validate our approach on standard tool calling benchmarks and demonstrate that, even in stateful problem settings, our approach results in strong performance gains.

</details>


### [53] [Modeling Next-Token Prediction as Left-Nested Intuitionistic Implication](https://arxiv.org/abs/2601.19915)
*Paul Tarau*

Main category: cs.CL

TL;DR: 本文介绍了一种源自问头逻辑解释的下一标记预测神经架构——箭头语言模型。它以左嵌套推导链编码前缀，利用合式证明扩展实现序列处理。证明了与变换器等基础模型的关联，并提出了低秩神经实现。


<details>
  <summary>Details</summary>
Motivation: 本文旨在从逻辑角度推导神经架构，促进对单一标记与多标记预测选择等基础问题的理解。

Method: 通过引入箭头语言模型，将前缀编码为左嵌套推导链，利用模态斯诺和预言逻辑，证明了模型的性质。

Result: 验证了箭头语言模型的性质，例如与可交换序列和非可交换序列之间的关系，并展示了其与变换器和状态空间模型的关系，开发了低秩神经实现。

Conclusion: 箭头语言模型提供了一种新的神经架构，能更接近逻辑解释地进行序列处理，并进一步展示了其作为一种潜在替代变换器基础模型的潜力。

Abstract: We introduce the \emph{Arrow Language Model}, a neural architecture derived from an intuitionistic-logic interpretation of next-token prediction. Instead of representing tokens as additive embeddings mixed by attention, we encode a prefix as a \emph{left-nested implication chain} whose structure preserves order through non-commutative composition. Next-token prediction corresponds to \emph{modus ponens}, and sequence processing becomes constructive proof extension under the Curry--Howard correspondence. Our Prolog-based specialized theorem provers validate fundamental properties of the neural models, among which relations between commutative vs. non-commutative sequencing and single-token vs. multi-token prediction choices. We show that a neural architecture equivalent to multiplicative RNNs arises naturally from a proof-theoretic interpretation of next-token prediction as nested intuitionistic implication, we present a practical low-rank neural realization and position the model relative to Transformers and state-space models.
  Keywords: logic-based derivation of neural architectures, intuitionistic implicational logic, token-as-operator neural models, state-space models, alternatives to transformer-based foundational models.

</details>


### [54] [PaperAudit-Bench: Benchmarking Error Detection in Research Papers for Critical Automated Peer Review](https://arxiv.org/abs/2601.19916)
*Songjun Tu,Yiwen Ma,Jiahao Lin,Qichao Zhang,Xiangyuan Lan,Junfeng. Li,Nan Xu,Linjing Li,Dongbin Zhao*

Main category: cs.CL

TL;DR: 该研究提出了PaperAudit-Bench，包含PaperAudit-Dataset和PaperAudit-Review两个部分，旨在评估大型语言模型在长文背景下处理细微技术错误的能力。实验显示不同模型在错误检测上的表现差异显著，结合显式错误检测能够产生更为严谨、区分度更高的评估结果。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型能够生成流畅的评审意见，但在处理细微且分布于全文的错误时，其评估常常缺乏足够的批判性。为解决这一问题，作者提出了PaperAudit-Bench框架。

Method: PaperAudit-Bench框架包括一个包含多种错误类型的误差数据集（PaperAudit-Dataset）和一个结合结构化错误检测与证据意识评审生成的自动化评审框架（PaperAudit-Review）。研究通过实验分析模型在长文本背景下检测错误的能力。

Result: 研究发现各模型在错误检测上的表现差异显著，长文本背景下的错误可检测性存在较大变化。将显式错误检测融入评审流程可以产生更加严谨和区分度更高的评估结果。

Conclusion: 该研究验证了结合显式错误检测的评审框架的有效性，并指出通过数据集训练轻量级语言模型进行错误检测具有计算成本低的优势。

Abstract: Large language models can generate fluent peer reviews, yet their assessments often lack sufficient critical rigor when substantive issues are subtle and distributed across a paper. In this paper, we introduce PaperAudit-Bench, which consists of two components: (1) PaperAudit-Dataset, an error dataset covering both errors identifiable within individual sections and those requiring cross-section reasoning, designed for controlled evaluation under long-context settings; and (2) PaperAudit-Review, an automated review framework that integrates structured error detection with evidence-aware review generation to support critical assessment. Experiments on PaperAudit-Bench reveal large variability in error detectability across models and detection depths, highlighting the difficulty of identifying such errors under long-context settings. Relative to representative automated reviewing baselines, incorporating explicit error detection into the review workflow produces systematically stricter and more discriminative evaluations, demonstrating its suitability for peer review. Finally, we show that the dataset supports training lightweight LLM detectors via SFT and RL, enabling effective error detection at reduced computational cost.

</details>


### [55] [PILOT: Planning via Internalized Latent Optimization Trajectories for Large Language Models](https://arxiv.org/abs/2601.19917)
*Haoyu Zheng,Yun Zhu,Yuqian Yuan,Bo Yuan,Wenqiao Zhang,Siliang Tang,Jun Xiao*

Main category: cs.CL

TL;DR: PILOT提出了一种轻量级的框架，使大型语言模型内部化规划能力，而非修改模型权重，以稳定多步推理并取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 小型语言模型缺乏全局策略导致长期任务中的错误传播；外部指导存在延迟和可用性问题。因此，需要一个框架来弥补这一不足，不得干扰原始模型架构。

Method: PILOT通过引入一个轻量级Hyper-Network合成基于查询的隐含指导向量，作为内部导航机制，引导模型更好地进行多步推理。

Result: 在多项数学和编程基准测试中，PILOT成功稳定了推理路径，超过竞争对手8.9%以上，并且几乎不会增加推理延迟。

Conclusion: PILOT框架展示了将大型语言模型的规划能力内部化的效果，提供了一种有效提高模型多步推理性能的方法。

Abstract: Strategic planning is critical for multi-step reasoning, yet compact Large Language Models (LLMs) often lack the capacity to formulate global strategies, leading to error propagation in long-horizon tasks. Our analysis reveals that LLMs possess latent reasoning capabilities that can be unlocked when conditioned on explicit plans from a teacher model; however, runtime reliance on external guidance is often impractical due to latency and availability constraints. To bridge this gap, we propose PILOT (Planning via Internalized Latent Optimization Trajectories), a non-invasive framework designed to internalize the strategic oversight of large models into intrinsic Latent Guidance. Instead of altering backbone weights, PILOT employs a lightweight Hyper-Network to synthesize a query-conditioned Latent Guidance vector. This vector acts as an internal steering mechanism, guiding the model's representations toward optimal reasoning paths. Extensive experiments on mathematical and coding benchmarks demonstrate that PILOT effectively stabilizes reasoning trajectories, consistently outperforming strong baselines (e.g., +8.9% on MATH500) with negligible inference latency.

</details>


### [56] [Lowest Span Confidence: A Zero-Shot Metric for Efficient and Black-Box Hallucination Detection in LLMs](https://arxiv.org/abs/2601.19918)
*Yitong Qiao,Licheng Pan,Yu Mi,Lei Liu,Yue Shen,Fei Sun,Zhixuan Chu*

Main category: cs.CL

TL;DR: 提出了一种名为Lowest Span Confidence (LSC) 的新零样本指标，用于在资源受限条件下高效检测大型语言模型中的幻觉。LSC 通过滑动窗口机制评估语义连贯片段的联合概率，并能捕获与事实不一致紧密相关的局部不确定性模式。


<details>
  <summary>Details</summary>
Motivation: 现有的幻觉检测方法通常基于不切实际的假设，即需要昂贵的严格一致性检查或白箱 LLM 状态，这些在常见 API 基础场景中不可用或效率低下。因此，需要一个能在资源有限环境下有效检测幻觉的方法。

Method: LSC 是一种零样本指标，无需昂贵的资源，仅需一次正向传播和输出概率。它通过滑动窗口机制评估变量长度 n-克的语义连贯片段的联合概率，并识别低边际置信度的区域来捕获与事实不一致相关的局部不确定性模式。

Result: 在多个先进模型和不同基准上的广泛实验表明，LSC 在资源受限条件下能够持续超越现有的零样本基线，具有较强的检测性能。

Conclusion: LSC 提供了一种在资源受限环境下检测大型语言模型幻觉的有效方法，对于实际应用中的高风险环境具有重要意义。

Abstract: Hallucinations in Large Language Models (LLMs), i.e., the tendency to generate plausible but non-factual content, pose a significant challenge for their reliable deployment in high-stakes environments. However, existing hallucination detection methods generally operate under unrealistic assumptions, i.e., either requiring expensive intensive sampling strategies for consistency checks or white-box LLM states, which are unavailable or inefficient in common API-based scenarios. To this end, we propose a novel efficient zero-shot metric called Lowest Span Confidence (LSC) for hallucination detection under minimal resource assumptions, only requiring a single forward with output probabilities. Concretely, LSC evaluates the joint likelihood of semantically coherent spans via a sliding window mechanism. By identifying regions of lowest marginal confidence across variable-length n-grams, LSC could well capture local uncertainty patterns strongly correlated with factual inconsistency. Importantly, LSC can mitigate the dilution effect of perplexity and the noise sensitivity of minimum token probability, offering a more robust estimate of factual uncertainty. Extensive experiments across multiple state-of-the-art (SOTA) LLMs and diverse benchmarks show that LSC consistently outperforms existing zero-shot baselines, delivering strong detection performance even under resource-constrained conditions.

</details>


### [57] [FastWhisper: Adaptive Self-knowledge Distillation for Real-time Automatic Speech Recognition](https://arxiv.org/abs/2601.19919)
*Junseok Lee,Nahoon Kim,Sangyong Lee,Chang-Jae Chun*

Main category: cs.CL

TL;DR: 提出了自适应自我知识蒸馏（ASKD）方法，通过动态减少对教师模型的依赖来提高学生模型的自训练能力和泛化能力。FastWhisper是一个比教师模型Whisper更小的变种，具有较低的词错误率和更快的推理速度。


<details>
  <summary>Details</summary>
Motivation: 减轻学生模型继承教师模型缺陷导致泛化能力下降的问题。

Method: 提出了一种自适应自我知识蒸馏（ASKD）方法，该方法动态地减少了学生模型对教师模型的依赖，同时通过自我知识蒸馏提高学生模型的泛化能力。

Result: 在Post-training设置下，FastWhisper相比Whisper的词错误率降低了1.07%，推理时间缩短为原来的五分之一。

Conclusion: 该研究成功地通过自适应自我知识蒸馏方法，有效地将Whisper模型压缩为FastWhisper，提高了模型的泛化能力和推理效率。

Abstract: Knowledge distillation is one of the most effective methods for model compression. Previous studies have focused on the student model effectively training the predictive distribution of the teacher model. However, during training, the student model may inherit the shortcomings of the teacher model, which can lead to a decline in generalization capacity. To mitigate this issue, we propose adaptive self-knowledge distillation (ASKD), which dynamically reduces the dependence of the teacher model to improve the self-training capacity, and performs the self-knowledge distillation method to improve the generalization capacity of the student model. We further distill the Whisper model into a smaller variant, called FastWhisper. In our post-training setting, FastWhisper achieved a word error rate of 1.07% lower than the teacher model Whisper, and its relative inference time was 5 times faster.

</details>


### [58] [Demystifying Multi-Agent Debate: The Role of Confidence and Diversity](https://arxiv.org/abs/2601.19921)
*Xiaochen Zhu,Caiqi Zhang,Yizhou Chi,Tom Stafford,Nigel Collier,Andreas Vlachos*

Main category: cs.CL

TL;DR: 该研究通过引入多样性的初始观点和显式、校准过的自信沟通机制，改进了传统多智能体辩论（MAD），从而在六个问答基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体辩论（MAD）尽管成本更高，但在一致的信念更新和同质智能体下往往不如简单的多数投票可靠。本文旨在通过借鉴人类辩论和集体决策的发现，提出两个轻量级的改进措施来增强MAD的效果。

Method: 本文提出了两种改进措施：一是动态多样的初始设定，二是自信校准化的辩论协议。

Result: 理论结果显示，动态多样的初始设定能够提高MAD成功的先验概率，而不改变基础更新动态；而自信校准化的更新可以使辩论系统地偏向正确的假设。实验结果显示，在六个推理导向的问答基准测试中，这些方法均优于传统的MAD和多数投票。

Conclusion: 本文通过上述两种简单的修改，展示了如何显著增强基于LLM的辩论的效率，同时也将人类的讨论和决策策略与AI系统的结合起来。

Abstract: Multi-agent debate (MAD) is widely used to improve large language model (LLM) performance through test-time scaling, yet recent work shows that vanilla MAD often underperforms simple majority vote despite higher computational cost. Studies show that, under homogeneous agents and uniform belief updates, debate preserves expected correctness and therefore cannot reliably improve outcomes. Drawing on findings from human deliberation and collective decision-making, we identify two key mechanisms missing from vanilla MAD: (i) diversity of initial viewpoints and (ii) explicit, calibrated confidence communication. We propose two lightweight interventions. First, a diversity-aware initialisation that selects a more diverse pool of candidate answers, increasing the likelihood that a correct hypothesis is present at the start of debate. Second, a confidence-modulated debate protocol in which agents express calibrated confidence and condition their updates on others' confidence. We show theoretically that diversity-aware initialisation improves the prior probability of MAD success without changing the underlying update dynamics, while confidence-modulated updates enable debate to systematically drift to the correct hypothesis. Empirically, across six reasoning-oriented QA benchmarks, our methods consistently outperform vanilla MAD and majority vote. Our results connect human deliberation with LLM-based debate and demonstrate that simple, principled modifications can substantially enhance debate effectiveness.

</details>


### [59] [HEART: A Unified Benchmark for Assessing Humans and LLMs in Emotional Support Dialogue](https://arxiv.org/abs/2601.19922)
*Laya Iyer,Kriti Aggarwal,Sanmi Koyejo,Gail Heyman,Desmond C. Ong,Subhabrata Mukherjee*

Main category: cs.CL

TL;DR: HEART（人际情感框架）是首个直接对比人类与语言模型在多轮情感支持对话中表现的框架。研究发现，先进模型在感知同理心和一致性方面接近或超越了普通人类表现，但在适应性重塑、紧张命名和细腻音调调整方面仍有人类的优势。该框架明确了模型生成的支持与人类社会判断间的差异，填补了语言模型在人际领域能力评估的空白。


<details>
  <summary>Details</summary>
Motivation: 现有的自然语言处理技术虽然进步迅速，但缺乏一种直接评估模型人际情感对话能力的方法。HEART框架旨在填补这一空白，将不同语言模型及其与人类的表现进行直接对比。

Method: 本研究通过HEART框架，为每个对话历史配对人类和模型的回应，并通过盲测的人类评估者和LLM评判员进行评估。评估维度包括人际沟通科学的五个方面：人本对齐、共情回应、调节、共鸣和任务遵循。

Result: 研究发现，一些前沿模型在感知同理心和一致性方面接近或超越了普通人类表现，特别在对抗性对话中。同时，人类仍占有优势，在适应性重塑、紧张命名和细腻音调调整方面。

Conclusion: HEART为理解模型生成的支持与人类社会判断间的差异提供了统一的实验基础，它揭示了情感对话作为一种独特能力轴的存在，该轴线与其广泛的推理或语言流畅性相分离。

Abstract: Supportive conversation depends on skills that go beyond language fluency, including reading emotions, adjusting tone, and navigating moments of resistance, frustration, or distress. Despite rapid progress in language models, we still lack a clear way to understand how their abilities in these interpersonal domains compare to those of humans. We introduce HEART, the first-ever framework that directly compares humans and LLMs on the same multi-turn emotional-support conversations. For each dialogue history, we pair human and model responses and evaluate them through blinded human raters and an ensemble of LLM-as-judge evaluators. All assessments follow a rubric grounded in interpersonal communication science across five dimensions: Human Alignment, Empathic Responsiveness, Attunement, Resonance, and Task-Following. HEART uncovers striking behavioral patterns. Several frontier models approach or surpass the average human responses in perceived empathy and consistency. At the same time, humans maintain advantages in adaptive reframing, tension-naming, and nuanced tone shifts, particularly in adversarial turns. Human and LLM-as-judge preferences align on about 80 percent of pairwise comparisons, matching inter-human agreement, and their written rationales emphasize similar HEART dimensions. This pattern suggests an emerging convergence in the criteria used to assess supportive quality. By placing humans and models on equal footing, HEART reframes supportive dialogue as a distinct capability axis, separable from general reasoning or linguistic fluency. It provides a unified empirical foundation for understanding where model-generated support aligns with human social judgment, where it diverges, and how affective conversational competence scales with model size.

</details>


### [60] [OPT-Engine: Benchmarking the Limits of LLMs in Optimization Modeling via Complexity Scaling](https://arxiv.org/abs/2601.19924)
*Yitian Chen,Cheng Cheng,Yinan Sun,Zi Ling,Dongdong Ge*

Main category: cs.CL

TL;DR: 该研究提出了一种名为OPT-ENGINE的基准框架，用于评估大型语言模型在复杂优化问题上的推理能力，并揭示了工具集成的外部求解器和约束自动化的性能瓶颈。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）在优化建模中的应用日益增多，有必要建立一个基准框架来评估其自动化建模和问题解决能力，尤其是针对复杂的现实世界任务。

Method: 研究设计了一个包含10个经典任务的基准框架，涵盖运营研究中的线性和混合整数编程问题。利用该框架，进行了广泛的实证研究，探讨了LLMs在问题解释和解决方案生成过程中的性能瓶颈。

Result: 研究发现，工具集成的外部求解器在任务复杂性增加时表现出更高的鲁棒性，而纯粹基于文本的推理达到了上限。约束自动化的建模是当前LLMs的主要性能瓶颈。

Conclusion: 研究结果为开发下一代用于高级优化的LLMs提供了行动指南，并揭示了继续研究的重要方向。

Abstract: Large Language Models (LLMs) have demonstrated impressive progress in optimization modeling, fostering a rapid expansion of new methodologies and evaluation benchmarks. However, the boundaries of their capabilities in automated formulation and problem solving remain poorly understood, particularly when extending to complex, real-world tasks. To bridge this gap, we propose OPT-ENGINE, an extensible benchmark framework designed to evaluate LLMs on optimization modeling with controllable and scalable difficulty levels. OPT-ENGINE spans 10 canonical tasks across operations research, with five Linear Programming and five Mixed-Integer Programming. Utilizing OPT-ENGINE, we conduct an extensive study of LLMs' reasoning capabilities, addressing two critical questions: 1.) Do LLMs' performance remain robust when generalizing to out-of-distribution optimization tasks that scale in complexity beyond current benchmark levels? and 2.) At what stage, from problem interpretation to solution generation, do current LLMs encounter the most significant bottlenecks? Our empirical results yield two key insights: first, tool-integrated reasoning with external solvers exhibits significantly higher robustness as task complexity escalates, while pure-text reasoning reaches a ceiling; second, the automated formulation of constraints constitutes the primary performance bottleneck. These findings provide actionable guidance for developing next-generation LLMs for advanced optimization. Our code is publicly available at \textcolor{blue}{https://github.com/Cardinal-Operations/OPTEngine}.

</details>


### [61] [Evaluating Large Language Models for Abstract Evaluation Tasks: An Empirical Study](https://arxiv.org/abs/2601.19925)
*Yinuo Liu,Emre Sezgin,Eric A. Youngstrom*

Main category: cs.CL

TL;DR: 本研究测试了ChatGPT-5、Gemini-3-Pro和Claude-Sonnet-4.5在评估学术摘要一致性与可靠性的表现，发现与其他AI和人类评审员相比，它们在总体质量和客观标准上有中等至好的一致性。


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型（LLM）在辅助科学评审中的潜力

Method: 使用单个评分标准对160篇来自本地会议的摘要进行人类评审员和三种LLM的评分，通过ICC计算人际可靠性和AI-人类一致性，并通过Bland-Altman图进行可视化和系统偏差分析。

Result: 三种LLM相互一致性良好（ICC：0.59-0.87），在综合分数、整体质量及特定标准上与人类评分员有中等至好的一致性，而在主观维度上表现出中等一致性。Gemini在某些标准上一致性较差。

Conclusion: LLM在批量处理摘要时能在整体质量和客观指标方面与人类专家达成中等至好的一致性，但人类专家在主观判断方面仍起关键作用。

Abstract: Introduction: Large language models (LLMs) can process requests and generate texts, but their feasibility for assessing complex academic content needs further investigation. To explore LLM's potential in assisting scientific review, this study examined ChatGPT-5, Gemini-3-Pro, and Claude-Sonnet-4.5's consistency and reliability in evaluating abstracts compared to one another and to human reviewers. Methods: 160 abstracts from a local conference were graded by human reviewers and three LLMs using one rubric. Composite score distributions across three LLMs and fourteen reviewers were examined. Inter-rater reliability was calculated using intraclass correlation coefficients (ICCs) for within-AI reliability and AI-human concordance. Bland-Altman plots were examined for visual agreement patterns and systematic bias. Results: LLMs achieved good-to-excellent agreement with each other (ICCs: 0.59-0.87). ChatGPT and Claude reached moderate agreement with human reviewers on overall quality and content-specific criteria, with ICCs ~.45-.60 for composite, impression, clarity, objective, and results. They exhibited fair agreement on subjective dimensions, with ICC ranging from 0.23-0.38 for impact, engagement, and applicability. Gemini showed fair agreement on half criteria and no reliability on impact and applicability. Three LLMs showed acceptable or negligible mean difference (ChatGPT=0.24, Gemini=0.42, Claude=-0.02) from the human mean composite scores. Discussion: LLMs could process abstracts in batches with moderate agreement with human experts on overall quality and objective criteria. With appropriate process architecture, they can apply a rubric consistently across volumes of abstracts exceeding feasibility for a human rater. The weaker performance on subjective dimensions indicates that AI should serve a complementary role in evaluation, while human expertise remains essential.

</details>


### [62] [The Grammar of Transformers: A Systematic Review of Interpretability Research on Syntactic Knowledge in Language Models](https://arxiv.org/abs/2601.19926)
*Nora Graichen,Iria de-Dios-Flores,Gemma Boleda*

Main category: cs.CL

TL;DR: 本文综述了337篇关于Transformer语言模型句法能力的论文，报告了1015个模型结果，涵盖了广泛的句法现象和可解释性方法。研究表明，这些先进模型在形式化现象上表现良好，但在句法与语义交界处的现象（如绑定或填充空位依赖）上表现更为多变和较弱。


<details>
  <summary>Details</summary>
Motivation: 为评估Transformer语言模型在句法能力方面的表现并提出未来研究方向。

Method: 对337篇研究进行系统性回顾，分析1015个模型结果，涵盖多种句法现象和可解释性方法。

Result: 先进模型在形式化现象上表现良好，但在句法与语义交界处的现象上表现较弱。特别指出，模型在绑定和填充空位依赖等现象上表现薄弱。

Conclusion: 强调未来工作应涵盖完整数据，使理论构想与方法更加一致，增加机械方法的应用，并扩展语言和语言现象的研究范围。

Abstract: We present a systematic review of 337 articles evaluating the syntactic abilities of Transformer-based language models, reporting on 1,015 model results from a range of syntactic phenomena and interpretability methods. Our analysis shows that the state of the art presents a healthy variety of methods and data, but an over-focus on a single language (English), a single model (BERT), and phenomena that are easy to get at (like part of speech and agreement). Results also suggest that TLMs capture these form-oriented phenomena well, but show more variable and weaker performance on phenomena at the syntax-semantics interface, like binding or filler-gap dependencies. We provide recommendations for future work, in particular reporting complete data, better aligning theoretical constructs and methods across studies, increasing the use of mechanistic methods, and broadening the empirical scope regarding languages and linguistic phenomena.

</details>


### [63] [Attribution Techniques for Mitigating Hallucinated Information in RAG Systems: A Survey](https://arxiv.org/abs/2601.19927)
*Yuqing Zhao,Ziyao Liu,Yongsen Zheng,Kwok-Yan Lam*

Main category: cs.CL

TL;DR: 本文概述了如何利用归因技术来减少RAG系统中的幻觉，并提出了归因技术的分类、统一框架，以及针对不同幻觉类型的技巧。这有助于未来研究和实际应用中的归因技术。


<details>
  <summary>Details</summary>
Motivation: 现代AI中，LLM在各类任务上的表现突出，但LMM的回答常存在不忠实的陈述。现有方法虽有用，但未形成一套统一的解决方案。

Method: 通过对RAG系统中的幻觉进行分类，设计了一套统一的方法，基于不同类型的幻觉评估不同的技巧，并提供了实践指南。

Result: 提出了一种统一的RAG系统幻觉归因方法框架，分类了幻觉类型，并探讨了各归因技术的优缺点。

Conclusion: 该研究为未来RAG系统中幻觉归因的改进提供了指导，有助于进一步的研究和实践应用。

Abstract: Large Language Models (LLMs)-based question answering (QA) systems play a critical role in modern AI, demonstrating strong performance across various tasks. However, LLM-generated responses often suffer from hallucinations, unfaithful statements lacking reliable references. Retrieval-Augmented Generation (RAG) frameworks enhance LLM responses by incorporating external references but also introduce new forms of hallucination due to complex interactions between the retriever and generator. To address these challenges, researchers have explored attribution-based techniques that ensure responses are verifiably supported by retrieved content. Despite progress, a unified pipeline for these techniques, along with a clear taxonomy and systematic comparison of their strengths and weaknesses, remains lacking. A well-defined taxonomy is essential for identifying specific failure modes within RAG systems, while comparative analysis helps practitioners choose appropriate solutions based on hallucination types and application context. This survey investigates how attribution-based techniques are used within RAG systems to mitigate hallucinations and addresses the gap by: (i) outlining a taxonomy of hallucination types in RAG systems, (ii) presenting a unified pipeline for attribution techniques, (iii) reviewing techniques based on the hallucinations they target, and (iv) discussing strengths and weaknesses with practical guidelines. This work offers insights for future research and practical use of attribution techniques in RAG systems.

</details>


### [64] [Towards a Mechanistic Understanding of Large Reasoning Models: A Survey of Training, Inference, and Failures](https://arxiv.org/abs/2601.19928)
*Yi Hu,Jiaqi Gu,Ruxin Wang,Zijun Yao,Hao Peng,Xiaobao Wu,Jianhui Chen,Muhan Zhang,Liangming Pan*

Main category: cs.CL

TL;DR: 该论文提供了一篇关于大型推理模型（LRMs）机理理解的全面综述，将最近的研究发现组织到三个核心维度：1）训练动力学，2）推理机制，3）意外行为，并意图弥合黑箱性能和机理透明之间的差距。


<details>
  <summary>Details</summary>
Motivation: 随着强化学习（RL）推动大型推理模型（LRMs）的能力达到新的高度，研究其内部机制变得同样重要。

Method: 论文通过系统整合最近的研究发现，将其组织为三个核心维度进行阐述：1）训练动力学，2）推理机制，3）意外行为。

Result: 通过综述和整合，在理解大型推理模型的机理方面取得进展，填补了黑箱性能与机理透明之间的差距。

Conclusion: 论文讨论了需要进一步探索的挑战，并为未来机理研究设定了研究路线图，包括应用可解释性、改进的方法论以及统一的理论框架的需求。

Abstract: Reinforcement learning (RL) has catalyzed the emergence of Large Reasoning Models (LRMs) that have pushed reasoning capabilities to new heights. While their performance has garnered significant excitement, exploring the internal mechanisms driving these behaviors has become an equally critical research frontier. This paper provides a comprehensive survey of the mechanistic understanding of LRMs, organizing recent findings into three core dimensions: 1) training dynamics, 2) reasoning mechanisms, and 3) unintended behaviors. By synthesizing these insights, we aim to bridge the gap between black-box performance and mechanistic transparency. Finally, we discuss under-explored challenges to outline a roadmap for future mechanistic studies, including the need for applied interpretability, improved methodologies, and a unified theoretical framework.

</details>


### [65] [Stingy Context: 18:1 Hierarchical Code Compression for LLM Auto-Coding](https://arxiv.org/abs/2601.19929)
*David Linus Ostby*

Main category: cs.CL

TL;DR: Stingy Context 是一种基于树的压缩方案，能够减少18倍的LLM上下文长度，同时保持任务的准确性。


<details>
  <summary>Details</summary>
Motivation: 降低大型语言模型的上下文长度以提高处理大量代码任务的效率。

Method: 使用基于树的分拆技术（TREEFRAG），对源代码进行压缩。

Result: 在239k token的源代码上，压缩至11k token，并在12款不同模型上解决40个真实世界问题的成功率为94%到97%，成本较低，并优于平坦方法。

Conclusion: Stingy Context能够有效减少LLM上下文长度，提升处理效率，同时保留任务精度，显示出在实际任务中的强大潜力。

Abstract: We introduce Stingy Context, a hierarchical tree-based compression scheme achieving 18:1 reduction in LLM context for auto-coding tasks. Using our TREEFRAG exploit decomposition, we reduce a real source code base of 239k tokens to 11k tokens while preserving task fidelity. Empirical results across 12 Frontier models show 94 to 97% success on 40 real-world issues at low cost, outperforming flat methods and mitigating lost-in-the-middle effects.

</details>


### [66] [SDUs DAISY: A Benchmark for Danish Culture](https://arxiv.org/abs/2601.19930)
*Jacob Nielsen,Stine L. Beltoft,Peter Schneider-Kamp,Lukas Galke Poech*

Main category: cs.CL

TL;DR: 该论文介绍了一个基于丹麦文化 canon 的新基准 Daisy，通过对文化 canon 中的每个文物查询其维基百科页面并随机生成问题，生成了一套涵盖从公元前1300年至今的广泛主题的封闭式问答对。


<details>
  <summary>Details</summary>
Motivation: 通过建立基于丹麦文化 canon 的新基准 Daisy，旨在提供一个独特的信息角度来看待丹麦文化遗产，不局限于主流信息，更多地涉及定义丹麦文化遗产的深层次基石。

Method: 从丹麦文化 canon 中每个文物对应的维基百科页面提取信息，自动生成随机问题，并经过人工校正最终形成741个闭合式问题回答对。

Result: 最终形成的封闭式问答对覆盖时间范围广，从公元前1300年至今，涵盖了考古发现、17世纪的诗歌和音乐作品到当代流行音乐和丹麦设计建筑。

Conclusion: 该研究为文化遗产数据库提供了一种新的构建方法，更加关注丹麦文化遗产的独特性和深度，丰富了文化遗产研究的数据集和方法论。

Abstract: We introduce a new benchmark for Danish culture via cultural heritage, Daisy, based on the curated topics from the Danish Culture Canon 2006. For each artifact in the culture canon, we query the corresponding Wikipedia page and have a language model generate random questions. This yields a sampling strategy within each work, with a mix of central of peripheral questions for each work, not only knowledge of mainstream information, but also in-depth cornerstones defining the heritage of Danish Culture, defined by the Canon committee. Each question-answer pair is humanly approved or corrected in the final dataset consisting of 741 close-ended question answer pairs covering topics, from 1300 BC. archaeological findings, 1700 century poems and musicals pieces to contemporary pop music and Danish design and architecture.

</details>


### [67] ["Newspaper Eat" Means "Not Tasty": A Taxonomy and Benchmark for Coded Languages in Real-World Chinese Online Reviews](https://arxiv.org/abs/2601.19932)
*Ruyuan Wan,Changye Li,Ting-Hao 'Kenneth' Huang*

Main category: cs.CL

TL;DR: 本文介绍了一个名为CodedLang的数据集，包含7,744条中文Google地图评论，并对语言模型在编码语言检测、分类和评论评分预测方面的表现进行了基准测试。


<details>
  <summary>Details</summary>
Motivation: 当前的语言模型在处理编码语言方面表现不佳，主要由于缺少实际数据集和清晰的分类体系。该研究旨在填补这一空白，为自然语言处理系统提供更多的现实挑战。

Method: 构建了一个包含8个编码策略类别的 taxonomy，并对包含900个含病例水平标注的编码语言的CodedLang数据集进行了语言模型基准测试。

Result: 结果显示即使强大的语言模型也无法识别或理解编码语言，特别是许多编码表达依赖于基于发音的策略。

Conclusion: 该研究强调了编码语言在真实世界NLP系统中的重要性和未被充分探索的挑战。

Abstract: Coded language is an important part of human communication. It refers to cases where users intentionally encode meaning so that the surface text differs from the intended meaning and must be decoded to be understood. Current language models handle coded language poorly. Progress has been limited by the lack of real-world datasets and clear taxonomies. This paper introduces CodedLang, a dataset of 7,744 Chinese Google Maps reviews, including 900 reviews with span-level annotations of coded language. We developed a seven-class taxonomy that captures common encoding strategies, including phonetic, orthographic, and cross-lingual substitutions. We benchmarked language models on coded language detection, classification, and review rating prediction. Results show that even strong models can fail to identify or understand coded language. Because many coded expressions rely on pronunciation-based strategies, we further conducted a phonetic analysis of coded and decoded forms. Together, our results highlight coded language as an important and underexplored challenge for real-world NLP systems.

</details>


### [68] [Text-to-State Mapping for Non-Resolution Reasoning: The Contradiction-Preservation Principle](https://arxiv.org/abs/2601.19933)
*Kei Saito*

Main category: cs.CL

TL;DR: 本文引入了文本到状态映射函数φ，将自然语言输入转化为非解析推理（NRR）框架中的叠加状态。通过实证验证，该映射能够保留真正意义上的模糊表达式的熵，并为语言模型推理提供缺失的算法桥梁。


<details>
  <summary>Details</summary>
Motivation: 当前自然语言处理研究中，如何将自然语言映射到数学结构的问题尚未解决。本文旨在填补这一空白，提出了一种将自然语言转化为叠加状态的方法。

Method: 本文设计了文本到状态映射函数φ，并通过其实现自然语言到叠加状态的转换。同时引入了Contradiction-Preservation Principle，确保模糊表达式的熵不为零。

Result: 通过实证验证，该方法在68个测试句子上表现良好，达到了平均香农熵H(S) = 1.087 bits，而基准单解释方法则为H(S) = 0.000。

Conclusion: 本文提出的框架填补了NRR与语言模型推理之间的算法缺口，为后续研究铺平了道路，有望在语言理解与生成方面有所突破。

Abstract: Non-Resolution Reasoning (NRR) provides a formal framework for maintaining semantic ambiguity rather than forcing premature interpretation collapse. While the foundational architecture establishes state spaces and operators for ambiguity-preserving computation, the critical question of how natural language maps to these mathematical structures remains open. This paper introduces the text-to-state mapping function φ that transforms linguistic input into superposition states within the NRR framework. We formalize the Contradiction-Preservation Principle, which requires that genuinely ambiguous expressions maintain non-zero entropy in their state representations, and develop extraction protocols using existing Large Language Models as interpretation generators. Empirical validation across 68 test sentences spanning lexical, structural, and pragmatic ambiguity demonstrates that our mapping achieves mean Shannon entropy H(S) = 1.087 bits for ambiguous inputs while baseline single-interpretation approaches yield H(S) = 0.000. The framework provides the missing algorithmic bridge between raw text and the formal state spaces on which NRR operators act, enabling architectural collapse deferment in language model inference.

</details>


### [69] [Quantifying non deterministic drift in large language models](https://arxiv.org/abs/2601.19934)
*Claire Nicholson*

Main category: cs.CL

TL;DR: 研究通过多次重复实验量化了大语言模型在不同条件下输出的不一致性，发现即使在温度为0.0时，模型的输出仍然存在变化，这种不一致性随模型大小、部署方式和提示类型的不同而有所差异。


<details>
  <summary>Details</summary>
Motivation: 研究旨在量化大语言模型在基础行为漂移方面的不一致性，通过实验控制变量观察模型在不同条件下的响应，以评估未来减轻和控制这种漂移的技术。

Method: 研究采用了重复运行实验的方法，使用了固定温度和解码参数的相同提示，比较了两种开源模型gpt-4o-mini和llama3.1-8b在不同提示类别下的输出变化，通过独特的输出比例、词法相似性和词数统计来量化这种差异。

Result: 研究结果显示，即使在温度为0.0时，模型的输出仍然具有不一致性，这种不一致性在不同的模型尺寸、部署类型和提示类型之间表现出不同的模式。

Conclusion: 研究揭示了即使在理论上应该最稳定的条件下，大语言模型也存在行为漂移，为未来研究提供了基准，有助于开发和评估减轻这种漂移的方法。

Abstract: Large language models (LLMs) are widely used for tasks ranging from summarisation to decision support. In practice, identical prompts do not always produce identical outputs, even when temperature and other decoding parameters are fixed. In this work, we conduct repeated-run experiments to empirically quantify baseline behavioural drift, defined as output variability observed when the same prompt is issued multiple times under operator-free conditions. We evaluate two publicly accessible models, gpt-4o-mini and llama3.1-8b, across five prompt categories using exact repeats, perturbed inputs, and reuse modes at temperatures of 0.0 and 0.7. Drift is measured using unique output fractions, lexical similarity, and word count statistics, enabling direct comparison across models, prompting modes, and deployment types. The results show that nondeterminism persists even at temperature 0.0, with distinct variability patterns by model size, deployment, and prompt type. We situate these findings within existing work on concept drift, behavioural drift, and infrastructure-induced nondeterminism, discuss the limitations of lexical metrics, and highlight emerging semantic approaches. By establishing a systematic empirical baseline in the absence of stabilisation techniques, this study provides a reference point for evaluating future drift mitigation and control methods.

</details>


### [70] [Benchmarking von ASR-Modellen im deutschen medizinischen Kontext: Eine Leistungsanalyse anhand von Anamnesegesprächen](https://arxiv.org/abs/2601.19945)
*Thomas Schuster,Julius Trögele,Nico Döring,Robin Krüger,Matthieu Hoffmann,Holger Friedrich*

Main category: cs.CL

TL;DR: 该研究通过比较29种不同的自动语音识别(ASR)模型在德语医疗对话中的表现，发现模型间性能差异显著，最好的系统已达到部分低于3%的词错误率(WER)，而其他模型在医学术语或方言影响下错误率较高。


<details>
  <summary>Details</summary>
Motivation: 鉴于自动语音识别技术在减轻医疗人员工作负担方面的潜力，尤其在文档自动化任务中，当前缺乏针对德语医疗上下文的专门评估，尤其是在包含地方方言的情况下。因此，本文旨在填补这一空白。

Method: 本研究采用了自建的模拟医生-病人对话数据集，对该数据集中的29种不同ASR模型进行了评估，涵盖了开放权重模型以及商业级最先进的API。

Result: 研究表明，不同模型的性能存在显著差异，最佳系统已实现部分低于3%的词错误率(WER)，但其他系统，特别是对于医学术语或方言影响较大的情况下，错误率较高。

Conclusion: 研究结论是强调了在德语医疗实践中提升ASR系统性能的必要性，特别是对于医学术语和方言的处理。

Abstract: Automatic Speech Recognition (ASR) offers significant potential to reduce the workload of medical personnel, for example, through the automation of documentation tasks. While numerous benchmarks exist for the English language, specific evaluations for the German-speaking medical context are still lacking, particularly regarding the inclusion of dialects. In this article, we present a curated dataset of simulated doctor-patient conversations and evaluate a total of 29 different ASR models. The test field encompasses both open-weights models from the Whisper, Voxtral, and Wav2Vec2 families as well as commercial state-of-the-art APIs (AssemblyAI, Deepgram). For evaluation, we utilize three different metrics (WER, CER, BLEU) and provide an outlook on qualitative semantic analysis. The results demonstrate significant performance differences between the models: while the best systems already achieve very good Word Error Rates (WER) of partly below 3%, the error rates of other models, especially concerning medical terminology or dialect-influenced variations, are considerably higher.

</details>


### [71] [On the Effectiveness of LLM-Specific Fine-Tuning for Detecting AI-Generated Text](https://arxiv.org/abs/2601.20006)
*Michał Gromadzki,Anna Wróblewska,Agnieszka Kaliska*

Main category: cs.CL

TL;DR: 本研究基于大规模语料库和新训练策略，开发并评估了多项检测模型，提出了两种新的微调方法：每模型微调和每模型家族微调，实现了99.6%的令牌级准确性，明显优于现有开源基准。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的快速发展，AI生成的文本已经接近人类写作，给教育、出版和数字安全中的真实性验证带来了挑战。因此，检测AI生成的文本变得至关重要。

Method: 研究构建了一个10亿令牌的由人类生成的文本语料库和一个19亿令牌的基于各种LLM的AI生成文本语料库。采用了大规模语料库和新型训练策略，开发并评估了多种检测模型，并提出了两种新的训练方法，即针对每个模型和模型家族进行微调。

Result: 在1亿令牌的基准测试数据集上，研究的最佳微调检测器在99.6%的令牌级别上达到了最高的准确性。

Conclusion: 研究提出了新的训练模式，显著提升了AI文本检测的性能，有助于解决AI生成文本带来的验证问题。

Abstract: The rapid progress of large language models has enabled the generation of text that closely resembles human writing, creating challenges for authenticity verification in education, publishing, and digital security. Detecting AI-generated text has therefore become a crucial technical and ethical issue. This paper presents a comprehensive study of AI-generated text detection based on large-scale corpora and novel training strategies. We introduce a 1-billion-token corpus of human-authored texts spanning multiple genres and a 1.9-billion-token corpus of AI-generated texts produced by prompting a variety of LLMs across diverse domains. Using these resources, we develop and evaluate numerous detection models and propose two novel training paradigms: Per LLM and Per LLM family fine-tuning. Across a 100-million-token benchmark covering 21 large language models, our best fine-tuned detector achieves up to $99.6\%$ token-level accuracy, substantially outperforming existing open-source baselines.

</details>


### [72] [TAIGR: Towards Modeling Influencer Content on Social Media via Structured, Pragmatic Inference](https://arxiv.org/abs/2601.20032)
*Nishanth Sridhar Nakshatri,Eylon Caplan,Rajkumar Pujari,Dan Goldwasser*

Main category: cs.CL

TL;DR: TAIGR是一种三阶段框架，用于分析健康影响者的对话，通过识别核心推荐、构建论证图并进行因子图概率推理来验证这些推荐。


<details>
  <summary>Details</summary>
Motivation: 当前的声明中心验证方法难以捕捉到影响者话语的语用意义，因此需要一种新的方法来分析影响者的对话。

Method: TAIGR框架包含三个阶段：(1)识别核心影响者推荐；(2)构建捕捉影响者为推荐辩护的论证图；(3)使用因子图进行概率推理，以验证这些推荐。

Result: TAIGR框架在健康影响者视频脚本的验证任务中展示了准确验证所需建模对话的语用和论证结构的重要性。

Conclusion: TAIGR提供了分析影响者话语和促进健康影响者内容真实性验证的新途径。

Abstract: Health influencers play a growing role in shaping public beliefs, yet their content is often conveyed through conversational narratives and rhetorical strategies rather than explicit factual claims. As a result, claim-centric verification methods struggle to capture the pragmatic meaning of influencer discourse. In this paper, we propose TAIGR (Takeaway Argumentation Inference with Grounded References), a structured framework designed to analyze influencer discourse, which operates in three stages: (1) identifying the core influencer recommendation--takeaway; (2) constructing an argumentation graph that captures influencer justification for the takeaway; (3) performing factor graph-based probabilistic inference to validate the takeaway. We evaluate TAIGR on a content validation task over influencer video transcripts on health, showing that accurate validation requires modeling the discourse's pragmatic and argumentative structure rather than treating transcripts as flat collections of claims.

</details>


### [73] [Counterfactual Cultural Cues Reduce Medical QA Accuracy in LLMs: Identifier vs Context Effects](https://arxiv.org/abs/2601.20102)
*Amirhossein Haji Mohammad Rezaei,Zahra Shakeri*

Main category: cs.CL

TL;DR: 该研究通过引入一个反事实基准测试，扩大了150项MedQA测试题目的规模，并检查模型在文化信息影响下的诊断准确性，发现文化相关信息显著影响模型性能。


<details>
  <summary>Details</summary>
Motivation: 工程可持续和公平的医疗保健需要医疗语言模型能够处理非决定性的文化信息而不改变临床正确的诊断。

Method: 研究者将150项MedQA测试项扩展至1650个变体，通过插入与文化相关的标识符、上下文提示或两者的组合，针对三组不同文化背景的人群（原住民加拿大人、中东穆斯林、东南亚人），以及一个长度匹配的中性对照组，由临床医生验证所有变体的正确诊断保持不变。使用GPT-5.2、Llama-3.1-8B、DeepSeek-R1和MedGemma等模型，在仅选项和简短解释的情况下进行评估。

Result: 研究发现文化提示显著影响模型性能（Q统计量，p<10^-14），其中标识符和上下文同时出现时表现最差（在仅选项提示下下降3-7个百分点）。文化参考性解释中超过一半导致错误答案，表明文化相关推理与诊断失败有关。

Conclusion: 研究结果表明，需要通过发布提示和增强功能来支持文化和诊断错误的评估和缓解。

Abstract: Engineering sustainable and equitable healthcare requires medical language models that do not change clinically correct diagnoses when presented with non-decisive cultural information. We introduce a counterfactual benchmark that expands 150 MedQA test items into 1650 variants by inserting culture-related (i) identifier tokens, (ii) contextual cues, or (iii) their combination for three groups (Indigenous Canadian, Middle-Eastern Muslim, Southeast Asian), plus a length-matched neutral control, where a clinician verified that the gold answer remains invariant in all variants. We evaluate GPT-5.2, Llama-3.1-8B, DeepSeek-R1, and MedGemma (4B/27B) under option-only and brief-explanation prompting. Across models, cultural cues significantly affect accuracy (Cochran's Q, $p<10^-14$), with the largest degradation when identifier and context co-occur (up to 3-7 percentage points under option-only prompting), while neutral edits produce smaller, non-systematic changes. A human-validated rubric ($κ=0.76$) applied via an LLM-as-judge shows that more than half of culturally grounded explanations end in an incorrect answer, linking culture-referential reasoning to diagnostic failure. We release prompts and augmentations to support evaluation and mitigation of culturally induced diagnostic errors.

</details>


### [74] [FFE-Hallu:Hallucinations in Fixed Figurative Expressions:Benchmark of Idioms and Proverbs in the Persian Language](https://arxiv.org/abs/2601.20105)
*Faezeh Hosseini,Mohammadali Yousefzadeh,Yadollah Yaghoobzadeh*

Main category: cs.CL

TL;DR: 该研究提出了FFEHallu基准，旨在评估大型语言模型处理固定隐喻表达时的推理和文化扎根能力，尤其是在波斯语中。研究发现，尽管某些模型在某些任务上表现良好，但大多数模型在区分真实和虚构的隐喻表达以及跨语言翻译时存在大量错误。


<details>
  <summary>Details</summary>
Motivation: 研究的动机在于解决大型语言模型在处理固定隐喻表达（如成语和谚语）时面临的挑战，特别是在波斯语等语言资源较少的语境下。

Method: 研究通过构建FFEHallu基准，涉及生成、检测及跨语言翻译等多种任务，评估了包括GPT4.1在内的六种主流多语言模型。

Result: 研究结果显示，模型在拒绝虚构隐喻表达和检索真实隐喻表达的任务上表现较好，但在区分真实与高质量虚构隐喻表达以及跨语言翻译方面效果不佳。

Conclusion: 研究揭示了当前大型语言模型在处理隐喻语言方面的不足，并强调了构建针对性评估基准的重要性以弥补这些差距。

Abstract: Figurative language, particularly fixed figurative expressions (FFEs) such as idioms and proverbs, poses persistent challenges for large language models (LLMs). Unlike literal phrases, FFEs are culturally grounded, largely non-compositional, and conventionally fixed, making them especially vulnerable to figurative hallucination. We define figurative hallucination as the generation or endorsement of expressions that sound idiomatic and plausible but do not exist as authentic figurative expressions in the target language. We introduce FFEHallu, the first comprehensive benchmark for evaluating figurative hallucination in LLMs, with a focus on Persian, a linguistically rich yet underrepresented language. FFEHallu consists of 600 carefully curated instances spanning three complementary tasks: (i) FFE generation from meaning, (ii) detection of fabricated FFEs across four controlled construction categories, and (iii) FFE to FFE translation from English to Persian. Evaluating six state of the art multilingual LLMs, we find systematic weaknesses in figurative competence and cultural grounding. While models such as GPT4.1 demonstrate relatively strong performance in rejecting fabricated FFEs and retrieving authentic ones, most models struggle to reliably distinguish real expressions from high quality fabrications and frequently hallucinate during cross lingual translation. These findings reveal substantial gaps in current LLMs handling of figurative language and underscore the need for targeted benchmarks to assess and mitigate figurative hallucination.

</details>


### [75] [Rewarding Intellectual Humility Learning When Not To Answer In Large Language Models](https://arxiv.org/abs/2601.20126)
*Abha Jha,Akanksha Mahajan,Ashwath Vaithinathan Aravindan,Praveen Saravanan,Sai Sailaja Policharla,Sonal Chaturbhuj Gehlot*

Main category: cs.CL

TL;DR: 本研究探讨了利用验证性奖励强化学习（RLVR）来减少大型语言模型的幻觉，通过在事实领域奖励谦逊的“我不知道”而非正确答案。研究使用不同类型的语言模型和基准测试，展示了适度奖励谦逊可以减少错误回答而不严重损害准确性。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型常常生成不可靠或无法验证的内容，因此该研究旨在通过验证性奖励强化学习（RLVR）促进谦逊，从而提高语言模型在事实领域的可靠性。

Method: 研究通过在Large Language Models（LLMs）上实施验证性奖励强化学习来减少幻觉。具体方法包括在MedMCQA 和 Hendrycks Math基准测试上对Granite-3.3-2B-Instruct和Qwen-3-4B-Instruct模型进行微调，使用三元奖励结构（-1，r_abs, 1）并调整谦逊奖励比例，同时研究结合监督微调的策略以在强化学习前期教授谦逊。

Result: 研究结果显示，中等水平的谦逊奖励（r_abs 约 -0.25 到 0.3）能够在多项选择题任务中减少错误回答而不严重影响准确性，且更大规模的模型表现出更强的谦逊激励稳健性。此外，研究还发现对开放式回答的限制主要由于探索不足，这可通过监督谦逊训练部分缓解。

Conclusion: 基于上述结果，研究证明了验证性奖励设计可作为一种实践上可行的方法来减少语言模型的幻觉现象。

Abstract: Large Language Models (LLMs) often produce hallucinated or unverifiable content, undermining their reliability in factual domains. This work investigates Reinforcement Learning with Verifiable Rewards (RLVR) as a training paradigm that explicitly rewards abstention ("I don't know") alongside correctness to promote intellectual humility. We fine-tune and evaluate Granite-3.3-2B-Instruct and Qwen-3-4B-Instruct on the MedMCQA and Hendrycks Math benchmarks using a ternary reward structure ($-1$, r_abs, 1) under varying abstention reward structures. We further study the effect of combining RLVR with supervised fine-tuning strategies that teach abstention prior to reinforcement learning. Our results show that moderate abstention rewards (r_abs $\approx -0.25$ to 0.3) consistently reduce incorrect responses without severe accuracy degradation on multiple-choice tasks, with larger models exhibiting greater robustness to abstention incentives. On open-ended question answering, we observe limitations due to insufficient exploration, which can be partially mitigated through supervised abstention training. Overall, these findings demonstrate the feasibility and flexibility of verifiable reward design as a practical approach for hallucination mitigation in language models. Reproducible code for our abstention training framework is available here https://github.com/Mystic-Slice/rl-abstention.

</details>


### [76] [BengaliSent140: A Large-Scale Bengali Binary Sentiment Dataset for Hate and Non-Hate Speech Classification](https://arxiv.org/abs/2601.20129)
*Akif Islam,Sujan Kumar Roy,Md. Ekramul Hamid*

Main category: cs.CL

TL;DR: BengaliSent140是将七种现有孟加拉语文本数据集合并而成的大规模二分类情感数据集，包含139,792条文本样本，平衡了仇恨言论和非仇恨言论的比例，旨在为深度学习模型提供更强的训练和基准测试基础。


<details>
  <summary>Details</summary>
Motivation: 现有的孟加拉语情感和仇恨言论数据集数量少且范围有限，无法满足现代深度学习模型的需求。BengaliSent140旨在解决这一问题，通过整合多种来源的数据，提供更全面的语言和语境覆盖，以便更有效地训练和评估深度学习模型。

Method: BengaliSent140通过合并来自不同来源和领域的七个现有数据库构建而成。为了保持数据的一致性，不同标注方案被系统地统一为二分类情感，即非仇恨言论(0)和仇恨言论(1)。

Result: BengaliSent140包含139,792个独特文本样本，其中包含了68,548例仇恨言论和71,244例非仇恨言论的实例。该数据集在类别分布上相对均衡，提供了更广泛的语言和语境覆盖，适用于训练和基准测试现代深度学习模型。

Conclusion: BengaliSent140作为一个大规模的二分类情感数据集，为孟加拉语的情感分析研究提供了重要资源，有助于推动该领域的发展。

Abstract: Sentiment analysis for the Bengali language has attracted increasing research interest in recent years. However, progress remains constrained by the scarcity of large-scale and diverse annotated datasets. Although several Bengali sentiment and hate speech datasets are publicly available, most are limited in size or confined to a single domain, such as social media comments. Consequently, these resources are often insufficient for training modern deep learning based models, which require large volumes of heterogeneous data to learn robust and generalizable representations. In this work, we introduce BengaliSent140, a large-scale Bengali binary sentiment dataset constructed by consolidating seven existing Bengali text datasets into a unified corpus. To ensure consistency across sources, heterogeneous annotation schemes are systematically harmonized into a binary sentiment formulation with two classes: Not Hate (0) and Hate (1). The resulting dataset comprises 139,792 unique text samples, including 68,548 hate and 71,244 not-hate instances, yielding a relatively balanced class distribution. By integrating data from multiple sources and domains, BengaliSent140 offers broader linguistic and contextual coverage than existing Bengali sentiment datasets and provides a strong foundation for training and benchmarking deep learning models. Baseline experimental results are also reported to demonstrate the practical usability of the dataset. The dataset is publicly available at https://www.kaggle.com/datasets/akifislam/bengalisent140/

</details>


### [77] [Mind the Shift: Using Delta SSL Embeddings to Enhance Child ASR](https://arxiv.org/abs/2601.20142)
*Zilai Wang,Natarajan Balaji Shankar,Kaiyuan Zhang,Zihan Wang,Abeer Alwan*

Main category: cs.CL

TL;DR: 该研究通过利用自监督学习模型的delta嵌入融合策略，显著提升了儿童自动语音识别（ASR）的效果，特别是在MyST儿童语料库上创造了新的最佳表现。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决儿童ASR因为数据有限和预训练领域不匹配所面临的挑战，通过融合预训练模型和微调模型的嵌入，以期提升ASR性能。

Method: 该研究采用自监督学习模型的微调嵌入与预训练嵌入的差异（delta嵌入）来构建成新的特征表示，并通过多种融合策略进行实验。

Result: 实验结果显示，与直接使用微调模型的嵌入相比，使用delta嵌入融合策略可以显著减少词错误率（WER），特别是在使用WavLM融合Delta W2V2嵌入时，达到了目前自监督学习模型在MyST语料库上的最佳性能。

Conclusion: 研究证明了delta嵌入的有效性，并指出特征融合是推动儿童ASR技术进步的一个有前景的方向。

Abstract: Self-supervised learning (SSL) models have achieved impressive results across many speech tasks, yet child automatic speech recognition (ASR) remains challenging due to limited data and pretraining domain mismatch. Fine-tuning SSL models on child speech induces shifts in the representation space. We hypothesize that delta SSL embeddings, defined as the differences between embeddings from a finetuned model and those from its pretrained counterpart, encode task-specific information that complements finetuned features from another SSL model. We evaluate multiple fusion strategies on the MyST childrens corpus using different models. Results show that delta embedding fusion with WavLM yields up to a 10 percent relative WER reduction for HuBERT and a 4.4 percent reduction for W2V2, compared to finetuned embedding fusion. Notably, fusing WavLM with delta W2V2 embeddings achieves a WER of 9.64, setting a new state of the art among SSL models on the MyST corpus. These findings demonstrate the effectiveness of delta embeddings and highlight feature fusion as a promising direction for advancing child ASR.

</details>


### [78] [Improving X-Codec-2.0 for Multi-Lingual Speech: 25 Hz Latent Rate and 24 kHz Sampling](https://arxiv.org/abs/2601.20185)
*Husein Zolkepli*

Main category: cs.CL

TL;DR: 该研究通过对X-Codec-2.0的简单改进，即引入额外的下采样和增加解码器步幅，将潜变量率从50 Hz减至25 Hz，同时将输出采样率从16 kHz提升至24 kHz，从而提高了效率和感知质量，在多语言通用语音17测试集中实现了比原始X-Codec-2.0基线0.29分的提高。


<details>
  <summary>Details</summary>
Motivation: 改进X-Codec-2.0以提高其在时间和频率上的效率与质量。

Method: 通过引入额外的下采样操作和增加解码器步幅来修改X-Codec-2.0的配置。

Result: 改进后的配置在多语言通用语音17测试集上实现了0.29分的MOS改进，这是所有25 Hz工作率编码器中最佳的报告性能。

Conclusion: 新的配置提高了X-Codec-2.0的效率和感知质量，同时保持了原始架构不变。

Abstract: X-Codec-2.0 has shown strong performance in neural audio compression and multilingual speech modeling, operating at a 50 Hz latent rate and a 16 kHz sampling rate using frozen HuBERT features. While effective, this configuration limits temporal efficiency and audio fidelity. In this work, we explore a simple and effective modification by introducing additional pooling and increasing the decoder hop size. This reduces the latent rate from 50 Hz to 25 Hz and simultaneously raises the output sampling rate from 16 kHz to 24 kHz, improving efficiency and perceptual quality without altering the core architecture. Evaluated on the multilingual Common Voice 17 test set, the proposed configuration achieves a 0.29 MOS improvement over the original X-Codec-2.0 baseline based on UTMOSv2, and attains the best reported performance among all codecs operating at 25 Hz. The source code, checkpoints, and generation comparisons are released at \href{https://huggingface.co/Scicom-intl/xcodec2-25TPS-24k}{https://huggingface.co/Scicom-intl/xcodec2-25TPS-24k}.

</details>


### [79] [Unit-Based Agent for Semi-Cascaded Full-Duplex Dialogue Systems](https://arxiv.org/abs/2601.20230)
*Haoyuan Yu,Yuxuan Chen,Minjie Cai*

Main category: cs.CL

TL;DR: 该框架将复杂对话分解为最小对话单元，使系统能够独立处理每个单元并预测转至下一个单元的时间。实验表明，该系统在半级联全双工对话系统中表现优异。


<details>
  <summary>Details</summary>
Motivation: 为了实现自然的人机交互，提高全双工语音交互的重要性，因此提出了这个框架。

Method: 该框架基于多模态大型语言模型，结合辅助模块如语音活动检测（VAD）和文本转语音（TTS）合成，实现免训练、即插即用的操作。

Result: 在HumDial数据集上的实验表明，该系统在全双工交互挑战中的半级联全双工对话系统赛道中排名第二。

Conclusion: 该框架的有效性得到了验证，提供了实验代码和详细的GitHub仓库地址。

Abstract: Full-duplex voice interaction is crucial for natural human computer interaction. We present a framework that decomposes complex dialogue into minimal conversational units, enabling the system to process each unit independently and predict when to transit to the next. This framework is instantiated as a semi-cascaded full-duplex dialogue system built around a multimodal large language model, supported by auxiliary modules such as voice activity detection (VAD) and text-to-speech (TTS) synthesis. The resulting system operates in a train-free, plug-and-play manner. Experiments on the HumDial dataset demonstrate the effectiveness of our framework, which ranks second among all teams on the test set of the Human-like Spoken Dialogue Systems Challenge (Track 2: Full-Duplex Interaction). Code is available at the GitHub repository https://github.com/yu-haoyuan/fd-badcat.

</details>


### [80] [Automated Benchmark Generation from Domain Guidelines Informed by Bloom's Taxonomy](https://arxiv.org/abs/2601.20253)
*Si Chen,Le Huy Khiem,Annalisa Szymanski,Ronald Metoyer,Ting Hua,Nitesh V. Chawla*

Main category: cs.CL

TL;DR: 该研究提出了一种基于布鲁姆分类学的自动化基准生成框架，将专家指南转化为隐式违规场景并扩展为自动评分的选择题和多轮对话，用于四个认知水平。在教育、营养学和护理三个实践领域应用此框架，发现模型与人类推理之间存在差异，且生产了大规模、具有心理测量学依据的基准，揭示了模型在上下文推理中的非直观行为。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）评估基准主要依赖于预先的人类考试数据集，而在实践基础的领域如教育、营养学和护理中，此类数据集往往不存在或不可用。因此，有必要开发一种能够生成适用于这些实践领域的自动化基准方法。

Method: 研究团队采用了布鲁姆分类学来设计多层次的认知评估场景，通过将专家实践转化为隐式违规场景来生成自动评分的选择题和轮对话。该方法覆盖了从简单记忆到高级分析的认知层次。

Result: 在教育、营养学和护理三个应用领域中应用该框架后，研究发现模型与人类推理之间的差异：模型在较高层次的推理（分析）上表现相对较好，但在较低层次的问题上失败率较高（记忆）。生成了大规模的心理测量学基准，揭示了模型在实际情境中的非直观行为。

Conclusion: 基于布鲁姆分类学的自动化基准生成框架能够在实践领域中有效评估模型的上下文推理能力，提供了一种新的评估模型性能的方法。

Abstract: Open-ended question answering (QA) evaluates a model's ability to perform contextualized reasoning beyond factual recall. This challenge is especially acute in practice-based domains, where knowledge is procedural and grounded in professional judgment, while most existing LLM benchmarks depend on pre-existing human exam datasets that are often unavailable in such settings. We introduce a framework for automated benchmark generation from expert-authored guidelines informed by Bloom's Taxonomy. It converts expert practices into implicit violation-based scenarios and expands them into auto-graded multiple-choice questions (MCQs) and multi-turn dialogues across four cognitive levels, enabling deterministic, reproducible, and scalable evaluation. Applied to three applied domains: teaching, dietetics, and caregiving, we find differences between model and human-like reasoning: LLMs sometimes perform relatively better on higher-order reasoning (Analyze) but fail more frequently on lower-level items (Remember). We produce large-scale, psychometrically informed benchmarks that surface these non-intuitive model behaviors and enable evaluation of contextualized reasoning in real-world settings.

</details>


### [81] [SoftHateBench: Evaluating Moderation Models Against Reasoning-Driven, Policy-Compliant Hostility](https://arxiv.org/abs/2601.20256)
*Xuanyu Su,Diana Inkpen,Nathalie Japkowicz*

Main category: cs.CL

TL;DR: 本文介绍了一个生成软仇恨言论基准，该基准在保留敌对立场的同时生成软版本，旨在评估现有的仇恨言论检测系统是否能够识别基于推理的敌意。


<details>
  <summary>Details</summary>
Motivation: 当前的仇恨言论检测系统主要针对表面的毒性提示，但无法有效识别和应对基于推理的敌意。因此，研究人员开发了SoftHateBench以填补这一研究空白。

Method: SoftHateBench通过结合Argumentum Model of Topics (AMT) 和Relevance Theory (RT)的理论，生成在逻辑上连贯且保留敌对立场的软仇恨言论。

Result: 该基准覆盖了7个社会文化领域和28个目标群体，共包含4745个软仇恨实例。进一步评估表明，检测器在处理从明确敌对到基于推理的敌对语言时，识别效果显著减弱。

Conclusion: 现有的基于推理的软仇恨言论检测挑战了现有的仇恨言论检测系统，使得开发更全面和有效的方法变得必要。

Abstract: Online hate on social media ranges from overt slurs and threats (\emph{hard hate speech}) to \emph{soft hate speech}: discourse that appears reasonable on the surface but uses framing and value-based arguments to steer audiences toward blaming or excluding a target group. We hypothesize that current moderation systems, largely optimized for surface toxicity cues, are not robust to this reasoning-driven hostility, yet existing benchmarks do not measure this gap systematically. We introduce \textbf{\textsc{SoftHateBench}}, a generative benchmark that produces soft-hate variants while preserving the underlying hostile standpoint. To generate soft hate, we integrate the \emph{Argumentum Model of Topics} (AMT) and \emph{Relevance Theory} (RT) in a unified framework: AMT provides the backbone argument structure for rewriting an explicit hateful standpoint into a seemingly neutral discussion while preserving the stance, and RT guides generation to keep the AMT chain logically coherent. The benchmark spans \textbf{7} sociocultural domains and \textbf{28} target groups, comprising \textbf{4,745} soft-hate instances. Evaluations across encoder-based detectors, general-purpose LLMs, and safety models show a consistent drop from hard to soft tiers: systems that detect explicit hostility often fail when the same stance is conveyed through subtle, reasoning-based language. \textcolor{red}{\textbf{Disclaimer.} Contains offensive examples used solely for research.}

</details>


### [82] [Beyond the Needle's Illusion: Decoupled Evaluation of Evidence Access and Use under Semantic Interference at 326M-Token Scale](https://arxiv.org/abs/2601.20276)
*Tianwei Lin,Zuyi Zhou,Xinda Zhao,Chenke Wang,Xiaohong Li,Yu Chen,Chuanrui Hu,Jian Pei,Yafeng Deng*

Main category: cs.CL

TL;DR: 该研究提出了EverMemBench-S（EMB-S），一种针对大规模语言模型（LLM）的对抗性基准测试，旨在评估模型在长期上下文中的证据访问能力。该基准测试通过对比有害的负样本和人工验证的正样本，揭示了模型在语义干扰下的表现差异。


<details>
  <summary>Details</summary>
Motivation: 当前常用的Needle-in-a-Haystack (NIAH) 评估无法全面衡量大规模语言模型在长上下文中的证据获取能力。现有的基准测试主要集中于简单的局部定位任务，而没有考虑实际应用中的复杂语义干扰问题。因此，研究人员设计了EverMemBench-S，以提供一个更严苛的评估环境，促进更真实的大规模语言模型研发。

Method: 研究者构建了一个基于3.26亿词的记忆银行（MemoryBank）的EMB-S基准测试。其具体做法包括：生成了对比性极高的近似负面影响和准确的正证据集；并提出了一个分拆诊断协议，单独报告证据访问和端到端的QA质量。此外，研究还在不同的参考语料库阶梯上进行测试，从孤立领域64K上下文到全球共享的3.26亿词环境。

Result: 研究发现，即使在正确的前后文下，一些模型的表现也会因语义干扰而急剧下降。这表明语义区分而非单纯的上下文长度是长期记忆能力的关键挑战。

Conclusion: 该研究揭示了大规模语言模型在长期上下文中的主要瓶颈，并且提出了一个综合评估框架（EMB-S），可以用来改进现有模型和引导未来的研发方向。

Abstract: Long-context LLM agents must access the right evidence from large environments and use it faithfully. However, the popular Needle-in-a-Haystack (NIAH) evaluation mostly measures benign span localization. The needle is near-unique, and the haystack is largely irrelevant. We introduce EverMemBench-S (EMB-S), an adversarial NIAH-style benchmark built on a 326M-token MemoryBank. While the full MemoryBank spans 326M tokens for retrieval-based (RAG) evaluation, we evaluate native long-context models only at scales that fit within each model's context window (up to 1M tokens in this work) to ensure a fair comparison. EMB-S pairs queries with collision-tested near-miss hard negatives and gold evidence sets spanning one or more documents, validated via human screening and LLM verification. We also propose a decoupled diagnostic protocol that reports evidence access (document-ID localization) separately from end-to-end QA quality under full-context prompting. This enables consistent diagnosis for both native long-context prompting and retrieval pipelines. Across a reference-corpus ladder from domain-isolated 64K contexts to a globally shared 326M-token environment, we observe a clear reality gap. Systems that saturate benign NIAH degrade sharply in evidence access under semantic interference. These results indicate that semantic discrimination, not context length alone, is the dominant bottleneck for long-context memory at scale.

</details>


### [83] [MiLorE-SSL: Scaling Multilingual Capabilities in Self-Supervised Models without Forgetting](https://arxiv.org/abs/2601.20300)
*Jing Xu,Minglin Wu,Xueyuan Chen,Xixin Wu,Helen Meng*

Main category: cs.CL

TL;DR: MiLorE-SSL 是一种轻量级框架，结合了低秩适应的 LoRA 模块和软专家混合机制，旨在更高效地进行多语言连续训练，减少语言间干扰和灾难性遗忘，通过少量可训练参数达到了良好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多语言 SSL 模型在处理未预训练的新语言时约束较多，且重新训练成本高，连续训练易导致灾难性遗忘。因此，提出了一种能减轻遗忘现象、促进多语言共享的 MiLorE-SSL 框架。

Method: MiLorE-SSL 包含两个关键技术：LoRA 和软专家混合机制。通过 LoRA 提供高效低秩适应，软专家混合机制促进跨语言专家资源共享，还引入了有限的历史语言回放数据，以此减少对大规模历史语料库的依赖，实现多语言的有效连续训练。

Result: 在 ML-SUPERB 上的实验表明，MiLorE-SSL 在新语言上的性能很强，而在现有语言上的性能也有所提升，仅使用了 2.14% 的可训练参数。

Conclusion: MiLorE-SSL 为多语言连续学习提供了一种有效的方法，能够减轻灾难性遗忘并实现多语言知识的有效共享。

Abstract: Self-supervised learning (SSL) has greatly advanced speech representation learning, but multilingual SSL models remain constrained to languages encountered during pretraining. Retraining from scratch to incorporate new languages is computationally expensive, while sequential training without migitation strategies often leads to catastrophic forgetting. To address this, we propose MiLorE-SSL, a lightweight framework that combines LoRA modules with a soft mixture-of-experts (MoE) mechanism for efficient continual multilingual training. LoRA provides efficient low-rank adaptation, while soft MoE promotes flexible expert sharing across languages, reducing cross-lingual interference. To further mitigate forgetting, we introduce limited replay data from existing languages, avoiding reliance on large historical corpora. Experiments on ML-SUPERB demonstrate that MiLorE-SSL achieves strong performance in new languages and improves the ability in existing ones with only 2.14% trainable parameters.

</details>


### [84] [SAPO: Self-Adaptive Process Optimization Makes Small Reasoners Stronger](https://arxiv.org/abs/2601.20312)
*Kaiyuan Chen,Guangmin Zheng,Jin Wang,Xiaobing Zhou,Xuejie Zhang*

Main category: cs.CL

TL;DR: 该研究提出了一种名为SAPO的方法，它通过自适应地引入过程监督信号，减少推理者与验证者的差距，从而提高了小型语言模型的自我优化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的自我进化方法忽视了细粒度推理步骤的影响，导致推理者-验证者差距。SAPO 方法受到错误相关负性（ERN）的启发，旨在更有效地减少这个差距。

Method: SAPO通过主动最小化推理者与验证者的差距，而不是依赖不高效的大规模蒙特卡洛估计，来适应性和高效地引入过程监督信号。

Result: SAPO 方法在数学和代码两个挑战性任务类型上都优于大多数现有的自我进化方法。

Conclusion: 研究引入了两个新的基准测试，用于评估过程奖励模型对验证者性能的影响，进一步探讨了SAPO对验证者性能的促进作用。

Abstract: Existing self-evolution methods overlook the influence of fine-grained reasoning steps, which leads to the reasoner-verifier gap. The computational inefficiency of Monte Carlo (MC) process supervision further exacerbates the difficulty in mitigating the gap. Motivated by the Error-Related Negativity (ERN), which the reasoner can localize error following incorrect decisions, guiding rapid adjustments, we propose a Self-Adaptive Process Optimization (SAPO) method for self-improvement in Small Language Models (SLMs). SAPO adaptively and efficiently introduces process supervision signals by actively minimizing the reasoner-verifier gap rather than relying on inefficient MC estimations. Extensive experiments demonstrate that the proposed method outperforms most existing self-evolution methods on two challenging task types: mathematics and code. Additionally, to further investigate SAPO's impact on verifier performance, this work introduces two new benchmarks for process reward models in both mathematical and coding tasks.

</details>


### [85] [Beyond Speedup -- Utilizing KV Cache for Sampling and Reasoning](https://arxiv.org/abs/2601.20326)
*Zeyu Xing,Xing Li,Hui-Ling Zhen,Mingxuan Yuan,Sinno Jialin Pan*

Main category: cs.CL

TL;DR: 本文探讨了键值（KV）缓存作为一种轻量级表示的使用方法，无需重新计算或存储完整的隐藏状态，即使在某些下游任务中的表现略逊于专用嵌入，KV衍生表示依然能够实现具有竞争力的表现。


<details>
  <summary>Details</summary>
Motivation: 为减少计算资源消耗，解决重复计算和存储完整隐藏状态的问题，同时提供了两种关键应用场景：链状嵌入和快速/慢速思考切换，以证明KV缓存的高效性和自由性。

Method: 研究表明基于KV的嵌入在两个场景中表现良好：分别是Llama-3.1-8B-Instruct中的链状嵌入任务和Qwen3-8B及DeepSeek-R1-Distil-Qwen-14B中的快速/慢速思考切换任务。

Result: 在Llama-3.1-8B-Instruct和Qwen2-7B-Instruct上的链状嵌入任务中，KV缓存实现的竞争或表现更优；在Qwen3-8B和DeepSeek-R1-Distil-Qwen-14B上的快速/慢速思考切换任务中，通过锯齿状思考切换，能够使令牌生成速度提高5.7倍，且保持较低的准确率损失。

Conclusion: KV缓存可以无成本地作为自由有效的采样和推理基底，促进了在LLM推理过程中表示重用的新方向。

Abstract: KV caches, typically used only to speed up autoregressive decoding, encode contextual information that can be reused for downstream tasks at no extra cost. We propose treating the KV cache as a lightweight representation, eliminating the need to recompute or store full hidden states. Despite being weaker than dedicated embeddings, KV-derived representations are shown to be sufficient for two key applications: \textbf{(i) Chain-of-Embedding}, where they achieve competitive or superior performance on Llama-3.1-8B-Instruct and Qwen2-7B-Instruct; and \textbf{(ii) Fast/Slow Thinking Switching}, where they enable adaptive reasoning on Qwen3-8B and DeepSeek-R1-Distil-Qwen-14B, reducing token generation by up to $5.7\times$ with minimal accuracy loss. Our findings establish KV caches as a free, effective substrate for sampling and reasoning, opening new directions for representation reuse in LLM inference. Code: https://github.com/cmd2001/ICLR2026_KV-Embedding.

</details>


### [86] [CE-RM: A Pointwise Generative Reward Model Optimized via Two-Stage Rollout and Unified Criteria](https://arxiv.org/abs/2601.20327)
*Xinyu Hu,Yancheng He,Weixun Wang,Tao Feng,Li Lin,Jiashun Liu,Wenbo Su,Bo Zheng,Xiaojun Wan*

Main category: cs.CL

TL;DR: 本文提出了一种名为CE-RM-4B的生成式奖励模型，通过专门的两阶段卷出方法和统一的查询基准则进行训练。仅使用约5.7K高质量数据，该模型在多样性的奖励模型基准测试中表现出色，特别是在Best-of-N场景中，并且在下游RL实践中提供了更有效的改进。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM作为评判者方法在实际强化学习场景中的效果与其在基准测试中的表现存在差距，证据指出这一差距的原因在于现有的研究偏向一对一评估和评价标准优化不足。因此，本文旨在提出一种改进的评估方式。

Method: 本文提出了一种新的两阶段卷出方法，并采用统一的查询基准则进行训练。该方法通过使用少量高质量数据实现了在多种奖励模型基准测试上的优秀表现。

Result: 该模型在多样性的奖励模型基准测试中表现出色，特别是在Best-of-N场景中实现超越。在下游强化学习应用中，该模型也提供了更有效的改进。

Conclusion: 本文提出的方法通过改进的两阶段卷出方法和统一的查询基准则有效提高了奖励模型的表现，在实际强化学习应用中展现了潜力。

Abstract: Automatic evaluation is crucial yet challenging for open-ended natural language generation, especially when rule-based metrics are infeasible. Compared with traditional methods, the recent LLM-as-a-Judge paradigms enable better and more flexible evaluation, and show promise as generative reward models for reinforcement learning. However, prior work has revealed a notable gap between their seemingly impressive benchmark performance and actual effectiveness in RL practice. We attribute this issue to some limitations in existing studies, including the dominance of pairwise evaluation and inadequate optimization of evaluation criteria. Therefore, we propose CE-RM-4B, a pointwise generative reward model trained with a dedicated two-stage rollout method, and adopting unified query-based criteria. Using only about 5.7K high-quality data curated from the open-source preference dataset, our CE-RM-4B achieves superior performance on diverse reward model benchmarks, especially in Best-of-N scenarios, and delivers more effective improvements in downstream RL practice.

</details>


### [87] [PsychePass: Calibrating LLM Therapeutic Competence via Trajectory-Anchored Tournaments](https://arxiv.org/abs/2601.20330)
*Zhuang Chen,Dazhen Wan,Zhangkai Zheng,Guanqun Bi,Xiyao Xiao,Binghang Li,Minlie Huang*

Main category: cs.CL

TL;DR: 该研究提出了一种名为PsychePass的统一框架，通过轨迹锚定的锦标赛来评估大型语言模型在心理咨询中的治疗能力，包括交互轨迹和判断轨迹的锚定，以及将其转化为奖励信号以提升模型表现。


<details>
  <summary>Details</summary>
Motivation: 当前评估方式存在的缺陷带来了两种不稳定性：过程漂移和标准漂移。为克服这些挑战，研究人员提出了PsychePass框架，旨在提供一种更稳定、可靠的评估机制。

Method: 该框架通过模拟中的精确控制咨询过程来锚定交互轨迹，并通过瑞士制锦标赛来锚定判断轨迹，涉及动态的两两对决以生成稳健的Elo评分。

Result: 研究结果表明，PsychePass框架的有效性得到了广泛实验证实，其评价结果与人类专家判断高度一致。

Conclusion: PsychePass框架能够有效评估大型语言模型的治疗能力，并提供可用于提升模型表现的奖励信号。

Abstract: While large language models show promise in mental healthcare, evaluating their therapeutic competence remains challenging due to the unstructured and longitudinal nature of counseling. We argue that current evaluation paradigms suffer from an unanchored defect, leading to two forms of instability: process drift, where unsteered client simulation wanders away from specific counseling goals, and standard drift, where static pointwise scoring lacks the stability for reliable judgment. To address this, we introduce Ps, a unified framework that calibrates the therapeutic competence of LLMs via trajectory-anchored tournaments. We first anchor the interaction trajectory in simulation, where clients precisely control the fluid consultation process to probe multifaceted capabilities. We then anchor the battle trajectory in judgments through an efficient Swiss-system tournament, utilizing dynamic pairwise battles to yield robust Elo ratings. Beyond ranking, we demonstrate that tournament trajectories can be transformed into credible reward signals, enabling on-policy reinforcement learning to enhance LLMs' performance. Extensive experiments validate the effectiveness of PsychePass and its strong consistency with human expert judgments.

</details>


### [88] [Beyond Accuracy: A Cognitive Load Framework for Mapping the Capability Boundaries of Tool-use Agents](https://arxiv.org/abs/2601.20412)
*Qihao Wang,Yue Hu,Mingzhe Lu,Jiayue Wu,Yanbing Liu,Yuanmin Tang*

Main category: cs.CL

TL;DR: 提出了一个基于认知负载理论的框架，用于评估大语言模型使用外部工具的能力。该框架通过工具交互图量化内在负载和由于任务呈现不清引起的外在负载。构建了可调节认知负载的基准ToolLoad-Bench，并通过实验揭示了模型能力边界的具体表现，验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 当前基准主要关注最终准确性，忽略了模型的认知瓶颈。为了更好地理解模型的能力边界，研究者提出了基于认知负载理论的评估框架。

Method: 该框架将任务复杂性分解为内在负载和外在负载两部分。内在负载通过设计的工具交互图量化，外在负载则衡量任务呈现的模糊程度。研究人员开发了ToolLoad-Bench作为实验基准。

Result: 实验展示了认知负载增加时性能的突变，准确地映射了模型的能力边界，验证了该方法的有效性。

Conclusion: 该研究提供了一种新的评估方法论，不仅能更准确地了解模型的限制，还能为构建更有效率的系统奠定基础。

Abstract: The ability of Large Language Models (LLMs) to use external tools unlocks powerful real-world interactions, making rigorous evaluation essential. However, current benchmarks primarily report final accuracy, revealing what models can do but obscuring the cognitive bottlenecks that define their true capability boundaries. To move from simple performance scoring to a diagnostic tool, we introduce a framework grounded in Cognitive Load Theory. Our framework deconstructs task complexity into two quantifiable components: Intrinsic Load, the inherent structural complexity of the solution path, formalized with a novel Tool Interaction Graph; and Extraneous Load, the difficulty arising from ambiguous task presentation. To enable controlled experiments, we construct ToolLoad-Bench, the first benchmark with parametrically adjustable cognitive load. Our evaluation reveals distinct performance cliffs as cognitive load increases, allowing us to precisely map each model's capability boundary. We validate that our framework's predictions are highly calibrated with empirical results, establishing a principled methodology for understanding an agent's limits and a practical foundation for building more efficient systems.

</details>


### [89] [SpeechMapper: Speech-to-text Embedding Projector for LLMs](https://arxiv.org/abs/2601.20417)
*Biswesh Mohapatra,Marcely Zanon Boito,Ioan Calapodescu*

Main category: cs.CL

TL;DR: SpeechMapper 是一种成本效益高的语音到大语言模型嵌入训练方法，通过在不使用大语言模型的廉价硬件上进行预训练，然后通过简短的指令调优阶段与目标大语言模型连接，从而解决过拟合问题，提升模型的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前的语音大语言模型使用投影层将语音基础模型与大语言模型连接起来，并在语音指令数据上训练所有组件，这在计算上消耗巨大且容易导致任务和提示过拟合。

Method: SpeechMapper 方法通过先在不使用大语言模型的情况下进行预训练（在廉价硬件上的预训练），然后通过简短的1000步指令调优阶段与目标大语言模型连接，来缓解过拟合问题。

Result: 在语音翻译和语音问题回答实验中，展示了 SpeechMapper 预训练块的灵活性，包括任务无关的指令调优和基于ASR的任务导向调优策略。在任务无关的设置中，Speechmapper 的性能与IWSLT25的最佳指令遵守语音大语言模型相当，没有进行过这些任务的训练。在任务特定的设置中，它在多个数据集中超越了该模型，虽然后者需要更多的数据和计算。

Conclusion: 总体而言，SpeechMapper 提供了一种实用且可扩展的方法，能够高效地集成语音和大语言模型，而无需大规模的指令调优。

Abstract: Current speech LLMs bridge speech foundation models to LLMs using projection layers, training all of these components on speech instruction data. This strategy is computationally intensive and susceptible to task and prompt overfitting. We present SpeechMapper, a cost-efficient speech-to-LLM-embedding training approach that mitigates overfitting, enabling more robust and generalizable models. Our model is first pretrained without the LLM on inexpensive hardware, and then efficiently attached to the target LLM via a brief 1K-step instruction tuning (IT) stage. Through experiments on speech translation and spoken question answering, we demonstrate the versatility of SpeechMapper's pretrained block, presenting results for both task-agnostic IT, an ASR-based adaptation strategy that does not train in the target task, and task-specific IT. In task-agnostic settings, Speechmapper rivals the best instruction-following speech LLM from IWSLT25, despite never being trained on these tasks, while in task-specific settings, it outperforms this model across many datasets, despite requiring less data and compute. Overall, SpeechMapper offers a practical and scalable approach for efficient, generalizable speech-LLM integration without large-scale IT.

</details>


### [90] [Hopes and Fears -- Emotion Distribution in the Topic Landscape of Finnish Parliamentary Speech 2000-2020](https://arxiv.org/abs/2601.20424)
*Anna Ristilä,Otto Tarkka,Veronika Laippala,Kimmo Elo*

Main category: cs.CL

TL;DR: 该研究通过分析芬兰议会（Eduskunta）2000年至2020年间议会演讲中的情绪表达，填补了现有研究中对政治话题情绪分类的空白，发现演讲中的情绪表达呈现积极增加的趋势，同时也提供了关于特定话题情绪表达的深入见解。


<details>
  <summary>Details</summary>
Motivation: 现有研究往往将议会演说视为一个统一的整体，忽视了主题特定的情绪模式。然而，不同的政治话题会引起不同程度的情感反应，学界对这些情感反应的理解还不够全面。

Method: 采用情绪分析模型从横向和纵向两方面研究议会演说中不同话题的情绪表达。

Result: 研究结果显示，议会演说中的情绪表达总体上变得更加积极；此外，还提供了关于特定话题情绪表达的详细分析。

Conclusion: 该研究证实了议会演说中情绪表达的积极趋势，并为理解特定话题在议会辩论中的情绪表达提供了新的视角。

Abstract: Existing research often treats parliamentary discourse as a homogeneous whole, overlooking topic-specific patterns. Parliamentary speeches address a wide range of topics, some of which evoke stronger emotions than others. While everyone has intuitive assumptions about what the most emotive topics in a parliament may be, there has been little research into the emotions typically linked to different topics. This paper strives to fill this gap by examining emotion expression among the topics of parliamentary speeches delivered in Eduskunta, the Finnish Parliament, between 2000 and 2020. An emotion analysis model is used to investigate emotion expression in topics, from both synchronic and diachronic perspectives. The results strengthen evidence of increasing positivity in parliamentary speech and provide further insights into topic-specific emotion expression within parliamentary debate.

</details>


### [91] [MuVaC: AVariational Causal Framework for Multimodal Sarcasm Understanding in Dialogues](https://arxiv.org/abs/2601.20451)
*Diandian Guo,Fangfang Yuan,Cong Cao,Xixun Lin,Chuan Zhou,Hao Peng,Yanan Cao,Yanbing Liu*

Main category: cs.CL

TL;DR: MuVaC 是一种新颖的变分因果推理框架，它通过建模结构因果模型中的 sarcasm 检测和解释任务，提供了一种有效的 joint 优化方法。MuVaC 通过集成对齐和融合多模态特征来生成可靠的表情原因，并确保检测结果和解释之间的一致性。


<details>
  <summary>Details</summary>
Motivation: 当前研究主要集中在 sarcasm 检测或解释中的一种任务上，忽视了它们之间的因果依赖性。MuVaC 的提出旨在填补这一空白，通过结合这两种任务，提供一个多模态特征学习的联合优化方法，以更全面地理解在线对话中的真实意图。

Method: MuVaC 采用了结构因果模型中的变分因果途径进行建模，通过一种对齐然后融合的多模态特征整合方法来生成检测和解释的融合表示，并通过一致性检查增强了推理的可信度。

Result: MuVaC 在公共数据集上的实验结果表明，它在 sarcasm 检测和解释方面具有优越性，为理解多模态 sarcasm 提供了新的视角。

Conclusion: MuVaC 提供了通过建模结构因果因果模型和多模态特征融合来实现 sarcasm 检测和解释联合优化的一种新的方法，能够更好地理解多模态对话中的真实意图。

Abstract: The prevalence of sarcasm in multimodal dialogues on the social platforms presents a crucial yet challenging task for understanding the true intent behind online content. Comprehensive sarcasm analysis requires two key aspects: Multimodal Sarcasm Detection (MSD) and Multimodal Sarcasm Explanation (MuSE). Intuitively, the act of detection is the result of the reasoning process that explains the sarcasm. Current research predominantly focuses on addressing either MSD or MuSE as a single task. Even though some recent work has attempted to integrate these tasks, their inherent causal dependency is often overlooked. To bridge this gap, we propose MuVaC, a variational causal inference framework that mimics human cognitive mechanisms for understanding sarcasm, enabling robust multimodal feature learning to jointly optimize MSD and MuSE. Specifically, we first model MSD and MuSE from the perspective of structural causal models, establishing variational causal pathways to define the objectives for joint optimization. Next, we design an alignment-then-fusion approach to integrate multimodal features, providing robust fusion representations for sarcasm detection and explanation generation. Finally, we enhance the reasoning trustworthiness by ensuring consistency between detection results and explanations. Experimental results demonstrate the superiority of MuVaC in public datasets, offering a new perspective for understanding multimodal sarcasm.

</details>


### [92] [Can We Improve Educational Diagram Generation with In-Context Examples? Not if a Hallucination Spoils the Bunch](https://arxiv.org/abs/2601.20476)
*Evanfiya Logacheva,Arto Hellas,Tsvetomila Mihaylova,Juha Sorva,Ava Heinonen,Juho Leinonen*

Main category: cs.CL

TL;DR: 本研究提出了一种基于论证结构理论(RST)的图代码生成新方法，旨在通过上下文示例调整模型输出与用户期望的对齐。研究通过计算机科学教育者的评估发现，该方法降低了事实幻觉的频率并提高了图的忠实度，但生成图的质量因LLMs的随机性而异。


<details>
  <summary>Details</summary>
Motivation: 计算教育中生成人工智能（AI）的广泛应用引起了教育者和学生对其质量的担忧，本研究旨在改进生成图的逻辑组织、连通性和布局美感，通过在生成材料中加入上下文示例来提高生成图的忠实度。

Method: 研究基于RST提出了一个新的图代码生成方法，通过从大规模语言模型生成150个图并由教育者评估来检验该方法的效果。

Result: 评估结果显示，新方法降低了事实幻觉的频率并提高了图的忠实度，但生成图的质量因LLMs的随机性而异。值得注意的是，复杂文本背景导致更高频率的幻觉，且LLMs往往无法检测到其输出中的错误。

Conclusion: 研究初步结论表明，在特定情况下，新的方法能够提高生成图的质量，但在进一步研究中仍需探讨如何提高生成图的一致性与可靠性，特别是在复杂背景信息下的表现。

Abstract: Generative artificial intelligence (AI) has found a widespread use in computing education; at the same time, quality of generated materials raises concerns among educators and students. This study addresses this issue by introducing a novel method for diagram code generation with in-context examples based on the Rhetorical Structure Theory (RST), which aims to improve diagram generation by aligning models' output with user expectations. Our approach is evaluated by computer science educators, who assessed 150 diagrams generated with large language models (LLMs) for logical organization, connectivity, layout aesthetic, and AI hallucination. The assessment dataset is additionally investigated for its utility in automated diagram evaluation. The preliminary results suggest that our method decreases the rate of factual hallucination and improves diagram faithfulness to provided context; however, due to LLMs' stochasticity, the quality of the generated diagrams varies. Additionally, we present an in-depth analysis and discussion on the connection between AI hallucination and the quality of generated diagrams, which reveals that text contexts of higher complexity lead to higher rates of hallucination and LLMs often fail to detect mistakes in their output.

</details>


### [93] [Beyond Divergent Creativity: A Human-Based Evaluation of Creativity in Large Language Models](https://arxiv.org/abs/2601.20546)
*Kumiko Nakajima,Jan Zuiderveld,Sandro Pezzelle*

Main category: cs.CL

TL;DR: 研究表明，虽然大型语言模型（LLMs）在创造性任务中得到了广泛应用，但现有的评估方法如Divergent Association Task (DAT)往往无法全面评估模型的创意能力。为此，作者提出了Conditional Divergent Association Task (CDAT)，通过在恰当性的条件下评估新颖性，更好地分离创造性输出和噪声。


<details>
  <summary>Details</summary>
Motivation: 现有的评估方法往往是单方面关注创意的某一方面，如DAT过多强调新颖性而忽视了恰当性，因此提出的CDAT旨在提供一种更加全面和客观的评估方法。

Method: 通过对比多种先进的LLMs在CDAT上的表现来验证其有效性，同时还重新评估了DAT的不足并提出了新的评估任务CDAT。

Result: 研究结果显示，小型号家庭在CDAT上的表现往往更好，这可能与训练与对齐过程中的模型调整有关。

Conclusion: 研究强调了构建准确反映人类创造力理论的评估方法对于模型开发和应用的重要性，同时为未来的创造性任务评估提供了一种新的视角。

Abstract: Large language models (LLMs) are increasingly used in verbal creative tasks. However, previous assessments of the creative capabilities of LLMs remain weakly grounded in human creativity theory and are thus hard to interpret. The widely used Divergent Association Task (DAT) focuses on novelty, ignoring appropriateness, a core component of creativity. We evaluate a range of state-of-the-art LLMs on DAT and show that their scores on the task are lower than those of two baselines that do not possess any creative abilities, undermining its validity for model evaluation. Grounded in human creativity theory, which defines creativity as the combination of novelty and appropriateness, we introduce Conditional Divergent Association Task (CDAT). CDAT evaluates novelty conditional on contextual appropriateness, separating noise from creativity better than DAT, while remaining simple and objective. Under CDAT, smaller model families often show the most creativity, whereas advanced families favor appropriateness at lower novelty. We hypothesize that training and alignment likely shift models along this frontier, making outputs more appropriate but less creative. We release the dataset and code.

</details>


### [94] [A Computational Approach to Language Contact -- A Case Study of Persian](https://arxiv.org/abs/2601.20592)
*Ali Basirat,Danial Namazifard,Navid Baradaran Hemmati*

Main category: cs.CL

TL;DR: 本文调查了一种单一语言模型的中介表示中语言接触的结构痕迹，通过对比不同与波斯语接触程度的语言，发现普遍的句法信息对历史接触不甚敏感，而形态学特征如格和性则强烈受到特定语言结构的影响。


<details>
  <summary>Details</summary>
Motivation: 探讨单一语言模型在在接触丰富语言中的表示学习情况，旨在理解语言接触对单一语言模型影响的选择性和结构约束。

Method: 使用波斯语训练的语言模型，并暴露在不同层级和类型与波斯语接触的语言中，量化中介表示中的语言信息，并评估信息在模型组件中的分布。

Result: 结果显示普遍的句法信息对历史接触不敏感，而形态特征如格和性则强烈地受到特定语言结构的影响。

Conclusion: 接触效应在单一语言模型中的表现是选择性的且结构上受到限制。

Abstract: We investigate structural traces of language contact in the intermediate representations of a monolingual language model. Focusing on Persian (Farsi) as a historically contact-rich language, we probe the representations of a Persian-trained model when exposed to languages with varying degrees and types of contact with Persian. Our methodology quantifies the amount of linguistic information encoded in intermediate representations and assesses how this information is distributed across model components for different morphosyntactic features. The results show that universal syntactic information is largely insensitive to historical contact, whereas morphological features such as Case and Gender are strongly shaped by language-specific structure, suggesting that contact effects in monolingual language models are selective and structurally constrained.

</details>


### [95] [P2S: Probabilistic Process Supervision for General-Domain Reasoning Question Answering](https://arxiv.org/abs/2601.20649)
*Wenlin Zhong,Chengyuan Liu,Yiquan Wu,Bovin Tan,Changlong Sun,Yi Wang,Xiaozhong Liu,Kun Kuang*

Main category: cs.CL

TL;DR: 该研究提出了一种新的自我监督框架P2S，用于处理缺乏可验证奖励信号的通用领域推理任务。P2S通过计算每个推理步骤的概率一致性奖励（PFR），提供了精细的过程奖励，无需额外的奖励模型或手动标注的推理步骤。实验结果表明，P2S在阅读理解和医学问答基准测试中显著优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理通用领域推理任务时面临挑战，尤其是在缺乏可验证奖励信号的情况下。为了改进这一问题，研究者提出了P2S框架。

Method: P2S框架通过计算每个推理步骤的概率一致性奖励（PFR），从当前模型推理前缀生成给定的黄金推理链后缀的条件概率来评估每个步骤的准确性，以此来提供密集的指导。

Result: 在阅读理解和医学问答的基准测试中，P2S显著优于现有基线方法。

Conclusion: P2S通过引入路径一致性奖励，弥补了基于结果的奖励方法忽视推理过程监督的问题，并且能够与其他基于结果的奖励灵活结合，有效解决了奖励稀疏性问题。

Abstract: While reinforcement learning with verifiable rewards (RLVR) has advanced LLM reasoning in structured domains like mathematics and programming, its application to general-domain reasoning tasks remains challenging due to the absence of verifiable reward signals. To this end, methods like Reinforcement Learning with Reference Probability Reward (RLPR) have emerged, leveraging the probability of generating the final answer as a reward signal. However, these outcome-focused approaches neglect crucial step-by-step supervision of the reasoning process itself. To address this gap, we introduce Probabilistic Process Supervision (P2S), a novel self-supervision framework that provides fine-grained process rewards without requiring a separate reward model or human-annotated reasoning steps. During reinforcement learning, P2S synthesizes and filters a high-quality reference reasoning chain (gold-CoT). The core of our method is to calculate a Path Faithfulness Reward (PFR) for each reasoning step, which is derived from the conditional probability of generating the gold-CoT's suffix, given the model's current reasoning prefix. Crucially, this PFR can be flexibly integrated with any outcome-based reward, directly tackling the reward sparsity problem by providing dense guidance. Extensive experiments on reading comprehension and medical Question Answering benchmarks show that P2S significantly outperforms strong baselines.

</details>


### [96] [A Dialectic Pipeline for Improving LLM Robustness](https://arxiv.org/abs/2601.20659)
*Sara Candussio*

Main category: cs.CL

TL;DR: 本文提出了一种辩证管道，以减少语言模型的幻觉并提高输出质量，该管道通过自我对话增强了语言模型的自我反思和纠错能力，无需特定领域的调整或额外的验证器，并在不同模型和数据集上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 当前方法如领域特定数据的微调或独立验证器需要昂贵的计算资源，限制了模型的应用范围。本文为了解决这一问题，提出了一种辩证管道，旨在保持语言模型的泛化能力，提高其自我反思和纠正错误答案的能力，同时减少对额外计算资源的依赖。

Method: 本文提出的方法包括一个多步骤的辩证管道，该管道在每个阶段都增加了相关信息（在 Oracle-RAG 模式下），并通过实验对比研究了其摘要或过滤效果。在不同模型和数据集上进行测试，评估方法的有效性。

Result: 实验结果显示，本文提出的辩证管道在显著的边际上优于标准模型答案，且在所有测试的模型和数据集上始终表现出更好的性能。

Conclusion: 研究证明，辩证管道可以显著提高语言模型输出的质量，适用于更广泛的应用场景，而无需额外的验证器或领域特定的数据调整。

Abstract: Assessing ways in which Language Models can reduce their hallucinations and improve the outputs' quality is crucial to ensure their large-scale use.
  However, methods such as fine-tuning on domain-specific data or the training of a separate \textit{ad hoc} verifier require demanding computational resources (not feasible for many user applications) and constrain the models to specific fields of knowledge.
  In this thesis, we propose a dialectic pipeline that preserves LLMs' generalization abilities while improving the quality of its answer via self-dialogue, enabling it to reflect upon and correct tentative wrong answers.
  We experimented with different pipeline settings, testing our proposed method on different datasets and on different families of models. All the pipeline stages are enriched with the relevant context (in an oracle-RAG setting) and a study on the impact of its summarization or its filtering is conducted.
  We find that our proposed dialectic pipeline is able to outperform by significative margins the standard model answers and that it consistently achieves higher performances than Chain-of-Thought only prompting.

</details>


### [97] [Harnessing Large Language Models for Precision Querying and Retrieval-Augmented Knowledge Extraction in Clinical Data Science](https://arxiv.org/abs/2601.20674)
*Juan Jose Rubio Jan,Jack Wu,Julia Ive*

Main category: cs.CL

TL;DR: 本研究使用大型语言模型（LLMs）处理电子健康记录（EHR）的结构化数据查询和非结构化文本抽取任务，并通过自动生成的评估框架进行实验，证实了LLMs在临床工作流中的精准查询和信息提取潜力。


<details>
  <summary>Details</summary>
Motivation: 研究强调了LLMs在处理复杂且重要的EHR数据科学任务中的应用潜力，尤其是结构化数据查询和非结构化文本提取。

Method: 本研究设计了一种灵活的评价框架，自动生成符合每个数据集或任务特点的问题与答案对。实验在MIMIC III数据集的部分子集上进行，包括四种结构化表和一种临床笔记类型，使用本地托管和API基础的LLMs进行测试。

Result: 实验结果显示，LLMs在结构化数据查询和非结构化文本提取方面表现出良好的准确性，并通过精确匹配、语义相似性和人工判断等多种评估方法得到了验证。

Conclusion: 研究表明，LLMs有潜力支持精确的查询和准确的信息提取，从而在临床工作流中发挥作用。

Abstract: This study applies Large Language Models (LLMs) to two foundational Electronic Health Record (EHR) data science tasks: structured data querying (using programmatic languages, Python/Pandas) and information extraction from unstructured clinical text via a Retrieval Augmented Generation (RAG) pipeline. We test the ability of LLMs to interact accurately with large structured datasets for analytics and the reliability of LLMs in extracting semantically correct information from free text health records when supported by RAG. To this end, we presented a flexible evaluation framework that automatically generates synthetic question and answer pairs tailored to the characteristics of each dataset or task. Experiments were conducted on a curated subset of MIMIC III, (four structured tables and one clinical note type), using a mix of locally hosted and API-based LLMs. Evaluation combined exact-match metrics, semantic similarity, and human judgment. Our findings demonstrate the potential of LLMs to support precise querying and accurate information extraction in clinical workflows.

</details>


### [98] [ShieldedCode: Learning Robust Representations for Virtual Machine Protected Code](https://arxiv.org/abs/2601.20679)
*Mingqiao Mo,Yunlong Tan,Hao Zhang,Heng Zhang,Yangfan He*

Main category: cs.CL

TL;DR: 本文提出了Protection-Aware框架ShieldedCode，旨在学习VM保护代码的稳健表示，以抵御逆向工程威胁。该框架通过大规模的源代码和规范化VM实现的数据集进行训练，利用从指令内到指令间的层次依赖建模，并通过语义对齐和保护对齐的对比目标优化语言模型。


<details>
  <summary>Details</summary>
Motivation: 当前逆向工程威胁软件安全，而传统的虚拟机保护（VMP）依赖于成本高且易受自动化分析影响的规则变换。本文通过构建新的框架来填补这一空白，它不仅学习保护代码的表示，还评估不同VM变体对同一源代码的保护效果。

Method: 本文构建了一个保护感知框架ShieldedCode，主要通过以下几个步骤：（1）建立大规模配对的数据集，包括源代码和规范化VM实现；（2）在指令内、指令前后的层次进行依赖建模；（3）通过语义对齐和保护对齐的对比目标联合优化语言模型；（4）提出了一种保护有效性优化任务来量化评估不同VM变体。同时，引入了两阶段连续预训练和微调流程。

Result: 实验结果显示，ShieldedCode框架在L0虚拟机代码生成上相比GPT-4o提升了26.95%的通过率（Pass@1），并在二进制相似性检测的Recall@1上比jTrans等方法提升了10%。

Conclusion: 本研究通过ShieldedCode框架展示了学习基于语言的软件防御的新方向，增强了保护代码的鲁棒性，为软件保护提供了新的思路。

Abstract: Large language models (LLMs) have achieved remarkable progress in code generation, yet their potential for software protection remains largely untapped. Reverse engineering continues to threaten software security, while traditional virtual machine protection (VMP) relies on rigid, rule-based transformations that are costly to design and vulnerable to automated analysis. In this work, we present the first protection-aware framework that learns robust representations of VMP-protected code. Our approach builds large-scale paired datasets of source code and normalized VM implementations, and introduces hierarchical dependency modeling at intra-, preceding-, and inter-instruction levels. We jointly optimize language modeling with functionality-aware and protection-aware contrastive objectives to capture both semantic equivalence and protection strength. To further assess resilience, we propose a protection effectiveness optimization task that quantifies and ranks different VM variants derived from the same source. Coupled with a two-stage continual pre-training and fine-tuning pipeline, our method enables models to generate, compare, and reason over protected code. Extensive experiments show that our framework significantly improves robustness across diverse protection levels, opening a new research direction for learning-based software defense. In this work, we present ShieldedCode, the first protection-aware framework that learns robust representations of VMP-protected code. Our method achieves 26.95% Pass@1 on L0 VM code generation compared to 22.58% for GPT-4o., and improves binary similarity detection Recall@1 by 10% over state of art methods like jTrans.

</details>


### [99] [Online Density-Based Clustering for Real-Time Narrative Evolution Monitorin](https://arxiv.org/abs/2601.20680)
*Ostap Vykhopen,Viktoria Skorik,Maxim Tereschenko,Veronika Solopova*

Main category: cs.CL

TL;DR: 本文研究了将离线聚类算法HDBSCAN替换为在线聚类算法，以提高社交媒体监控中的自动叙事智能系统处理连续数据流的效率。


<details>
  <summary>Details</summary>
Motivation: 传统的批处理聚类算法在处理大规模连续社交媒体数据流时存在可扩展性挑战，而HDBSCAN作为离线算法难以适应实时变化的叙事内容。

Method: 本文采用了一种三层架构（数据收集、建模、仪表板生成），实验了多种在线聚类算法，并通过滑动窗口在历史数据集上的模拟进行表现比较。

Result: 研究表明，所提出的在线聚类算法在保留聚类质量、计算效率、内存占用比HDBSCAN更具优势，并能更好地适应叙事变化。

Conclusion: 本文的工作有助于填补批处理主题建模框架与社交媒体监控流式特性之间的鸿沟，对于计算社会学、危机信息学和叙事监视系统具有重要意义。

Abstract: Automated narrative intelligence systems for social media monitoring face significant scalability challenges when processing continuous data streams using traditional batch clustering algorithms. We investigate the replacement of HDBSCAN (offline clustering) with online (streaming/incremental) clustering methods in a production narrative report generation pipeline. The proposed system employs a three-stage architecture (data collection, modeling, dashboard generation) that processes thousands of multilingual social media documents daily. While HDBSCAN excels at discovering hierarchical density-based clusters and handling noise, its batch-only nature necessitates complete retraining for each time window, resulting in memory constraints, computational inefficiency, and inability to adapt to evolving narratives in real-time. This work evaluates a bunch of online clustering algorithms across dimensions of cluster quality preservation, computational efficiency, memory footprint, and integration compatibility with existing workflows. We propose evaluation criteria that balance traditional clustering metrics (Silhouette Coefficient, Davies-Bouldin Index) with narrative metrics (narrative distinctness, contingency and variance). Our methodology includes sliding-window simulations on historical datasets from Ukraine information space, enabling comparative analysis of algorithmic trade-offs in realistic operational contexts. This research addresses a critical gap between batch-oriented topic modeling frameworks and the streaming nature of social media monitoring, with implications for computational social science, crisis informatics, and narrative surveillance systems.

</details>


### [100] [QueerGen: How LLMs Reflect Societal Norms on Gender and Sexuality in Sentence Completion Tasks](https://arxiv.org/abs/2601.20731)
*Mae Sosto,Delfina Sol Martinez Pandiani,Laura Hollink*

Main category: cs.CL

TL;DR: 本研究探讨了大型语言模型（LLMs）如何复制社会规范，尤其是异 cis 正常化，并且这些规范如何在文本生成中转化为可测量的偏差。研究还发现，掩码语言模型（MLMs）对于标记为同性恋的主体产生了最不积极的情感，较高的毒性，以及更负面的态度。


<details>
  <summary>Details</summary>
Motivation: 研究的动机在于揭示大型语言模型在文本生成中嵌入的偏见，特别是性别和性取向相关的社会规范，以及不同类型的大型语言模型如何处理这些偏差。

Method: 研究通过分析特定主题的掩码语言模型（MLMs）和自回归语言模型（ARLMs）的文本生成，比较不同类别主题的情感、态度、毒性及预测多样性。

Result: 结果表明，掩码语言模型（MLMs）对标记为同性恋的主体产生了较低的情感积极度、较高毒性以及更负面的态度；自回归语言模型（ARLMs）部分缓解了这些模式；而封闭访问的自回归语言模型（ARLMs）倾向于对未标记主题产生更具伤害性的影响。

Conclusion: 结论指出，大型语言模型确实复制了规范的社会假设，尽管具体形式和程度的偏差依赖于特定模型特征，但这些偏差可能会被重新分配，而不会被完全消除。

Abstract: This paper examines how Large Language Models (LLMs) reproduce societal norms, particularly heterocisnormativity, and how these norms translate into measurable biases in their text generations. We investigate whether explicit information about a subject's gender or sexuality influences LLM responses across three subject categories: queer-marked, non-queer-marked, and the normalized "unmarked" category. Representational imbalances are operationalized as measurable differences in English sentence completions across four dimensions: sentiment, regard, toxicity, and prediction diversity. Our findings show that Masked Language Models (MLMs) produce the least favorable sentiment, higher toxicity, and more negative regard for queer-marked subjects. Autoregressive Language Models (ARLMs) partially mitigate these patterns, while closed-access ARLMs tend to produce more harmful outputs for unmarked subjects. Results suggest that LLMs reproduce normative social assumptions, though the form and degree of bias depend strongly on specific model characteristics, which may redistribute, but not eliminate, representational harms.

</details>


### [101] [Like a Therapist, But Not: Reddit Narratives of AI in Mental Health Contexts](https://arxiv.org/abs/2601.20747)
*Elham Aghakhani,Rezvaneh Rezapour*

Main category: cs.CL

TL;DR: 该研究分析了5,126篇有关日常使用人工智能进行情感支持或治疗的Reddit帖子，通过技术接受模型和治疗联盟理论，发现参与度主要由叙述结果、信任和回应质量决定，而非情感纽带。正面情感与任务和目标一致性关联最紧密，而伙伴关系导向的使用则更常见不一致的联盟和依赖、症状加剧等风险。


<details>
  <summary>Details</summary>
Motivation: 面对LLM在非临床环境中的广泛应用，研究用户对其的评价与人际关系建立方式，旨在更好地理解情感支持AI在实际使用中的效果与潜在风险。

Method: 研究基于Technology Acceptance Model和therapeutic alliance theory，设计了一种理论导向的注释框架，应用LLM与人类结合的方法大规模分析评价语言、采用态度和关系对齐。

Result: 研究结果表明，参与度主要由叙述结果、信任和回应质量决定。正面情感最常与任务和目标一致性相关。伙伴关系导向使用可能带来不一致的联盟和依赖、症状加剧等风险。

Conclusion: 该研究展示了通过理论导向框架进行大规模话语分析的应用，强调了在敏感的真实世界环境中研究用户如何解读语言技术的重要性。

Abstract: Large language models (LLMs) are increasingly used for emotional support and mental health-related interactions outside clinical settings, yet little is known about how people evaluate and relate to these systems in everyday use. We analyze 5,126 Reddit posts from 47 mental health communities describing experiential or exploratory use of AI for emotional support or therapy. Grounded in the Technology Acceptance Model and therapeutic alliance theory, we develop a theory-informed annotation framework and apply a hybrid LLM-human pipeline to analyze evaluative language, adoption-related attitudes, and relational alignment at scale. Our results show that engagement is shaped primarily by narrated outcomes, trust, and response quality, rather than emotional bond alone. Positive sentiment is most strongly associated with task and goal alignment, while companionship-oriented use more often involves misaligned alliances and reported risks such as dependence and symptom escalation. Overall, this work demonstrates how theory-grounded constructs can be operationalized in large-scale discourse analysis and highlights the importance of studying how users interpret language technologies in sensitive, real-world contexts.

</details>


### [102] [Persona Prompting as a Lens on LLM Social Reasoning](https://arxiv.org/abs/2601.20757)
*Jing Yang,Moritz Hechtbauer,Elisabeth Khalilov,Evelyn Luise Brinkmann,Vera Schmitt,Nils Feldhus*

Main category: cs.CL

TL;DR: 本研究考察了不同模拟的人格化特征对大语言模型在仇恨言论检测任务中生成解释质量的影响，发现尽管个性提示可以提升分类准确性，但往往牺牲了解释质量，并未能缓解潜在偏见。


<details>
  <summary>Details</summary>
Motivation: 社会敏感任务（如仇恨言论检测）中，模型解释的质量对用户信任和模型对齐至关重要，而人格提示作为模型个性化生成的途径，其对模型解释的影响尚未充分研究。

Method: 使用带有词语级解释标注的数据集，测量不同模拟的人格化特征下的大语言模型解释与人类标注的符合度，评估个性提示对模型偏差和人类对齐的影响。

Result: 研究发现，（1）个性提示能提高最主观任务（仇恨言论）的分类准确率，但解释质量下降。（2）模拟的人格化特征难以与现实中的群体特征对齐，且高的人格化特征间的共识表明模型不易受到显著引导。（3）模型存在持续的群体偏见，倾向于过度标记内容为有害，不受个性提示影响。

Conclusion: 个性提示虽然可提升社会敏感任务中的分类表现，但往往以牺牲解释质量和未能缓解潜在偏见为代价，提示在使用时应谨慎。

Abstract: For socially sensitive tasks like hate speech detection, the quality of explanations from Large Language Models (LLMs) is crucial for factors like user trust and model alignment. While Persona prompting (PP) is increasingly used as a way to steer model towards user-specific generation, its effect on model rationales remains underexplored. We investigate how LLM-generated rationales vary when conditioned on different simulated demographic personas. Using datasets annotated with word-level rationales, we measure agreement with human annotations from different demographic groups, and assess the impact of PP on model bias and human alignment. Our evaluation across three LLMs results reveals three key findings: (1) PP improving classification on the most subjective task (hate speech) but degrading rationale quality. (2) Simulated personas fail to align with their real-world demographic counterparts, and high inter-persona agreement shows models are resistant to significant steering. (3) Models exhibit consistent demographic biases and a strong tendency to over-flag content as harmful, regardless of PP. Our findings reveal a critical trade-off: while PP can improve classification in socially-sensitive tasks, it often comes at the cost of rationale quality and fails to mitigate underlying biases, urging caution in its application.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [103] [Flexible Bit-Truncation Memory for Approximate Applications on the Edge](https://arxiv.org/abs/2601.19900)
*William Oswald,Mario Renteria-Pinon,Md. Sajjad Hossain,Kyle Mooney,Md. Bipul Hossain,Destinie Diggs,Yiwen Xu,Mohamed Shaban,Jinhui Wang,Na Gong*

Main category: cs.AR

TL;DR: 论文提出了一种具有适应灵活性的位截断内存，能够在运行时截断任意数量的数据位以满足不同应用的品质与功耗之间的权衡要求。这种内存被应用于视频处理和深度学习两大数据密集型近似应用中，实验结果显示其相比于现存方案能够提供更高的功耗效率和显著的能效提升。


<details>
  <summary>Details</summary>
Motivation: 现有的位截断内存需要为特定应用进行定制设计，缺乏灵活性。为了解决这个问题，作者提出了一个具有全适应灵活性的新型位截断内存。

Method: 研究人员首先设计了具有灵活位截断能力的内存架构，然后将该内存应用于多种视频处理和深度学习模型中，通过实验验证其性能和效率。

Result: 通过应用所提出的内存结构，作者展示了其在不同视频应用（包括亮度感知、内容感知和兴趣区域感知）中能够实现最高47.02%的功耗节省。此外，该内存还可为基础和剪枝的轻量级深度学习模型实现高达51.69%的功耗节省。

Conclusion: 提出的灵活位截断内存为近似应用提供了优化的功率/能量效率，并解决了现有内存设计缺乏灵活性的问题，为近似应用在边缘环境中的部署奠定了基础。

Abstract: Bit truncation has demonstrated great potential to enable run-time quality-power adaptive data storage, thereby optimizing the power/energy efficiency of approximate applications and supporting their deployment in edge environments. However, existing bit-truncation memories require custom designs for a specific application. In this paper, we present a novel bit-truncation memory with full adaptation flexibility, which can truncate any number of data bits at run time to meet different quality and power trade-off requirements for various approximate applications. The developed bit-truncation memory has been applied to two representative data-intensive approximate applications: video processing and deep learning. Our experiments show that the proposed memory can support three different video applications (including luminance-aware, content-aware, and region-of-interest-aware) with enhanced power efficiency (up to 47.02% power savings) as compared to state-of-the-art. In addition, the proposed memory achieves significant (up to 51.69%) power savings for both baseline and pruned lightweight deep learning models, respectively, with a low implementation cost (2.89% silicon area overhead).

</details>


### [104] [A Flower-Inspired Solution for Computer Memory Wear-Leveling](https://arxiv.org/abs/2601.19902)
*Elizabeth Shen,Huiyang Zhou*

Main category: cs.AR

TL;DR: 该研究提出了一种新的磨损均衡方法——双环磨损均衡，它通过模仿植物花瓣布局的黄金比例来均匀分配内存访问，从而减少磨损并延长内存使用寿命。


<details>
  <summary>Details</summary>
Motivation: 为了减少电子废弃物和提高可持续性，需要延长计算机内存的使用寿命。传统方法由于需要复杂的硬件扩展或仅适用于特定程序结构而受到限制。因此，研究提出了双环磨损均衡方法，以提供一种简单有效的方法来减少内存磨损，延长内存的使用寿命。

Method: 研究采用了黄金比例的概念，将其应用于内存访问模式，设计了一种新的内存管理策略，结合了现有的垃圾回收机制，提出了一种可以自动适应内存大小、无需硬件更改且不影响程序执行速度的双环磨损均衡方法。

Result: 双环磨损均衡方法能够减少内存磨损，延长内存的使用寿命，同时也兼具了确定性、自动适应内存大小、无需额外硬件变更以及不影响程序执行速度的优点。

Conclusion: 总的来说，双环磨损均衡方法是一种有效的解决方案，可以在软件层面减少内存磨损并延长内存使用寿命，对于当前及未来的内存技术发展具有重要价值。

Abstract: Lengthening a computer memory's lifespan is important for e-waste and sustainability. Uneven wear of memory is a major barrier. The problem is becoming even more urgent as emerging memory such as phase-change memory is subject to even shorter lifespan. Various solutions have been proposed, but they either require complicated hardware extensions or apply only to certain program constructs such as loops. This research proposes a new method, dual-ring wear leveling. It takes inspiration from the natural law known as the ``golden ratio" and how it helps flower petals evenly receive sun lights. By modeling memory as two rings and combines the idea with existing memory management, garbage collection, the new solution offers an effective way to reduce memory wear and hence lengthen memory lifespan. It is deterministic, able to automatically adapt to memory size, requiring no hardware changes, and adding no slowdown to program executions.

</details>


### [105] [STELLAR: Structure-guided LLM Assertion Retrieval and Generation for Formal Verification](https://arxiv.org/abs/2601.19903)
*Saeid Rajabi,Chengmo Yang,Satwik Patnaik*

Main category: cs.AR

TL;DR: STELLAR 是首个在生成 SystemVerilog Assertions (SVAs) 时利用结构相似性的框架，通过代表 RTL 块作为 AST 结构指纹并从知识库中检索结构相关 (RTL, SVA) 对，与现有方法相比，STELLAR 在语法正确性、风格对齐和功能正确性方面表现更佳。


<details>
  <summary>Details</summary>
Motivation: 现有的基于大语言模型生成 SVAs 的方法存在局限性，如生成的 SVAs 可能不准确且不考虑硬件设计中的结构模式，因此需要一个能够提高 SVAs 质量的新框架。

Method: STELLAR 使用抽象语法树 (AST) 结构指纹来表示 RTL 块，从知识库中检索相关的设计模式和 SVAs 对，将其整合进结构指导的提示中进行生成。

Result: 实验表明，STELLAR 在 SVAs 的语法正确性、风格对齐和功能正确性方面表现更出色，显示了结构感知检索在工业形式验证中的潜力。

Conclusion: STELLAR 将结构引导纳入 SVA 生成过程，提供了一种有效提升 SVAs 质量的新方法，对未来的工业形式验证有着重要的意义。

Abstract: Formal Verification (FV) relies on high-quality SystemVerilog Assertions (SVAs), but the manual writing process is slow and error-prone. Existing LLM-based approaches either generate assertions from scratch or ignore structural patterns in hardware designs and expert-crafted assertions. This paper presents STELLAR, the first framework that guides LLM-based SVA generation with structural similarity. STELLAR represents RTL blocks as AST structural fingerprints, retrieves structurally relevant (RTL, SVA) pairs from a knowledge base, and integrates them into structure-guided prompts. Experiments show that STELLAR achieves superior syntax correctness, stylistic alignment, and functional correctness, highlighting structure-aware retrieval as a promising direction for industrial FV.

</details>


### [106] [DABench-LLM: Standardized and In-Depth Benchmarking of Post-Moore Dataflow AI Accelerators for LLMs](https://arxiv.org/abs/2601.19904)
*Ziyu Hu,Zhiqing Zhong,Weijian Zheng,Zhijing Ye,Xuwei Tan,Xueru Zhang,Zheng Xie,Rajkumar Kettimuthu,Xiaodong Yu*

Main category: cs.AR

TL;DR: 该研究提出了DABench-LLM，这是第一个用于评估基于数据流加速器的大语言模型工作负载的基准框架，通过结合片内性能分析和跨片扩展性分析，该框架帮助研究人员快速了解底层硬件和系统行为，并提供性能优化指导。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的指数增长，传统CPU和GPU性能的提升已不如摩尔定律，因此出现了用于大语言模型训练的新型加速器。然而，缺乏深入的性能分析和标准化基准方法。为此，该研究旨在填补这一空白，开发DABench-LLM基准框架。

Method: 该研究结合了片内性能分析和跨片扩展性分析，构建了DABench-LLM基准框架，用于评估基于数据流的加速器上的大语言模型工作负载。

Result: DABench-LLM在三种商品化的数据流加速器上进行了验证，揭示了性能瓶颈，提供了具体的优化策略，表明其在多种数据流AI硬件平台上的通用性和有效性。

Conclusion: 该研究为评估基于数据流的加速器上的大语言模型性能提供了一个全面且有效的基准框架，有助于指导硬件和软件的性能优化。

Abstract: The exponential growth of large language models has outpaced the capabilities of traditional CPU and GPU architectures due to the slowdown of Moore's Law. Dataflow AI accelerators present a promising alternative; however, there remains a lack of in-depth performance analysis and standardized benchmarking methodologies for LLM training. We introduce DABench-LLM, the first benchmarking framework designed for evaluating LLM workloads on dataflow-based accelerators. By combining intra-chip performance profiling and inter-chip scalability analysis, DABench-LLM enables comprehensive evaluation across key metrics such as resource allocation, load balance, and resource efficiency. The framework helps researchers rapidly gain insights into underlying hardware and system behaviors, and provides guidance for performance optimizations. We validate DABench-LLM on three commodity dataflow accelerators, Cerebras WSE-2, SambaNova RDU, and Graphcore IPU. Our framework reveals performance bottlenecks and provides specific optimization strategies, demonstrating its generality and effectiveness across a diverse range of dataflow-based AI hardware platforms.

</details>


### [107] [GTAC: A Generative Transformer for Approximate Circuits](https://arxiv.org/abs/2601.19906)
*Jingxin Wang,Shitong Guo,Ruicheng Dai,Wenhui Liang,Ruogu Ding,Xin Ning,Weikang Qian*

Main category: cs.AR

TL;DR: 本文提出了一种新颖的生成型Transformer模型GTAC，用于生成容错电路，该方法在相同误差率约束下比现有技术减少6.4%的面积，且加速4.3倍。


<details>
  <summary>Details</summary>
Motivation: 当前对容错应用（error-tolerant applications）的电路设计中，虽然已有一些方法，但GTAC通过结合近似计算原理与AI驱动的EDA工具，创新性地将误差阈值纳入设计流程中，从而提高了电路性能、降低了功耗和面积，适用于对误差有一定容忍度的应用场景。

Method: GTAC利用生成型Transformer模型，结合近似计算和AI驱动的电子设计自动化（EDA）技术，创新性地将误差阈值集成到设计过程中。

Result: 实验结果显示，与最先进的方法相比，在相同的误差率约束下，GTAC能进一步减少6.4%的面积，同时加速4.3倍。

Conclusion: 总体而言，GTAC在近似电路生成领域取得了显著成果，展示了其在提高电路性能、提升设计效率方面的潜力。

Abstract: Targeting error-tolerant applications, approximate circuits introduce controlled errors to significantly improve performance, power, and area (PPA) of circuits. In this work, we introduce GTAC, a novel generative Transformer-based model for producing approximate circuits. By leveraging principles of approximate computing and AI-driven EDA, our model innovatively integrates error thresholds into the design process. Experimental results show that compared with a state-of-the-art method, GTAC further reduces 6.4% area under the error rate constraint, while being 4.3x faster.

</details>


### [108] [RAPID-Graph: Recursive All-Pairs Shortest Paths Using Processing-in-Memory for Dynamic Programming on Graphs](https://arxiv.org/abs/2601.19907)
*Yanru Chen,Zheyu Li,Keming Fan,Runyang Tian,John Hsu,Weihong Xu,Minxuan Zhou,Tajana Rosing*

Main category: cs.AR

TL;DR: RAPID-Graph通过设计一种基于内存计算的系统，提供了APSP问题的高效解决方案，相比现有GPU加速器在速度和能效上分别提高了8.3x和104x。


<details>
  <summary>Details</summary>
Motivation: 针对大规模图数据分析中的APSP瓶颈，现有内存层次结构的数据移动复杂度导致了计算效率低下。

Method: 通过算法层面的递归感知分区器，来减小程序中的数据依赖性；在架构和设备层面，采用2.5D PIM堆栈，结合相变存储器计算片、逻辑片和高带宽容量缓存，存储大尺寸的APSP结果。

Result: RAPID-Graph在2.45M节点的数据集上，相比最先进的GPU集群提高了5.8倍的速度，1,186倍的能耗效率；与之前的基于内存计算的加速器相比，速度提高了8.3倍，能效提高了104倍。相比于NVIDIA H100 GPU，它提供了42.8倍的速度提升和392倍的能效提升。

Conclusion: 此研究通过提出一种综合算法、架构和设备优化的方案，显著提高了大型图数据的APSP计算速度和能效，为大规模图分析的实际应用提供了有力支持。

Abstract: All-pairs shortest paths (APSP) remains a major bottleneck for large-scale graph analytics, as data movement with cubic complexity overwhelms the bandwidth of conventional memory hierarchies. In this work, we propose RAPID-Graph to address this challenge through a co-designed processing-in-memory (PIM) system that integrates algorithm, architecture, and device-level optimizations. At the algorithm level, we introduce a recursion-aware partitioner that enables an exact APSP computation by decomposing graphs into vertex tiles to reduce data dependency, such that both Floyd-Warshall and Min-Plus kernels execute fully in-place within digital PIM arrays. At the architecture and device levels, we design a 2.5D PIM stack integrating two phase-change memory compute dies, a logic die, and high-bandwidth scratchpad memory within a unified advanced package. An external non-volatile storage stack stores large APSP results persistently. The design achieves both tile-level and unit-level parallel processing to sustain high throughput. On the 2.45M-node OGBN-Products dataset, RAPID-Graph is 5.8x faster and 1,186x more energy efficient than state-of-the-art GPU clusters, while exceeding prior PIM accelerators by 8.3x in speed and 104x in efficiency. It further delivers up to 42.8x speedup and 392x energy savings over an NVIDIA H100 GPU.

</details>


### [109] [CHIME: Chiplet-based Heterogeneous Near-Memory Acceleration for Edge Multimodal LLM Inference](https://arxiv.org/abs/2601.19908)
*Yanru Chen,Runyang Tian,Yue Pan,Zheyu Li,Weihong Xu,Tajana Rosing*

Main category: cs.AR

TL;DR: CHIME是一种基于chiplet的异构近存加速方案，用于边缘多模态大型语言模型（MLLM）推理。该方案利用了集成的3D DRAM和RRAM芯片级的优势，优化了带宽和存储效率，从而实现了高达54倍的推理速度和246倍的能效提升。


<details>
  <summary>Details</summary>
Motivation: 研究表明，随着大型语言模型（LLMs）的演进，它们所处理的大量维度视觉输入转化为庞大的token序列。这不仅增加了关键值（KV）缓存的负担，还对边缘设备的延迟和能量约束提出了严峻挑战。CHIME旨在解决这些问题。

Method: CHIME方案采用了一种基于chiplet的异构近存加速技术，结合了集成的3D DRAM（低延迟带宽）和RRAM（高密度非易失性存储）。这种方法通过主机设计的映射框架，将融合内核执行推近数据，以尽可能减少跨芯片通信，从而最大化带宽效率。

Result: 实验结果表明，CHIME在FastVLM和MobileVLM上的表现显著优于NVIDIA Jetson Orin NX，实现了高达54倍的推理速度和246倍的能效提升。与最先进的PIM加速器FACIL相比，CHIME的吞吐量提高了69.2倍。此外，CHIME的混合内存设计相对于3D DRAM仅硬件提高了7%的能效和2.4倍的性能。

Conclusion: 总之，CHIME通过合理利用异构硬件和优化算法，显著提升了边缘多模态大型语言模型的推理性能和能效。

Abstract: The proliferation of large language models (LLMs) is accelerating the integration of multimodal assistants into edge devices, where inference is executed under stringent latency and energy constraints, often exacerbated by intermittent connectivity. These challenges become particularly acute in the context of multimodal LLMs (MLLMs), as high-dimensional visual inputs are transformed into extensive token sequences, thereby inflating the key-value (KV) cache and imposing substantial data movement overheads to the LLM backbone. To address these issues, we present CHIME, a chiplet-based heterogeneous near-memory acceleration for edge MLLMs inference. CHIME leverages the complementary strengths of integrated monolithic 3D (M3D) DRAM and RRAM chiplets: DRAM supplies low-latency bandwidth for attention, while RRAM offers dense, non-volatile storage for weights. This heterogeneous hardware is orchestrated by a co-designed mapping framework that executes fused kernels near data, minimizing cross-chiplet traffic to maximize effective bandwidth. On FastVLM (0.6B/1.7B) and MobileVLM (1.7B/3B), CHIME achieves up to 54x speedup and up to 246x better energy efficiency per inference as compared to the edge GPU NVIDIA Jetson Orin NX. It sustains 116.5-266.5 token/J compared to Jetson's 0.7-1.1 token/J. Furthermore, it delivers up to 69.2x higher throughput than the state-of-the-art PIM accelerator FACIL. Compared to the M3D DRAM-only design, CHIME's heterogeneous memory further improves energy efficiency by 7% and performance by 2.4x.

</details>


### [110] [Understanding Bottlenecks for Efficiently Serving LLM Inference With KV Offloading](https://arxiv.org/abs/2601.19910)
*William Meng,Benjamin Lee,Hong Wang*

Main category: cs.AR

TL;DR: 该研究提出了一种分析框架，以确定关键缓存与预填充标记比率，并展示了典型负载远超此阈值，导致大部分延迟用于传输，而GPU利用率极低的情况。文章提出了硬件互连、模型架构和调度算法的优化建议。


<details>
  <summary>Details</summary>
Motivation: 分析KV缓存卸载对长上下文LLM推理的影响，特别是PCIe带宽限制带来的瓶颈，旨在提高整体性能。

Method: 开发了一个分析框架，用于确定关键缓存与预填充标记比率，并通过实验分析负载特性。

Result: 研究发现，典型工作负载中99%的延迟用于传输，而GPU仅使用其最大功耗的28%，表明需要优化。

Conclusion: 文章提出了针对硬件互连、模型架构和调度算法的优化策略，以提高KV缓存卸载技术和LLM推理的整体效率。

Abstract: KV cache offloading enables long-context LLM inference by storing caches in CPU DRAM, but PCIe bandwidth limitations create severe bottlenecks. In this paper, we develops an analytical framework that derives $κ_{\text{crit}}$, the critical cached-to-prefill token ratio where execution becomes memory-bound and show typical workloads exceed this threshold by orders of magnitude. Empirical characterization reveals 99\% of latency spent on transfers and serving offloaded requests results in GPU's consuming only 28\% of their rated TDP, motivating our proposed optimizations for hardware interconnects, model architectures, and scheduling algorithms.

</details>


### [111] [Analysis of LLM Vulnerability to GPU Soft Errors: An Instruction-Level Fault Injection Study](https://arxiv.org/abs/2601.19912)
*Duo Chai,Zizhen Liu,Shuhuai Wang,Songwei Pei,Cheng Liu,Huawei Li,Shangguang Wang*

Main category: cs.AR

TL;DR: 该研究首次对大型语言模型（LLMs）的指令级故障注入进行了研究，揭示了其可靠性特征，从多个角度展示了模型架构、参数规模和任务复杂性对可靠性的影响。


<details>
  <summary>Details</summary>
Motivation: 研究发现，大型语言模型在软错误抗性方面可能与早期模型有所不同。由于它们在多场景中的广泛应用，因此需要进行系统分析以改进容错机制。

Method: 通过指令级故障注入方法研究大型语言模型的可靠性。

Result: 研究表明，模型架构、参数规模和任务复杂性对可靠性有显著影响。

Conclusion: 研究为理解大型语言模型的可靠性提供了新见解，并有助于设计更有效的容错机制。

Abstract: Large language models (LLMs) are highly compute- and memory-intensive, posing significant demands on high-performance GPUs. At the same time, advances in GPU technology driven by shrinking transistor sizes and lower operating voltages have made these devices increasingly susceptible to soft errors. While prior work has examined GPU reliability, most studies have focused on general-purpose applications or conventional neural networks mostly used for vision tasks such as classification and detection. In contrast, systematic analysis of modern large-scale LLMs remains limited, despite their rapid adoption in diverse application scenarios. Given the unique characteristics of LLMs, their resilience to soft errors may differ substantially from earlier models. To bridge this gap, we conduct the first instruction-level fault injection study of LLM inference. Our approach reveals reliability characteristics from multiple perspectives, highlighting the effects of model architecture, parameter scale, and task complexity. These findings provide new insights into LLM reliability and inform the design of more effective fault tolerance mechanisms.

</details>


### [112] [Bench4HLS: End-to-End Evaluation of LLMs in High-Level Synthesis Code Generation](https://arxiv.org/abs/2601.19941)
*M Zafir Sadik Khan,Kimia Azar,Hadi Kamali*

Main category: cs.AR

TL;DR: Bench4HLS 是一个全面的基准和评估框架，用于评估 LLM 生成的 HLS 设计。该框架包含 170 个手动撰写的案例研究，涵盖了从小型内核到复杂加速器的各个方面，支持自动化评估编译成功、功能正确性及综合可行性，并集成了可插拔的 API 以进行 PPA 分析。


<details>
  <summary>Details</summary>
Motivation: 随着 LLM 在 HLS 应用中的兴趣逐渐增加，现有的评估框架不足够支持这一趋势。因此，需要一个专门为 LLM-HLS 提供基准测试与评估的框架。

Method: Bench4HLS 通过收集来自广泛公共仓库的手动撰写的 170 个案例研究，并全面支持自动化评估编译成功、功能正确性和综合可行性。此外，该框架还包含插件式 API，用于进行 PPA 分析。

Result: Bench4HLS 建立了一个结构化、可扩展且即插即用的测试平台，不仅能够评估 LLM 生成的 HLS 设计的多方面性能，还演示了 Xilinx Vitis HLS 和 Catapult HLS 的 PPA 分析。

Conclusion: Bench4HLS 为 LLM 在 HLS 工作流中的基准测试提供了一个开创性的方法，促进了该领域进一步研究的发展。

Abstract: In last two years, large language models (LLMs) have shown strong capabilities in code generation, including hardware design at register-transfer level (RTL). While their use in high-level synthesis (HLS) remains comparatively less mature, the ratio of HLS- to RTL-focused studies has shifted from 1:10 to 2:10 in the past six months, indicating growing interest in leveraging LLMs for high-level design entry while relying on downstream synthesis for optimization. This growing trend highlights the need for a comprehensive benchmarking and evaluation framework dedicated to LLM-based HLS. To address this, We present Bench4HLS for evaluating LLM-generated HLS designs. Bench4HLS comprises 170 manually drafted and validated case studies, spanning small kernels to complex accelerators, curated from widely used public repositories. The framework supports fully automated assessment of compilation success, functional correctness via simulation, and synthesis feasibility/optimization. Crucially, Bench4HLS integrates a pluggable API for power, performance, and area (PPA) analysis across various HLS toolchains and architectures, demonstrated here with Xilinx Vitis HLS and validated on Catapult HLS. By providing a structured, extensible, and plug-and-play testbed, Bench4HLS establishes a foundational methodology for benchmarking LLMs in HLS workflows.

</details>


### [113] [Primitive-Driven Acceleration of Hyperdimensional Computing for Real-Time Image Classification](https://arxiv.org/abs/2601.20061)
*Dhruv Parikh,Jebacyril Arockiaraj,Viktor Prasanna*

Main category: cs.AR

TL;DR: 本文提出了一种使用 FPGA 实现的端到端加速器，用于在 FPGA 上通过管道架构执行 Hyperdimensional Computing（HDC）操作，从而在保证高精度的同时大幅度提高了推理延迟。


<details>
  <summary>Details</summary>
Motivation: 由于 HDC 的高维度、稀疏性和重复的数据移动导致传统处理器难以高效加速，因此需要开发一种新的方法来实现 HDC 在 FPGA 上的高效计算。

Method: 本文开发了一种图像编码算法，将局部图像块映射为包含空间信息的 hypervector，然后通过 HDC 基本操作结合成全局表示。同时设计了一种基于 FPGA 的端到端加速器，采用管道架构利用 hypervector 维度和图像块集合中的并行性。

Result: 该图像编码器在 MNIST 数据集上达到了 95.67% 的准确性，在 Fashion-MNIST 数据集上达到了 85.14% 的准确性，超过了之前的基于 HDC 的图像编码器。FPGA 实现达到了 0.09ms 的推理延迟，与最先进的 CPU 和 GPU 基准相比分别实现了高达 1300 倍和 60 倍的加速。

Conclusion: 通过结合有效的图像编码技术和基于 FPGA 的高效计算架构，本文提出的方法显著提高了 HDC 的实时性能，为图像任务提供了高效准确的解决方案。

Abstract: Hyperdimensional Computing (HDC) represents data using extremely high-dimensional, low-precision vectors, termed hypervectors (HVs), and performs learning and inference through lightweight, noise-tolerant operations. However, the high dimensionality, sparsity, and repeated data movement involved in HDC make these computations difficult to accelerate efficiently on conventional processors. As a result, executing core HDC operations: binding, permutation, bundling, and similarity search: on CPUs or GPUs often leads to suboptimal utilization, memory bottlenecks, and limits on real-time performance. In this paper, our contributions are two-fold. First, we develop an image-encoding algorithm that, similar in spirit to convolutional neural networks, maps local image patches to hypervectors enriched with spatial information. These patch-level hypervectors are then merged into a global representation using the fundamental HDC operations, enabling spatially sensitive and robust image encoding. This encoder achieves 95.67% accuracy on MNIST and 85.14% on Fashion-MNIST, outperforming prior HDC-based image encoders. Second, we design an end-to-end accelerator that implements these compute operations on an FPGA through a pipelined architecture that exploits parallelism both across the hypervector dimensionality and across the set of image patches. Our Alveo U280 implementation delivers 0.09ms inference latency, achieving up to 1300x and 60x speedup over state-of-the-art CPU and GPU baselines, respectively.

</details>


### [114] [A Paradigm for Generalized Multi-Level Priority Encoders](https://arxiv.org/abs/2601.20067)
*Maxwell Phillips,Firas Hassan,Ahmed Ammar*

Main category: cs.AR

TL;DR: 提出了一个多级优先编码器的新型架构，评估了多级结构与传统单级、树形和递归结构的性能和复杂度差异，为硬件设计师提供了选择优先编码器架构的建议，旨在帮助创建最优设计。


<details>
  <summary>Details</summary>
Motivation: 尽管传统的优先编码器复杂度较高，增加实现效率的技术具有加速高精度整数算术和内容寻址存储器等关键应用的潜力。因此，提出了一种新颖的多级优先编码器架构来减少复杂度并加速这些应用的执行。

Method: 作者通过对多级结构与其他已有的优先编码器设计（如单级、树形和递归设计）进行复杂度和延迟的性能比较，探索了不同架构的特点和模式，并提供了一些建议。

Result: 研究结果表明，传统的两层结构在复杂度和延迟之间提供了平衡，而增加层级会逐步获得更低的回报。树形和递归设计虽然更快，但复杂度更高。基于此，作者提供了一种优先编码器工具包来协助硬件设计师。

Conclusion: 作者通过深入分析这些优先编码器的设计原则和方法，为硬件设计师提供了有关哪种结构应在特定应用中使用的指南。

Abstract: Priority encoders are typically considered expensive hardware components in terms of complexity, especially at high bit precisions or input lengths (e.g., above 512 bits). However, if the complexity can be reduced, priority encoders can feasibly accelerate a variety of key applications, such as high-precision integer arithmetic and content-addressable memory. We propose a new paradigm for constructing priority encoders by generalizing the previously proposed two-level priority encoder structure. We extend this concept to three and four levels using two techniques -- cascading and composition -- and discuss further generalization. We then analyze the complexity and delay of new and existing priority encoder designs as a function of input length, for both FPGA and ASIC implementation technologies. In particular, we compare the multi-level structure to the traditional single-level priority encoder structure, a tree-based design, a recursive design, and the two-level structure. We find that the two-level architecture provides balanced performance -- reducing complexity by around half, but at the cost of a corresponding increase in delay. Additional levels have diminishing returns, highlighting a tradeoff between complexity and delay. Meanwhile, the tree and recursive designs are generally faster, but are more complex than the two-level and multi-level structures. We explore several characteristics and patterns of the designs across a wide range of input lengths. We then provide recommendations on which architecture to use for a given input length and implementation technology, based on which design factors -- such as complexity or delay -- are most important to the hardware designer. With this overview and analysis of various priority encoder architectures, we provide a priority encoder toolkit to assist hardware designers in creating the most optimal design.

</details>


### [115] [How Much Progress Has There Been in NVIDIA Datacenter GPUs?](https://arxiv.org/abs/2601.20115)
*Emanuele Del Sozzo,Martin Fleming,Kenneth Flamm,Neil Thompson*

Main category: cs.AR

TL;DR: 本文详细分析了NVIDIA数据中心GPU从2000年代中期至今的技术进步，包括计算性能、内存大小和带宽、价格以及功耗的变化，并量化了当前美国出口控制法规可能带来的潜在性能差距。


<details>
  <summary>Details</summary>
Motivation: 由于快速的技术进步和激烈的全球竞争使得美国实施了限制先进AI芯片出口的管控措施，因此研究NVIDIA数据中心GPU的技术进步趋势有助于对未来的研究限制做出预估。

Method: 论文编制了一个全面的数据中心NVIDIA GPU数据集，包含多个特征，如计算性能和发布价格。分析了主要GPU特征的趋势，并估计了每兆字节带宽、每美元和每瓦性能增长速率。

Result: FP16和FP32操作的双倍时间分别为1.44年和1.69年（未考虑稀疏性优势），而FP64操作为2.06-3.79年。外部内存大小和带宽的增长速度低于计算性能，每3.32至3.53年翻一番。数据中心GPU的价格大约每5.1年翻一番，而其功耗则大约每16年翻一番。

Conclusion: 最新的出口控制法规更改可能将潜在性能差距从23.6倍缩小至3.54倍，但即便如此，性能差距仍然显著。

Abstract: Graphics Processing Units (GPUs) are the state-of-the-art architecture for essential tasks, ranging from rendering 2D/3D graphics to accelerating workloads in supercomputing centers and, of course, Artificial Intelligence (AI). As GPUs continue improving to satisfy ever-increasing performance demands, analyzing past and current progress becomes paramount in determining future constraints on scientific research. This is particularly compelling in the AI domain, where rapid technological advancements and fierce global competition have led the United States to recently implement export control regulations limiting international access to advanced AI chips. For this reason, this paper studies technical progress in NVIDIA datacenter GPUs released from the mid-2000s until today. Specifically, we compile a comprehensive dataset of datacenter NVIDIA GPUs comprising several features, ranging from computational performance to release price. Then, we examine trends in main GPU features and estimate progress indicators for per-memory bandwidth, per-dollar, and per-watt increase rates. Our main results identify doubling times of 1.44 and 1.69 years for FP16 and FP32 operations (without accounting for sparsity benefits), while FP64 doubling times range from 2.06 to 3.79 years. Off-chip memory size and bandwidth grew at slower rates than computing performance, doubling every 3.32 to 3.53 years. The release prices of datacenter GPUs have roughly doubled every 5.1 years, while their power consumption has approximately doubled every 16 years. Finally, we quantify the potential implications of current U.S. export control regulations in terms of the potential performance gaps that would result if implementation were assumed to be complete and successful. We find that recently proposed changes to export controls would shrink the potential performance gap from 23.6x to 3.54x.

</details>


### [116] [SATA: Sparsity-Aware Scheduling for Selective Token Attention](https://arxiv.org/abs/2601.20267)
*Zhenkun Fan,Zishen Wan,Che-Kai Liu,Ashwin Sanjay Lele,Win-San Khwa,Bo Zhang,Meng-Fan Chang,Arijit Raychowdhury*

Main category: cs.AR

TL;DR: 本文提出了一种名为SATA的局部导向动态调度方案，通过主动管理稀疏分布的查询-键操作访问模式，优化了中间查询/键向量的早取和早退，从而提高了系统吞吐量和能效。


<details>
  <summary>Details</summary>
Motivation: 现有的基于选择性注意力机制的模型面临着计算复杂度高的问题，而SATA旨在通过减少不必要的计算和提高数据局部性来解决这一挑战。

Method: SATA方法通过重构操作流和利用数据局部性，提前获取并处理中间的查询/键向量，优化了系统的资源利用。

Result: 实验结果显示，SATA可以将系统吞吐量提高1.76倍，并将能量效率提升2.94倍，同时保持低调度开销。

Conclusion: SATA为处理选择性注意力模型中的访问模式提供了一种有效的方法，展示了其在提高系统性能上的优势。

Abstract: Transformers have become the foundation of numerous state-of-the-art AI models across diverse domains, thanks to their powerful attention mechanism for modeling long-range dependencies. However, the quadratic scaling complexity of attention poses significant challenges for efficient hardware implementation. While techniques such as quantization and pruning help mitigate this issue, selective token attention offers a promising alternative by narrowing the attention scope to only the most relevant tokens, reducing computation and filtering out noise.
  In this work, we propose SATA, a locality-centric dynamic scheduling scheme that proactively manages sparsely distributed access patterns from selective Query-Key operations. By reordering operand flow and exploiting data locality, our approach enables early fetch and retirement of intermediate Query/Key vectors, improving system utilization. We implement and evaluate our token management strategy in a control and compute system, using runtime traces from selective-attention-based models. Experimental results show that our method improves system throughput by up to 1.76x and boosts energy efficiency by 2.94x, while incurring minimal scheduling overhead.

</details>


### [117] [VersaQ-3D: A Reconfigurable Accelerator Enabling Feed-Forward and Generalizable 3D Reconstruction via Versatile Quantization](https://arxiv.org/abs/2601.20317)
*Yipu Zhang,Jintao Cheng,Xingyu Liu,Zeyu Li,Carol Jingyi Li,Jin Wu,Lin Jiang,Yuan Xie,Jiang Xu,Wei Zhang*

Main category: cs.AR

TL;DR: VersaQ-3D是一种算法与架构协同设计框架，通过引入无校准、场景无关的4位量化，以及支持BF16、INT8和INT4的可重构加速器，优化了VGGT在设备上的性能，同时保持高精度并大幅提高速度。


<details>
  <summary>Details</summary>
Motivation: 当前的方法无法有效量化VGGT模型，原因在于复杂且多样的3D语义导致激活通道饱和，以及硬件对于精度敏感的非线性操作和内存密集型的全局注意力机制有挑战。

Method: 提出了VersaQ-3D框架，包含算法层面引入了一种基于正交变换的无校准、场景无关的4位量化方法，以及架构层面设计支持BF16、INT8和INT4的可重构加速器，统一流水线处理线性和非线性操作，采用双阶段重计算基于的贴图来缓解内存压力。

Result: VersaQ-3D在W4A8配置下保持了98-99%的精度，而在W4A4配置下，其性能超过先前方法1.61-2.39倍，适用于多种场景。进一步，加速器提供了在边缘GPU上低功耗的5.2-10.8倍的加速速度，支持即时3D重建。

Conclusion: VersaQ-3D框架有效解决了3D重建中的量化难题，通过算法与架构的协同优化，显著提升了VGGT在实际部署中的性能和效率。

Abstract: The Visual Geometry Grounded Transformer (VGGT) enables strong feed-forward 3D reconstruction without per-scene optimization. However, its billion-parameter scale creates high memory and compute demands, hindering on-device deployment. Existing LLM quantization methods fail on VGGT due to saturated activation channels and diverse 3D semantics, which cause unreliable calibration. Furthermore, VGGT presents hardware challenges regarding precision-sensitive nonlinear operators and memory-intensive global attention. To address this, we propose VersaQ-3D, an algorithm-architecture co-design framework. Algorithmically, we introduce the first calibration-free, scene-agnostic quantization for VGGT down to 4-bit, leveraging orthogonal transforms to decorrelate features and suppress outliers. Architecturally, we design a reconfigurable accelerator supporting BF16, INT8, and INT4. A unified systolic datapath handles both linear and nonlinear operators, reducing latency by 60%, while two-stage recomputation-based tiling alleviates memory pressure for long-sequence attention. Evaluations show VersaQ-3D preserves 98-99% accuracy at W4A8. At W4A4, it outperforms prior methods by 1.61x-2.39x across diverse scenes. The accelerator delivers 5.2x-10.8x speedup over edge GPUs with low power, enabling efficient instant 3D reconstruction.

</details>


### [118] [Beyond GEMM-Centric NPUs: Enabling Efficient Diffusion LLM Sampling](https://arxiv.org/abs/2601.20706)
*Binglei Lou,Haoran Wu,Yao Lai,Jiayi Nie,Can Xiao,Xuan Guo,Rika Antonova,Robert Mullins,Aaron Zhao*

Main category: cs.AR

TL;DR: 该研究通过识别关键指令来优化dLLM的采样阶段，使用轻量级非GEMM向量原语、原位内存重用策略和解耦的混合精度内存层次结构，从而在不增加工艺节点的情况下，提高速度至2.53倍。


<details>
  <summary>Details</summary>
Motivation: 由于采样阶段在dLLM中的计算负担和内存访问模式不同于传统GEMM运算，常规的NPU难以高效处理，因此需要为dLLM采样特别优化NPU架构。

Method: 设计采用了轻量级非GEMM向量原语、原位内存重用策略和解耦的混合精度内存层次结构，从而在硬件层面优化dLLM的采样过程。

Result: 实验结果表明，该设计在等效nm技术节点下，相较于NVIDIA RTX A6000 GPU，可实现高达2.53倍的加速。

Conclusion: 通过开放源代码的循环准确模拟和后综合RTL验证，研究表明该设计与当前dLLM PyTorch实现具有功能等效性。

Abstract: Diffusion Large Language Models (dLLMs) introduce iterative denoising to enable parallel token generation, but their sampling phase displays fundamentally different characteristics compared to GEMM-centric transformer layers. Profiling on modern GPUs reveals that sampling can account for up to 70% of total model inference latency-primarily due to substantial memory loads and writes from vocabulary-wide logits, reduction-based token selection, and iterative masked updates. These processes demand large on-chip SRAM and involve irregular memory accesses that conventional NPUs struggle to handle efficiently. To address this, we identify a set of critical instructions that an NPU architecture must specifically optimize for dLLM sampling. Our design employs lightweight non-GEMM vector primitives, in-place memory reuse strategies, and a decoupled mixed-precision memory hierarchy. Together, these optimizations deliver up to a 2.53x speedup over the NVIDIA RTX A6000 GPU under an equivalent nm technology node. We also open-source our cycle-accurate simulation and post-synthesis RTL verification code, confirming functional equivalence with current dLLM PyTorch implementations.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [119] [NeuroAI and Beyond](https://arxiv.org/abs/2601.19955)
*Jean-Marc Fellous,Gert Cauwenberghs,Cornelia Fermüller,Yulia Sandamisrkaya,Terrence Sejnowski*

Main category: cs.AI

TL;DR: 这篇论文基于2025年8月的工作坊，探讨了神经科学与人工智能之间的潜在协同作用，特别是在实体化、语言与沟通、机器人技术、人类与机器学习以及神经形态工程等领域，提出了神经启发式人工智能（NeuroAI）的概念，并分析了其优势与风险。


<details>
  <summary>Details</summary>
Motivation: 作者希望通过整合神经科学与人工智能，发展出一种受到神经生物学启发的人工智能技术，以提高AI算法的范围和效率，并改革我们对生物神经计算的理解。

Method: 通过组织工作坊并收集来自领导研究人员的观点以及由研究人员和研究生撰写的SWOT分析。

Result: 论文指出了生物学和神经科学对AI算法以及其他相关领域的潜在影响，并提出了几条未来的发展道路。

Conclusion: 最终，论文倡导发展神经启发式人工智能（NeuroAI），并强调了其对AI领域的潜在贡献和风险。

Abstract: Neuroscience and Artificial Intelligence (AI) have made significant progress in the past few years but have only been loosely inter-connected. Based on a workshop held in August 2025, we identify current and future areas of synergism between these two fields. We focus on the subareas of embodiment, language and communication, robotics, learning in humans and machines and Neuromorphic engineering to take stock of the progress made so far, and possible promising new future avenues. Overall, we advocate for the development of NeuroAI, a type of Neuroscience-informed Artificial Intelligence that, we argue, has the potential for significantly improving the scope and efficiency of AI algorithms while simultaneously changing the way we understand biological neural computations. We include personal statements from several leading researchers on their diverse views of NeuroAI. Two Strength-Weakness-Opportunities-Threat (SWOT) analyses by researchers and trainees are appended that describe the benefits and risks offered by NeuroAI.

</details>


### [120] [Teaching LLMs to Ask: Self-Querying Category-Theoretic Planning for Under-Specified Reasoning](https://arxiv.org/abs/2601.20014)
*Shuhui Qu*

Main category: cs.AI

TL;DR: 本研究提出了一种名为Self-Querying Bidirectional Categorical Planning（SQ-BCP）的新方法，用于了解具有大语言模型推理时的不完全观察性问题，SQ-BCP通过目标自查询和假设桥梁建立机制解决未知条件，从而降低资源违规率并保持高质量的参考标准。


<details>
  <summary>Details</summary>
Motivation: 通过解决在任务关键性前提条件未在查询时指定时，大语言模型容易产生虚假事实或违反硬性限制的问题，提出了SQ-BCP方法。

Method: SQ-BCP 方法通过双向搜索，结合使用拉回验证器作为类别证书来验证目标兼容性，并使用基于距离的评分仅用于排序和剪枝。当验证器成功并硬约束通过确定性检查时，接受的计划与目标要求兼容；在分支限制和有限解析深度下，SQ-BCP 能够找到一个存在的接受计划。

Result: 在 WikiHow 和 RecipeNLG 任务中，当预设前提条件被扣留时，SQ-BCP 将资源违规率降低到 14.9% 和 5.8%，相比基线分别是 26.0% 和 15.7%；同时，SQ-BCP 保持了竞争性的参考标准。

Conclusion: SQ-BCP 能有效地解决大语言模型在部分观测性下的缺陷，显著减少资源违规情况，同时保持输出质量。

Abstract: Inference-time planning with large language models frequently breaks under partial observability: when task-critical preconditions are not specified at query time, models tend to hallucinate missing facts or produce plans that violate hard constraints. We introduce \textbf{Self-Querying Bidirectional Categorical Planning (SQ-BCP)}, which explicitly represents precondition status (\texttt{Sat}/\texttt{Viol}/\texttt{Unk}) and resolves unknowns via (i) targeted self-queries to an oracle/user or (ii) \emph{bridging} hypotheses that establish the missing condition through an additional action. SQ-BCP performs bidirectional search and invokes a pullback-based verifier as a categorical certificate of goal compatibility, while using distance-based scores only for ranking and pruning. We prove that when the verifier succeeds and hard constraints pass deterministic checks, accepted plans are compatible with goal requirements; under bounded branching and finite resolution depth, SQ-BCP finds an accepting plan when one exists. Across WikiHow and RecipeNLG tasks with withheld preconditions, SQ-BCP reduces resource-violation rates to \textbf{14.9\%} and \textbf{5.8\%} (vs.\ \textbf{26.0\%} and \textbf{15.7\%} for the best baseline), while maintaining competitive reference quality.

</details>


### [121] [Fuzzy Categorical Planning: Autonomous Goal Satisfaction with Graded Semantic Constraints](https://arxiv.org/abs/2601.20021)
*Shuhui Qu*

Main category: cs.AI

TL;DR: 本文提出了Fuzzy Category-theoretic Planning（FCP），旨在解决传统规划方法中关于模糊谓词应用性处理不够精确的问题。FCP为每个操作标注一个[0,1]之间的隶属度，并通过Lukasiewicz t-范来组合计划质量，而保持硬约束验证的清晰性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理自然语言规划中的模糊谓词时存在问题，这些谓词的满意程度是赋值度量的，但现有的规划方法将这种模糊性处理得太过于确定性，造成有意义的区别被抹平，并且无法有效地追踪多步骤计划中的质量下降。因此，需要一种能够处理这种模糊性的方法。

Method: FCP提出了一个新颖的方法，通过为每个操作赋予一个隶属度，以及使用Lukasiewicz t-范来组合计划质量，同时保留了拉普卡验证的清晰性来处理这些模糊性问题。

Result: FCP在公众PDDL3偏好/超负荷基准测试以及基于RecipeNLG-Subs的缺失替代食谱规划基准测试中表现出色，相较于LLM-only和ReAct方式的基准测试，提高了成功概率并减少了硬约束违规行为，同时保持与经典PDDL3规划器相当的竞争力。

Conclusion: FCP通过模糊逻辑在自然语言规划应用性的处理上取得了成功，展示了其解决复杂规划问题的优势。

Abstract: Natural-language planning often involves vague predicates (e.g., suitable substitute, stable enough) whose satisfaction is inherently graded. Existing category-theoretic planners provide compositional structure and pullback-based hard-constraint verification, but treat applicability as crisp, forcing thresholding that collapses meaningful distinctions and cannot track quality degradation across multi-step plans. We propose Fuzzy Category-theoretic Planning (FCP), which annotates each action (morphism) with a degree in [0,1], composes plan quality via a t-norm Lukasiewicz, and retains crisp executability checks via pullback verification. FCP grounds graded applicability from language using an LLM with k-sample median aggregation and supports meeting-in-the-middle search using residuum-based backward requirements. We evaluate on (i) public PDDL3 preference/oversubscription benchmarks and (ii) RecipeNLG-Subs, a missing-substitute recipe-planning benchmark built from RecipeNLG with substitution candidates from Recipe1MSubs and FoodKG. FCP improves success and reduces hard-constraint violations on RecipeNLG-Subs compared to LLM-only and ReAct-style baselines, while remaining competitive with classical PDDL3 planners.

</details>


### [122] [Scaling Medical Reasoning Verification via Tool-Integrated Reinforcement Learning](https://arxiv.org/abs/2601.20221)
*Hang Zhang,Ruheng Wang,Yuelyu Ji,Mingu Kwak,Xizhi Wu,Chenyu Li,Li Zhang,Wenqi Shi,Yifan Peng,Yanshan Wang*

Main category: cs.AI

TL;DR: 该研究引入了一个新的框架$	ext{method}$，用于医学推理验证，通过迭代查询外部医学资料库，实现了显著性能提升，并减少了样本预算需求。


<details>
  <summary>Details</summary>
Motivation: 现有的语言模型在医学推理上取得了很好的成绩，但在临床应用中需要严格的验证以保证事实的准确性。现有的奖励模型方法虽然具有可扩展性，但存在缺乏具体解释和单一检索过程的问题。

Method: 研究提出了一个新的框架$	ext{method}$，采用工具辅助的验证方法，并结合迭代的强化学习框架，要求只有轨迹级别的监督，并配置了一个自适应的学习课程机制，能够动态调整训练数据分布。

Result: 实验结果显示，该方法在多个医学推理基准测试中取得显著性能提升，特别是在MedQA和MedXpertQA上的精度分别提高了23.5%和32.0%，并且与之前的奖励模型方法相比，样本预算减少了8倍。

Conclusion: 该研究表明，将验证嵌入动态检索的证据中是实现更可靠医学推理系统的一个有前景的方法。

Abstract: Large language models have achieved strong performance on medical reasoning benchmarks, yet their deployment in clinical settings demands rigorous verification to ensure factual accuracy. While reward models offer a scalable approach for reasoning trace verification, existing methods face two limitations: they produce only scalar reward values without explicit justification, and they rely on single-pass retrieval that precludes adaptive knowledge access as verification unfolds. We introduce $\method$, an agentic framework that addresses these limitations by training medical reasoning verifiers to iteratively query external medical corpora during evaluation. Our approach combines tool-augmented verification with an iterative reinforcement learning paradigm that requires only trace-level supervision, alongside an adaptive curriculum mechanism that dynamically adjusts training data distribution. Across four medical reasoning benchmarks, $\method$ achieves substantial gains over existing methods, improving MedQA accuracy by 23.5% and MedXpertQA by 32.0% relative to the base generator in particular. Crucially, $\method$ demonstrates an $\mathbf{8\times}$ reduction in sampling budget requirement compared to prior reward model baselines. These findings establish that grounding verification in dynamically retrieved evidence offers a principled path toward more reliable medical reasoning systems.

</details>


### [123] [Endogenous Reprompting: Self-Evolving Cognitive Alignment for Unified Multimodal Models](https://arxiv.org/abs/2601.20305)
*Zhenchen Tang,Songlin Yang,Zichuan Wang,Bo Peng,Yang Li,Beibei Dong,Jing Dong*

Main category: cs.AI

TL;DR: 文章提出了一种称为Endogenous Reprompting的方法，通过SEER框架在生成过程中生成自我对齐描述符来增强模型的生成能力，从而填补认知空白。


<details>
  <summary>Details</summary>
Motivation: 当前的统一多模态模型虽然能力强，但其理解能力并未有效指导生成过程，文章旨在通过引入Endogenous Reprompting机制填补这一认知差距。

Method: SEER（Self-Evolving Evaluator and Reprompter）框架，包括两个阶段：1）使用RLVR（Reinforcement Learning with Verifiable Rewards）激活模型的内部评价能力，通过生成高保真的内生奖励信号；2）使用RLMT（Reinforcement Learning with Model-rewarded Thinking）优化生成推理政策。

Result: SEER在评估准确性、提示效率和生成质量方面均优于当前最先进的基线方法，同时保持了统一多模态模型的通用能力。

Conclusion: 文章提出的方法和框架成果显著，在多模态生成任务中具有潜在的实际应用价值。

Abstract: Unified Multimodal Models (UMMs) exhibit strong understanding, yet this capability often fails to effectively guide generation. We identify this as a Cognitive Gap: the model lacks the understanding of how to enhance its own generation process. To bridge this gap, we propose Endogenous Reprompting, a mechanism that transforms the model's understanding from a passive encoding process into an explicit generative reasoning step by generating self-aligned descriptors during generation. To achieve this, we introduce SEER (Self-Evolving Evaluator and Reprompter), a training framework that establishes a two-stage endogenous loop using only 300 samples from a compact proxy task, Visual Instruction Elaboration. First, Reinforcement Learning with Verifiable Rewards (RLVR) activates the model's latent evaluation ability via curriculum learning, producing a high-fidelity endogenous reward signal. Second, Reinforcement Learning with Model-rewarded Thinking (RLMT) leverages this signal to optimize the generative reasoning policy. Experiments show that SEER consistently outperforms state-of-the-art baselines in evaluation accuracy, reprompting efficiency, and generation quality, without sacrificing general multimodal capabilities.

</details>


### [124] [AMA: Adaptive Memory via Multi-Agent Collaboration](https://arxiv.org/abs/2601.20352)
*Weiquan Huang,Zixuan Wang,Hehai Lin,Sudong Wang,Bo Xu,Qian Li,Beier Zhu,Linyi Yang,Chengwei Qin*

Main category: cs.AI

TL;DR: 本文提出了一种名为AMA的自适应记忆系统，通过多智能体协作实现多粒度记忆管理，同时提高检索精度和长期记忆的一致性，相比全上下文方法，节省了约80%的token。


<details>
  <summary>Details</summary>
Motivation: 现有的记忆系统通常依赖于固定的检索粒度、积累为主的维护策略和粗粒度的更新机制，导致存储的信息与特定任务的推理需求不匹配，并随着时间积累逻辑不一致性。

Method: AMA框架采用分层记忆设计，动态调整检索粒度以适应任务复杂性。具体地，Constructor和Retriever共同实现多粒度记忆构建和自适应查询路由，Judge验证检索内容的相关性和一致性，当证据不足时触发迭代检索或在检测到逻辑冲突时调用Refresher实现记忆一致性。

Result: 在具有挑战性的长上下文基准测试中，AMA显著优于最先进的基准方法，相比全上下文方法减少了约80%的token消耗，证明了其在保持检索精度和长期记忆一致性方面的有效性。

Conclusion: AMA通过多智能体协作实现自适应记忆管理，解决了现有记忆系统中的问题，提高了模型在长交互场景中的表现。

Abstract: The rapid evolution of Large Language Model (LLM) agents has necessitated robust memory systems to support cohesive long-term interaction and complex reasoning. Benefiting from the strong capabilities of LLMs, recent research focus has shifted from simple context extension to the development of dedicated agentic memory systems. However, existing approaches typically rely on rigid retrieval granularity, accumulation-heavy maintenance strategies, and coarse-grained update mechanisms. These design choices create a persistent mismatch between stored information and task-specific reasoning demands, while leading to the unchecked accumulation of logical inconsistencies over time. To address these challenges, we propose Adaptive Memory via Multi-Agent Collaboration (AMA), a novel framework that leverages coordinated agents to manage memory across multiple granularities. AMA employs a hierarchical memory design that dynamically aligns retrieval granularity with task complexity. Specifically, the Constructor and Retriever jointly enable multi-granularity memory construction and adaptive query routing. The Judge verifies the relevance and consistency of retrieved content, triggering iterative retrieval when evidence is insufficient or invoking the Refresher upon detecting logical conflicts. The Refresher then enforces memory consistency by performing targeted updates or removing outdated entries. Extensive experiments on challenging long-context benchmarks show that AMA significantly outperforms state-of-the-art baselines while reducing token consumption by approximately 80% compared to full-context methods, demonstrating its effectiveness in maintaining retrieval precision and long-term memory consistency.

</details>


### [125] [Policy of Thoughts: Scaling LLM Reasoning via Test-time Policy Evolution](https://arxiv.org/abs/2601.20379)
*Zhengbo Jiao,Hongyu Xian,Qinglong Wang,Yunpu Ma,Zhebo Wang,Zifan Zhang,Dezhang Kong,Meng Han*

Main category: cs.AI

TL;DR: 本文提出了一种名为Policy of Thoughts (PoT) 的框架，通过在线优化机制和执行反馈来动态改进模型的推理策略，显著提升了大语言模型在长期复杂推理任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 当前的大语言模型在处理长期复杂推理时存在不稳定问题，传统测试时间扩展方法仅将执行反馈作为外部信号，未从根本上改善模型的推理策略。本文受Popper“猜想与反驳”知识论启发，提出了PoT框架，旨在通过实时学习和调整策略来提升模型的推理能力。

Method: PoT框架包括高效的探索机制以生成多样化候选解决方案，使用Group Relative Policy Optimization (GRPO) 更新基于执行反馈的LoRA适配器。这种闭环设计可以实现模型推理策略的动态、实例特定优化。

Result: 实验结果显示，PoT框架显著提升了模型性能。一个4B模型在LiveCodeBench任务中达到了49.71%的准确率，超越了GPT-4o和DeepSeek-V3，尽管后者模型更大。

Conclusion: 本文提出了PoT框架，通过实现模型推理策略的动态调整，有效提升了大语言模型在复杂推理任务中的性能。

Abstract: Large language models (LLMs) struggle with complex, long-horizon reasoning due to instability caused by their frozen policy assumption. Current test-time scaling methods treat execution feedback merely as an external signal for filtering or rewriting trajectories, without internalizing it to improve the underlying reasoning strategy. Inspired by Popper's epistemology of "conjectures and refutations," we argue that intelligence requires real-time evolution of the model's policy through learning from failed attempts. We introduce Policy of Thoughts (PoT), a framework that recasts reasoning as a within-instance online optimization process. PoT first generates diverse candidate solutions via an efficient exploration mechanism, then uses Group Relative Policy Optimization (GRPO) to update a transient LoRA adapter based on execution feedback. This closed-loop design enables dynamic, instance-specific refinement of the model's reasoning priors. Experiments show that PoT dramatically boosts performance: a 4B model achieves 49.71% accuracy on LiveCodeBench, outperforming GPT-4o and DeepSeek-V3 despite being over 50 smaller.

</details>


### [126] [CtrlCoT: Dual-Granularity Chain-of-Thought Compression for Controllable Reasoning](https://arxiv.org/abs/2601.20467)
*Zhenxuan Fan,Jie Cao,Yang Dai,Zheqi Lv,Wenqiao Zhang,Zhongle Xie,Peng LU,Beng Chin Ooi*

Main category: cs.AI

TL;DR: CtrlCoT 是一种双粒度的链式思考压缩框架，通过层次推理抽象、逻辑保真精简和分布对齐生成三个组件，提高了压缩链式思考的有效性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有的链式思考压缩方法存在保守性或过度裁剪的问题，CtrlCoT通过引入层次推理抽象、逻辑保真精简和分布对齐生成来解决这些问题，从而在保持准确性的前提下减少令牌数。

Method: CtrlCoT 包含三个组件：层次推理抽象、逻辑保真精简和分布对齐生成。层次推理抽象生成具有多个语义粒度水平的链式思考；逻辑保真精简训练一个逻辑感知裁剪器，以保留推理关键线索；分布对齐生成则确保压缩后的推理风格连贯，避免片段化。

Result: 在包含 500 个问题的 MATH 数据集上，使用 Qwen2.5-7B-Instruct 进行实验，CtrlCoT 比最强基线减少了 30.7% 的令牌数量，同时提高了 7.6 个百分点的准确率。

Conclusion: CtrlCoT 通过高效的链式思考压缩方法，展示了更有效和可靠的推理能力，为后续的研究指明了方向。

Abstract: Chain-of-thought (CoT) prompting improves LLM reasoning but incurs high latency and memory cost due to verbose traces, motivating CoT compression with preserved correctness. Existing methods either shorten CoTs at the semantic level, which is often conservative, or prune tokens aggressively, which can miss task-critical cues and degrade accuracy. Moreover, combining the two is non-trivial due to sequential dependency, task-agnostic pruning, and distribution mismatch. We propose \textbf{CtrlCoT}, a dual-granularity CoT compression framework that harmonizes semantic abstraction and token-level pruning through three components: Hierarchical Reasoning Abstraction produces CoTs at multiple semantic granularities; Logic-Preserving Distillation trains a logic-aware pruner to retain indispensable reasoning cues (e.g., numbers and operators) across pruning ratios; and Distribution-Alignment Generation aligns compressed traces with fluent inference-time reasoning styles to avoid fragmentation. On MATH-500 with Qwen2.5-7B-Instruct, CtrlCoT uses 30.7\% fewer tokens while achieving 7.6 percentage points higher than the strongest baseline, demonstrating more efficient and reliable reasoning. Our code will be publicly available at https://github.com/fanzhenxuan/Ctrl-CoT.

</details>


### [127] [PathWise: Planning through World Model for Automated Heuristic Design via Self-Evolving LLMs](https://arxiv.org/abs/2601.20539)
*Oguzhan Gungordu,Siheng Xiong,Faramarz Fekri*

Main category: cs.AI

TL;DR: PathWise 是一种多智能体推理框架，通过自进化大型语言模型（LLMs）进行自动化启发式设计。它将启发式生成视为基于演绎图的序贯决策过程，该图作为搜索轨迹的紧凑状态记忆。实验表明，PathWise 在各类组合优化问题中能更快收敛至更优启发式，并能够跨不同大模型进行泛化。


<details>
  <summary>Details</summary>
Motivation: 现有的自动化启发式设计框架依赖固定的进化规则和静态的提示模板，导致目光短浅的启发式生成、重复的评估以及有限的新启发式的推导能力。因此，需提出一种新的解决方法来改进这个问题。

Method: PathWise 利用多智能体进行启发式生成，具体包括：(1) 政策智能体规划进化动作；(2) 世界模型智能体根据这些动作生成启发式演示；(3) 批判智能体提供经过推理的反思，总结前一步骤中的教训。将 LLM 基础的自动启发式设计从试错进化的模式转向具有状态感知的推理规划，提高启发式的质量和效率。

Result: 跨多种组合优化问题的实验表明，PathWise 能够更快地收敛到更好的启发式解决方案，具有更强的跨大模型的泛化能力和处理更大问题规模的能力。

Conclusion: PathWise 框架提出了一种新的基于 LLM 的自动化启发式设计方法，通过引入多智能体推理，解决了传统方法中的短视问题、重复评估和推理限制。实验结果验证了其有效性和优越性。

Abstract: Large Language Models (LLMs) have enabled automated heuristic design (AHD) for combinatorial optimization problems (COPs), but existing frameworks' reliance on fixed evolutionary rules and static prompt templates often leads to myopic heuristic generation, redundant evaluations, and limited reasoning about how new heuristics should be derived. We propose a novel multi-agent reasoning framework, referred to as Planning through World Model for Automated Heuristic Design via Self-Evolving LLMs (PathWise), which formulates heuristic generation as a sequential decision process over an entailment graph serving as a compact, stateful memory of the search trajectory. This approach allows the system to carry forward past decisions and reuse or avoid derivation information across generations. A policy agent plans evolutionary actions, a world model agent generates heuristic rollouts conditioned on those actions, and critic agents provide routed reflections summarizing lessons from prior steps, shifting LLM-based AHD from trial-and-error evolution toward state-aware planning through reasoning. Experiments across diverse COPs show that PathWise converges faster to better heuristics, generalizes across different LLM backbones, and scales to larger problem sizes.

</details>


### [128] [Online Risk-Averse Planning in POMDPs Using Iterated CVaR Value Function](https://arxiv.org/abs/2601.20554)
*Yaacov Pariente,Vadim Indelman*

Main category: cs.AI

TL;DR: 该研究提出了在部分可观测性下使用迭代条件 Value-at-Risk (ICVaR) 的动态风险衡量进行风险敏感规划的方法，开发了ICVaR的策略评估算法，并将其应用于Sparse Sampling、PFT-DPW和POMCPOW三种在线规划算法，使它们优化ICVaR价值函数。实验表明，提出的ICVaR规划器相较于风险中性的规划器在极小风险方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 在部分可观测性和风险敏感性问题上，传统的期望值最大化策略可能无法有效处理风险偏好不同时的情况。因此，该研究引入ICVaR来作为风险敏感性的框架，以加强对风险的态度。

Method: 该研究开发了针对ICVaR的策略评估算法，并将其集成到现有的在线规划算法中，包括Sparse Sampling、PFT-DPW和POMCPOW。通过这种方法，规划算法可以考虑风险参数α，从而实现不同程度的风险偏好。

Result: 通过实验验证，使用ICVaR规划的算法能够在降低尾部风险方面优于原有的风险中性算法。

Conclusion: 该研究展示了如何将ICVaR引入在线规划算法中，以处理风险敏感性问题，并通过实验证明这一方法的有效性。

Abstract: We study risk-sensitive planning under partial observability using the dynamic risk measure Iterated Conditional Value-at-Risk (ICVaR). A policy evaluation algorithm for ICVaR is developed with finite-time performance guarantees that do not depend on the cardinality of the action space. Building on this foundation, three widely used online planning algorithms--Sparse Sampling, Particle Filter Trees with Double Progressive Widening (PFT-DPW), and Partially Observable Monte Carlo Planning with Observation Widening (POMCPOW)--are extended to optimize the ICVaR value function rather than the expectation of the return. Our formulations introduce a risk parameter $α$, where $α= 1$ recovers standard expectation-based planning and $α< 1$ induces increasing risk aversion. For ICVaR Sparse Sampling, we establish finite-time performance guarantees under the risk-sensitive objective, which further enable a novel exploration strategy tailored to ICVaR. Experiments on benchmark POMDP domains demonstrate that the proposed ICVaR planners achieve lower tail risk compared to their risk-neutral counterparts.

</details>


### [129] [Dialogical Reasoning Across AI Architectures: A Multi-Model Framework for Testing AI Alignment Strategies](https://arxiv.org/abs/2601.20604)
*Gray Cox*

Main category: cs.AI

TL;DR: 本文提出了一种方法论框架，通过结构化的多模型对话验通过利益相关者谈判、冲突转化和公共资源治理的传统，将AI对齐策略从控制问题重新定义为关系问题。实验中使用Claude、Gemini和GPT-4o模型进行72次对话，结果显示，这些模型可以在复杂对齐框架中产生有意义的交流，并生成初始框架中缺失的新兴见解。


<details>
  <summary>Details</summary>
Motivation: 鉴于AI系统的快速发展，本文旨在通过实验验证现有大型语言模型是否能够有效应用到AI对齐策略中。本文通过引入Viral Collaborative Wisdom (VCW)框架，将对齐问题从控制问题转变为关系问题，旨在促进建构性对话和协调。

Method: 实验设计将四个角色（提案者、回应者、监测者和翻译者）分配给不同的AI系统，共设置了六个条件，测试了现有大型语言模型是否能够与复杂的对齐框架进行实质性对话。实验使用Claude、Gemini和GPT-4o三种模型进行详细分析。

Result: 研究表明，AI系统可以有意义地与和平研究的概念进行互动，从不同架构的角度揭示互补的反对意见，并生成先前框架中未出现的新兴见解，包括“VCW作为过渡框架”的新合成。不同架构显示出不同的关注点：Claude强调验证挑战，Gemini关注偏见和可扩展性，GPT-4o突出实施障碍。

Conclusion: 本文框架为研究人员提供了测试对齐提案可行性的方法，同时实验成果提供了初步的证据，显示AI在进行沟通推理方面的潜力。然而，研究也指出对话更多集中在过程要素上，而非AI本质的基础主张，并为未来研究建议了人类与AI的混合协议以及扩展对话研究的方向。

Abstract: This paper introduces a methodological framework for empirically testing AI alignment strategies through structured multi-model dialogue. Drawing on Peace Studies traditions - particularly interest-based negotiation, conflict transformation, and commons governance - we operationalize Viral Collaborative Wisdom (VCW), an approach that reframes alignment from a control problem to a relationship problem developed through dialogical reasoning.
  Our experimental design assigns four distinct roles (Proposer, Responder, Monitor, Translator) to different AI systems across six conditions, testing whether current large language models can engage substantively with complex alignment frameworks. Using Claude, Gemini, and GPT-4o, we conducted 72 dialogue turns totaling 576,822 characters of structured exchange.
  Results demonstrate that AI systems can engage meaningfully with Peace Studies concepts, surface complementary objections from different architectural perspectives, and generate emergent insights not present in initial framings - including the novel synthesis of "VCW as transitional framework." Cross-architecture patterns reveal that different models foreground different concerns: Claude emphasized verification challenges, Gemini focused on bias and scalability, and GPT-4o highlighted implementation barriers.
  The framework provides researchers with replicable methods for stress-testing alignment proposals before implementation, while the findings offer preliminary evidence about AI capacity for the kind of dialogical reasoning VCW proposes. We discuss limitations, including the observation that dialogues engaged more with process elements than with foundational claims about AI nature, and outline directions for future research including human-AI hybrid protocols and extended dialogue studies.

</details>


### [130] [Harder Is Better: Boosting Mathematical Reasoning via Difficulty-Aware GRPO and Multi-Aspect Question Reformulation](https://arxiv.org/abs/2601.20614)
*Yanqi Dai,Yuxiang Ji,Xiao Zhang,Yong Wang,Xiangxiang Chu,Zhiwu Lu*

Main category: cs.AI

TL;DR: 本研究提出了一种名为MathForge的框架，旨在通过两种策略解决强化学习中数学推理能力的不足：一种是难度感知分组策略（DGPO），另一种是多方面问题重述策略（MQR）。DGPO解决了Group Relative Policy Optimization中隐含的难度平衡问题，而MQR则通过多方面重述问题以增加难度。实验结果表明，MathForge在数学推理任务上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在强化学习中处理数学推理时，存在着对难题重视不够的问题，这影响了关键能力的提升。为了改进这一不足，研究人员设计了MathForge框架。

Method: MathForge框架由两种策略组成：一、难度感知分组策略（DGPO），通过难度平衡分组优势估计来修正GRPO的隐含不平衡问题，进一步通过难度感知问题级加权来优先处理难题。二、多方面问题重述策略（MQR），通过多个角度重述问题以增加难度，同时保持原始正确答案不变。

Result: 实验表明，MathForge在各种数学推理任务上的表现显著优于现有的学习方法。

Conclusion: MathForge框架通过综合使用难度感知分组策略和多方面问题重述策略，有效提高了数学推理任务中的性能，并开放了代码和增强数据供研究者使用。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) offers a robust mechanism for enhancing mathematical reasoning in large models. However, we identify a systematic lack of emphasis on more challenging questions in existing methods from both algorithmic and data perspectives, despite their importance for refining underdeveloped capabilities. Algorithmically, widely used Group Relative Policy Optimization (GRPO) suffers from an implicit imbalance where the magnitude of policy updates is lower for harder questions. Data-wise, augmentation approaches primarily rephrase questions to enhance diversity without systematically increasing intrinsic difficulty. To address these issues, we propose a two-dual MathForge framework to improve mathematical reasoning by targeting harder questions from both perspectives, which comprises a Difficulty-Aware Group Policy Optimization (DGPO) algorithm and a Multi-Aspect Question Reformulation (MQR) strategy. Specifically, DGPO first rectifies the implicit imbalance in GRPO via difficulty-balanced group advantage estimation, and further prioritizes harder questions by difficulty-aware question-level weighting. Meanwhile, MQR reformulates questions across multiple aspects to increase difficulty while maintaining the original gold answer. Overall, MathForge forms a synergistic loop: MQR expands the data frontier, and DGPO effectively learns from the augmented data. Extensive experiments show that MathForge significantly outperforms existing methods on various mathematical reasoning tasks. The code and augmented data are all available at https://github.com/AMAP-ML/MathForge.

</details>


### [131] [Implementing Metric Temporal Answer Set Programming](https://arxiv.org/abs/2601.20735)
*Arvid Becker,Pedro Cabalar,Martin Diéguez,Susana Hahn,Javier Romero,Torsten Schaub*

Main category: cs.AI

TL;DR: 该研究开发了一种计算方法以支持Metric ASP，并利用差分约束处理时间相关的约束，从而提高算法的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 为了解决细粒度时间约束带来的ASP grounding瓶颈问题，需要一种能够在不影响时间精度的情况下处理定量时间约束的方法。

Method: 该方法通过利用ASP扩展的差分约束（简化形式的线性约束）来外部处理时间相关约束，从而实现时间精度无关的解决方案。

Result: 实验证明，该方法可以在不牺牲计算效率的情况下处理定量的时间约束，展现出良好的可扩展性。

Conclusion: 该研究提供了一种有效的方法，可以从时间细节中分离出Metric ASP的问题，以增强其处理细粒度时间约束的能力。

Abstract: We develop a computational approach to Metric Answer Set Programming (ASP) to allow for expressing quantitative temporal constraints, like durations and deadlines. A central challenge is to maintain scalability when dealing with fine-grained timing constraints, which can significantly exacerbate ASP's grounding bottleneck. To address this issue, we leverage extensions of ASP with difference constraints, a simplified form of linear constraints, to handle time-related aspects externally. Our approach effectively decouples metric ASP from the granularity of time, resulting in a solution that is unaffected by time precision.

</details>


### [132] [SokoBench: Evaluating Long-Horizon Planning and Reasoning in Large Language Models](https://arxiv.org/abs/2601.20856)
*Sebastiano Monti,Carlo Nicolini,Gianni Pellegrini,Jacopo Staiano,Bruno Lepri*

Main category: cs.AI

TL;DR: 该研究评估了先进语言模型在长视野规划和推理任务上的能力，提出了一种基于Sokoban的基准测试，并发现当需要超过25步才能解决问题时，规划性能出现下降，表明存在根本性的前向规划限制。


<details>
  <summary>Details</summary>
Motivation: 鉴于大型语言模型在复杂推理任务中的表现日益提升，但其长期规划能力尚未有充分研究，因此进行此研究以系统评估最先进的大型推理模型在长视野规划和推理任务上的表现。

Method: 研究设计了一种基于Sokoban的基准测试，简化以区分长期规划和状态保持。通过这种方式，研究团队能够考察模型在长程规划中的具体表现，并评估增强工具（如PDDL解析、验证和解决工具）的效果。

Result: 研究结果表明，当需要超过25步才能解决问题时，模型的规划性能出现明显的下降。通过使用PDDL增强工具，研究观察到了微小的性能改进，这表明模型存在固有的架构限制，仅靠测试时的扩展方法可能无法克服。

Conclusion: 研究总结指出，大型语言模型在需要长远规划的任务上存在根本性限制，而PDDL增强工具只能提供有限的帮助，未来可能需要从模型架构改进寻求突破。

Abstract: Although the capabilities of large language models have been increasingly tested on complex reasoning tasks, their long-horizon planning abilities have not yet been extensively investigated. In this work, we provide a systematic assessment of the planning and long-horizon reasoning capabilities of state-of-the-art Large Reasoning Models (LRMs). We propose a novel benchmark based on Sokoban puzzles, intentionally simplified to isolate long-horizon planning from state persistence. Our findings reveal a consistent degradation in planning performance when more than 25 moves are required to reach the solution, suggesting a fundamental constraint on forward planning capacity. We show that equipping LRMs with Planning Domain Definition Language (PDDL) parsing, validation, and solving tools allows for modest improvements, suggesting inherent architectural limitations which might not be overcome by test-time scaling approaches alone.

</details>


<div id='cs.PF'></div>

# cs.PF [[Back]](#toc)

### [133] [Colored Markov Modulated Fluid Queues](https://arxiv.org/abs/2601.20537)
*Benny Van Houdt*

Main category: cs.PF

TL;DR: 本文介绍了一种新的马尔可夫调制流体队列（MMFQ）变体，称为带颜色的MMFQ和带有流体跳跃的MMFQ，通过引入颜色机制和跳跃，这种框架增强了对具有复杂事件的队列系统的建模灵活性。


<details>
  <summary>Details</summary>
Motivation: 传统的MMFQs由于缺乏对跳跃过程的建模能力，限制了它们在处理复杂工作负载和性能相关量研究中的适用性。因此，本文提出了一种新的方法，即使用带颜色和跳跃的MMFQs，从而增强对这些复杂系统的建模能力。

Method: 本文通过扩展经典的MMFQ模型，并引入了颜色和流体跳跃的概念来定义新的MMFQ模型，这使得模型能够更加灵活地跟踪与特定事件相关的流体水平，从而解决传统模型的限制。

Result: 通过引入颜色和流体跳跃的概念，新的MMFQ模型能够处理复杂的队列系统，避免了维数问题和状态空间爆炸，为分析计算机和通信系统的性能提供了更强大的工具。

Conclusion: 本文提出的带颜色和流体跳跃的MMFQs是一种强大的建模工具，适用于分析受复杂事件影响的计算机和通信系统的性能。通过这种方式，解决了传统方法因维度或状态空间问题而导致的分析困难。

Abstract: Markov-modulated fluid queues (MMFQs) are a powerful modeling framework for analyzing the performance of computer and communication systems. Their distinguishing feature is that the underlying Markov process evolves on a continuous state space, making them well suited to capture the dynamics of workloads, energy levels, and other performance-related quantities. Although classical MMFQs do not permit jumps in the fluid level, they can still be applied to analyze a wide range of jump processes.
  In this paper, we generalize the MMFQ framework in a new direction by introducing {\bf colored MMFQs} and {\bf colored MMFQs with fluid jumps}. This enriched framework provides an additional form of memory: the color of incoming fluid can be used to keep track of the fluid level when certain events took place. This capability greatly enhances modeling flexibility and enables the analysis of queueing systems that would otherwise be intractable due to the curse of dimensionality or state-space explosion.

</details>


### [134] [The Multiserver-Job Stochastic Recurrence Equation for Cloud Computing Performance Evaluation](https://arxiv.org/abs/2601.20653)
*Francois Baccelli,Diletta Olliaro,Marco Ajmone Marsan,Andrea Marin*

Main category: cs.PF

TL;DR: 研究了具有独立一般到达和服务时间的多服务器-任务队列模型（MJQM），通过随机递归方程和遍历理论证明了单调性和可分性，引入了两种算法：一个是绘制子完美样本（SPS）的系统工作负荷，另一个是估计系统稳定性的给定任务输入流统计信息的算法。


<details>
  <summary>Details</summary>
Motivation: 探讨使用随机递归方程和遍历理论分析具有非严格一致和非独立任务队列的系统的稳定性和性能问题。

Method: 使用随机递归方程和遍历理论来研究该模型，通过单调性和可分性的证明引入了两种算法来处理系统的工作负荷及稳定性。

Result: 提出了适用于GPU并行化的子完美样本算法和稳定性估计算法，提高了性能指标评估效率。

Conclusion: 此方法不仅适用于简单的MJQM，还可扩展到更复杂的系统，例如带有类型资源的MJQM。

Abstract: We study the Multiserver-Job Queuing Model (MJQM) with general independent arrivals and service times under FCFS scheduling, using stochastic recurrence equations (SREs) and ergodic theory. We prove the monotonicity and separability properties of the MJQM SRE, enabling the application of the monotone-separable extension of Loynes' theorem and the formal definition of the MJQM stability condition. Based on these results, we introduce and implement two algorithms: one for drawing sub-perfect samples (SPS) of the system's workload and the second one to estimate the system's stability condition given the statistics of the jobs' input stream. The SPS algorithm allows for a massive GPU parallelization, greatly improving the efficiency of performance metrics evaluation. We also show that this approach extends to more complex systems, including MJQMs with typed resources.

</details>
